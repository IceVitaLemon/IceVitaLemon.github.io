<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AES加密使用256位密钥报Illegal key size or default parameters异常处理</title>
    <url>/2022/12/20/AES%E5%8A%A0%E5%AF%86%E4%BD%BF%E7%94%A8256%E4%BD%8D%E5%AF%86%E9%92%A5%E6%8A%A5Illegal-key-size-or-default-parameters%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h2 id="1-出现的现象"><a href="#1-出现的现象" class="headerlink" title="1. 出现的现象"></a>1. 出现的现象</h2><blockquote>
<p>如果报<code>Illegal key size or default parameters</code>异常，首先要确认的是自己的密钥有没有错误</p>
</blockquote>
<p>使用 javax.crypto.Cipher 包里的 AES 算法时，128 位的密钥没有任何问题，如果使用 256 位的密钥会报<code>Illegal key size or default parameters</code>异常，但是能够确认自己使用的密钥没有问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Caused by: java.security.InvalidKeyException: Illegal key size or default parameters</span><br><span class="line">    at javax.crypto.Cipher.a(DashoA13*..) ~[na:1.6]</span><br><span class="line">    at javax.crypto.Cipher.a(DashoA13*..) ~[na:1.6]</span><br><span class="line">    at javax.crypto.Cipher.a(DashoA13*..) ~[na:1.6]</span><br><span class="line">    at javax.crypto.Cipher.init(DashoA13*..) ~[na:1.6]</span><br><span class="line">    at javax.crypto.Cipher.init(DashoA13*..) ~[na:1.6]</span><br><span class="line">    at my.package.Something.decode(RC4Decoder.java:25) ~[my.package.jar:na]</span><br><span class="line">    ... 5 common frames omitted</span><br></pre></td></tr></table></figure>



<h2 id="2-出现问题的原因"><a href="#2-出现问题的原因" class="headerlink" title="2. 出现问题的原因"></a>2. 出现问题的原因</h2><p>在 Java 核心类库中，有一个 JCE（Java Cryptography Extension）扩展包，提供加密、密钥生成和协商以及 Message Authentication Code（MAC）算法的框架和实现，所以这个是实现加密解密的重要类库。</p>
<p><strong>不过呢，美国限制了 AES 256位以上加密出口，因此 Sun 公司通过权限文件（local_policy.jar, US_export_policy.jar）做了相应的限制（位于<code>$&#123;java.home&#125;/jre/lib/security/</code>文件夹中）</strong>。</p>
<h2 id="3-解决办法"><a href="#3-解决办法" class="headerlink" title="3. 解决办法"></a>3. 解决办法</h2><h3 id="3-1-Java-8u151-之前的版本"><a href="#3-1-Java-8u151-之前的版本" class="headerlink" title="3.1 Java 8u151 之前的版本"></a>3.1 Java 8u151 之前的版本</h3><p>2009年 Oracle 宣布收购 Sun 公司，提供有 Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files（即： Java加密扩展无限强度权限政策文件）。文件包含<code>local_policy.jar </code>和<code>US_export_policy.jar</code>这两个 jar 包，需要我们手动到官网中下载并且进行替换，不同 java 版本使用的文件不同。</p>
<p><strong>使用方式为：解压后替换<code>$&#123;java.home&#125;/jre/lib/security/</code>文件夹中的<code>local_policy.jar </code>和<code>US_export_policy.jar</code>两个 jar 包，并且重启 Java 程序。</strong></p>
<ul>
<li><p>JDK8，<a href="https://www.oracle.com/java/technologies/javase-jce8-downloads.html">JCE 下载地址</a></p>
</li>
<li><p>JDK7，<a href="https://www.oracle.com/java/technologies/javase-jce7-downloads.html">JCE下载地址</a></p>
</li>
<li><p>JDK6，<a href="https://www.oracle.com/java/technologies/jce-6-download.html">JCE下载地址</a></p>
</li>
</ul>
<h3 id="3-2-Java-8u151-之后的版本"><a href="#3-2-Java-8u151-之后的版本" class="headerlink" title="3.2 Java 8u151 之后的版本"></a>3.2 Java 8u151 之后的版本</h3><p>可以在程序调用 JCE 中的类方法前，调用以下方法设置为无限制的加密：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Security.setProperty(<span class="string">&quot;crypto.policy&quot;</span>, <span class="string">&quot;unlimited&quot;</span>);</span><br></pre></td></tr></table></figure>



<h3 id="3-3-Java-9、-Java-8u161、-Java-7u171和-Java-6u181之后的版本"><a href="#3-3-Java-9、-Java-8u161、-Java-7u171和-Java-6u181之后的版本" class="headerlink" title="3.3 Java 9、 Java 8u161、 Java 7u171和 Java 6u181之后的版本"></a>3.3 Java 9、 Java 8u161、 Java 7u171和 Java 6u181之后的版本</h3><p>Java 9、 Java 8u161、 Java 7u171和 Java 6u181之后的版本来说，加密的限制默认已经关闭，所以不需要其他处理就能够使用 256 位的加密密钥。</p>
<hr>
<p>参考链接</p>
<ul>
<li><p><a href="https://stackoverflow.com/questions/6481627/java-security-illegal-key-size-or-default-parameters">Java Security: Illegal key size or default parameters?</a></p>
</li>
<li><p><a href="https://blog.csdn.net/dafeige8/article/details/76019911">AES的256位密钥加解密报 java.security.InvalidKeyException: Illegal key size or default parameters 异常的处理及处理工具</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>日常踩坑</category>
      </categories>
      <tags>
        <tag>加密算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Go中的new与make</title>
    <url>/2023/04/07/Go%E4%B8%AD%E7%9A%84new%E4%B8%8Emake/</url>
    <content><![CDATA[<h3 id="Go中的数据类型"><a href="#Go中的数据类型" class="headerlink" title="Go中的数据类型"></a>Go中的数据类型</h3><p>Go 中的数据类型分两种：</p>
<ul>
<li>值类型：布尔、数字、字符串 String、数组 Array、结构体 Struct</li>
<li>引用类型：切片 Slice、字典 Map、通道 Channel、函数 Function、指针 Pointer、接口 Interface</li>
</ul>
<h3 id="图示创建切片"><a href="#图示创建切片" class="headerlink" title="图示创建切片"></a>图示创建切片</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">x := []<span class="type">int</span>&#123;<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">11</span>&#125;     <span class="comment">// 先创建了一个数组[5]int，随后创建了一个指向该数组的切片</span></span><br><span class="line">y := x[<span class="number">1</span>:<span class="number">3</span>]                <span class="comment">// 切片y与切片x使用同一个底层数组[5]int，只是窗口范围不同</span></span><br></pre></td></tr></table></figure>



<p><img src="/2023/04/07/Go%E4%B8%AD%E7%9A%84new%E4%B8%8Emake/image-20230724210253450.png" alt="image-20230724210253450"></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">a := <span class="built_in">new</span>([]<span class="type">int</span>)     <span class="comment">// 首先new([]int)创建了一个切片，但是切片没有指向任何数组，所有底层指针为nil，随后返回一个指向切片类型的指针赋值给指针a</span></span><br><span class="line">b := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">0</span>) <span class="comment">// 首先make()创建了一个切片和一个数组[0]int，并且初始化切片指针指向[0]int，返回一个切片类型赋值给变量b</span></span><br></pre></td></tr></table></figure>

<p><img src="/2023/04/07/Go%E4%B8%AD%E7%9A%84new%E4%B8%8Emake/image-20230724210636292.png" alt="image-20230724210636292"></p>
<h3 id="new-和make-的区别"><a href="#new-和make-的区别" class="headerlink" title="new()和make()的区别"></a>new()和make()的区别</h3><blockquote>
<p>看起来两者没有什么区别，都在堆上分配内存，但是它们的行为不同，适用于不同的类型。</p>
</blockquote>
<ul>
<li><p><code>new</code> 函数：</p>
<ul>
<li><code>new(T) </code>为每个新的类型 <code>T</code> 分配一片内存，初始化为 <code>0</code> 并且返回类型为 <code>*T</code> 的内存地址。返回一个指向类型 <code>T</code> ，值为 <code>0</code> 的地址的指针（所以需要赋值给指针），相当于 <code>&amp;T&#123;&#125;</code> 。</li>
<li><strong>适用于创建值类型的变量，不适用于创建引用类型的变量。</strong></li>
<li>如：<code>p := new(int)</code>。</li>
</ul>
</li>
<li><p><code>make</code> 函数：</p>
<ul>
<li><code>make(T)</code> 返回一个类型为T的初始值。</li>
<li><code>make(T, args...)</code> 用于创建引用类型的实例，并进行初始化。</li>
<li><strong>只适用于3种内建的引用类型：切片 Slice、字典 Map、通道 Channel</strong>。</li>
<li>如：<code>slice := make([]int, 5)</code> 创建一个长度为 5 的整形切片。</li>
</ul>
</li>
</ul>
<blockquote>
<ol>
<li><em>slice、map 以及 channel 都是 golang 内建的一种引用类型，三者在内存中存在多个组成部分， 需要对内存组成部分初始化后才能使用，而 make 就是对三者进行初始化的一种操作方式</em></li>
<li><em>new 获取的是存储指定变量内存地址的一个变量，对于变量内部结构并不会执行相应的初始化操作， 所以 slice、map、channel 需要 make 进行初始化并获取对应的内存地址，而非 new 简单的获取内存地址</em></li>
</ol>
</blockquote>
<hr>
<p>参考资料：</p>
<p><a href="https://github.com/unknwon/the-way-to-go_ZH_CN/blob/master/eBook/07.2.md">Go入门指南</a></p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo个人博客搭建</title>
    <url>/2022/08/17/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h3><p>最近想找个地方简单地记录下自己学习过的一些东西，但是又不想用 CSDN 这种博客平台。寻思着就自己动手搞一下，目的是搭建一个比较简单的博客记录些思路，不太过花里胡哨，清晰明了即可。</p>
<p>博客主要的框架是 Hexo + NexT + Github Pages：</p>
<ul>
<li><strong>Hexo ：</strong>一个快速、简介且高效的博客框架，使用 Markdown 解析文章生成静态页面。</li>
<li><strong>NexT ：</strong>Hexo 的一个博客主题。</li>
<li><strong>Github Pages：</strong>Github 提供的一个网页寄存服务，可以用于存放静态网页、博客或者项目文档等等，一般GitHub Pages的网站使用github.io的子域名，但是用户也可以使用第三方域名（好处是不用自己租服务器和买域名）。</li>
</ul>
<h3 id="2-环境准备"><a href="#2-环境准备" class="headerlink" title="2. 环境准备"></a>2. 环境准备</h3><h4 id="2-1-版本信息"><a href="#2-1-版本信息" class="headerlink" title="2.1 版本信息"></a>2.1 版本信息</h4><table>
<thead>
<tr>
<th align="center">软件名称</th>
<th align="center">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Node.js</td>
<td align="center">16.17.0</td>
</tr>
<tr>
<td align="center">Git</td>
<td align="center">2.24.1.windows.2</td>
</tr>
<tr>
<td align="center">Hexo</td>
<td align="center">6.3.0</td>
</tr>
<tr>
<td align="center">NexT</td>
<td align="center">8.12.3</td>
</tr>
</tbody></table>
<h4 id="2-2-软件安装"><a href="#2-2-软件安装" class="headerlink" title="2.2 软件安装"></a>2.2 软件安装</h4><h5 id="2-2-1-Node-js"><a href="#2-2-1-Node-js" class="headerlink" title="2.2.1 Node.js"></a>2.2.1 Node.js</h5><p>Node.js 是能够在服务器端运行 JavaScript 的开放源代码、跨平台执行环境。</p>
<p>到<a href="https://nodejs.org/en/">Node.js官网</a>中下载安装包安装，安装完成后，可以使用<code>node --version</code>查看 Node.js 版本信息，或者使用<code>npm --version</code>查看 npm 版本信息。</p>
<h5 id="2-2-2-Git"><a href="#2-2-2-Git" class="headerlink" title="2.2.2 Git"></a>2.2.2 Git</h5><p>Git 是一个分布式版本控制软件，本文使用 Git 是为了将生成的静态网页文件推送到 Github 仓库中。</p>
<p>到<a href="https://git-scm.com/">Git官网</a>中下载软件安装包安装，安装完成后，可以使用<code>git --version</code>查看版本信息。</p>
<h5 id="2-2-3-Hexo"><a href="#2-2-3-Hexo" class="headerlink" title="2.2.3 Hexo"></a>2.2.3 Hexo</h5><blockquote>
<p>如果自己操作，可以查看<a href="https://hexo.io/zh-cn/">官网文档</a>。</p>
</blockquote>
<p>Hexo 就是我们的博客框架。按照以下步骤操作：</p>
<ol>
<li>键盘输入<code>win + r</code>输入<code>cmd</code>点击确定打开命令行界面</li>
<li>在命令行界面输入<code>D: </code>，表示切换到电脑 D 盘</li>
<li>在命令行界面中输入<code>npm install -g hexo-cli</code>安装 Hexo</li>
<li>安装完成后，可以使用<code>hexo --version</code>查看版本信息</li>
<li>执行<code>hexo init blog</code>，初始化并新建博客文件到 blog 文件夹中</li>
<li>初始化完成之后，执行命令<code>hexo g; hexo s</code>，在浏览器中输入<code>localhost:4000</code>即可在本地访问到博客页面</li>
</ol>
<p><img src="/2022/08/17/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/image-20221219134126330.png" alt="image-20221219134126330"></p>
<h5 id="2-2-4-NexT"><a href="#2-2-4-NexT" class="headerlink" title="2.2.4 NexT"></a>2.2.4 NexT</h5><blockquote>
<p>详细的安装文档可以参考<a href="https://theme-next.js.org/docs/getting-started/">官方文档</a></p>
</blockquote>
<p>可以看到，刚安装好的 Hexo 博客框架起来了，但是外观上面还是有点不如人意的。因此需要安装 NexT 主题来变得好看一点。</p>
<p>步骤如下：</p>
<ol>
<li>执行命令<code>cd D:\blog</code>，切换到 Hexo 博客根目录 <code>D:\blog</code>中</li>
<li>执行命令<code>git clone https://github.com/iissnan/hexo-theme-next themes/next</code>，将 NexT 主题的文件下载到<code>themes/next</code>文件夹中</li>
<li>打开<code>D:\blog\_config.yml</code>中的<strong>站点配置文件</strong>，修改<code>theme: landscape</code>为<code>theme: next</code></li>
<li>执行<code>hexo g; hexo s</code>重新生成并部署网页静态文件，在浏览器中输入<code>localhost:4000</code>即可在本地访问到博客页面</li>
</ol>
<p><img src="/2022/08/17/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/image-20221219141916931.png" alt="image-20221219141916931"></p>
<h3 id="3-博客使用"><a href="#3-博客使用" class="headerlink" title="3. 博客使用"></a>3. 博客使用</h3><h4 id="3-1-常用命令"><a href="#3-1-常用命令" class="headerlink" title="3.1 常用命令"></a>3.1 常用命令</h4><blockquote>
<p>对于我们来说，主要关心的是怎么创建一篇博客文章，并且发布到网站上面去。</p>
</blockquote>
<p>常用的命令，一般有以下几条（需要切换到博客根目录中执行）：</p>
<ul>
<li><strong>hexo n “博客文章名”</strong> ：新建一篇博客文章，文件位于<code>D:\blog\source\_posts</code>中，使用 Markdown 语法进行编写</li>
<li><strong>hexo clean：</strong>清除生成的缓存文件</li>
<li><strong>hexo g：</strong>将使用 Markdown 语法编写的博客文件转换成静态 html 文件</li>
<li><strong>hexo s：</strong>在自己本机部署服务，使用<code>localhost:4000</code>即可访问页面</li>
<li><strong>hexo d：</strong>部署网页服务，通常是将生成的静态文件推送到 Github 中（需要下文配置）</li>
</ul>
<h4 id="3-2-目录结构说明"><a href="#3-2-目录结构说明" class="headerlink" title="3.2 目录结构说明"></a>3.2 目录结构说明</h4><blockquote>
<p>仅例举部分重要文件</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">D:\blog</span><br><span class="line">|-source              # 博客的源文件夹</span><br><span class="line">|   |-_posts          # 博客文章源文件所在位置</span><br><span class="line">|-themes              # 主题文件，如果使用其他的主题，主题文件也放置于这个目录中</span><br><span class="line">|   |-next            # next 主题文件</span><br><span class="line">|       |-_config.yml # 主题配置文件</span><br><span class="line">|-scaffolds           # 模板文件夹，如果想调整一个新生成的博客文章的默认内容，可以调整里面的文件的内容</span><br><span class="line">|-_config.yml         # 站点配置文件</span><br></pre></td></tr></table></figure>

<p>在我们的博客中主要有两个配置文件，分别位于：<code>D:\blog\_config.yml</code>和<code>D:\blog\themes\next\_config.yml</code>，这两个配置文件文件是不同的，需要分别修改。</p>
<ul>
<li><strong>D:\blog\_config.yml：</strong>这个文件位于博客的根目录，是 Hexo 的配置文件，一般称为<strong>站点配置文件</strong>，跟博客功能的相关配置都在这里设置。</li>
<li><strong>D:\blog\themes\next\_config.yml：</strong>这个文件位于 NexT 主题的文件夹下，一般称为<strong>主题配置文件</strong>，跟 NexT 主题外貌相关的功能都在这里设置。</li>
</ul>
<h3 id="4-博客配置"><a href="#4-博客配置" class="headerlink" title="4. 博客配置"></a>4. 博客配置</h3><h4 id="4-1-部署文件至Github-Pages并访问"><a href="#4-1-部署文件至Github-Pages并访问" class="headerlink" title="4.1 部署文件至Github Pages并访问"></a>4.1 部署文件至Github Pages并访问</h4><p>执行完了上面的操作，仅能够在本地环境中访问博客页面。如果想要在互联网上使用，还需要将网页文件部署到服务器，并且提供域名访问。不过，为了省钱好用，可以将网页文件部署到Github Pages中，Github Pages会提供一个统一格式的域名，使得我们能够在互联网上访问（但是不排除什么时候 Github 被墙了）。<strong>首先需要自己注册一个 Github 账号。</strong></p>
<h5 id="4-1-1-Github-免密登录配置"><a href="#4-1-1-Github-免密登录配置" class="headerlink" title="4.1.1 Github 免密登录配置"></a>4.1.1 Github 免密登录配置</h5><p>首先配置 Git 全局用户和全局邮箱：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global user.name &quot;Github账号&quot;</span><br><span class="line">git config --global user.email &quot;邮箱&quot;</span><br></pre></td></tr></table></figure>

<p>执行以下命令生成 SSH 密钥：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure>

<p>打开 <code>C:\Users\&#123;用户名&#125;\ssh\id_rsa.pub</code>文件，将文件内容复制并黏贴到 Github 页面的<code>setting -&gt; SSH and GPG keys -&gt; New SSH key</code>中，保存。</p>
<p><img src="/2022/08/17/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/image-20221219170146404.png" alt="image-20221219170146404"></p>
<p>可以使用以下命令测试是否配置成功：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Hi IceVitaLemon! You<span class="string">&#x27;ve successfully authenticated, but GitHub does not provide shell access.</span></span></span><br></pre></td></tr></table></figure>



<h5 id="4-1-2-创建-Github-page-仓库"><a href="#4-1-2-创建-Github-page-仓库" class="headerlink" title="4.1.2 创建 Github  page 仓库"></a>4.1.2 创建 Github  page 仓库</h5><p><strong>注意仓库名一定要以<code>&#123;用户名&#125;.github.io</code>的格式命名，并且勾选上Add a README file</strong>。</p>
<img src="image-20221219163414532.png" alt="image-20221219163414532" style="zoom:67%;" />

<h5 id="4-1-3-配置站点文件"><a href="#4-1-3-配置站点文件" class="headerlink" title="4.1.3 配置站点文件"></a>4.1.3 配置站点文件</h5><p>打开<strong>站点配置文件</strong>，修改以下属性：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">git@github.com:&#123;Github用户名&#125;/&#123;Github用户名&#125;.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>

<p><strong>之后就能够使用 <code>Hexo d</code>命令部署网页文件到 Github Pages中</strong>。</p>
<h4 id="4-2-博客站点设置"><a href="#4-2-博客站点设置" class="headerlink" title="4.2 博客站点设置"></a>4.2 博客站点设置</h4><h5 id="4-2-1-基本信息"><a href="#4-2-1-基本信息" class="headerlink" title="4.2.1 基本信息"></a>4.2.1 基本信息</h5><p>在<strong>站点配置文件</strong>中，可以博客的一些基本信息配置，比如作者、描述、语言、时区。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># D:\blog\_config.yml</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">IceVitalemon&#x27;s</span> <span class="string">Blog</span></span><br><span class="line"><span class="attr">subtitle:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">&#x27;朝花夕拾&#x27;</span></span><br><span class="line"><span class="attr">keywords:</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">Junhao</span> <span class="string">Lin</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-CN</span></span><br><span class="line"><span class="attr">timezone:</span> <span class="string">&#x27;Asia/Shanghai&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>NexT 主题提供了四种样式</strong>，分别是：Muse、Mist、Pisces、Gemini，我觉得 Muse 就已经足够了简洁好看了，因此本文主要按照 Muse 的样式来进行配置。如果想要修改为其他样式，可以在<strong>主题配置文件</strong>中，修改<code>scheme</code>字段为其他值。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># D:\blog\themes\next\_config.yml</span></span><br><span class="line"><span class="comment"># Schemes</span></span><br><span class="line"><span class="attr">scheme:</span> <span class="string">Muse</span></span><br><span class="line"><span class="comment">#scheme: Mist</span></span><br><span class="line"><span class="comment">#scheme: Pisces</span></span><br><span class="line"><span class="comment">#scheme: Gemini</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-2-生成标签、分类、归档页面"><a href="#4-2-2-生成标签、分类、归档页面" class="headerlink" title="4.2.2 生成标签、分类、归档页面"></a>4.2.2 生成标签、分类、归档页面</h5><p>首页默认页面中是没有标签、分类、归档页面的，需要自己手动生成。先在博客根目录下执行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo new page tags</span><br><span class="line">hexo new page categories</span><br><span class="line">hexo new page archives</span><br></pre></td></tr></table></figure>

<p>然后打开新创建的<code>source/tags/index.md</code>文件，修改如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">title: 标签</span><br><span class="line">date: 2018-10-19 22:57:00</span><br><span class="line">type: tags</span><br></pre></td></tr></table></figure>

<p>同理，其他两个文件<code>source/categories/index.md</code>和<code>source/archives/index.md</code>分别新增<code>type: categories</code>和<code>type: archives</code>。</p>
<p>最后，修改<strong>主题配置文件</strong>的 menu 字段：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="attr">home:</span> <span class="string">/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-home</span></span><br><span class="line">  <span class="comment">#about: /about/ || fa fa-user</span></span><br><span class="line">  <span class="attr">tags:</span> <span class="string">/tags/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-tags</span></span><br><span class="line">  <span class="attr">categories:</span> <span class="string">/categories/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-th</span></span><br><span class="line">  <span class="attr">archives:</span> <span class="string">/archives/</span> <span class="string">||</span> <span class="string">fa</span> <span class="string">fa-archive</span></span><br><span class="line">  <span class="comment">#schedule: /schedule/ || fa fa-calendar</span></span><br><span class="line">  <span class="comment">#sitemap: /sitemap.xml || fa fa-sitemap</span></span><br><span class="line">  <span class="comment">#commonweal: /404/ || fa fa-heartbeat</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-3-首页显示文章摘要"><a href="#4-2-3-首页显示文章摘要" class="headerlink" title="4.2.3 首页显示文章摘要"></a>4.2.3 首页显示文章摘要</h5><p>默认的主题配置里，首页会显示每一篇文章的全文，如果想只显示文章摘要，需要修改<strong>站点配置文件</strong>（以前有些文章是要修改 Next 的主题配置文件，但是现在 Hexo 已经自带了这个功能）：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hexo-excerpt插件</span></span><br><span class="line"><span class="attr">excerpt:</span></span><br><span class="line">  <span class="attr">depth:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">excerpt_excludes:</span> []</span><br><span class="line">  <span class="attr">more_excludes:</span> []</span><br><span class="line">  <span class="attr">hideWholePostExcerpts:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>用户也可以在文章中通过<code>&lt;!-- more --&gt;</code>标记来精确划分摘要信息，标记之前的段落将作为摘要显示在首页。</p>
<p>如果在文章的 Front-Matter 中有非空的 <code>description</code> 字段，则该字段的内容会被作为摘要显示在首页。</p>
<h5 id="4-2-4-修改站点页脚"><a href="#4-2-4-修改站点页脚" class="headerlink" title="4.2.4 修改站点页脚"></a>4.2.4 修改站点页脚</h5><p>隐藏页面底下的<code>Powered by Hexo &amp; NexT</code>，修改<strong>主题配置文件</strong>中的<code>powered</code>字段为 false：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">footer:</span></span><br><span class="line">  <span class="comment"># Specify the year when the site was setup. If not defined, current year will be used.</span></span><br><span class="line">  <span class="attr">since:</span> <span class="number">2021</span></span><br><span class="line">  <span class="comment"># Icon between year and copyright info.</span></span><br><span class="line">  <span class="attr">icon:</span></span><br><span class="line">    <span class="comment"># Icon name in Font Awesome. See: https://fontawesome.com/icons</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">fa</span> <span class="string">fa-heart</span></span><br><span class="line">    <span class="comment"># If you want to animate the icon, set it to true.</span></span><br><span class="line">    <span class="attr">animated:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Change the color of icon, using Hex Code.</span></span><br><span class="line">    <span class="attr">color:</span> <span class="string">&quot;#ff0000&quot;</span></span><br><span class="line">  <span class="comment"># If not defined, `author` from Hexo `_config.yml` will be used.</span></span><br><span class="line">  <span class="attr">copyright:</span></span><br><span class="line">  <span class="comment"># Powered by Hexo &amp; NexT</span></span><br><span class="line">  <span class="attr">powered:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-5-修改网站图标"><a href="#4-2-5-修改网站图标" class="headerlink" title="4.2.5 修改网站图标"></a>4.2.5 修改网站图标</h5><p>Favicon 即浏览器标签左侧的图标。下载自己喜欢的图标置于 <code>themes\next\source\images\</code> 目录下，命名方式参考主题配置文件中的 <code>favicon</code> 字段。这里介绍一个<a href="https://tool.lu/favicon/">在线制作 <code>favicon</code>的网站</a>，可以上传喜欢的图片制作成<code>favicon</code>。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">favicon:</span></span><br><span class="line">  <span class="attr">small:</span> <span class="string">/images/favicon-16x16-next.png</span>  <span class="comment"># 小图标</span></span><br><span class="line">  <span class="attr">medium:</span> <span class="string">/images/favicon-32x32-next.png</span>  <span class="comment"># 大图标</span></span><br><span class="line">  <span class="attr">apple_touch_icon:</span> <span class="string">/images/apple-touch-icon-next.png</span>  <span class="comment"># 苹果图标</span></span><br><span class="line">  <span class="attr">safari_pinned_tab:</span> <span class="string">/images/logo.svg</span>  <span class="comment"># safari浏览器标签页图标</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-6-添加友情-amp-社交链接"><a href="#4-2-6-添加友情-amp-社交链接" class="headerlink" title="4.2.6 添加友情&amp;社交链接"></a>4.2.6 添加友情&amp;社交链接</h5><p>分别修改主题配置文件中的<code>social</code>和<code>links_settings</code>字段。</p>
<h5 id="4-2-7-使用标签图片替代-符号"><a href="#4-2-7-使用标签图片替代-符号" class="headerlink" title="4.2.7 使用标签图片替代 # 符号"></a>4.2.7 使用标签图片替代 # 符号</h5><p>修改主题配置文件中的 <code>tag_icon</code>字段：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use icon instead of the symbol # to indicate the tag at the bottom of the post</span></span><br><span class="line"><span class="attr">tag_icon:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-8-页面加载进度条"><a href="#4-2-8-页面加载进度条" class="headerlink" title="4.2.8 页面加载进度条"></a>4.2.8 页面加载进度条</h5><p>主题配置文件中的<code>pace.enable</code>字段设置为 true：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">pace:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># All available colors:</span></span><br><span class="line">  <span class="comment"># black | blue | green | orange | pink | purple | red | silver | white | yellow</span></span><br><span class="line">  <span class="attr">color:</span> <span class="string">blue</span></span><br><span class="line">  <span class="comment"># All available themes:</span></span><br><span class="line">  <span class="comment"># big-counter | bounce | barber-shop | center-atom | center-circle | center-radar | center-simple</span></span><br><span class="line">  <span class="comment"># corner-indicator | fill-left | flat-top | flash | loading-bar | mac-osx | material | minimal</span></span><br><span class="line">  <span class="attr">theme:</span> <span class="string">minimal</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-9-英文单词前后加空格"><a href="#4-2-9-英文单词前后加空格" class="headerlink" title="4.2.9 英文单词前后加空格"></a>4.2.9 英文单词前后加空格</h5><p>英文单词与前后中文间增加空格，能够使得文章更加清晰明了，修改主题配置文件中的<code>pangu</code>字段：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Pangu Support</span></span><br><span class="line"><span class="comment"># For more information: https://github.com/vinta/pangu.js</span></span><br><span class="line"><span class="comment"># Server-side plugin: https://github.com/next-theme/hexo-pangu</span></span><br><span class="line"><span class="attr">pangu:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-10-站点及文章字数统计"><a href="#4-2-10-站点及文章字数统计" class="headerlink" title="4.2.10 站点及文章字数统计"></a>4.2.10 站点及文章字数统计</h5><p>设置主题配置文件<code>symbols_count_time</code>字段，详细设置可以参考下面的链接：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Post wordcount display settings</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/next-theme/hexo-word-counter</span></span><br><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">separated_meta:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">item_text_total:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-11-展开目录所有层级"><a href="#4-2-11-展开目录所有层级" class="headerlink" title="4.2.11 展开目录所有层级"></a>4.2.11 展开目录所有层级</h5><p>默认情况下，目录只显示最顶层，浏览的时候才会展开当前的分支。我比较喜欢展开所有的目录，可以通过主题配置文件中的<code>toc.expand_all</code>字段：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Table of Contents in the Sidebar</span></span><br><span class="line"><span class="comment"># Front-matter variable (nonsupport wrap expand_all).</span></span><br><span class="line"><span class="attr">toc:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Automatically add list number to toc.</span></span><br><span class="line">  <span class="attr">number:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># If true, all words will placed on next lines if header width longer then sidebar width.</span></span><br><span class="line">  <span class="attr">wrap:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># If true, all level of TOC in a post will be displayed, rather than the activated part of it.</span></span><br><span class="line">  <span class="attr">expand_all:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Maximum heading depth of generated toc.</span></span><br><span class="line">  <span class="attr">max_depth:</span> <span class="number">6</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-12-开启粒子漂浮聚合特效"><a href="#4-2-12-开启粒子漂浮聚合特效" class="headerlink" title="4.2.12 开启粒子漂浮聚合特效"></a>4.2.12 开启粒子漂浮聚合特效</h5><p>这个功能需要用到<a href="https://github.com/theme-next/theme-next-canvas-nest">Theme NexT Canvas Nest插件</a></p>
<ul>
<li>在博客根目录下的<code>source\_data</code>文件夹中创建文件<code>footer.njk</code>并且把填入以下内容</li>
</ul>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">color</span>=<span class="string">&quot;0,0,255&quot;</span> <span class="attr">opacity</span>=<span class="string">&quot;0.5&quot;</span> <span class="attr">zIndex</span>=<span class="string">&quot;-1&quot;</span> <span class="attr">count</span>=<span class="string">&quot;99&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/js/canvas-nest.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>创建<code>source\js\canvas-nest.js</code>文件，并且把把<a href="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js">canvas-nest.js</a>中的内容全部复制到其中保存</li>
<li>修改主题配置文件：</li>
</ul>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">custom_file_path:</span></span><br><span class="line">  <span class="attr">footer:</span> <span class="string">source/_data/footer.njk</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-13-Tab-键缩进替换"><a href="#4-2-13-Tab-键缩进替换" class="headerlink" title="4.2.13 Tab 键缩进替换"></a>4.2.13 Tab 键缩进替换</h5><p>修改站点配置文件（需要根据自己启动的是哪个代码块渲染引擎，有<code>highlight</code>和<code>prismjs</code>两种）：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">highlight:</span></span><br><span class="line">    <span class="attr">tab_replace:</span> <span class="string">&#x27;    &#x27;</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-14-添加文章搜索功能"><a href="#4-2-14-添加文章搜索功能" class="headerlink" title="4.2.14 添加文章搜索功能"></a>4.2.14 添加文章搜索功能</h5><p>修改主题配置文件：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Local Search</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/next-theme/hexo-generator-searchdb</span></span><br><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加以下字段</span></span><br><span class="line"><span class="attr">search:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">search.xml</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">post</span></span><br><span class="line">  <span class="attr">content:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">format:</span> <span class="string">html</span></span><br></pre></td></tr></table></figure>



<h4 id="4-3-开启评论功能"><a href="#4-3-开启评论功能" class="headerlink" title="4.3 开启评论功能"></a>4.3 开启评论功能</h4><blockquote>
<p>博客的评论功能有很多种实现方法，比如说 Gitalk、Gitter、Valine 等等。</p>
<p>本文选用的是 Gitalk，因为根 NexT 主题结合得比较好，外观上比较漂亮，而且不用第三方服务，托管于 Github Pages 的 issue，只要登录 Github 就能够评论。</p>
<p>缺点是初始化比较麻烦，不初始化的话会出现 “未找到相关的 Issues 进行评论，请联系xxx初始化创建” 和 “Request failed with status code 403” 的问题。</p>
</blockquote>
<h5 id="4-3-1-启用-Gitalk"><a href="#4-3-1-启用-Gitalk" class="headerlink" title="4.3.1 启用 Gitalk"></a>4.3.1 启用 Gitalk</h5><ul>
<li>注册 OAuth Apps，在Github 个人页面中的<code>Setting -&gt; Developer settings -&gt; OAtuh Apps</code>中点击<code>New OAuth App</code></li>
</ul>
<img src="image-enable-gitalk.png" alt="image-enable-gitalk" style="zoom:67%;" />

<ul>
<li>创建完成之后会得到一个<code>Client ID</code>，点击<code>Generate a new client secret</code>产生一个密钥，记住这两个值，后面配置文件中会用到</li>
<li>修改主题配置文件，填入上面获得的<code>Client ID</code>和密钥分别到<code>client_id</code>和<code>client_secret</code>中：</li>
</ul>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Multiple Comment System Support</span></span><br><span class="line"><span class="attr">comments:</span></span><br><span class="line">  <span class="comment"># Available values: tabs | buttons</span></span><br><span class="line">  <span class="attr">style:</span> <span class="string">tabs</span></span><br><span class="line">  <span class="comment"># Choose a comment system to be displayed by default.</span></span><br><span class="line">  <span class="comment"># Available values: disqus | disqusjs | changyan | livere | gitalk | utterances</span></span><br><span class="line">  <span class="attr">active:</span> <span class="string">gitalk</span></span><br><span class="line">  <span class="comment"># Setting `true` means remembering the comment system selected by the visitor.</span></span><br><span class="line">  <span class="attr">storage:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Lazyload all comment systems.</span></span><br><span class="line">  <span class="attr">lazyload:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Modify texts or order for any naves, here are some examples.</span></span><br><span class="line">  <span class="attr">nav:</span></span><br><span class="line">    <span class="comment">#disqus:</span></span><br><span class="line">    <span class="comment">#  text: Load Disqus</span></span><br><span class="line">    <span class="comment">#  order: -1</span></span><br><span class="line">    <span class="comment">#gitalk:</span></span><br><span class="line">    <span class="comment">#  order: -2</span></span><br><span class="line">    </span><br><span class="line"><span class="attr">gitalk:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">github_id:</span> <span class="string">Github用户名</span> <span class="comment"># GitHub repo owner</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">Github用户名.github.io</span> <span class="comment"># Repository name to store issues</span></span><br><span class="line">  <span class="attr">client_id:</span> <span class="string">2bac2fxxxxxxxxxx</span> <span class="comment"># GitHub Application Client ID</span></span><br><span class="line">  <span class="attr">client_secret:</span> <span class="string">cde742xxxxxxxxxxxxxxxxxxxxx</span> <span class="comment"># GitHub Application Client Secret</span></span><br><span class="line">  <span class="attr">admin_user:</span> <span class="string">Github用户名</span> <span class="comment"># GitHub repo owner and collaborators, only these guys can initialize gitHub issues</span></span><br><span class="line">  <span class="attr">distraction_free_mode:</span> <span class="literal">true</span> <span class="comment"># Facebook-like distraction free mode</span></span><br><span class="line">  <span class="comment"># When the official proxy is not available, you can change it to your own proxy address</span></span><br><span class="line">  <span class="attr">proxy:</span> <span class="string">https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token</span> <span class="comment"># This is official proxy address</span></span><br><span class="line">  <span class="comment"># Gitalk&#x27;s display language depends on user&#x27;s browser or system environment</span></span><br><span class="line">  <span class="comment"># If you want everyone visiting your site to see a uniform language, you can set a force language value</span></span><br><span class="line">  <span class="comment"># Available values: en | es-ES | fr | ru | zh-CN | zh-TW</span></span><br><span class="line">  <span class="attr">language:</span></span><br></pre></td></tr></table></figure>



<h5 id="4-3-2-Gitalk自动初始化"><a href="#4-3-2-Gitalk自动初始化" class="headerlink" title="4.3.2 Gitalk自动初始化"></a>4.3.2 Gitalk自动初始化</h5><blockquote>
<p>Gitalk 是把每一篇博客文章都关联到一个 issue 上，因此如果不自己先创建好 issue 的话，会出现“未找到相关的 Issues 进行评论，请联系xxx初始化创建” 和 “Request failed with status code 403” 的问题。</p>
<p>不过这个初始化的过程可以使用脚本代劳。</p>
</blockquote>
<p>Gitalk 自动初始化方法是通过 sitemap 中的信息，使用脚本请求 Github 的开放 API 为每篇文章产生 issue。</p>
<ul>
<li>申请 Github Token：需要使用 Personal access tokens，这种方式限制每小时 5000 次，页面路径为<code>Setting -&gt; Developer settings -&gt; Personal access tokens -&gt; Token(classic)</code>，点击<code>Generate new token</code></li>
</ul>
<p><img src="/2022/08/17/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/image-20221220091233388.png" alt="image-20221220091233388"></p>
<ul>
<li><p>设置权限：设置永不过期，允许 Token 拥有者访问提交状态、部署状态、公共仓库。</p>
<p><img src="/2022/08/17/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/image-20221220091449919.png" alt="image-20221220091449919"></p>
</li>
<li><p>安装 npm 依赖：md5、moment、request xml-parser，执行以下命令</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm i -D md5 moment request xml-parser</span><br><span class="line">npm i -S hexo-generator-sitemap</span><br></pre></td></tr></table></figure>

<ul>
<li>配置 sitemap：在博客根目录中创建<code>sitemap_template.xml</code>文件</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">urlset</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.sitemaps.org/schemas/sitemap/0.9&quot;</span>&gt;</span></span><br><span class="line">  &#123;% for post in posts %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">loc</span>&gt;</span>&#123;&#123; post.permalink | uriencode &#125;&#125;<span class="tag">&lt;/<span class="name">loc</span>&gt;</span></span><br><span class="line">    &#123;% if post.updated %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">lastmod</span>&gt;</span>&#123;&#123; post.updated.toISOString() &#125;&#125;<span class="tag">&lt;/<span class="name">lastmod</span>&gt;</span></span><br><span class="line">    &#123;% elif post.date %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">lastmod</span>&gt;</span>&#123;&#123; post.date.toISOString() &#125;&#125;<span class="tag">&lt;/<span class="name">lastmod</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">date</span>&gt;</span>&#123;&#123; post.date &#125;&#125;<span class="tag">&lt;/<span class="name">date</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>&#123;&#123; post.title + &#x27; | &#x27; + config.title &#125;&#125;<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    &#123;# nunjucks 模版语法 https://github.com/mozilla/nunjucks #&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">desc</span>&gt;</span>&#123;&#123; post.description | default(post.excerpt) | default(post.content) | default(config.description) | striptags | truncate(200, true, &#x27;&#x27;) &#125;&#125;<span class="tag">&lt;/<span class="name">desc</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">  &#123;% endfor %&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">urlset</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>修改站点配置文件：</li>
</ul>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">sitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">sitemap.xml</span></span><br><span class="line">  <span class="attr">template:</span> <span class="string">./sitemap_template.xml</span></span><br></pre></td></tr></table></figure>

<ul>
<li>生成新的<code>sitemap.xml</code>文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br></pre></td></tr></table></figure>

<ul>
<li>博客根目录中新建<code>talk-auto-init.js</code>文件，并修改配置信息，填入上文申请的 Personal access tokens 和用户信息</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">&#x27;fs&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> path = <span class="built_in">require</span>(<span class="string">&#x27;path&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> url = <span class="built_in">require</span>(<span class="string">&#x27;url&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> request = <span class="built_in">require</span>(<span class="string">&#x27;request&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> xmlParser = <span class="built_in">require</span>(<span class="string">&#x27;xml-parser&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> md5 = <span class="built_in">require</span>(<span class="string">&#x27;md5&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 配置信息</span></span><br><span class="line"><span class="keyword">const</span> config = &#123;</span><br><span class="line">  <span class="attr">username</span>: <span class="string">&#x27;&#123;Github用户名&#125;&#x27;</span>, <span class="comment">// GitHub repository 所有者，可以是个人或者组织。对应Gitalk配置中的owner</span></span><br><span class="line">  <span class="attr">repo</span>: <span class="string">&quot;&#123;Github用户名&#125;.github.io&quot;</span>, <span class="comment">// 储存评论issue的github仓库名，仅需要仓库名字即可。对应 Gitalk配置中的repo</span></span><br><span class="line">  <span class="attr">token</span>: <span class="string">&#x27;ghp_xxxxxxxxxxxxxxxxxx&#x27;</span>, <span class="comment">// 前面申请的 personal access token</span></span><br><span class="line">  <span class="attr">sitemap</span>: path.<span class="title function_">join</span>(__dirname, <span class="string">&#x27;./public/sitemap.xml&#x27;</span>), <span class="comment">// 自己站点的 sitemap 文件地址</span></span><br><span class="line">  <span class="attr">cache</span>: <span class="literal">true</span>, <span class="comment">// 是否启用缓存，启用缓存会将已经初始化的数据写入配置的 gitalkCacheFile 文件，下一次直接通过缓存文件判断</span></span><br><span class="line">  <span class="attr">gitalkCacheFile</span>: path.<span class="title function_">join</span>(__dirname, <span class="string">&#x27;./gitalk-init-cache.json&#x27;</span>), <span class="comment">// 用于保存 gitalk 已经初始化的 id 列表</span></span><br><span class="line">  <span class="attr">gitalkErrorFile</span>: path.<span class="title function_">join</span>(__dirname, <span class="string">&#x27;./gitalk-init-error.json&#x27;</span>), <span class="comment">// 用于保存 gitalk 初始化报错的数据</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> api = <span class="string">&#x27;https://api.github.com/repos/&#x27;</span> + config.<span class="property">username</span> + <span class="string">&#x27;/&#x27;</span> + config.<span class="property">repo</span> + <span class="string">&#x27;/issues&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 读取 sitemap 文件</span></span><br><span class="line"><span class="comment">* 远程 sitemap 文件获取可参考 https://www.npmjs.com/package/sitemapper</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">sitemapXmlReader</span> = (<span class="params">file</span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">const</span> data = fs.<span class="title function_">readFileSync</span>(file, <span class="string">&#x27;utf8&#x27;</span>);</span><br><span class="line">    <span class="keyword">const</span> sitemap = <span class="title function_">xmlParser</span>(data);</span><br><span class="line">    <span class="keyword">let</span> ret = [];</span><br><span class="line">    sitemap.<span class="property">root</span>.<span class="property">children</span>.<span class="title function_">forEach</span>(<span class="keyword">function</span> (<span class="params">url</span>) &#123;</span><br><span class="line">      <span class="keyword">const</span> loc = url.<span class="property">children</span>.<span class="title function_">find</span>(<span class="keyword">function</span> (<span class="params">item</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> item.<span class="property">name</span> === <span class="string">&#x27;loc&#x27;</span>;</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="keyword">if</span> (!loc) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">const</span> title = url.<span class="property">children</span>.<span class="title function_">find</span>(<span class="keyword">function</span> (<span class="params">item</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> item.<span class="property">name</span> === <span class="string">&#x27;title&#x27;</span>;</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="keyword">const</span> desc = url.<span class="property">children</span>.<span class="title function_">find</span>(<span class="keyword">function</span> (<span class="params">item</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> item.<span class="property">name</span> === <span class="string">&#x27;desc&#x27;</span>;</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="keyword">const</span> date = url.<span class="property">children</span>.<span class="title function_">find</span>(<span class="keyword">function</span> (<span class="params">item</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> item.<span class="property">name</span> === <span class="string">&#x27;date&#x27;</span>;</span><br><span class="line">      &#125;);</span><br><span class="line">      ret.<span class="title function_">push</span>(&#123;</span><br><span class="line">        <span class="attr">url</span>: loc.<span class="property">content</span>,</span><br><span class="line">        <span class="attr">title</span>: title.<span class="property">content</span>,</span><br><span class="line">        <span class="attr">desc</span>: desc.<span class="property">content</span>,</span><br><span class="line">        <span class="attr">date</span>: date.<span class="property">content</span>,</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (e) &#123;</span><br><span class="line">    <span class="keyword">return</span> [];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取 gitalk 使用的 id</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">getGitalkId</span> = (<span class="params">&#123;</span></span><br><span class="line"><span class="params">  url: u,</span></span><br><span class="line"><span class="params">  date</span></span><br><span class="line"><span class="params">&#125;</span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">const</span> link = url.<span class="title function_">parse</span>(u);</span><br><span class="line">  <span class="comment">// 链接不存在，不需要初始化</span></span><br><span class="line">  <span class="keyword">if</span> (!link || !link.<span class="property">pathname</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!date) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="title function_">md5</span>(link.<span class="property">pathname</span>);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 通过以请求判断是否已经初始化</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> &#123;<span class="type">string</span>&#125; gitalk 初始化的id</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> &#123;<span class="type">[boolean, boolean]</span>&#125; 第一个值表示是否出错，第二个值 false 表示没初始化， true 表示已经初始化</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">getIsInitByRequest</span> = (<span class="params">id</span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">const</span> options = &#123;</span><br><span class="line">    <span class="attr">headers</span>: &#123;</span><br><span class="line">      <span class="string">&#x27;Authorization&#x27;</span>: <span class="string">&#x27;token &#x27;</span> + config.<span class="property">token</span>,</span><br><span class="line">      <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">url</span>: api + <span class="string">&#x27;?labels=&#x27;</span> + id + <span class="string">&#x27;,Gitalk&#x27;</span>,</span><br><span class="line">    <span class="attr">method</span>: <span class="string">&#x27;GET&#x27;</span></span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Promise</span>(<span class="function">(<span class="params">resolve</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="title function_">request</span>(options, <span class="keyword">function</span> (<span class="params">err, response, body</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (err) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_">resolve</span>([err, <span class="literal">false</span>]);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (response.<span class="property">statusCode</span> != <span class="number">200</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_">resolve</span>([response, <span class="literal">false</span>]);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">const</span> res = <span class="title class_">JSON</span>.<span class="title function_">parse</span>(body);</span><br><span class="line">      <span class="keyword">if</span> (res.<span class="property">length</span> &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_">resolve</span>([<span class="literal">false</span>, <span class="literal">true</span>]);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="title function_">resolve</span>([<span class="literal">false</span>, <span class="literal">false</span>]);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 通过缓存判断是否已经初始化</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> &#123;<span class="type">string</span>&#125; gitalk 初始化的id</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> &#123;<span class="type">boolean</span>&#125; false 表示没初始化， true 表示已经初始化</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">const</span> getIsInitByCache = (<span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// 判断缓存文件是否存在</span></span><br><span class="line">  <span class="keyword">let</span> gitalkCache = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    gitalkCache = <span class="built_in">require</span>(config.<span class="property">gitalkCacheFile</span>);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (e) &#123;&#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">function</span> (<span class="params">id</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!gitalkCache) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (gitalkCache.<span class="title function_">find</span>(<span class="function">(<span class="params">&#123;</span></span></span><br><span class="line"><span class="params"><span class="function">        id: itemId</span></span></span><br><span class="line"><span class="params"><span class="function">      &#125;</span>) =&gt;</span> (itemId === id))) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;)();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据缓存，判断链接是否已经初始化</span></span><br><span class="line"><span class="comment">// 第一个值表示是否出错，第二个值 false 表示没初始化， true 表示已经初始化</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">idIsInit</span> = <span class="keyword">async</span> (<span class="params">id</span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">if</span> (!config.<span class="property">cache</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> <span class="title function_">getIsInitByRequest</span>(id);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 如果通过缓存查询到的数据是未初始化，则再通过请求判断是否已经初始化，防止多次初始化</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="title function_">getIsInitByCache</span>(id) === <span class="literal">false</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> <span class="title function_">getIsInitByRequest</span>(id);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> [<span class="literal">false</span>, <span class="literal">true</span>];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 初始化</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">gitalkInit</span> = (<span class="params">&#123;</span></span><br><span class="line"><span class="params">  url,</span></span><br><span class="line"><span class="params">  id,</span></span><br><span class="line"><span class="params">  title,</span></span><br><span class="line"><span class="params">  desc</span></span><br><span class="line"><span class="params">&#125;</span>) =&gt; &#123;</span><br><span class="line">  <span class="comment">//创建issue</span></span><br><span class="line">  <span class="keyword">const</span> reqBody = &#123;</span><br><span class="line">    <span class="string">&#x27;title&#x27;</span>: title,</span><br><span class="line">    <span class="string">&#x27;labels&#x27;</span>: [id, <span class="string">&#x27;Gitalk&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;body&#x27;</span>: url + <span class="string">&#x27;\r\n\r\n&#x27;</span> + desc</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> options = &#123;</span><br><span class="line">    <span class="attr">headers</span>: &#123;</span><br><span class="line">      <span class="string">&#x27;Authorization&#x27;</span>: <span class="string">&#x27;token &#x27;</span> + config.<span class="property">token</span>,</span><br><span class="line">      <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json;charset=UTF-8&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">url</span>: api,</span><br><span class="line">    <span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(reqBody),</span><br><span class="line">    <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span></span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Promise</span>(<span class="function">(<span class="params">resolve</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="title function_">request</span>(options, <span class="keyword">function</span> (<span class="params">err, response, body</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (err) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_">resolve</span>([err, <span class="literal">false</span>]);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (response.<span class="property">statusCode</span> != <span class="number">201</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="title function_">resolve</span>([response, <span class="literal">false</span>]);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="title function_">resolve</span>([<span class="literal">false</span>, <span class="literal">true</span>]);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 写入内容</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> &#123;<span class="type">string</span>&#125; fileName 文件名</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> &#123;<span class="type">string</span>&#125; content 内容</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">write</span> = <span class="keyword">async</span> (<span class="params">fileName, content, flag = <span class="string">&#x27;w+&#x27;</span></span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Promise</span>(<span class="function">(<span class="params">resolve</span>) =&gt;</span> &#123;</span><br><span class="line">    fs.<span class="title function_">open</span>(fileName, flag, <span class="keyword">function</span> (<span class="params">err, fd</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (err) &#123;</span><br><span class="line">        <span class="title function_">resolve</span>([err, <span class="literal">false</span>]);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      fs.<span class="title function_">writeFile</span>(fd, content, <span class="keyword">function</span> (<span class="params">err</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (err) &#123;</span><br><span class="line">          <span class="title function_">resolve</span>([err, <span class="literal">false</span>]);</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        fs.<span class="title function_">close</span>(fd, <span class="function">(<span class="params">err</span>) =&gt;</span> &#123;</span><br><span class="line">          <span class="keyword">if</span> (err) &#123;</span><br><span class="line">            <span class="title function_">resolve</span>([err, <span class="literal">false</span>]);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="title function_">resolve</span>([<span class="literal">false</span>, <span class="literal">true</span>]);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">init</span> = <span class="keyword">async</span> (<span class="params"></span>) =&gt; &#123;</span><br><span class="line">  <span class="keyword">const</span> urls = <span class="title function_">sitemapXmlReader</span>(config.<span class="property">sitemap</span>);</span><br><span class="line">  <span class="comment">// 报错的数据</span></span><br><span class="line">  <span class="keyword">const</span> errorData = [];</span><br><span class="line">  <span class="comment">// 已经初始化的数据</span></span><br><span class="line">  <span class="keyword">const</span> initializedData = [];</span><br><span class="line">  <span class="comment">// 成功初始化数据</span></span><br><span class="line">  <span class="keyword">const</span> successData = [];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> item <span class="keyword">of</span> urls) &#123;</span><br><span class="line">    <span class="keyword">const</span> &#123;</span><br><span class="line">      url,</span><br><span class="line">      date,</span><br><span class="line">      title,</span><br><span class="line">      desc</span><br><span class="line">    &#125; = item;</span><br><span class="line">    <span class="keyword">const</span> id = <span class="title function_">getGitalkId</span>(&#123;</span><br><span class="line">      url,</span><br><span class="line">      date</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">if</span> (!id) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`id: 生成失败 [ <span class="subst">$&#123;id&#125;</span> ] `</span>);</span><br><span class="line">      errorData.<span class="title function_">push</span>(&#123;</span><br><span class="line">        ...item,</span><br><span class="line">        <span class="attr">info</span>: <span class="string">&#x27;id 生成失败&#x27;</span>,</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> [err, res] = <span class="keyword">await</span> <span class="title function_">idIsInit</span>(id);</span><br><span class="line">    <span class="keyword">if</span> (err) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Error: 查询评论异常 [ <span class="subst">$&#123;title&#125;</span> ] , 信息：`</span>, err || <span class="string">&#x27;无&#x27;</span>);</span><br><span class="line">      errorData.<span class="title function_">push</span>(&#123;</span><br><span class="line">        ...item,</span><br><span class="line">        <span class="attr">info</span>: <span class="string">&#x27;查询评论异常&#x27;</span>,</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (res === <span class="literal">true</span>) &#123;</span><br><span class="line">      <span class="comment">// console.log(`--- Gitalk 已经初始化 --- [ $&#123;title&#125; ] `);</span></span><br><span class="line">      initializedData.<span class="title function_">push</span>(&#123;</span><br><span class="line">        id,</span><br><span class="line">        url,</span><br><span class="line">        title,</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Gitalk 初始化开始... [ <span class="subst">$&#123;title&#125;</span> ] `</span>);</span><br><span class="line">    <span class="keyword">const</span> [e, r] = <span class="keyword">await</span> <span class="title function_">gitalkInit</span>(&#123;</span><br><span class="line">      id,</span><br><span class="line">      url,</span><br><span class="line">      title,</span><br><span class="line">      desc</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">if</span> (e || !r) &#123;</span><br><span class="line">      <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Error: Gitalk 初始化异常 [ <span class="subst">$&#123;title&#125;</span> ] , 信息：`</span>, e || <span class="string">&#x27;无&#x27;</span>);</span><br><span class="line">      errorData.<span class="title function_">push</span>(&#123;</span><br><span class="line">        ...item,</span><br><span class="line">        <span class="attr">info</span>: <span class="string">&#x27;初始化异常&#x27;</span>,</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    successData.<span class="title function_">push</span>(&#123;</span><br><span class="line">      id,</span><br><span class="line">      url,</span><br><span class="line">      title,</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`Gitalk 初始化成功! [ <span class="subst">$&#123;title&#125;</span> ] - <span class="subst">$&#123;id&#125;</span>`</span>);</span><br><span class="line">    <span class="keyword">continue</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;&#x27;</span>); <span class="comment">// 空输出，用于换行</span></span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;--------- 运行结果 ---------&#x27;</span>);</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;&#x27;</span>); <span class="comment">// 空输出，用于换行</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (errorData.<span class="property">length</span> !== <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`报错数据： <span class="subst">$&#123;errorData.length&#125;</span> 条。参考文件 <span class="subst">$&#123;config.gitalkErrorFile&#125;</span>。`</span>);</span><br><span class="line">    <span class="keyword">await</span> <span class="title function_">write</span>(config.<span class="property">gitalkErrorFile</span>, <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(errorData, <span class="literal">null</span>, <span class="number">2</span>));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`本次成功： <span class="subst">$&#123;successData.length&#125;</span> 条。`</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 写入缓存</span></span><br><span class="line">  <span class="keyword">if</span> (config.<span class="property">cache</span>) &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`写入缓存： <span class="subst">$&#123;(initializedData.length + successData.length)&#125;</span> 条，已初始化 <span class="subst">$&#123;initializedData.length&#125;</span> 条，本次成功： <span class="subst">$&#123;successData.length&#125;</span> 条。参考文件 <span class="subst">$&#123;config.gitalkCacheFile&#125;</span>。`</span>);</span><br><span class="line">    <span class="keyword">await</span> <span class="title function_">write</span>(config.<span class="property">gitalkCacheFile</span>, <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(initializedData.<span class="title function_">concat</span>(successData), <span class="literal">null</span>, <span class="number">2</span>));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`已初始化： <span class="subst">$&#123;initializedData.length&#125;</span> 条。`</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="title function_">init</span>();</span><br></pre></td></tr></table></figure>

<ul>
<li>修改博客根目录中的<code>package.json</code>文件，添加执行脚本命令：</li>
</ul>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;scripts&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;talk&quot;</span><span class="punctuation">:</span> <span class="string">&quot;node gitalk-auto-init.js&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>最后就能够使用 <code>npm run talk</code>命令初始化 Gitalk，但是需要注意脚本只负责初始化 issue，并不负责部署网页文件，所以还需要自己再执行<code>hexo d</code>命令部署网页文件。</li>
</ul>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中的BIO、NIO、AIO</title>
    <url>/2022/12/05/Java%E4%B8%AD%E7%9A%84BIO%E3%80%81NIO%E3%80%81AIO/</url>
    <content><![CDATA[<h3 id="1-I-x2F-O"><a href="#1-I-x2F-O" class="headerlink" title="1. I&#x2F;O"></a>1. I&#x2F;O</h3><blockquote>
<p>Input&#x2F;Output的缩写，简单的理解为<strong>数据的输入输出</strong>，通常有网络IO、磁盘IO。而IO的类型又分为同步&#x2F;异步IO、阻塞&#x2F;非阻塞I&#x2F;O，组合成具体的IO模型。IO属于操作系统层面上的知识，Java只是在操作系统提供的系统调用上封装了操作接口。</p>
</blockquote>
<blockquote>
<p>所有的系统IO都分为两个阶段：等待就绪和操作。以网络IO举例来说，读函数，分为等待网卡可以读和真正的读；同理，写函数，分为等待网卡可以写和真正的写。</p>
<p>需要说明的是等待网卡就绪的阻塞是不使用CPU的，是在<strong>空等</strong>；而真正的读写操作的阻塞是在使用CPU的，真正的在<strong>干活</strong>，而且这个过程非常快，属于内存拷贝，带宽通常在1GB&#x2F;s级别以上，可以理解为基本不耗时。</p>
</blockquote>
<blockquote>
<p>操作系统层面上的IO模型包括</p>
<ul>
<li>同步阻塞IO</li>
<li>同步非阻塞IO</li>
<li>异步非阻塞IO</li>
<li>IO多路复用</li>
<li>信号驱动IO</li>
</ul>
</blockquote>
<p>我们通常在Java中说BIO、NIO、AIO都是在网络IO层面上的，因此处理<strong>大量网络连接、连接输入和输出数据的准备（因为数据的输入和输出需要经过网络，所以时延一定不会短）</strong>就是关键要处理的问题。</p>
<p>在Java中，JVM读写数据都需要经过操作系统内核</p>
<ul>
<li>发送数据：JVM首先要把数据发送给内核，然后内核把数据交给网卡，网卡将数据通过互联网发送至客户端。</li>
<li>接收数据：需要让内核到网卡中查看数据是否已经准备好，如果准备好，则将数据放入内核，内核将数据转交给JVM，JVM再把数据交给我们具体的应用程序；如果没有准备好，通常会被阻塞，也有通过回调方式检测就绪事件（epoll相关）。</li>
</ul>
<img src="JVM IO读写数据.png" alt="image-20221012105409202" style="zoom: 40%;" />

<img src="IO模型对比.png" alt="image-20221012144951976" style="zoom: 50%;" />



<h3 id="2-阻塞和非阻塞"><a href="#2-阻塞和非阻塞" class="headerlink" title="2. 阻塞和非阻塞"></a>2. 阻塞和非阻塞</h3><blockquote>
<p>阻塞和非阻塞的着重点在发起请求后，是否需要等待</p>
</blockquote>
<ul>
<li>阻塞：阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。</li>
<li>非阻塞：非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。</li>
</ul>
<h3 id="3-同步和异步"><a href="#3-同步和异步" class="headerlink" title="3. 同步和异步"></a>3. 同步和异步</h3><blockquote>
<p>同步和异步的着重点在两个任务之间是否需要等待</p>
</blockquote>
<ul>
<li>同步：两个同步任务相互依赖，并且一个任务必须依赖于另一任务的某种方式执行。比如在<code>A-&gt;B</code>事件模型中，需要先完成A才能执行B。换句话说，同步调用中，被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。举个例子，我要去买蛋糕和买菜，但是蛋糕还没做好，我需要等待蛋糕做好之后才能去买菜。</li>
<li>异步：两个异步的任务完全独立，一方的执行不需要等待另一方的执行。换句话说，异步调用中，调用后就返回，不需要等待结果返回，当结果返回的时候，通过回调函数或者其他方式拿着结果进行处理。举例来说，我要去买蛋糕和买菜，但是蛋糕还没做好，店主说留下地址蛋糕做好之后会送上门，那我立马就能去买菜了。</li>
</ul>
<h3 id="4-Linux中的select、poll、-epoll"><a href="#4-Linux中的select、poll、-epoll" class="headerlink" title="4. Linux中的select、poll、 epoll"></a>4. Linux中的select、poll、 epoll</h3><blockquote>
<p>select、poll、 epoll都是Linux内核提供给用户态的多路复用系统调用。进程可以通过一个系统调用函数从内核中获取多个事件。</p>
</blockquote>
<h4 id="4-1-select-x2F-poll"><a href="#4-1-select-x2F-poll" class="headerlink" title="4.1 select&#x2F;poll"></a>4.1 select&#x2F;poll</h4><p>select实现多路复用的方式是，将已连接的Socket都放到一个<strong>文件描述符集合</strong>，然后调用select函数将文件描述符集合<strong>拷贝</strong>到内核中，让内核来检查是否有网络事件产生，检测的方式很粗暴，就是通过<strong>遍历</strong>文件描述符集合的方式，当检查到有事件产生后，将此Socket标记伟可读或可写，接着再把整个文件描述符集合<strong>拷贝</strong>回用户态中，随后用户态还需要通过<strong>遍历</strong>的方法找到可读、可写或可建立连接的Socket，然后再对其处理。</p>
<p>所以，对于select这种方式，需要进行<strong>2次遍历文件描述符集合的操作</strong>，一次是在内核态中，一个是在用户态中，而且还会发生<strong>2次拷贝文件描述符集合的操作</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</p>
<p>select使用固定长度的BitsMap，表示文件描述符集合，而且BitsMap所支持的文件描述符的个数是有限的，在Linux系统中，由内核的FD_SETSIZE限制，默认最大值为<strong>1024</strong>。</p>
<p>poll不再用BitsMap来储存所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了select使用BitsMap存储文件描述符个数限制，当然还是会受到系统文件描述符的数量限制。</p>
<p>但是poll和select并没有太大的本质区别，都是使用线性结构储存进程关注的Socket集合，因此都需要遍历文件描述符集合来找到可读或可写的Socket，<strong>时间复杂度为O(n)</strong> ，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。</p>
<h4 id="4-2-epoll"><a href="#4-2-epoll" class="headerlink" title="4.2 epoll"></a>4.2 epoll</h4><p>epoll在两个方面解决select&#x2F;poll的问题</p>
<p><strong>第一点</strong>，epoll在内核里使用<strong>红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的socket通过 <strong>epoll_ctl()</strong> 函数加入到内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是O(logn)，通过维护内核中的这颗红黑树，就不需要像select&#x2F;poll每次操作时都传入整个socket集合，只需要传入一个待检测的socket，减少了内核和用户态间大量的数据拷贝和内存分配。</p>
<p><strong>第二点</strong>，epoll使用<strong>事件驱动的机制</strong>，内核里<strong>维护了一个链表来记录就绪事件</strong>，当某个socket有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用<strong>epoll_wait()</strong> 函数时，只会返回有事件发生的文件描述符，不需要像select&#x2F;poll一样遍历整个socket集合，大大提高了检测的效率。</p>
<img src="epoll.png" alt="epoll" style="zoom:70%;" />

<p>epoll的方式即使监听的Socket数量越多的时候，效率不会大幅度降低，能够同时监听Socket的数目也非常的多，上限就是系统定义的进程能够打开的最大文件描述符个数。因此epoll被称为解决C10K问题的利器。</p>
<p>epoll 支持两种事件触发模式，分别是<strong>边缘触发（edge-triggered，ET）</strong>和<strong>水平触发（level-triggered，LT）</strong>：</p>
<ul>
<li><strong>边缘触发（edge-triggered，ET）</strong>：当被监控的Socket描述符上有可读事件发生时，<strong>服务器端只会从epoll_wait中苏醒一次</strong>，即使进程没有调用read函数从内核读取数据，也依然只苏醒一次，因为我们程序要保证一次性将内核缓冲区的数据读完。</li>
<li><strong>水平触发（level-triggered，LT）</strong>：当被监控的Socket上有可读事件发生时，<strong>服务器端不断地从epoll_wait中苏醒，直到内核缓冲区数据被read函数读完才结束</strong>，目的时告诉我们有数据要读取（其实从这里就可以看出需要将数据从内核中拷贝到用户态）。</li>
</ul>
<p>如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据（需要等待接收到所有的数据），以免错失读写的机会。因此，我们会<strong>循环</strong>从文件描述符读写数据，那么如果文件描述符读写是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，<strong>边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用</strong>，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</p>
<p>一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。</p>
<p>select&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。</p>
<h3 id="5-同步阻塞（JAVA-BIO）"><a href="#5-同步阻塞（JAVA-BIO）" class="headerlink" title="5. 同步阻塞（JAVA BIO）"></a>5. 同步阻塞（JAVA BIO）</h3><blockquote>
<p>服务端实现模式为一个连接一个线程，所以当有大量连接的时候，线程数可能会超出JVM限制导致应用崩溃，当然可以使用线程池改善，限制线程池的最大线程数以限制最大连接数</p>
</blockquote>
<blockquote>
<p>在服务端视角，如果有N个客户端通讯，想要知道他们有没有发送数据过来，就需要告诉内核到网卡中查看，如果都没有数据过来，这N个线程就都被阻塞了</p>
</blockquote>
<h4 id="5-1-服务端Demo"><a href="#5-1-服务端Demo" class="headerlink" title="5.1 服务端Demo"></a>5.1 服务端Demo</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.net.ServerSocket;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BIOServer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="comment">// 可以通过替换为BIOServer::BIODemo、BIOServer::BIOThreadDemo、BIOServer::BIOThreadPoolDemo</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(BIOServer::BIODemo).start();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIODemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="comment">// serverSocket.accept()代表着去内核中取数据，如果没数据就会被阻塞</span></span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="comment">// 从socket中获取数据流</span></span><br><span class="line">                <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> socket.getInputStream();</span><br><span class="line">                <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                <span class="comment">// 读操作是同步阻塞的</span></span><br><span class="line">                inputStream.read(data);</span><br><span class="line">                <span class="comment">// 打印获取到的数据</span></span><br><span class="line">                System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                <span class="comment">// 将获取到的数据发送回客户端</span></span><br><span class="line">                <span class="type">OutputStream</span> <span class="variable">out</span> <span class="operator">=</span> socket.getOutputStream();</span><br><span class="line">                <span class="comment">// 写操作是同步阻塞的</span></span><br><span class="line">                out.write(data);</span><br><span class="line">                socket.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIOThreadDemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="keyword">final</span> <span class="type">Socket</span> <span class="variable">clientSocket</span> <span class="operator">=</span> socket;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span>&#123;</span><br><span class="line">                            <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> clientSocket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            inputStream.read(data);</span><br><span class="line"></span><br><span class="line">                            System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                            </span><br><span class="line">                            <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> clientSocket.getOutputStream();</span><br><span class="line">                            outputStream.write(data);</span><br><span class="line">                            outputStream.close();</span><br><span class="line">                        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;).start();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIOThreadPoolDemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ExecutorService</span> <span class="variable">executorService</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="keyword">final</span> <span class="type">Socket</span> <span class="variable">clientSocket</span> <span class="operator">=</span> socket;</span><br><span class="line">                executorService.submit(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span>&#123;</span><br><span class="line">                            <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> clientSocket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            inputStream.read(data);</span><br><span class="line"></span><br><span class="line">                            System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                            </span><br><span class="line">                            <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> clientSocket.getOutputStream();</span><br><span class="line">                            outputStream.write(data);</span><br><span class="line">                            outputStream.close();</span><br><span class="line">                        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-2-客户端Demo"><a href="#5-2-客户端Demo" class="headerlink" title="5.2 客户端Demo"></a>5.2 客户端Demo</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BIOClient</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Socket</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">8888</span>);</span><br><span class="line">        <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> socket.getInputStream();</span><br><span class="line">        <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> socket.getOutputStream();</span><br><span class="line">        <span class="type">DataInputStream</span> <span class="variable">dataInputStream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataInputStream</span>(inputStream);</span><br><span class="line">        <span class="type">DataOutputStream</span> <span class="variable">dataOutputStream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataOutputStream</span>(outputStream);</span><br><span class="line">        dataOutputStream.writeUTF(<span class="string">&quot;Hello world!&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">response</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">if</span>((response = dataInputStream.readUTF()) != <span class="literal">null</span>)&#123;</span><br><span class="line">            System.out.println(response);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        dataInputStream.close();</span><br><span class="line">        dataOutputStream.close();</span><br><span class="line">        socket.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="6-同步非阻塞（JAVA-NIO）"><a href="#6-同步非阻塞（JAVA-NIO）" class="headerlink" title="6. 同步非阻塞（JAVA NIO）"></a>6. 同步非阻塞（JAVA NIO）</h3><blockquote>
<p>JAVA NIO由IO多路复用实现，其中Socket主要的接收连接、读和写函数，在等待就绪阶段都是非阻塞的，真正的I&#x2F;O操作是同步阻塞的（消耗CPU但性能非常高）。</p>
</blockquote>
<p>JAVA NIO中有三个重要的概念，分别是缓冲区Buffer、通道Channel、选择器Selector：</p>
<ul>
<li><strong>缓冲区Buffer</strong>：包含一些要写入或者要读出的数据，在NIO库中，所有数据都是用缓冲区处理的。ByteBuffer、IntBuffer、CharBuffer、LongBuffer等都是其实现类。</li>
<li><strong>通道Channel</strong>：Channel是全双工的，可以通过它读取和写入数据。通道和流的不通之处就是通道是双向的，流是单向的（一个流必须是 InputStream 或者 OutputStream 的子类）。</li>
<li><strong>多路复用器Selector</strong>：多路复用器提供选择已经就绪的任务的能力，Selector 能够获取就绪的 Channel（<strong>Linux中select和poll是轮询来获取就绪的事件，但epoll实现是采用回调方式检测就绪事件，而不是轮询</strong>），如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 感知，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I&#x2F;O 操作。</li>
</ul>
<h4 id="6-1-服务端Demo"><a href="#6-1-服务端Demo" class="headerlink" title="6.1 服务端Demo"></a>6.1 服务端Demo</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SelectionKey;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.Selector;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.ServerSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NIOServer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//1、打开ServerSocketChannel,监听客户端的链接</span></span><br><span class="line">        <span class="type">ServerSocketChannel</span> <span class="variable">serverSocketChannel</span> <span class="operator">=</span> ServerSocketChannel.open();</span><br><span class="line">        <span class="comment">//2、绑定监听端口,设置backlog（默认50）:请求传入连接队列的最大长度</span></span><br><span class="line">        serverSocketChannel.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">        <span class="comment">//3、false,设置为非阻塞模式</span></span><br><span class="line">        serverSocketChannel.configureBlocking(<span class="literal">false</span>);</span><br><span class="line">        <span class="comment">//4、创建Selector, Selector是NIO的多路复用器, Selector能够获取注册在它上面就绪的通道Channel(Channel通道发生接收连接、读、写事件)</span></span><br><span class="line">        <span class="type">Selector</span> <span class="variable">selector</span> <span class="operator">=</span> Selector.open();</span><br><span class="line">        <span class="comment">//5、注册通道Channel到多路复用器Selector，并说明关注点SelectionKey.OP_ACCEPT，监听ACCEPT事件</span></span><br><span class="line">        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//6、不断轮询Selector中就绪的Channel</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)&#123;</span><br><span class="line">            <span class="comment">//7、阻塞等待，直到有就绪的Channel，能够设置超时时间</span></span><br><span class="line">            selector.select();</span><br><span class="line">            Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();</span><br><span class="line">            Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();</span><br><span class="line">            <span class="comment">//8、遍历就绪的channel</span></span><br><span class="line">            <span class="keyword">while</span> (iterator.hasNext())&#123;</span><br><span class="line">                <span class="type">SelectionKey</span> <span class="variable">key</span> <span class="operator">=</span> iterator.next();</span><br><span class="line">                <span class="comment">//9、判断Channel还是否有效</span></span><br><span class="line">                <span class="keyword">if</span> (!key.isValid())&#123;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span>(key.isAcceptable())&#123;</span><br><span class="line">                    <span class="comment">//10、Channel接收连接就绪</span></span><br><span class="line">                    <span class="comment">// 通过SelectionKey获取就绪的Channel</span></span><br><span class="line">                    <span class="type">ServerSocketChannel</span> <span class="variable">serverChannel</span> <span class="operator">=</span> (ServerSocketChannel) key.channel();</span><br><span class="line">                    <span class="comment">//11、Selector监听到有新的客户端连接，通过Channel完成TCP三次握手建立连接</span></span><br><span class="line">                    <span class="type">SocketChannel</span> <span class="variable">clientChannel</span> <span class="operator">=</span> serverChannel.accept();</span><br><span class="line">                    <span class="comment">//12、设置客户端SocketChannel为非阻塞模式</span></span><br><span class="line">                    <span class="comment">// 注意ServerSocketChannel用于服务器端接收新连接，SocketChannel用于服务器和客户端之间的连接</span></span><br><span class="line">                    clientChannel.configureBlocking(<span class="literal">false</span>);</span><br><span class="line">                    <span class="comment">//13、将客户端的SocketChannel注册到Selector中，并且监听读就绪事件</span></span><br><span class="line">                    clientChannel.register(selector, SelectionKey.OP_READ);</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isReadable())&#123;</span><br><span class="line">                    <span class="comment">//10、Channel读就绪</span></span><br><span class="line">                    <span class="comment">//11、创建缓冲区Buffer</span></span><br><span class="line">                    <span class="type">ByteBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> ByteBuffer.wrap(<span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>]);</span><br><span class="line">                    <span class="type">SocketChannel</span> <span class="variable">clientChannel</span> <span class="operator">=</span> (SocketChannel) key.channel();</span><br><span class="line">                    <span class="comment">//12、从Channel中读取数据到Buffer中</span></span><br><span class="line">                    <span class="type">int</span> <span class="variable">read</span> <span class="operator">=</span> clientChannel.read(buffer);</span><br><span class="line">                    <span class="keyword">if</span>(read == -<span class="number">1</span>)&#123;</span><br><span class="line">                        <span class="comment">// Buffer中无数据可读，关闭Channel，并且使SelectionKey失效</span></span><br><span class="line">                        key.cancel();</span><br><span class="line">                        clientChannel.close();</span><br><span class="line">                    &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 设置缓冲区的位置记录为数据的实际长度</span></span><br><span class="line">                        buffer.flip();</span><br><span class="line">                        System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(buffer.array(), StandardCharsets.UTF_8));</span><br><span class="line">                        <span class="comment">//13、通过Channel写出数据</span></span><br><span class="line">                        clientChannel.write(buffer);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                iterator.remove();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="6-2-客户端Demo"><a href="#6-2-客户端Demo" class="headerlink" title="6.2 客户端Demo"></a>6.2 客户端Demo</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NIOClient</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String[] messages = &#123;</span><br><span class="line">            <span class="string">&quot;message1 from client&quot;</span>,</span><br><span class="line">            <span class="string">&quot;message2 from client&quot;</span></span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>(<span class="type">SocketChannel</span> <span class="variable">socketChannel</span> <span class="operator">=</span> SocketChannel.open(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="number">8888</span>)))&#123;</span><br><span class="line">            <span class="keyword">for</span>(String message: messages)&#123;</span><br><span class="line">                <span class="type">ByteBuffer</span> <span class="variable">writeBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                writeBuffer.put(message.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">                writeBuffer.flip();</span><br><span class="line">                <span class="comment">// 这里写是阻塞的</span></span><br><span class="line">                socketChannel.write(writeBuffer);</span><br><span class="line"></span><br><span class="line">                <span class="type">ByteBuffer</span> <span class="variable">readBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                <span class="comment">// 这里读是阻塞的</span></span><br><span class="line">                socketChannel.read(readBuffer);</span><br><span class="line">                readBuffer.flip();</span><br><span class="line">                System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(readBuffer.array(), StandardCharsets.UTF_8));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="6-3-优化线程模型"><a href="#6-3-优化线程模型" class="headerlink" title="6.3 优化线程模型"></a>6.3 优化线程模型</h4><p>回忆BIO模型，之所以需要多线程，是因为在进行IO操作的时候，没办法知道硬件读写是否就绪，只能阻塞等待，造成大量的<strong>空等</strong>从而阻塞需要进行线程切换（<strong>浪费大量CPU资源在线程上下文切换</strong>）。而NIO通过将通道Channel注册到多路复用器Selector上，达到<strong>只有事件就绪才会执行真正的操作，减少空等的时间，提高CPU的利用率</strong>（CPU一直都在跑，没有等待），只有调用selector.select()时，没有就绪事件才会被阻塞，而这时没有事件就绪说明不需要处理，阻塞等待也是正常的。</p>
<p><strong>NIO将原来BIO的阻塞读写变成了单线程轮询事件（单Reactor单线程模型）</strong>，除了事件的轮询是阻塞的，剩余的IO操作都是纯CPU操作，没有必要开启多线程。并且由于节约线程，当连接数大的时候由线程切换带来的问题也随之解决，为海量连接提供可能。单线程处理I&#x2F;O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。<strong>但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I&#x2F;O，无疑对效率会有更大的提高。</strong></p>
<p>分析我们程序的主要功能，包括：</p>
<ul>
<li>网络IO处理，包括accept、read、write等</li>
<li>业务逻辑，通过网络获取到需要的数据之后需要对数据进行处理后返回，这里还会有其他的阻塞IO，如DB操作、RPC等</li>
</ul>
<p>根据功能的线程划分，能够将Reactor线程设计模式分为：</p>
<ul>
<li>单Reactor单线程模型</li>
<li>单Reactor多线程模型</li>
<li>主从Reactor多线程模型</li>
</ul>
<h4 id="6-4-Reactor设计模式"><a href="#6-4-Reactor设计模式" class="headerlink" title="6.4 Reactor设计模式"></a>6.4 Reactor设计模式</h4><blockquote>
<p>Reactor模型是可以处理一个或多个输入源，并通过Service Handler同步的将输入事件（Event）采用多路复用分发给相应的Request Handler（多个）处理的事件驱动模式</p>
</blockquote>
<blockquote>
<p>Reactor模型用于NIO，是一种思想，多线程的思想。其中定义了三个角色：</p>
<ul>
<li><strong>Reactor</strong>：负责监听和分配事件</li>
<li><strong>Acceptor</strong>：处理客户端到来的新连接，并分派请求到Handler链中</li>
<li><strong>Handler</strong>：执行非阻塞读写任务，完成数据读入，处理业务逻辑后，将结果写出</li>
</ul>
</blockquote>
<h5 id="6-4-1-单Reactor单线程模型"><a href="#6-4-1-单Reactor单线程模型" class="headerlink" title="6.4.1 单Reactor单线程模型"></a>6.4.1 单Reactor单线程模型</h5><blockquote>
<p>Reactor、Acceptor、Handler都在一个线程中</p>
<p>优点：模型简单，没有多线程、进程通信、竞争的问题</p>
<p>缺点：无法发挥多核CPU的性能，此外如果业务处理速度比较慢就会影响到程序的高并发性能，任何地方不可用都会导致整个通信模块的不可用</p>
<p>Redis就是这种模型，实际使用的是单线程+队列</p>
</blockquote>
<img src="单Reactor单线程.png" alt="image-20221013095437617" style="zoom:50%;" />

<h5 id="6-4-2-单Reactor多线程模型"><a href="#6-4-2-单Reactor多线程模型" class="headerlink" title="6.4.2 单Reactor多线程模型"></a>6.4.2 单Reactor多线程模型</h5><blockquote>
<p>Reactor主线程中主要负责网络IO相关的处理，包括连接的建立、数据读写，把具体的业务处理逻辑放到线程池中处理</p>
<p>优点：充分利用多核CPU的处理能力，业务阻塞不会影响通信模块</p>
<p>缺点：多线程数据共享和访问的问题，Reactor在单线程中承担所有事件的监听和相应，高并发场景下容易成为性能瓶颈</p>
</blockquote>
<img src="单Reactor多线程.png" alt="image-20221013100405912" style="zoom:53%;" />

<h5 id="6-4-3-主从Reactor多线程模型"><a href="#6-4-3-主从Reactor多线程模型" class="headerlink" title="6.4.3 主从Reactor多线程模型"></a>6.4.3 主从Reactor多线程模型</h5><blockquote>
<p>Reactor主线程中只负责连接的建立，Reactor子线程负责读写数据，在线程池完成业务处理</p>
<p><strong>对连接的处理和读写通常可以选择分开</strong>，这样对于海量连接的注册和读写就可以分发到不同的线程中进行处理，在单线程Reactor模型和单Reactor多线程模型中，虽然read()和write()都是效率比较高的非阻塞函数，但Reactor线程毕竟只占用一个CPU内核，如果面对更高的并发则无能为力。主从Reactor多线程模型就能够解决这个问题。</p>
<p>这种模型在许多项目中广泛使用，包括Nginx主从Reactor多进程模型，Memcached主从多线程，Netty主从多线程模型的支持。</p>
</blockquote>
<img src="主从Reactor多线程.png" alt="image-20221013100926483" style="zoom:52%;" />



<h3 id="7-异步非阻塞（JAVA-AIO）"><a href="#7-异步非阻塞（JAVA-AIO）" class="headerlink" title="7. 异步非阻塞（JAVA AIO）"></a>7. 异步非阻塞（JAVA AIO）</h3><blockquote>
<p>BIO和NIO对于内核来说，都是<strong>应用程序不询问我，我绝不会主动通知</strong>的方式</p>
</blockquote>
<blockquote>
<p>还记得IO操作分为两个阶段：等待就绪和实际操作。在NIO中，等待就绪阶段是不会被阻塞的，但是还是需要实际操作数据，将数据从内核态中拷贝到用户态。AIO解决的就是这个问题，当应用程序发起异步IO之后，内核会完成数据的就绪和将数据从内核态拷贝到用户态中，应用程序并不需要主动发起拷贝动作。</p>
</blockquote>
<blockquote>
<p>AIO采用<strong>订阅-通知</strong>的方式：应用程序向操作系统注册IO监听，然后继续做自己的事情。当操作系统发生IO事件，并且准备好数据后，再主动通知应用程序，触发相应的回调函数。<strong>如果发起异步读写请求，还需要传入数据缓冲区Buffer的地址（用于存放结果数据）等信息，这样内核才能自动帮我们把数据的读写工作完成。</strong></p>
</blockquote>
<blockquote>
<p>AIO也是需要操作系统支持，<strong>微软的windows系统提供了一种异步IO技术IOCP(I&#x2F;O Completion Port，I&#x2F;O完成端口)；Linux下由于没有这种异步IO技术，所以使用的是epoll对异步IO进行模拟</strong></p>
</blockquote>
<blockquote>
<p>NIO中有一个重要的概念多路复用器Selector，负责替应用查询中所有已注册的通道到操作系统中进行IO事件轮询、管理当前注册的通道集合，定位发生事件的通道等操操作；但是在Java AIO框架中，由于应用程序不是<strong>轮询</strong>方式，而是<strong>订阅-通知</strong>方式，所以不再需要Selector(选择器)了，改由channel通道直接到操作系统注册监听，让操作系统回调实际操作函数。</p>
</blockquote>
<img src="JAVA_AIO.png" alt="image-20221013142450630" style="zoom:50%;" />

<h4 id="7-1-服务器Demo"><a href="#7-1-服务器Demo" class="headerlink" title="7.1 服务器Demo"></a>7.1 服务器Demo</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.17.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.17.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousChannelGroup;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousServerSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.CompletionHandler;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.Log;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.LogFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.BasicConfigurator;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AIOServer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        BasicConfigurator.configure();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Object</span> <span class="variable">waitObject</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 对于使用的线程池技术，我一定要多说几句</span></span><br><span class="line"><span class="comment">         * 1、Executors是线程池生成工具，通过这个工具我们可以很轻松的生成“固定大小的线程池”、“调度池”、“可伸缩线程数量的池”。具体请看API Doc</span></span><br><span class="line"><span class="comment">         * 2、当然您也可以通过ThreadPoolExecutor直接生成池。</span></span><br><span class="line"><span class="comment">         * 3、这个线程池是用来得到操作系统的“IO事件通知”的，不是用来进行“得到IO数据后的业务处理的”。要进行后者的操作，您可以再使用一个池(最好不要混用)</span></span><br><span class="line"><span class="comment">         * 4、您也可以不使用线程池(不推荐)，如果决定不使用线程池，直接AsynchronousServerSocketChannel.open()就行了。</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">ExecutorService</span> <span class="variable">threadPool</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">20</span>);</span><br><span class="line">        <span class="type">AsynchronousChannelGroup</span> <span class="variable">group</span> <span class="operator">=</span> AsynchronousChannelGroup.withThreadPool(threadPool);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">AsynchronousServerSocketChannel</span> <span class="variable">serverSocket</span> <span class="operator">=</span> AsynchronousServerSocketChannel.open(group);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置要监听的端口“0.0.0.0”代表本机所有IP设备</span></span><br><span class="line">        serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">83</span>));</span><br><span class="line">        <span class="comment">//为AsynchronousServerSocketChannel注册监听，注意只是为AsynchronousServerSocketChannel通道注册监听</span></span><br><span class="line">        <span class="comment">//并不包括为 随后客户端和服务器 socketchannel通道注册的监听</span></span><br><span class="line">        serverSocket.accept(<span class="literal">null</span>, <span class="keyword">new</span> <span class="title class_">ServerSocketChannelHandle</span>(serverSocket));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//等待，以便观察现象(这个和要讲解的原理本身没有任何关系，只是为了保证守护线程不会退出)</span></span><br><span class="line">        <span class="keyword">synchronized</span>(waitObject) &#123;</span><br><span class="line">            waitObject.wait();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 这个处理器类，专门用来响应 ServerSocketChannel 的事件。</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ServerSocketChannelHandle</span> <span class="keyword">implements</span> <span class="title class_">CompletionHandler</span>&lt;AsynchronousSocketChannel, Void&gt; &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 日志</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Log</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LogFactory.getLog(ServerSocketChannelHandle.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> AsynchronousServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> serverSocketChannel</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ServerSocketChannelHandle</span><span class="params">(AsynchronousServerSocketChannel serverSocketChannel)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.serverSocketChannel = serverSocketChannel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注意，我们分别观察 this、socketChannel、attachment三个对象的id。</span></span><br><span class="line"><span class="comment">     * 来观察不同客户端连接到达时，这三个对象的变化，以说明ServerSocketChannelHandle的监听模式</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">completed</span><span class="params">(AsynchronousSocketChannel socketChannel, Void attachment)</span> &#123;</span><br><span class="line">        ServerSocketChannelHandle.LOGGER.info(<span class="string">&quot;completed(AsynchronousSocketChannel result, ByteBuffer attachment)&quot;</span>);</span><br><span class="line">        <span class="comment">//每次都要重新注册监听(一次注册，一次响应)，但是由于“文件状态标示符”是独享的，所以不需要担心有“漏掉的”事件</span></span><br><span class="line">        <span class="built_in">this</span>.serverSocketChannel.accept(attachment, <span class="built_in">this</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//为这个新的socketChannel注册“read”事件，以便操作系统在收到数据并准备好后，主动通知应用程序</span></span><br><span class="line">        <span class="comment">//在这里，由于我们要将这个客户端多次传输的数据累加起来一起处理，所以我们将一个stringbuffer对象作为一个“附件”依附在这个channel上</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="type">ByteBuffer</span> <span class="variable">readBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">50</span>);</span><br><span class="line">        socketChannel.read(readBuffer, <span class="keyword">new</span> <span class="title class_">StringBuffer</span>(), <span class="keyword">new</span> <span class="title class_">SocketChannelReadHandle</span>(socketChannel , readBuffer));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#failed(java.lang.Throwable, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">failed</span><span class="params">(Throwable exc, Void attachment)</span> &#123;</span><br><span class="line">        ServerSocketChannelHandle.LOGGER.info(<span class="string">&quot;failed(Throwable exc, ByteBuffer attachment)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 负责对每一个socketChannel的数据获取事件进行监听。&lt;p&gt;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 重要的说明: 一个socketchannel都会有一个独立工作的SocketChannelReadHandle对象(CompletionHandler接口的实现)，</span></span><br><span class="line"><span class="comment"> * 其中又都将独享一个“文件状态标示”对象FileDescriptor、</span></span><br><span class="line"><span class="comment"> * 一个独立的由程序员定义的Buffer缓存(这里我们使用的是ByteBuffer)、</span></span><br><span class="line"><span class="comment"> * 所以不用担心在服务器端会出现“窜对象”这种情况，因为JAVA AIO框架已经帮您组织好了。&lt;p&gt;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 但是最重要的，用于生成channel的对象: AsynchronousChannelProvider是单例模式，无论在哪组socketchannel，</span></span><br><span class="line"><span class="comment"> * 对是一个对象引用(但这没关系，因为您不会直接操作这个AsynchronousChannelProvider对象)。</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SocketChannelReadHandle</span> <span class="keyword">implements</span> <span class="title class_">CompletionHandler</span>&lt;Integer, StringBuffer&gt; &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 日志</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Log</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LogFactory.getLog(SocketChannelReadHandle.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> AsynchronousSocketChannel socketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 专门用于进行这个通道数据缓存操作的ByteBuffer&lt;br&gt;</span></span><br><span class="line"><span class="comment">     * 当然，您也可以作为CompletionHandler的attachment形式传入。&lt;br&gt;</span></span><br><span class="line"><span class="comment">     * 这是，在这段示例代码中，attachment被我们用来记录所有传送过来的Stringbuffer了。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> ByteBuffer byteBuffer;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SocketChannelReadHandle</span><span class="params">(AsynchronousSocketChannel socketChannel , ByteBuffer byteBuffer)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.socketChannel = socketChannel;</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer = byteBuffer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#completed(java.lang.Object, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">completed</span><span class="params">(Integer result, StringBuffer historyContext)</span> &#123;</span><br><span class="line">        <span class="comment">//如果条件成立，说明客户端主动终止了TCP套接字，这时服务端终止就可以了</span></span><br><span class="line">        <span class="keyword">if</span>(result == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="built_in">this</span>.socketChannel.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;completed(Integer result, Void attachment) : 然后我们来取出通道中准备好的值&quot;</span>);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 实际上，由于我们从Integer result知道了本次channel从操作系统获取数据总长度</span></span><br><span class="line"><span class="comment">         * 所以实际上，我们不需要切换成“读模式”的，但是为了保证编码的规范性，还是建议进行切换。</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 另外，无论是JAVA AIO框架还是JAVA NIO框架，都会出现“buffer的总容量”小于“当前从操作系统获取到的总数据量”，</span></span><br><span class="line"><span class="comment">         * 但区别是，JAVA AIO框架中，我们不需要专门考虑处理这样的情况，因为JAVA AIO框架已经帮我们做了处理(做成了多次通知)</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.flip();</span><br><span class="line">        <span class="type">byte</span>[] contexts = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.get(contexts, <span class="number">0</span>, result);</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.clear();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">nowContent</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(contexts , <span class="number">0</span> , result , <span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line">            historyContext.append(nowContent);</span><br><span class="line">            SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;================目前的传输结果: &quot;</span> + historyContext);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">            SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果条件成立，说明还没有接收到“结束标记”</span></span><br><span class="line">        <span class="keyword">if</span>(historyContext.indexOf(<span class="string">&quot;over&quot;</span>) == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//=========================================================================</span></span><br><span class="line">        <span class="comment">//          和上篇文章的代码相同，我们以“over”符号作为客户端完整信息的标记</span></span><br><span class="line">        <span class="comment">//=========================================================================</span></span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;=======收到完整信息，开始处理业务=========&quot;</span>);</span><br><span class="line">        historyContext = <span class="keyword">new</span> <span class="title class_">StringBuffer</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//还要继续监听(一次监听一次通知)</span></span><br><span class="line">        <span class="built_in">this</span>.socketChannel.read(<span class="built_in">this</span>.byteBuffer, historyContext, <span class="built_in">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#failed(java.lang.Throwable, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">failed</span><span class="params">(Throwable exc, StringBuffer historyContext)</span> &#123;</span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;=====发现客户端异常关闭，服务器将关闭TCP通道&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.socketChannel.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="7-2-Proactor设计模式"><a href="#7-2-Proactor设计模式" class="headerlink" title="7.2 Proactor设计模式"></a>7.2 Proactor设计模式</h4><blockquote>
<p>Reactor是用于非阻塞同步的设计模型，Proactor是用于异步IO的设计模型</p>
</blockquote>
<blockquote>
<p>Proactor整体上与Reactor一致，区别在于Proactor模式将所有IO操作都交给内核处理，工作线程仅仅负责业务逻辑。<strong>Proactor关注的不是就绪事件，而是完成事件，这是区分Reactor模式的关键点</strong>。</p>
<p>Proactor模型主要包括四个角色：</p>
<ul>
<li><strong>Procator Initiator</strong>：负责创建Handler和Procator，并将Procator和Handler（作为回调）都通过Asynchronous operation processor注册到内核</li>
<li><strong>Handler</strong>：执行业务流程的业务处理器</li>
<li><strong>Asynchronous operation processor</strong>：负责处理注册请求，并完成IO操作。完成IO操作后会通知Procator</li>
<li><strong>Procator</strong>：根据不同的事件类型回调不同的handler进行业务处理</li>
</ul>
</blockquote>
<img src="Proactor模型.png" alt="image-20221013172016259" style="zoom:60%;" />



<hr>
<p>参考资料：</p>
<p><a href="https://tech.meituan.com/2016/11/04/nio.html">Java NIO浅析</a></p>
<p><a href="https://developer.aliyun.com/article/726698#slide-11">JAVA中BIO、NIO、AIO的分析理解</a></p>
<p><a href="https://blog.csdn.net/zdreamLife/article/details/124222337">Java I&#x2F;O模型、BIO、Reactor线程模型基本介绍</a></p>
<p><a href="https://blog.csdn.net/u013256816/article/details/115388239">五分钟快速理解 Reactor 模型</a></p>
<p><a href="ttps://pdai.tech/md/java/io/java-io-aio.html">Java AIO - 异步IO详解</a></p>
<p><a href="https://www.zhihu.com/question/26943938">如何深刻理解Reactor和Proactor？</a></p>
<p><a href="https://www.cnblogs.com/chenssy/p/15526729.html">【死磕 NIO】— Proactor模式是什么？很牛逼吗？</a></p>
<p><a href="https://mp.weixin.qq.com/s/Qpa0qXxuIM8jrBqDaXmVNA">这次答应我，一举拿下 I&#x2F;O 多路复用！</a></p>
]]></content>
      <categories>
        <category>Java基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基于String实现同步锁</title>
    <url>/2023/02/21/Java%E5%9F%BA%E4%BA%8EString%E5%AE%9E%E7%8E%B0%E5%90%8C%E6%AD%A5%E9%94%81/</url>
    <content><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p>在分布式应用中，能够通过 Redis、Zookeeper 等组件实现分布式锁。针对一个订单号、任务 ID 进行加锁，避免其它进程或者线程操作相同的资源。</p>
<p>但是，如果项目不依赖这些组件，单进程的情况下，针对不同订单号、任务 ID 进行加锁就变得比较困难。像是 ReentrantLock 或者 CountDownLatch 这种 JUC 实现的锁，都是针对单个资源的锁，不能用于变换莫测的 String。</p>
<h2 id="2-需要考虑的问题"><a href="#2-需要考虑的问题" class="headerlink" title="2. 需要考虑的问题"></a>2. 需要考虑的问题</h2><blockquote>
<ul>
<li>基于 String 的锁字典</li>
<li>内存泄漏问题</li>
</ul>
</blockquote>
<p>我们需要做的，是根据 String 获取一把锁，来锁定该 String 代表的资源。既然不同的 String 代表着不同的锁，我们需要的是使用一个池子，来缓存 String 及其对应的锁，即 String 锁的字典。</p>
<p>这个锁字典的生命周期基本上是伴随着整个进程，因为我们使用的场景就是单个进程下根据 String  来获取锁。那么，如果大量地根据不同的 String 获取锁，就会在池子中缓存了大量的 key，value，不及时释放可能会导致内存泄漏问题。</p>
<h2 id="3-实现方法"><a href="#3-实现方法" class="headerlink" title="3. 实现方法"></a>3. 实现方法</h2><h3 id="3-1-基于-JVM-的字符串常量池"><a href="#3-1-基于-JVM-的字符串常量池" class="headerlink" title="3.1 基于 JVM 的字符串常量池"></a>3.1 基于 JVM 的字符串常量池</h3><blockquote>
<p>JVM里面有一块内存是用于储存字符串常量的，从这里面拿出来的字符串都是同一个对象。</p>
<p>但是我们自己创建的字符串是不同的对象，不在这个字符串常量池里面，而 synchronized是向对象加锁的，所以直接对字符串对象加锁，可能加到两个两个不同的对象上，就会出问题了。</p>
<p>因此可以使用 String 类的 intern() 方法，将字符串加到字符串常量池中，调用方法后，返回的是字符串常量池中的字符串对象。</p>
</blockquote>
<h4 id="3-1-1-实现"><a href="#3-1-1-实现" class="headerlink" title="3.1.1 实现"></a>3.1.1 实现</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">StringMutexLock</span> &#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">operation</span><span class="params">(String bizId)</span>&#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">lock</span> <span class="operator">=</span> bizId; <span class="comment">// 业务ID</span></span><br><span class="line">        lock = lock.intern();</span><br><span class="line">        <span class="keyword">synchronized</span> (lock)&#123;</span><br><span class="line">            <span class="comment">// 实际业务</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-1-2-存在的问题"><a href="#3-1-2-存在的问题" class="headerlink" title="3.1.2 存在的问题"></a>3.1.2 存在的问题</h4><p>这种方法问题很大，因为字符串常量池中的对象不一定会被垃圾回收器回收，因此可能会造成内存泄露的问题。</p>
<h3 id="3-2-基于-ConcurrentHashMap-和-CountDownLatch"><a href="#3-2-基于-ConcurrentHashMap-和-CountDownLatch" class="headerlink" title="3.2 基于 ConcurrentHashMap 和 CountDownLatch"></a>3.2 基于 ConcurrentHashMap 和 CountDownLatch</h3><blockquote>
<p>使用 ConcurrentHashMap 来储存 key 和对应的锁，加锁时判断 ConcurrentHashMap 是否已经存在对应的锁对象，解锁时将锁对象从 ConcurrentHashMap 中移除。</p>
</blockquote>
<h4 id="3-2-1-实现"><a href="#3-2-1-实现" class="headerlink" title="3.2.1 实现"></a>3.2.1 实现</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ConcurrentHashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.CountDownLatch;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">StringMutexLock</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ConcurrentHashMap&lt;String, CountDownLatch&gt; lockHolder = <span class="keyword">new</span> <span class="title class_">ConcurrentHashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 基于lockKey上锁，同步执行</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> lockKey</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">lock</span><span class="params">(String lockKey)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="keyword">while</span> (!tryLock(lockKey))&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                log.info(<span class="string">&quot;Get lock[&#123;&#125;] failed, waiting...&quot;</span>, lockKey);</span><br><span class="line">                blockOnLock(lockKey);</span><br><span class="line">            &#125;<span class="keyword">catch</span> (InterruptedException e)&#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">errMsg</span> <span class="operator">=</span> String.format(<span class="string">&quot;Error occur while get lock[%s]: %s&quot;</span>, lockKey, e.getMessage());</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">InterruptedException</span>(errMsg);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 基于lockKey, 释放锁, 只要调用者传入正确的lockKey, 锁就会被释放</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> lockKey</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">unlock</span><span class="params">(String lockKey)</span>&#123;</span><br><span class="line">        <span class="type">CountDownLatch</span> <span class="variable">lock</span> <span class="operator">=</span> lockHolder.remove(lockKey);</span><br><span class="line">        lock.countDown();</span><br><span class="line">        log.info(<span class="string">&quot;Release lock[&#123;&#125;] success.&quot;</span>, lockKey);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 尝试给指定字符串上锁</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> lockKey 字符串</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> true: 上锁成功  false：上锁失败</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">tryLock</span><span class="params">(String lockKey)</span>&#123;</span><br><span class="line">        <span class="comment">// 这里每次调用都会创建一个 CountDownLatch 对象，对GC不太友好</span></span><br><span class="line">        <span class="keyword">return</span> lockHolder.putIfAbsent(lockKey, <span class="keyword">new</span> <span class="title class_">CountDownLatch</span>(<span class="number">1</span>)) == <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取实际锁对象，并阻塞等待</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> lockKey</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">blockOnLock</span><span class="params">(String lockKey)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">CountDownLatch</span> <span class="variable">lock</span> <span class="operator">=</span> lockHolder.get(lockKey);</span><br><span class="line">        <span class="keyword">if</span> (lock != <span class="literal">null</span>)&#123;</span><br><span class="line">            lock.await();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-2-2-存在的问题"><a href="#3-2-2-存在的问题" class="headerlink" title="3.2.2 存在的问题"></a>3.2.2 存在的问题</h4><ul>
<li>每次调用 tryLock 都会创建一个 CountDownLatch 对象，对 GC 不太友好。</li>
<li>不会记录获取锁的线程，其他线程通过 String 获取锁对象之后，可能会误释放锁。</li>
<li>不支持的超时设置，需要主动释放锁。</li>
</ul>
<h3 id="3-3-Guava包的常量池"><a href="#3-3-Guava包的常量池" class="headerlink" title="3.3 Guava包的常量池"></a>3.3 Guava包的常量池</h3><blockquote>
<p>Google 的第三方工具包 Guava 里面提供了常量池的实现，能够创建<strong>基于弱引用的常量池</strong>，避免 GC 问题。</p>
</blockquote>
<h4 id="3-3-1-实现"><a href="#3-3-1-实现" class="headerlink" title="3.3.1 实现"></a>3.3.1 实现</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.collect.Interner;</span><br><span class="line"><span class="keyword">import</span> com.google.common.collect.Interners;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">class</span> <span class="title class_">StringMutexLock</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Interner&lt;String&gt; internPool = Interners.newWeakInterner();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">operation</span><span class="params">(String bizId)</span>&#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">lock</span> <span class="operator">=</span> internPool.intern(bizId);</span><br><span class="line">        <span class="keyword">synchronized</span> (lock)&#123;</span><br><span class="line">            <span class="comment">// 具体业务</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-3-2-存在的问题"><a href="#3-3-2-存在的问题" class="headerlink" title="3.3.2 存在的问题"></a>3.3.2 存在的问题</h4><ul>
<li>不会记录获取锁的线程，其他线程通过 String 获取锁对象之后，可能会误释放锁。</li>
<li>不支持的超时设置，需要主动释放锁。</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Keepalived部署高可用集群</title>
    <url>/2023/07/20/Keepalived%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h3><h4 id="1-1-Keepalived程序"><a href="#1-1-Keepalived程序" class="headerlink" title="1.1 Keepalived程序"></a>1.1 Keepalived程序</h4><p><a href="https://www.keepalived.org/">Keepalived</a> 通过 VRRP 协议，允许多台服务器共享一个虚拟 IP 地址（VIP）。其中一台服务器（Master服务器）被选为 VIP 的所有者，负责处理访问 VIP 的网络请求。其他服务器（BACKUP服务器）处于待命状态，当主服务器失效时，备用服务器会接管 VIP，确保 VIP 的高可用性。</p>
<ul>
<li>高可用：VIP 高可用。</li>
<li>负载均衡：支持LVS。</li>
<li>健康检查：支持对后端服务器进行健康检查。如果后端服务器出现故障或不可用，Keepalived 会自动将其从负载均衡池中移除。</li>
<li>可配置性：允许用户根据具体需求配置 VRRP 和负载均衡参数。</li>
<li>高性能：采用 C 语言编写，运行效率高，对系统资源的消耗较低。</li>
</ul>
<h4 id="1-2-VRRP协议"><a href="#1-2-VRRP协议" class="headerlink" title="1.2 VRRP协议"></a>1.2 VRRP协议</h4><blockquote>
<p> VRRP（Virtual Router Redundancy Protocol，虚拟路由器冗余协议），旨在实现多个路由器的冗余和高可用性。</p>
</blockquote>
<p>VRRP 协议中每个路由器都有各自的 IP 地址和共同的 VRID(0-255)，其中一个 VRRP 路由器通过竞选成为 MASTER，占有 VIP，对外提供路由服务，其他路由器则成为 BACKUP。MASTER 以 IP 组播（组播地址：224.0.0.18）（通过配置可以使用单播）发送 VRRP 协议包，与 BACKUP 保持心跳连接， 若 MASTER 不可用（或 BACKUP 接收不到 VRRP 协议包），则 BACKUP 通过竞选产生新的 MASTER 并继续对外提供路由服务，从而实现高可用（可能会有脑裂的情况）。</p>
<h3 id="2-Keepalived配置"><a href="#2-Keepalived配置" class="headerlink" title="2. Keepalived配置"></a>2. Keepalived配置</h3><blockquote>
<p>说实话，Keepalived的配置非常之多而且杂，如果想要一个个看，还是需要看<a href="https://www.keepalived.org/manpage.html">官方文档</a>，这里只介绍些常用的配置。</p>
</blockquote>
<blockquote>
<p>如果使用 RPM 安装 Keepalived，默认配置文件在 <code>/etc/keepalived/keepalived.conf</code>。</p>
</blockquote>
<blockquote>
<p>默认使用组播，单播查看配置 <code>unicast_peer </code>。</p>
</blockquote>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Keepalived默认配置文件</span></span><br><span class="line"><span class="comment"># 配置文件主要由4大块组成：global配置、BFD配置、VRRPD配置、LVS配置（详情见官方文档）</span></span><br><span class="line">! <span class="attribute">Configuration</span> File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">    <span class="section">notification_email</span> &#123;                <span class="comment">#报警邮件收件地址</span></span><br><span class="line">      acassen@firewall.<span class="attribute">loc</span></span><br><span class="line">      failover<span class="variable">@firewall</span>.loc</span><br><span class="line">      sysadmin<span class="variable">@firewall</span>.loc</span><br><span class="line">    &#125;</span><br><span class="line">    notification_email_from Alexandre.Cassen<span class="variable">@firewall</span>.loc    <span class="comment"># 报警邮件发送地址</span></span><br><span class="line">    smtp_server <span class="number">192.168.200.1</span>            <span class="comment"># 邮件服务器地址</span></span><br><span class="line">    smtp_connect_timeout <span class="number">30</span>                <span class="comment"># smtp超时时间</span></span><br><span class="line">    router_id LVS_DEVEL                    <span class="comment"># 标识主机的ID（默认为hostname）</span></span><br><span class="line">    vrrp_skip_check_adv_addr               <span class="comment"># 配置LVS实例是否跳过对VRRP通告报文（Advertisement）中的源IP地址的检查</span></span><br><span class="line">    vrrp_strict                            <span class="comment"># 用于控制LVS实例是否严格执行VRRP协议中的状态转换规则</span></span><br><span class="line">    vrrp_mcast_group4 <span class="number">224.0.0.18</span>        <span class="comment"># IPv4 VRRP 通告的组播地址</span></span><br><span class="line">    static_ipaddress &#123;                  <span class="comment"># 配置主机静态IP</span></span><br><span class="line">      192.168.1.1/24 <span class="attribute">dev</span> eth0 scope global</span><br><span class="line">    &#125;</span><br><span class="line">    static_routes &#123;                      <span class="comment"># 配置主机静态路由</span></span><br><span class="line">      192.168.2.0/24 <span class="attribute">via</span> <span class="number">192.168.1.100</span> dev eth0 track_group GROUP1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_sync_group &lt;STRING&gt; &#123;</span><br><span class="line">    <span class="section">group</span> &#123;                         <span class="comment"># vrrp_instance 实例名称</span></span><br><span class="line">      <span class="attribute">VI_1</span></span><br><span class="line">      <span class="comment">#VI_2</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;                <span class="comment"># 定义一个虚拟路由器（或者说是当前主机的配置）</span></span><br><span class="line">    <span class="attribute">state</span> MASTER                    <span class="comment"># MASTER|BACKUP，配置文件所在虚拟路由器上的初始状态，同一个虚拟路由器集群只能有一个MASTER</span></span><br><span class="line">    interface eth0                  <span class="comment"># VIP使用的默认物理接口</span></span><br><span class="line">    virtual_router_id <span class="number">51</span>            <span class="comment"># 1-255，虚拟路由器集群唯一标识</span></span><br><span class="line">    priority <span class="number">100</span>                    <span class="comment"># 1-254，当前主机优先级</span></span><br><span class="line">    advert_int <span class="number">1</span>                    <span class="comment"># #通告发送间隔，包含主机优先级、心跳等</span></span><br><span class="line">    nopreempt                       <span class="comment"># 定义工作模式为非抢占模式</span></span><br><span class="line">    preempt_delay                   <span class="comment"># 抢占工作模式下，节点上线后触发新选举操作的延迟时长</span></span><br><span class="line">    authentication &#123;                <span class="comment"># 用于集群认证，除了单播模式时，不建议使用</span></span><br><span class="line">      <span class="attribute">auth_type</span> PASS                <span class="comment"># 认证类型</span></span><br><span class="line">      auth_pass <span class="number">1111</span>                <span class="comment"># 密码,PASS密码最长为8位</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;             <span class="comment"># 成为MASTER时设置 VIP，类似 ip add，所以节点配置相同</span></span><br><span class="line">      192.168.200.16</span><br><span class="line">      192.168.200.18/24 <span class="attribute">dev</span> eth2 label eth2:<span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    notify_master &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]] <span class="comment"># 成为MASTER时触发的脚本</span></span><br><span class="line">    notify_backup &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]] <span class="comment"># 成为BACKUP时触发的脚本</span></span><br><span class="line">    notify_fault &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]]  <span class="comment"># 当前节点转为失败状态时触发的脚本</span></span><br><span class="line">    notify &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]]        <span class="comment"># 任何状态转变都触发的脚本</span></span><br><span class="line"></span><br><span class="line">    smtp_alert <span class="literal">true</span>                 <span class="comment"># 设定是否通过邮件告警</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下属于LVS特定的配置</span></span><br><span class="line">virtual_server <span class="number">192.168.200.16</span> <span class="number">443</span> &#123; <span class="comment"># 配置LVS集群，VIP:端口</span></span><br><span class="line">    <span class="attribute">delay_loop</span> <span class="number">6</span>                    <span class="comment"># 服务器轮询间隔，检测RS服务器的状态</span></span><br><span class="line">    lb_algo rr                      <span class="comment"># LVS的调度算法</span></span><br><span class="line">    lb_kind NAT                     <span class="comment"># LVS的集群类型</span></span><br><span class="line">    persistence_timeout <span class="number">50</span>          <span class="comment"># 是否启用长连接，默认6分钟</span></span><br><span class="line">    protocol TCP                    <span class="comment"># 协议</span></span><br><span class="line">    sorry_server &lt;IPADDR&gt; &lt;PORT&gt;    <span class="comment"># RS服务器不可用时，请求转发到sorry服务器</span></span><br><span class="line">    real_server <span class="number">192.168.201.100</span> <span class="number">443</span> &#123; <span class="comment"># RS服务器地址和服务端口</span></span><br><span class="line">      <span class="attribute">weight</span> <span class="number">1</span>                        <span class="comment"># 负载权重</span></span><br><span class="line">      SSL_GET &#123;                       <span class="comment"># 通过发送GET请求，检测RS服务器状态，有多种健康检查器：HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|DNS_CHECK|MISC_CHECK|BFD_CHECK|UDP_CHECK|PING_CHECK|FILE_CHEC</span></span><br><span class="line">        <span class="section">url</span> &#123;</span><br><span class="line">          <span class="attribute">path</span> /                    <span class="comment"># 请求的URL</span></span><br><span class="line">          digest ff20ad2481f97b1754ef3e12ecd3a9cc <span class="comment"># 对页面返回进行hash运算，并与digest对比是否一致</span></span><br><span class="line">        &#125;</span><br><span class="line">        url &#123;                       <span class="comment"># 可配置多个检查</span></span><br><span class="line">          <span class="attribute">path</span> /mrtg/</span><br><span class="line">          digest 9b3a0c85a887a256d6939da88aabd8cd</span><br><span class="line">        &#125;</span><br><span class="line">        connect_timeout <span class="number">3</span>       <span class="comment"># 连接超时时间</span></span><br><span class="line">        nb_get_retry <span class="number">3</span>          <span class="comment"># 超时重试次数</span></span><br><span class="line">        delay_before_retry <span class="number">3</span>    <span class="comment"># 超时后等待时间</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    real_server <span class="number">192.168.201.101</span> <span class="number">443</span> &#123;</span><br><span class="line">      <span class="attribute">weight</span> <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="3-Keepalived部署高可用LVS集群"><a href="#3-Keepalived部署高可用LVS集群" class="headerlink" title="3. Keepalived部署高可用LVS集群"></a>3. Keepalived部署高可用LVS集群</h3><h4 id="3-1-集群信息"><a href="#3-1-集群信息" class="headerlink" title="3.1 集群信息"></a>3.1 集群信息</h4><table>
<thead>
<tr>
<th>主机名</th>
<th>IP</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>DS01</td>
<td>172.24.0.15<br />VIP（172.24.0.159）</td>
<td>Keepalived、DS01、初始化MASTER</td>
</tr>
<tr>
<td>DS02</td>
<td>172.24.0.16<br />VIP（172.24.0.159）</td>
<td>Keepalived、DS02、初始化BACKUP</td>
</tr>
<tr>
<td>RS01</td>
<td>172.24.0.17</td>
<td>后端真实服务器1</td>
</tr>
<tr>
<td>RS02</td>
<td>172.24.0.18</td>
<td>后端真实服务器2</td>
</tr>
</tbody></table>
<h4 id="3-2-集群部署"><a href="#3-2-集群部署" class="headerlink" title="3.2 集群部署"></a>3.2 集群部署</h4><h5 id="3-2-1-DS服务器配置"><a href="#3-2-1-DS服务器配置" class="headerlink" title="3.2.1 DS服务器配置"></a>3.2.1 DS服务器配置</h5><ul>
<li>安装 Keepalived、ipvsadm</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Keepalived也可以在官网上下载源码编译后安装，官网也有详细的文档</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y keepalived ipvsadm</span></span><br></pre></td></tr></table></figure>

<ul>
<li>配置 Keepalived 配置文件<code>/etc/keepalived/keepalived.conf</code></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">    notification_email &#123;</span><br><span class="line">        root@localhost</span><br><span class="line">    &#125;</span><br><span class="line">    notification_email_from keepalived@localhost</span><br><span class="line">    smtp_server 127.0.0.1</span><br><span class="line">    smtp_connect_timeout 30</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance LVS_DEMO &#123;</span><br><span class="line">    state MASTER             # DS01设置为MASTER, DS02设置为BACKUP</span><br><span class="line">    interface eth0</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100            # DS01设置为100，DS02设置为90</span><br><span class="line">    advert_int 1</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.24.0.159</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 172.24.0.159 80 &#123;</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo rr</span><br><span class="line">    lb_kind NAT</span><br><span class="line">    protocol TCP</span><br><span class="line">    sorry_server 127.0.0.1 80</span><br><span class="line"></span><br><span class="line">    real_server 172.24.0.17 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        HTTP_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">                path /</span><br><span class="line">                status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        connect_timeout 1</span><br><span class="line">        nb_get_retry 3</span><br><span class="line">        delay_before_retry 1</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    real_server 172.24.0.18 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        HTTP_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">                path /</span><br><span class="line">                status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        connect_timeout 1</span><br><span class="line">        nb_get_retry 3</span><br><span class="line">        delay_before_retry 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>启动 Keepalived</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl start keepalived</span></span><br></pre></td></tr></table></figure>



<h5 id="3-2-2-RS服务器配置"><a href="#3-2-2-RS服务器配置" class="headerlink" title="3.2.2 RS服务器配置"></a>3.2.2 RS服务器配置</h5><ul>
<li>安装并启动 httpd</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y httpd</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">service httpd start</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">RS01 服务器执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="built_in">echo</span> RS01 &gt; /var/www/html/index.html</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://localhost</span></span><br><span class="line">RS01</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">RS02服务器执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> RS02 &gt; /var/www/html/index.html</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://localhost</span></span><br><span class="line">RS02</span><br></pre></td></tr></table></figure>



<h4 id="3-3-验证"><a href="#3-3-验证" class="headerlink" title="3.3 验证"></a>3.3 验证</h4><ul>
<li>访问集群</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">DS01上</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS01</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS01</span><br></pre></td></tr></table></figure>

<ul>
<li>检查 VIP 绑定情况</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">DS01上查看LVS规则</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ipvsadm -Ln</span></span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">RemoteAddress:Port           Forward Weight ActiveConn InActConn</span></span><br><span class="line">TCP  172.24.0.159:80 rr</span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">172.24.0.17:80               Masq    1      0          3</span>         </span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">172.24.0.18:80               Masq    1      0          4</span>  </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">DS01上查看VIP绑定（VIP绑定在eth0上）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:db:c3:81 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.24.0.15/24 brd 172.24.0.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 75532sec preferred_lft 75532sec</span><br><span class="line">    inet 172.24.0.159/32 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f816:3eff:fedb:c381/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">DS02上查看VIP绑定</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:db:c3:80 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.24.0.16/24 brd 172.24.0.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 75516sec preferred_lft 75516sec</span><br><span class="line">    inet6 fe80::f816:3eff:fedb:c380/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<ul>
<li>使 DS01 关机后查看 VIP 绑定情况</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">DS01关机，或者关闭keepalived服务</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl stop keepalived</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看DS02机器上ip绑定情况（可以看到VIP已经飘移到DS02上）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:db:c3:80 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.24.0.16/24 brd 172.24.0.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 75363sec preferred_lft 75363sec</span><br><span class="line">    inet 172.24.0.159/32 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f816:3eff:fedb:c380/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>



<h3 id="4-Keepalived部署高可用Nginx集群"><a href="#4-Keepalived部署高可用Nginx集群" class="headerlink" title="4. Keepalived部署高可用Nginx集群"></a>4. Keepalived部署高可用Nginx集群</h3><blockquote>
<p>其实大体上跟 LVS 的配置差不多，只不过 LVS 的配置能够在 Keepalived 中一起配置，而 Nginx 的配置需要在 Nginx 配置文件中单独配置。</p>
</blockquote>
<blockquote>
<p>如果想要实现更多的功能，能够通过 Keepalived 提供的脚本配置监控 Nginx，实现特定功能。</p>
</blockquote>
<h4 id="4-1-集群信息"><a href="#4-1-集群信息" class="headerlink" title="4.1 集群信息"></a>4.1 集群信息</h4><table>
<thead>
<tr>
<th>主机名</th>
<th>IP</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>Nginx01</td>
<td>172.24.0.15<br />VIP（172.24.0.159）</td>
<td>Keepalived、Nginx01、初始化MASTER</td>
</tr>
<tr>
<td>Nginx02</td>
<td>172.24.0.16<br />VIP（172.24.0.159）</td>
<td>Keepalived、Nginx02、初始化BACKUP</td>
</tr>
<tr>
<td>RS01</td>
<td>172.24.0.17</td>
<td>后端服务器1</td>
</tr>
<tr>
<td>RS02</td>
<td>172.24.0.18</td>
<td>后端服务器2</td>
</tr>
</tbody></table>
<h4 id="4-2-集群部署"><a href="#4-2-集群部署" class="headerlink" title="4.2 集群部署"></a>4.2 集群部署</h4><h5 id="4-2-1-Nginx服务器配置"><a href="#4-2-1-Nginx服务器配置" class="headerlink" title="4.2.1 Nginx服务器配置"></a>4.2.1 Nginx服务器配置</h5><ul>
<li>安装 Keepalived、ipvsadm、Nginx</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y epel-release</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y keepalived ipvsadm nginx</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Nginx配置文件<code>/etc/nginx/nginx.conf</code></li>
</ul>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="comment"># For more information on configuration, see:</span></span><br><span class="line"><span class="comment">#   * Official English Documentation: http://nginx.org/en/docs/</span></span><br><span class="line"><span class="comment">#   * Official Russian Documentation: http://nginx.org/ru/docs/</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">user</span> nginx;</span><br><span class="line"><span class="attribute">worker_processes</span> auto;</span><br><span class="line"><span class="attribute">error_log</span> /var/log/nginx/<span class="literal">error</span>.log;</span><br><span class="line"><span class="attribute">pid</span> /run/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.</span></span><br><span class="line"><span class="attribute">include</span> /usr/share/nginx/modules/<span class="regexp">*.conf</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="attribute">worker_connections</span> <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="attribute">log_format</span>  main  <span class="string">&#x27;<span class="variable">$remote_addr</span> - <span class="variable">$remote_user</span> [<span class="variable">$time_local</span>] &quot;<span class="variable">$request</span>&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;<span class="variable">$status</span> <span class="variable">$body_bytes_sent</span> &quot;<span class="variable">$http_referer</span>&quot; &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;&quot;<span class="variable">$http_user_agent</span>&quot; &quot;<span class="variable">$http_x_forwarded_for</span>&quot;&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">access_log</span>  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">sendfile</span>            <span class="literal">on</span>;</span><br><span class="line">    <span class="attribute">tcp_nopush</span>          <span class="literal">on</span>;</span><br><span class="line">    <span class="attribute">tcp_nodelay</span>         <span class="literal">on</span>;</span><br><span class="line">    <span class="attribute">keepalive_timeout</span>   <span class="number">65</span>;</span><br><span class="line">    <span class="attribute">types_hash_max_size</span> <span class="number">4096</span>;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">include</span>             /etc/nginx/mime.types;</span><br><span class="line">    <span class="attribute">default_type</span>        application/octet-stream;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 配置后端服务器组</span></span><br><span class="line">    <span class="section">upstream</span> realservice &#123;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">172.24.0.17:80</span>;</span><br><span class="line">        <span class="attribute">server</span> <span class="number">172.24.0.18:80</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load modular configuration files from the /etc/nginx/conf.d directory.</span></span><br><span class="line">    <span class="comment"># See http://nginx.org/en/docs/ngx_core_module.html#include</span></span><br><span class="line">    <span class="comment"># for more information.</span></span><br><span class="line">    <span class="attribute">include</span> /etc/nginx/conf.d/<span class="regexp">*.conf</span>;</span><br><span class="line"></span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span>       <span class="number">80</span>;</span><br><span class="line">        <span class="attribute">listen</span>       [::]:<span class="number">80</span>;</span><br><span class="line">        <span class="attribute">server_name</span>  www.test.com;</span><br><span class="line"></span><br><span class="line">        <span class="section">location</span> / &#123;</span><br><span class="line">            <span class="attribute">proxy_pass</span> http://realservice;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">error_page</span> <span class="number">404</span> /<span class="number">404</span>.html;</span><br><span class="line">            <span class="section">location</span> = /<span class="number">404</span>.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="attribute">error_page</span> <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span> /50x.html;</span><br><span class="line">            <span class="section">location</span> = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>配置 Keepalived 配置文件<code>/etc/keepalived/keepalived.conf</code></li>
</ul>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">global_defs</span> &#123;</span><br><span class="line">    <span class="section">notification_email</span> &#123;</span><br><span class="line">        root@<span class="attribute">localhost</span></span><br><span class="line">    &#125;</span><br><span class="line">    notification_email_from keepalived<span class="variable">@localhost</span></span><br><span class="line">    smtp_server <span class="number">127.0.0.1</span></span><br><span class="line">    smtp_connect_timeout <span class="number">30</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script check_nginx &#123;    <span class="comment"># 定义检测脚本</span></span><br><span class="line">    <span class="attribute">script</span> <span class="string">&quot;curl localhost&quot;</span> <span class="comment"># 脚本路径，或者需要执行的命令</span></span><br><span class="line">    interval <span class="number">1</span>                <span class="comment"># 检测间隔</span></span><br><span class="line">    weight  -<span class="number">12</span>                <span class="comment"># weight &gt; 0 且脚本执行成功返回值为 0 时，,则实例 priority = priority + weight；</span></span><br><span class="line">                            <span class="comment"># weight &lt; 0 且脚本执行成功返回值不为 0 时，,则实例 priority = priority - weight；</span></span><br><span class="line">    rise <span class="number">1</span>                    <span class="comment"># 检测几次判定为成功</span></span><br><span class="line">    fall <span class="number">2</span>                    <span class="comment"># 检测几次判定为失败</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance NGINX_DEMO &#123;</span><br><span class="line">    <span class="attribute">state</span> MASTER             <span class="comment"># Nginx01设置为MASTER, Nginx02设置为BACKUP</span></span><br><span class="line">    interface eth0</span><br><span class="line">    virtual_router_id <span class="number">51</span></span><br><span class="line">    priority <span class="number">100</span>            <span class="comment"># Nginx01设置为100，Nginx02设置为90</span></span><br><span class="line">    advert_int <span class="number">1</span></span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.24.0.159</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="section">track_script</span> &#123;</span><br><span class="line">        <span class="attribute">check_nginx</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>启动 Nginx 服务，Keepalived 服务</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl start nginx</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl start keepalived</span></span><br></pre></td></tr></table></figure>



<h5 id="4-2-2-后端服务器配置"><a href="#4-2-2-后端服务器配置" class="headerlink" title="4.2.2 后端服务器配置"></a>4.2.2 后端服务器配置</h5><ul>
<li>安装并启动 httpd</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y httpd</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">service httpd start</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">RS01 服务器执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="built_in">echo</span> RS01 &gt; /var/www/html/index.html</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://localhost</span></span><br><span class="line">RS01</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">RS02服务器执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> RS02 &gt; /var/www/html/index.html</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://localhost</span></span><br><span class="line">RS02</span><br></pre></td></tr></table></figure>



<h4 id="4-3-验证"><a href="#4-3-验证" class="headerlink" title="4.3 验证"></a>4.3 验证</h4><ul>
<li>在 Nginx01 上访问集群</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS01</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl http://172.24.0.159</span></span><br><span class="line">RS01</span><br></pre></td></tr></table></figure>

<ul>
<li>检查 VIP 绑定情况</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Nginx01</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:db:c3:2f brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.24.0.15/24 brd 172.24.0.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 81004sec preferred_lft 81004sec</span><br><span class="line">    inet 172.24.0.159/32 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f816:3eff:fedb:c32f/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Nginx02</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:db:c3:56 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.24.0.16/24 brd 172.24.0.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 80973sec preferred_lft 80973sec</span><br><span class="line">    inet6 fe80::f816:3eff:fedb:c356/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<ul>
<li>停止 Nginx01 的 Nginx服务</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Nginx01 上执行，两秒后检查 VIP 绑定情况(因为Keepalived默认时抢占模式，当Nginx01上的Nginx服务重新起来之后，会抢占VIP,重新成为 MASTER)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl stop nginx</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip addr</span></span><br><span class="line">ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:db:c3:2f brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.24.0.15/24 brd 172.24.0.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 80865sec preferred_lft 80865sec</span><br><span class="line">    inet6 fe80::f816:3eff:fedb:c32f/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查 Nginx01 VIP绑定情况</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether fa:16:3e:db:c3:56 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.24.0.16/24 brd 172.24.0.255 scope global noprefixroute dynamic eth0</span><br><span class="line">       valid_lft 80840sec preferred_lft 80840sec</span><br><span class="line">    inet 172.24.0.159/32 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f816:3eff:fedb:c356/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>



<h3 id="5-关于Keepalived的抢占模式"><a href="#5-关于Keepalived的抢占模式" class="headerlink" title="5. 关于Keepalived的抢占模式"></a>5. 关于Keepalived的抢占模式</h3><p>通常情况下，利用 Keepalived 做热备，其中一台为 Master，一台设置为 Backup。当 Master 出现异常后，Backup会自动切换为 Master。但是，当原 Master 恢复正常后，会再次抢占成为 Master，导致不必要的主备切换，影响业务。</p>
<p>Keepalived 实例中，能够通过参数 <code>nopreempt</code> 配置为非抢占模式。通常设置 Master 为非抢占模式，Backup 为抢占模式。</p>
<blockquote>
<p>考虑以下情况：</p>
<p>实例 A 为 Master，设置了 <code>nopreempt</code> ；实例 B 为 Backup，没有设置 <code>nopreempt</code>。</p>
<p>突然，实例 A 业务上出现了问题，因此优先级降低，实例 B 抢占成为新的 Master。后来实例 A 业务恢复正常，但是由于设置了 <code>nopreempt</code>，因此不会抢占实例 B 重新成为 Master。</p>
<p>但是如果此时实例 B 业务上也出现了问题，就算优先级比实例 A 低，实例 A 也不会重新抢占成为 Master。那要如何解决呢？</p>
<p>可以通过在实例 B 的检测脚本中判断，如果实例 B 业务出现问题，则杀掉 Keepalived 进程，此时，实例 A 会重新接管 VIP 成为 Master。</p>
<p>你说如果实例 A 还是挂了的怎么办？这时候两台机器都挂了，还不找运维找谁。</p>
</blockquote>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka知识总结</title>
    <url>/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h3 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h3><blockquote>
<p>主要是分清Broker、主题Topic、分区Partition、副本Replica之间的概念</p>
</blockquote>
<h4 id="1-1-服务器层面"><a href="#1-1-服务器层面" class="headerlink" title="1.1 服务器层面"></a>1.1 服务器层面</h4><ul>
<li><strong>Broker</strong>：一个独立的Kafka服务被称为Broker，可以理解为Kafka集群中的一个节点。</li>
<li><strong>集群控制器（Controller）</strong>：每一个集群都会选举出一个Broker作为集群控制器Controller（第一个成功在zookeeper中创建<code>/kafka/controller</code>节点的Broker会被指定为集群控制器），主要负责集群管理工作，包括：<ul>
<li>创建删除主题、增加分区并选择副本的Leader</li>
<li>集群Broker管理（Broker新增、退出、故障）</li>
<li>分区副本Preferred Leader选举</li>
<li>消费者组分区重分配</li>
<li>数据服务 – 向其他Broker提供集群的元数据信息</li>
</ul>
</li>
</ul>
<h4 id="1-2-主题层面"><a href="#1-2-主题层面" class="headerlink" title="1.2 主题层面"></a>1.2 主题层面</h4><ul>
<li><strong>主题（Topic）：</strong>主题-订阅的模式，生产者将消息发送至相应的Topic中，消费者则从感兴趣的Topic中取出消息消费。Topic是一个逻辑概念。</li>
<li><strong>分区（Partition）</strong>：一个Topic被分成多个分区Partition，一个Partition从属于一个Broker，是最基本的<strong>储存单元</strong>，储存着一个Topic中的部分数据。每个Partition都有自己独立的log文件，每条记录都以追加的形式写入。</li>
<li><strong>副本（Replica）</strong>：为了保证Kafka的高可用，一个分区通常拥有多个副本。其中一个为<strong>Leader replica</strong>，其他为<strong>Follower replica</strong>，所有的事件都直接发送给<strong>Leader replica</strong>，<strong>Follower replica</strong>通过主从同步来保持与<strong>Leader replica</strong>数据一致。</li>
<li><strong>偏移量（Offset）</strong>：Partition中的每条记录都会被分配一个唯一的序号，称为偏移量Offset。</li>
<li><strong>消息（Message）</strong>：Kafka的基本数据单元。</li>
<li><strong>批次（Batch）</strong>：为了减少网络了开销，提高IO效率，多个消息会被放入同一批次之后再发送给Kafka。</li>
</ul>
<h4 id="1-3-Leader选举"><a href="#1-3-Leader选举" class="headerlink" title="1.3 Leader选举"></a>1.3 Leader选举</h4><blockquote>
<p>Kafka中多处涉及选举机制，容易混淆</p>
</blockquote>
<ul>
<li>Broker Controller组件Leader的选举 – 主要是监控Kafka集群状态</li>
<li>分区多副本机制选举Leader – 副本的Leader负责与生产者消费者的所有通信，Follower只是作为可靠性备份（主从机制）</li>
<li>消费者选举Leader – 消费者的Leader选举主要是负责消费者组内各个消费者消费分区的分配</li>
</ul>
<h3 id="2-生产者客户端工作原理"><a href="#2-生产者客户端工作原理" class="headerlink" title="2. 生产者客户端工作原理"></a>2. 生产者客户端工作原理</h3><img src="kafka消费者工作流程.png" alt="kafka消费者工作流程" style="zoom:80%;" />

<blockquote>
<p>整个生产者客户端主要由两个线程协调运行，分别是程序主线程和发送线程。</p>
<ul>
<li>程序主线程：主要负责消息的产生，然后通过拦截器、序列化器和分区器处理之后缓存到消息收集器RecordAccumulator中（多个消息打包之后变成ProducerBatch）</li>
<li>发送线程：主要负责从消息收集器中获取消息并将其发送至Kafka集群中</li>
</ul>
</blockquote>
<ol>
<li>首先，客户端生成消息，交给拦截器，拦截器可以对数据进行预处理，比如消息的格式化显示等。</li>
<li>随后，消息交给序列化器，对其中的key和value进行序列化</li>
<li>分区器使得生产者能够根据一定的规则，将特定的消息发送至特定的分区中</li>
<li>之后消息会到消息收集器中，根据设定的batch.size或者linger.ms触发消息发送之后，才会将收集器中的消息发送给kafka集群<ol>
<li><strong>batch.size</strong>：数据累积到batch.size大小之后，sender才会发送数据，默认16k</li>
<li><strong>linger.ms</strong>：如果数据没有达到batch.size，sender等待linger.ms设置的时间之后就会发送数据，默认值是0，表示没有延迟，一有消息到达就将消息发送出去（会导致网络IO频繁）</li>
</ol>
</li>
<li>在发送线程中，InFlightRequests缓存这已经发出去，但是还没有收到响应的请求（Map&lt;NodeId, Deque&gt;，即Kafka节点Id和发出去的请求队列）。主要是限制最多缓存的请求数，通过<code>max.in.flight.requests.per.connection</code>参数设置，默认为5，即每个连接维护一个长度为5的滑动窗口，最多只能缓存5个未响应的请求间隔（有点像TCP的滑动窗口，就算中间已经收到了响应，但是头和尾未响应，也是算头和尾之间的间距），如果超过该数据之后就不能向这个连接中发送更多的请求了</li>
<li>Kafka集群的应答acks：<ol>
<li>设置为0：生产者发送的数据，不需要等待Kafka集群数据落盘立即应答</li>
<li>设置为1：生产者发送的数据，Leader分区收到数据落盘后应答</li>
<li>设置为-1（all）：生产者发送的数据，<strong>Leader和ISR队列</strong>里面的所有节点数据落盘之后再由Leader应答</li>
</ol>
</li>
</ol>
<h4 id="2-1-分区策略"><a href="#2-1-分区策略" class="headerlink" title="2.1 分区策略"></a>2.1 分区策略</h4><blockquote>
<p>如果自定义了分区器的话，当然是用自定义的方法，这里说的是默认情况下</p>
</blockquote>
<p>使用默认分区器的情况下：</p>
<ol>
<li>如果指定了消息的发往的分区，则使用这个分区</li>
<li>如果没有指定分区，但是指定了消息的key，则根据key的hash值映射到特定的分区（如果主题的分区数不变，key跟分区的映射关系就能保持一致）</li>
<li>如果没有指定分区或者是消息的key，会采用粘性分区器，消息会被随机发送到指定主题的其中一个可用分区，并尽可能一直使用该分区，直到发送至该分区的消息收集器中能够达到batch.size之后，才会切换发送至别的分区（随机至另外一个分区）</li>
</ol>
<h4 id="2-2-数据可靠性保证"><a href="#2-2-数据可靠性保证" class="headerlink" title="2.2 数据可靠性保证"></a>2.2 数据可靠性保证</h4><p>acks设置为不同值下可能出现的情况</p>
<ul>
<li><strong>0：</strong>生产者发送至Kafka集群中的数据，不需要等待落盘，立即应答<strong>（应答之后Leader挂了，数据存在丢失的问题）</strong></li>
<li><strong>1：</strong>Leader分区收到数据并落盘之后应答<strong>（应答之后Leader挂了，其他Follower都还没有同步到数据，也存在数据丢失的问题）</strong></li>
<li><strong>-1（all）：</strong>Leader和ISR队列里面的所有节点数据落盘之后再由Leader应答<strong>（可能因为某个Follower网络或者挂掉的原因迟迟未能同步，会导致ACK响应阻塞，Kafka使用ISR队列来解决这个问题）（如果分区副本设置为1个，或者ISR中应答的最小副本数量min.insync.replicas为1，则跟ack&#x3D;1效果差不多，还是有数据丢失的问题）</strong><ul>
<li><strong>ISR（in-sync replicas）队列：</strong>和Leader保持同步的所有Follower+Leader的集合（Leader：0，ISR：0、1、2），如果Follower长时间未向Leader发送通信请求或者同步数据，则会被Leader踢出ISR队列，由replica.lag.time.max.ms参数设置，默认30s。</li>
<li><strong>OSR（out-sync replicas）队列：</strong>与Leader不同步的Follower集合</li>
</ul>
</li>
</ul>
<p><strong>数据完全可靠的条件</strong> &#x3D; <strong>ACK级别为-1</strong> + <strong>分区副本数大于等于2</strong> + <strong>ISR里应答的最小副本数量大于等于2</strong></p>
<h4 id="2-3-数据重复问题"><a href="#2-3-数据重复问题" class="headerlink" title="2.3 数据重复问题"></a>2.3 数据重复问题</h4><blockquote>
<p>acks设置为-1的时候，生产者可能发送了数据过来，Leader正在跟Follower同步数据，还未响应，但是此时，部分Follower已经同步了数据，Leader却挂了，Kafka集群会重新挑选出新的Leader分区，生产者会重新发送数据，如果这个新选出来的Leader已经同步了旧Leader的数据，那么就会出现数据重复的问题。</p>
</blockquote>
<h5 id="2-3-1-数据传递的语义"><a href="#2-3-1-数据传递的语义" class="headerlink" title="2.3.1 数据传递的语义"></a>2.3.1 数据传递的语义</h5><ul>
<li><strong>至少一次（At Least Once）：</strong> ACK级别为-1 + 分区副本数大于等于2 + ISR里应答的最小副本数量大于等于2，<strong>保证生产者发送的数据Kafka集群会落盘，保证数据不会丢失，但可能重复</strong></li>
<li><strong>最多一次（At Most Once）：</strong> ACK &#x3D; 0，<strong>保证生产者发送的数据最多只发送一次到Kafka集群，保证数据不重复，但是可能会丢失</strong></li>
<li><strong>精确一次（Exactly Once）：</strong> <strong>数据即不能重复，也不能丢失</strong><ul>
<li><strong>幂等性（单会话单分区精确一次）：</strong>生产者无论向Broker发送多少次重复数据，Broker都只会持久化一条，保证不会重复，结合至少一次就能达到精确一次。</li>
<li><strong>事务：</strong>通过事务保证精确一次，实现多个Topic、多个Partition原子性的写入（见下文）</li>
</ul>
</li>
</ul>
<h5 id="2-3-2-生产者幂等性"><a href="#2-3-2-生产者幂等性" class="headerlink" title="2.3.2 生产者幂等性"></a>2.3.2 生产者幂等性</h5><blockquote>
<p>Kafka的幂等性是单会话单分区幂等</p>
</blockquote>
<p>通过 <strong>&lt;PID，partition，SeqNumber&gt;</strong> 区分每一条数据。（单分区的原因看区分规则就知道，不同分区当成不同的消息）</p>
<ul>
<li><p><strong>PID（Producer ID）</strong>：对用户完全透明，是Producer每次连接上Kafka集群之后，都会向Broker申请一个全局唯一的PID，用来标识本次会话，<strong>如果Producer重启会导致PID的变化，所以Broker就会当成是一个新的生产者（单次会话的原因）</strong>。</p>
</li>
<li><p><strong>partition</strong>：消息需要发往的分区号</p>
</li>
<li><p><strong>SeqNumber</strong>：从0开始单调递增的，Broker端缓存了SeqNumber，对于每条接收的消息，只有SeqNumber比Broker缓存中的大1才接受，否则丢弃（实现幂等）。</p>
</li>
</ul>
<h3 id="3-消费者客户端工作原理"><a href="#3-消费者客户端工作原理" class="headerlink" title="3. 消费者客户端工作原理"></a>3. 消费者客户端工作原理</h3><blockquote>
<p>消息的两种<strong>消费方式</strong>：</p>
<ul>
<li><strong>pull（拉）模式：</strong>消费者主动从  mq 服务器中拉取数据（Kafka采用的方式）</li>
<li><strong>push（推）模式：</strong>mq服务器主动将数据推送至消费者（很难保证消费者的消费速度能跟得上mq服务器的推送速度）</li>
</ul>
</blockquote>
<blockquote>
<p>常见的有两种<strong>消费模型</strong>：</p>
<ul>
<li><strong>队列模型（queuing）：</strong>一组消费者从服务读取消息，一条消息只有其中的一个消费者来处理。</li>
<li><strong>发布-订阅模型（publish-subscribe）：</strong>消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。</li>
</ul>
</blockquote>
<blockquote>
<p>Kafka 提供两种<strong>订阅方式</strong>：</p>
<ul>
<li><strong>subscribe：</strong>订阅主题，能够通过正则表达式订阅多个主题，<strong>具有消费者组再平衡的功能</strong>。</li>
<li><strong>assign：</strong>能够直接订阅特定主题的特定分区，<strong>不具备消费者再平衡的功能</strong>。</li>
</ul>
</blockquote>
<p>Kafka 为这两种模型提供单一的消费者抽象模型：<strong>消费者组（Comsumer group）</strong>。</p>
<p>消费者用一个消费者组名（GroupId）标记自己，一个发布在 Topic 上的消息被分发给此消费者组中的一个成员（<strong>每个Topic的 Partition 只能由消费者组中的一个成员消费，但是一个消费者成员能够消费多个 Partition中的消息，是多对一关系</strong>）。</p>
<ul>
<li>假如<strong>所有的消费者都在一个组中，那么这就变成了队列模型</strong></li>
<li>假如<strong>所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型</strong></li>
</ul>
<p>一个消费者组中的消费者成员订阅同一个 Topic，每个消费者成员接收 Topic 的一部分分区的消息，从而实现对消费者的横向扩展，对消息进行分流。<strong>但是不要让消费者组中消费者成员的数量多于 Topic的 Partition 的数量，因为多余的消费者成员会空闲出来。</strong></p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E5%88%86%E5%8C%BA%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB.png" alt="img"></p>
<h4 id="3-1-分区的分配策略"><a href="#3-1-分区的分配策略" class="headerlink" title="3.1 分区的分配策略"></a>3.1 分区的分配策略</h4><blockquote>
<p>分区分配策略的主要作用是决定每个消费者组成员消费订阅 Topic 中的哪个分区。</p>
</blockquote>
<blockquote>
<p>Kafka 可以同时使用多个分区分配策略，由<code>partition.assignment.strategy</code>参数设定，默认是 Range + CooperativeSticky。</p>
<p>消费者也可以自定分区策略，通过继承<code>PartitionAssignor</code>接口或者<code>AbstractPartitionAssignor</code>抽象类来实现。</p>
</blockquote>
<p>消费者组分区的分配策略主要有：</p>
<ul>
<li><strong>RangeAssignor（范围）</strong></li>
<li><strong>RoundRobinAssignor（轮询）</strong></li>
<li><strong>StickyAssignor（粘性）</strong></li>
<li><strong>CooperativeStickyAssignor（合作者粘性）</strong>：与StickyAssignor类似</li>
</ul>
<h5 id="3-1-1-RangeAssignor"><a href="#3-1-1-RangeAssignor" class="headerlink" title="3.1.1 RangeAssignor"></a>3.1.1 RangeAssignor</h5><blockquote>
<p>对<strong>每个 Topic 进行独立的分区分配</strong>。对于每一个 Topic，首先对分区按照分区 ID 进行排序，然后对订阅该 Topic 的消费者组成员进行排序，之后尽量均衡地将分区分配给消费者。</p>
<p>首先要决定每个消费者消费分区的个数，Topic 分区数对消费者个数取余便是每个消费者至少要处理的分区个数，但是会有剩余的分区，剩余的分区则平均分配给排序靠前的消费者。然后从0号分区开始按每个消费者的消费分区个数按顺序分配。</p>
<p>缺点：随着消费者订阅 Topic 数量的增加，会导致不平衡问题，排序靠前的消费者会被分配更多的分区（因为上面的分配策略是针对单个 Topic 的）。</p>
</blockquote>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5Range.png" alt="img"></p>
<h5 id="3-1-2-RoundRobinAssignor"><a href="#3-1-2-RoundRobinAssignor" class="headerlink" title="3.1.2 RoundRobinAssignor"></a>3.1.2 RoundRobinAssignor</h5><blockquote>
<p>将<strong>消费者组内订阅所有 Topic 的分区</strong>及所有消费者进行排序后尽量均衡的分配。如果消费者组内，消费者订阅 Topic 列表是相同的（每个消费者成员都订阅了相同的 Topic），那么分配结果是尽量均衡的（针对所有 Topic，消费者成员之间分配到的分区数的差值不会超过 1）。如果订阅的 Topic 列表是不同的，那么分配结果是不保证“尽量均衡”的，因为某些消费者成员不参与部分 Topic 的分配。</p>
<p>分配策略是：将所有 Topic 的 Partition  和所有消费者成员都列出来，分别按照 <code>hashcode</code> 进行排序，最后通过轮询算法分配 Partition给消费者成员。</p>
</blockquote>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5RoundRobin.png" alt="img"></p>
<blockquote>
<p>对于订阅组内消费者订阅 Topic 不一致的情况：假设有三个消费者分别为C0、C1、C2，有3个 Topic T0、T1、T2，分别拥有1、2、3个分区，并且C0订阅T0，C1订阅T0和T1，C2订阅T0、T1、T0，那么RoundRobinAssignor的分配结果如下图所示，<strong>没有订阅对应 Topic 的消费者不参与分配，但是排序轮询还是按正常一样</strong>。</p>
<p>可以看到已经尽量保证均衡了，但是 C2 承担了 4 个分区，而 C1 其实是订阅了 T1 的，如果把 T1P1 交给 C1 负责会更加均衡。</p>
</blockquote>
<img src="Kafka分区分配策略RoundRobin缺点.png" alt="img" style="zoom:50%;" />

<h5 id="3-1-3-StickyAssignor"><a href="#3-1-3-StickyAssignor" class="headerlink" title="3.1.3 StickyAssignor"></a>3.1.3 StickyAssignor</h5><blockquote>
<p>无论是RangeAssignor，还是RoundRobinAssignor，当前的分区分配算法都没有考虑上一次的分配结果。StickyAssignor解决的就是这个问题。</p>
</blockquote>
<blockquote>
<p>StickyAssignor的主要目标：</p>
<ul>
<li>分区的分配尽量均衡</li>
<li>每一次重分配的结果尽量与上一次分配结果保持一致</li>
</ul>
</blockquote>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5StickyAssignor.png" alt="img"></p>
<blockquote>
<p>上面的例子中，C1 下线后，Sticky 模式原来分配给 C0、C2 的分区都没有发生变动，并且最终 C0、C1达到均衡的目的；而RoundRobin 模式中原本分配给 C0 的 T1P1，以及原本分配给 C2 的 T1P0 都发生了变动。</p>
</blockquote>
<blockquote>
<p>下面是另外一个例子</p>
</blockquote>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5StickyAssignor2.png" alt="img"></p>
<h4 id="3-2-消费者组再平衡"><a href="#3-2-消费者组再平衡" class="headerlink" title="3.2 消费者组再平衡"></a>3.2 消费者组再平衡</h4><blockquote>
<p><strong>再平衡是指 Kafka 消费者组成员或者订阅 Topic 发生变化时的一种分区重分配机制，再平衡期间消费者会停下手头的事情</strong>，一般有三种情况会触发再平衡：</p>
<ul>
<li><strong>消费者组成员数量发生变化：</strong>消费者组中新增或者删除某个成员，导致需要重新调整分区分配</li>
<li><strong>订阅主题 Topic 数量发生变化：</strong>消费者订阅的 Topic 发生变化，比如订阅的 Topic 采用的是正则表达式的形式 <code>test-*</code>，如果新建了一个 Topic 名为 <code>test-hello</code>，那么该 Topic 也是需要分配给消费者的，此时就会触发再平衡</li>
<li><strong>订阅主题 Topic 的分区数发生变化：</strong>订阅主题 Topic  增加或减少了分区数量，也会触发再平衡</li>
</ul>
</blockquote>
<blockquote>
<p>再平衡主要涉及到Kafka Broker中的<strong>Group Coordinator</strong>以及内部 Topic <strong>__consumer_offsets（更正式的名字是 Offset Topic）</strong>。</p>
</blockquote>
<h5 id="3-2-1-Group-Coordinator"><a href="#3-2-1-Group-Coordinator" class="headerlink" title="3.2.1 Group Coordinator"></a>3.2.1 Group Coordinator</h5><blockquote>
<p>Group Coordinator 主要用于消费者 offset 管理、消费者组成员与 Topic Partition的分配和 Consumer Rebalance。</p>
<p>在 Broker 启动时，每个 Broker 都会启动一个 Group Coordinator ，但只有<code>__consumer_offsets</code> 的 Partition 的 Leader 才会直接与消费者进行交互，也就是该消费者组的 Group Coordinator，其他的分区副本的 Group Coordinator只是作备份，一旦 Leader 所在 Broker 挂掉之后及时进行替代。</p>
</blockquote>
<h5 id="3-2-2-消费者组状态机"><a href="#3-2-2-消费者组状态机" class="headerlink" title="3.2.2 消费者组状态机"></a>3.2.2 消费者组状态机</h5><blockquote>
<p>Kafka 设计了一套消费者组状态机，来帮 Group Coordinator 完成整个再平衡流程。状态机中为消费者组定义了 5 种状态：Empty、Dead、PreparingRebalance、CompletingRebalance 和 Stable。</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">状态</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Empty</td>
<td>消费者组内没有任何成员，但消费者组可能存在已提交的 offset 数据，而且这些 offset 数据尚未过期</td>
</tr>
<tr>
<td align="center">Dead</td>
<td>同样是消费者组内没有任何成员，但消费者组的元数据信息已经在 Group Coordinator 端被移除。Group Coordinator 组件保存着当前向它注册过的所有消费者组信息，所谓的元数据信息就类似于这个注册信息</td>
</tr>
<tr>
<td align="center">PreparingRebalance</td>
<td>消费者组准备开启再平衡，此时所有成员都要重新请求加入消费者组</td>
</tr>
<tr>
<td align="center">CompletingRebalance</td>
<td>消费者组下所有成员已经加入，各个成员正在等待分配方案。该状态在老一点的版本种被称为 AwaitingSync，它和 CompletingRebalance是等价的</td>
</tr>
<tr>
<td align="center">Stable</td>
<td>消费者组的稳定状态。该状态表明再平衡已经完成，组内各成员能够正常消费数据了</td>
</tr>
</tbody></table>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1%E7%8A%B6%E6%80%81%E6%9C%BA.png" alt="img"></p>
<p> 一个消费者组最开始是 Empty 状态，当再平衡开启后，它会被置于 PreparingRebalance 状态等待成员加入，之后变更到  CompletingRebalance 状态等待分区分配方案，最后流转到 Stable 状态完成再平衡。</p>
<p>当有新成员加入或者已有成员退出消费者组的时候，消费者组的状态从 Stable 直接跳到 PreparingRebalance 状态，此时，所有现存成员就必须重新申请加入消费者组。当所有成员都退出组后，消费者组状态变更为 Empty。<strong>Kafka定期自动删除过期位移的条件就是，消费者组要处于 Empty 状态。</strong>因此，如果你的消费者组停掉了很长的时间（超过 7 天），那么 Kafka 很可能就把该组的 offset 数据删除了。我相信，你在 Kafka 的日志种一定经常看到下面这个输出：<code>Removed ✘✘✘ expired offsets in ✘✘✘ milliseconds.</code>。这就是 Kafka 在尝试定期删除过期 offset。</p>
<h5 id="3-2-3-再平衡全流程"><a href="#3-2-3-再平衡全流程" class="headerlink" title="3.2.3 再平衡全流程"></a>3.2.3 再平衡全流程</h5><h6 id="第一步-FIND-COORDINATOR"><a href="#第一步-FIND-COORDINATOR" class="headerlink" title="第一步 FIND_COORDINATOR"></a>第一步 FIND_COORDINATOR</h6><p>消费者启动的时候会发送 FindCoordinatorRequest 请求。</p>
<p><strong>目的：</strong></p>
<ul>
<li>确定负责该消费者组的 Group Coordinator 所在的 Broker（每个 Broker 中都会有 Group Coordinator，但是一个消费者组由一个 Group Coordinator 协调工作）</li>
<li>创建与该 Broker相互通信的网络连接</li>
</ul>
<p><strong>过程：</strong></p>
<ul>
<li>如果消费者已经保存了消费者组对应的 Group Coordinator 节点的信息，并且与它之间的网络连接是正常的，那么可以进入下一阶段；否则向 Kafka 集群中<strong>负载最小的 Broker</strong>发送 FindCoordinatorRequest 请求寻找 Group Coordinator。</li>
<li><strong>Group Coordinator的选择方式是：BrokerId &#x3D;  PartitionLeader( Hash( GroupId ) % __consumer_offsets的分区数 )</strong> ，即将 GroupId 取哈希之后对 <code>__consumer_offsets</code> 的分区数取余，然后<strong>这个余数就作为以后 消费者 offset 要写入的<code>__consumer_offsets</code> 的分区，这个分区 Partition Leader 所在的 Broker 中的 Group Coordinator 就负责这个消费者组的工作协调</strong>（非常绕，多看几遍）（其实就是消费者 offset 需要写入 __consumer_offsets分区的Leader所在 Broker中）。</li>
</ul>
<h6 id="第二步-JOIN-GROUP"><a href="#第二步-JOIN-GROUP" class="headerlink" title="第二步 JOIN_GROUP"></a>第二步 JOIN_GROUP</h6><p>当消费者组成员加入组时，会向 Group Coordinator 发送 JoinGroup 请求，该请求中包含成员订阅的主题。</p>
<p><strong>目的：</strong></p>
<ul>
<li>选举消费者 Leader</li>
<li>由消费者 Leader 制定具体的分区分配方案</li>
</ul>
<p><strong>过程：</strong></p>
<ul>
<li>第一个发送 JoinGroup 请求到 Group Coordinator 的成员自动成为消费者 Leader，根据 Group Coordinator 响应中的消费者组成员订阅信息制定分区分配方案。</li>
</ul>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1JoinGroup%E8%AF%B7%E6%B1%82.png" alt="img"></p>
<h6 id="第三步-SYNC-GROUP"><a href="#第三步-SYNC-GROUP" class="headerlink" title="第三步 SYNC_GROUP"></a>第三步 SYNC_GROUP</h6><p>消费者 Leader 将制定好的分区分配方案发送在 SyncGroup 请求中发送给 Group Coordinator。其他消费者成员也会向  Group Coordinator 发送 SyncGroup 请求，只不过请求体中没有实际的内容。然后 Group Coordinator 以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区。当所有成员都成功接收到分配方案之后，消费者组就进入到了 Stable 状态，开始正常消费工作（也会经过反序列化器、拦截器）。</p>
<p><strong>目的：</strong></p>
<ul>
<li>通过  Group Coordinator 同步消费者 Leader 制定好的分区分配方案</li>
</ul>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1SyncGroup%E8%AF%B7%E6%B1%82.png" alt="img"></p>
<h6 id="Heartbeat-线程"><a href="#Heartbeat-线程" class="headerlink" title="Heartbeat 线程"></a>Heartbeat 线程</h6><p>心跳线程是一个独立的线程，通过向 Group Coordinator 发送心跳来维持自己与消费者组的从属关系，以及对分区的所有权关系。</p>
<p>当消费者组有新成员加入时，也是<strong>通过心跳请求的响应来通知组内现有成员开启新一轮的再平衡</strong>。</p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%96%B0%E6%88%90%E5%91%98%E5%85%A5%E7%BB%84.png" alt="img"></p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%88%90%E5%91%98%E7%A6%BB%E7%BB%84.png" alt="img"></p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%88%90%E5%91%98%E5%B4%A9%E6%BA%83%E7%A6%BB%E7%BB%84.png" alt="img"></p>
<blockquote>
<p>正常情况下，每个组内成员都会定期汇报位移给协调者。当重平衡开启时，协调者会给予成员一段缓冲时间，要求每个成员必须在这段时间内快速地上报自己的位移信息，然后再开启正常的 JoinGroup&#x2F;SyncGroup 请求发送。</p>
</blockquote>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E7%BB%84%E6%88%90%E5%91%98%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB.png" alt="img"></p>
<p><a href="https://blog.csdn.net/jy02268879/article/details/112273332">【三】kafka体系架构之消费者客户端概述（分区分配策略、再均衡、偏移量）</a></p>
<p><a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/25%20%20%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%87%8D%E5%B9%B3%E8%A1%A1%E5%85%A8%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90.md">25 消费者组重平衡全流程解析</a></p>
<h4 id="3-3-内部Offset-Topic"><a href="#3-3-内部Offset-Topic" class="headerlink" title="3.3 内部Offset Topic"></a>3.3 内部Offset Topic</h4><blockquote>
<p>在 Kafka 0.9 版本之前，消费者的 offset 是保存在 zookeeper 中的，但是 <strong>zookeeper 不适合用于高频写操作的场景</strong>，这会影响 Kafka 的消息吞吐量，所以 Kafka 需要一个能够提供<strong>高持久性、支持高频写操作</strong>的地方保存 offset。明显 Kafka 的Topic 设计天然就满足了这两个条件，因此 Kafka 使用内部主题保存 offset 的这件事，是自然而然的。</p>
</blockquote>
<blockquote>
<p>Offset Topic 的 offset管理机制其实也很简单，就是<strong>将 Consumer 的消费的 offset 数据作为一条普通的 Kafka 消息， 提交到 __consumer_offsets 中</strong>。默认情况下，__consumer_offsets 主题的<strong>分区数是 50，副本数是 3。</strong></p>
</blockquote>
<p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题，Offset Topic 主题的 Key 和 Value 组成如下：</p>
<ul>
<li><strong>Key：</strong> 应该保存 3 部分的内容 <strong>&lt;GroupId, 主题名, 分区号&gt;</strong></li>
<li><strong>Value：</strong> 应该保存的数据有 <strong>&lt;offset, 时间戳， 元数据&gt;</strong> ，元数据是为了帮助 Kafka 执行各种各样的后续操作，比如删除过期位移消息等。</li>
</ul>
<p>具体消费者消费的 offset 储存到 <code>__consumer_offsets</code> 的哪个分区上，是根据<code>abs(GroupId.hashCode()) % NumPartitions</code>来计算（其中，NumPartitions 是 <code>__consumer_offsets的分区数</code>）</p>
<h5 id="3-3-1-提交偏移量"><a href="#3-3-1-提交偏移量" class="headerlink" title="3.3.1 提交偏移量"></a>3.3.1 提交偏移量</h5><p>如果消费者消费到了 offset，则提交的偏移量位置是 offset + 1，指向下一跳消息的位置。</p>
<p>提交的偏移量是 poll() 最后一次拉取的偏移量。当然手动提交的时候，也能够指定偏移量位置。</p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%81%8F%E7%A7%BB%E9%87%8F%E6%8F%90%E4%BA%A4%E6%96%B9%E6%B3%95.jpeg" alt="img"></p>
<h6 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h6><p>开启时，消费者使用 poll() 方法从 Kafka 中拉取消息数据，同时消费者会有一个后台线程定时向 Kafka 提交消费者的 offset，自动提交涉及两个参数：</p>
<ul>
<li><strong>enable.auto.commit：</strong>设为 true，表示开启自动提交（默认）</li>
<li><strong>auto.commit.interval.ms：</strong>自动提交时间间隔，默认是 5 秒</li>
</ul>
<p><strong>自动提交丢数据场景</strong>：消费者A，第一次 poll 了100条数据，刚好第一次提交偏移量也是 100+1（ 5 秒提交一次），但是拉取的这 100 条才处理了前 50 条，A 就挂了，相当于51 - 100 的数据已经提交了偏移量，但还没处理。因此发生了消费再平衡，由 B 来接着消费这个分区，B 从 101 开始消费，51-101 的数据就丢失了。</p>
<p><strong>自动提交重复消费场景：</strong>消费者A，第一次 poll 了 100 条数据，刚好第一次提交偏移量也是 100+1（ 5 秒提交一次），在后面的 3 秒中，消费者 A 又 poll 了 2 次数据，每次 100 条，相当于此时消费者 A 已经消费到了偏移量 300 了，此时才过 3 秒，还没有到下一次触发自动提交的时间。此时，消费者 A 挂了，发生了消费再平衡，由 B 来接着消费这个分区，那 B 就是从 101 偏移量开始消费，那么101-300都被重复消费了。</p>
<h6 id="手动提交"><a href="#手动提交" class="headerlink" title="手动提交"></a>手动提交</h6><p>使用手动提交的时候，需要将 <strong>enable.auto.commit</strong> 设置为 false。</p>
<p><strong>同步提交commitSync()</strong> ：调用 commitSync() 时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果。</p>
<p><strong>异步提交commitAsync()</strong> ：调用 commitAsync() 之后，它会立即返回，不会阻塞。commitAsync 的问题在于，出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经 “过期” 或不是最新值了（重试之前，已经有另外一次提交）。</p>
<p><a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/18%20%20Kafka%E4%B8%AD%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF.md">Kafka中位移提交那些事儿</a></p>
<h3 id="4-Broker工作原理"><a href="#4-Broker工作原理" class="headerlink" title="4. Broker工作原理"></a>4. Broker工作原理</h3><blockquote>
<p>Kafka在2.8版本之前的集群信息管理依赖于Zookeeper，在2.8版本之后引入了Raft协议，去除了Zookeeper的依赖，但是还是提供多Zookeeper的版本（因为Raft协议的版本暂时还不成熟），下面主要以Zookeeper的版本介绍</p>
</blockquote>
<h4 id="4-1-Zookeeper中储存的信息"><a href="#4-1-Zookeeper中储存的信息" class="headerlink" title="4.1 Zookeeper中储存的信息"></a>4.1 Zookeeper中储存的信息</h4><p>Zookeeper中主要储存以下信息</p>
<ul>
<li><strong>&#x2F;brokers&#x2F;ids</strong>： 记录有哪些在线的Broker</li>
<li><strong>&#x2F;brokers&#x2F;topics&#x2F;主题名&#x2F;partitions&#x2F;分区号&#x2F;state</strong>： 记录分区副本中谁是Leader，谁是Follower，记录有哪些分区的副本是在线的（ISR队列）</li>
<li><strong>&#x2F;controller</strong>： 负责Broker Controller组件Leader的选举，谁能先注册到这个节点，谁就是Leader</li>
</ul>
<h4 id="4-2-Broker中的Controller组件"><a href="#4-2-Broker中的Controller组件" class="headerlink" title="4.2 Broker中的Controller组件"></a>4.2 Broker中的Controller组件</h4><blockquote>
<p>Controller组件是Kafka的核心组件，主要作用是在Zookeeper的帮助下管理和协调整个Kafka集群。Kafka集群中的任意一个Broker都会有一个Controller组件，但是在运行的过程中只有一个Controller能够称为集群的Leader Controller，管理和协调集群的运行，其他的Controller作为高可用的后备，Leader Controller挂了就顶上。</p>
</blockquote>
<p>Controller组件主要负责：</p>
<ul>
<li>创建删除主题、增加分区并选择副本的Leader</li>
<li>集群Broker管理（Broker新增、退出、故障）</li>
<li>分区副本Preferred Leader选举</li>
<li>消费者组分区重分配</li>
<li>数据服务 – 向其他Broker提供集群的元数据信息</li>
</ul>
<h5 id="4-2-1-工作流程"><a href="#4-2-1-工作流程" class="headerlink" title="4.2.1 工作流程"></a>4.2.1 工作流程</h5><p>![image-20221027232023434](Broker Controller工作流程.png)</p>
<ol>
<li>当Broker启动的时候，会向Zookeeper中的<code>/brokers/ids/</code>写入自己的Broker ID</li>
<li>随后Controller会尝试向Zookeeper中创建<code>/controller</code>节点，第一个成功创建<code>/controller</code>节点的Controller会写入自己的Broker ID成为Leader Controller，并向<code>/controller_epoch</code>节点写入自己的任期Epoch（任期是单调递增的），然后拉取Zookeeper中相应节点中的信息进行集群的初始化。</li>
<li>其他尝试创建<code>/controller</code>节点的Controller会向<code>/controller</code>节点注册监听，当Leader挂了，就尝试顶上。</li>
<li>Leader Controller会监听<code>/brokers/ids/</code>中子节点的变化，以监控Broker的上下线。</li>
<li>Leader Controller开始负责集群信息的管理，并且维护<code>/brokers/topics/</code>节点中的信息。</li>
<li>当Leader Controller挂了之后，其他Controller会尝试创建<code>/controller</code>节点成为新的Leader Controller并将任期Epoch + 1，从Zookeeper中拉取信息初始化集群上下文，其他Broker收到小于当前Leader Controller任期Epoch的事件都会丢弃，以隔离僵尸Leader的影响。</li>
</ol>
<h5 id="4-2-2-Controller内部结构"><a href="#4-2-2-Controller内部结构" class="headerlink" title="4.2.2 Controller内部结构"></a>4.2.2 Controller内部结构</h5><blockquote>
<p>在 Kafka 0.11 版本之前，控制器的设计是相当繁琐的，代码更是有些混乱，这就导致社区中很多控制器方面的 Bug 都无法修复。<strong>控制器是多线程的设计，会在内部创建很多个线程。</strong>比如，控制器需要为每个 Broker 都创建一个对应的 Socket 连接，然后再创建一个专属的线程，用于向这些 Broker 发送特定请求。如果集群中的 Broker 数量很多，那么控制器端需要创建的线程就会很多。另外，控制器连接 ZooKeeper 的会话，也会创建单独的线程来处理 Watch 机制的通知回调。除了以上这些线程，控制器还会为主题删除创建额外的 I&#x2F;O 线程。</p>
<p>比起多线程的设计，更糟糕的是，这些线程还会访问共享的控制器缓存数据。我们都知道，多线程访问共享可变数据是维持线程安全最大的难题。为了保护数据安全性，控制器不得不在代码中大量使用ReentrantLock同步机制，这就进一步拖慢了整个控制器的处理速度。</p>
<p><strong>鉴于这些原因，社区于 0.11 版本重构了控制器的底层设计，最大的改进就是，把多线程的方案改成了单线程加事件队列的方案。</strong></p>
<p>从这张图中，我们可以看到，社区引入了一个事件处理线程，统一处理各种控制器事件，然后控制器将原来执行的操作全部建模成一个个独立的事件，发送到专属的事件队列中，供此线程消费。这就是所谓的单线程 + 队列的实现方式。 值得注意的是，这里的单线程不代表之前提到的所有线程都被“干掉”了，控制器只是把缓存状态变更方面的工作委托给了这个线程而已。</p>
<p>这个方案的最大好处在于，控制器缓存中保存的状态只被一个线程处理，因此不再需要重量级的线程同步机制来维护线程安全，Kafka 不用再担心多线程并发访问的问题，非常利于社区定位和诊断控制器的各种问题。事实上，自 0.11 版本重构控制器代码后，社区关于控制器方面的 Bug 明显少多了，这也说明了这种方案是有效的。</p>
<p>针对控制器的第二个改进就是，将之前同步操Zookeeper 全部改为异步操作。ZooKeeper 本身的 API 提供了同步写和异步写两种方式。之前控制器操作 ZooKeeper 使用的是同步的 API，性能很差，集中表现为，当有大量主题分区发生变更时，ZooKeeper 容易成为系统的瓶颈。新版本 Kafka 修改了这部分设计，完全摒弃了之前的同步 API 调用，转而采用异步 API 写入 ZooKeeper，性能有了很大的提升。根据社区的测试，改成异步之后，ZooKeeper 写入提升了 10 倍！</p>
</blockquote>
<img src="./Broker Controller结构.jpg" alt="img"  />



<h4 id="4-3-数据的储存"><a href="#4-3-数据的储存" class="headerlink" title="4.3 数据的储存"></a>4.3 数据的储存</h4><blockquote>
<p>Kafka的存储最终实现方案是<strong>基于顺序追加写日志  + 稀疏哈希索引</strong></p>
</blockquote>
<p>一般通过以下手段来提高数据的读写性能：</p>
<ul>
<li><strong>提高读速度：</strong>利用索引，来提高查询速度，但是有了索引，大量写操作都会维护索引，那么会降低写入效率。常见的如关系型数据库MySQL</li>
<li><strong>提高写操作：</strong>这种一般是采用日志储存，通过顺序追加写的方式来提高写入速度，因为没有索引，无法快速查询，只能顺序遍历</li>
</ul>
<p>Kafka主要用来处理海量数据流，这个场景的特点主要包括：</p>
<ul>
<li><strong>写操作：</strong>写并发要求非常高，基本得达到百万级TPS。顺序追加写日志即可，<strong>无需考虑更新操作（无需考虑更新操作是跟数据库最大的区别）</strong></li>
<li><strong>读操作：</strong>相对写操作来说，比较简单，只要能按照一定规则高效查询即可（Offset或者时间戳）</li>
</ul>
<blockquote>
<p>这个时候就显示了数据结构的重要性了，因为使用的场景不一样。Kafka无需考虑数据的更新操作，只要能快速写数据，快速读数据就可以了。那么，提高写速度的就只有通过顺序追加写的方式（这是由硬件底层决定的），需要考虑的就是怎么提高读速度。这种数据有序的情况下，最好方式就是哈希索引，在内存中维护一个映射关系，每次根据消息Offset查询消息的时候，从哈希表中得到文件偏移量。再去读文件就能快速定位。但是，哈希表是要常驻在内存的，对于Kafka来说不太现实。可以在写消息的时候，将Offset设计成一个有序的字段与消息一起记录，将消息文件按照一定大小分割成块，用一个表索引每个消息文件块中第一条消息记录的Offset和磁盘位置（分片和索引），就能够通过索引快速定位消息所在文件块的位置，再顺序遍历找到消息的位置。（为什么不用B+树索引呢？因为Kafka是要删除过期数据的，用B+树索引在删除的时候就需要大量的维护，而现在这种方式只要把块文件一删，块索引一删就完事了，而且<strong>对于生产者和消费者来说，后续都是追加写或者是顺序读</strong>）</p>
</blockquote>
<img src="Kafka稀疏索引.png" style="zoom: 67%;" />

<img src="Kafka储存机制.png" style="zoom:67%;" />

<blockquote>
<p>根据 Offset 查找消息过程：</p>
<ol>
<li>根据目标 Offset 定位到 Segment 文件</li>
<li>根据<code>.index</code>文件找到小于等于目标值 Offset 的最大 Offset 对应的索引项</li>
<li>根据索引项索引 Position 定位到<code>.log</code>文件中的指定位置</li>
<li>向下遍历找到目标Record</li>
</ol>
</blockquote>
<p>Kafka 是基于「主题 + 分区 + 副本 + 分段 + 索引」的结构，每一个分区副本Replica都对应一个Log，一个Log又分为多个日志分段Segment：</p>
<ul>
<li>Kafka 中消息是以主题 Topic 为基本单位进行归类的，这里的 Topic 是逻辑上的概念，实际上在磁盘存储是根据分区 Partition 存储的, 即每个 Topic 被分成多个 Partition，分区 Partition 的数量可以在主题 Topic 创建的时候进行指定。</li>
<li>Partition 分区主要是为了解决 Kafka 存储的水平扩展问题而设计的，如果一个 Topic 的所有消息都只存储到一个 Kafka Broker 上的话， 对于 Kafka 每秒写入几百万消息的高并发系统来说，这个 Broker 肯定会出现瓶颈， 故障时候不好进行恢复，所以 Kafka 将 Topic 的消息划分成多个 Partition，然后均衡的分布到整个 Kafka Broker 集群中。</li>
<li>Partition 分区内每条消息都会被分配一个唯一的消息 id，即我们通常所说的 偏移量 Offset，因此 Kafka 只能保证每个分区内部有序性，并不能保证全局有序性。</li>
<li>然后每个 Partition 分区又被划分成了多个 LogSegment，这是为了防止 Log 日志过大，Kafka 又引入了日志分段（LogSegment）的概念，将 Log 切分为多个 LogSegement，相当于一个巨型文件被平均分割为一些相对较小的文件，这样也便于消息的查找、维护和清理。这样在做历史数据清理的时候，直接删除旧的 LogSegement 文件就可以了。</li>
<li>Log 日志在物理上只是以文件夹的形式存储，文件夹的命名规则是<code>topic名称-分区号</code>，而每个 LogSegement 对应磁盘上的4个文件：<code>.index</code>索引文件（ <strong>.index文件中保存的是相对 Offset，相对于 Segment 中的第一条消息，能够保证 Offset 的值所占用的空间不会过大</strong>）、<code>.log</code>消息数据文件、<code>.snapshot</code>快照文件、<code>.timeindex</code>时间索引文件，<strong>这些文件以当前Segment的第一条消息的Offset命名</strong>。</li>
</ul>
<h4 id="4-4-PageCache和零拷贝"><a href="#4-4-PageCache和零拷贝" class="headerlink" title="4.4 PageCache和零拷贝"></a>4.4 PageCache和零拷贝</h4><blockquote>
<p>在 Kafka 中，大量使用了 <strong>PageCache（ Java 中使用 mmap 实现，将进程的一段虚拟地址空间映射到文件的内存地址中，避免用户态和内核态之间的数据拷贝过程</strong>），这也是 Kafka 能实现高吞吐的重要因素之一。</p>
<p>PageCache 的作用是当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据页是否在 PageCache 中，如果命中则直接返回数据，从而避免了对磁盘IO操作；如果没有命中，操作系统则会向磁盘发起读取请求并将读取的数据页存入 PageCache 中，之后再将数据返回给进程。</p>
<p>同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检查数据页是否存在缓存中，如果不存在，则 PageCache 中添加相应的数据页，最后将数据写入对应的磁盘块中。被修改过的数据页会变成脏页，操作系统会在合适的时间把脏页中断数据写入磁盘（当PageCache 被读取或者失效的时候），以保持数据的一致性。</p>
</blockquote>
<p>为什么 Kafka 不自己管理缓存，而用 PageCache 呢，主要是因为：</p>
<ul>
<li>JVM 中一切皆对象，数据的对象储存会带来所谓 Object overhead 浪费空间</li>
<li>如果由 JVM 来管理缓存，会受到 GC 的影响，并且过大的堆也会拖累 GC 的效率，降低吞吐量</li>
<li>一旦程序崩溃，自己管理的缓存数据会全部丢失（用 PageCache 的话，PageCache 中的数据会随着内核中的 Flusher 线程的调度以及对 sync()&#x2F;fsync() 的调用写回到磁盘，就算进程崩溃，也不用担心数据丢失）</li>
</ul>
<p>Kafka还使用了<strong>零拷贝（Zero-Copy）</strong>来提高系统性能，其实对于消费者来说，读取的是原原本本的数据，不需要Kafka进行加工，所以数据其实不需要经过用户态（Kafka进程），而<strong>在内核态的时候，直接就把读取到的数据发送给消费者，这样就能够避免数据从内核态传输到用户态，再传输给用户的时候又从用户态拷贝到内核态再发送到网卡中发送给消费者</strong>。</p>
<p>Linux 2.4+ 内核通过<code>sendfile</code>系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件-网络发送由一个<code>sendfile</code>调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E9%9B%B6%E6%8B%B7%E8%B4%9D.png"></p>
<h4 id="4-5-日志清理机制"><a href="#4-5-日志清理机制" class="headerlink" title="4.5 日志清理机制"></a>4.5 日志清理机制</h4><blockquote>
<p>Kafka无论消息是否被消费，Kafka都会保留所有消息，随着写入数据不断增加，磁盘占用空间越来越大，为了控制占用空间就需要对消息进行清理。日志的清理比较简单，因为Log被分为多个日志分段Segment，最先创建的Segment一定是历史日志，只要根据一定的策略删除这个Segment即可。</p>
</blockquote>
<p>Kafka中由日志管理器（LogManager）周期性检测和清理日志分段文件，提供以下两种日志清理策略，</p>
<ul>
<li><strong>日志删除（Log Retention）：</strong>按照指定策略删除日志分段LogSegment<ul>
<li><strong>基于时间策略：</strong>能够设定日志分段文件保留多久<strong>（参数优先级毫秒log.retention.ms &gt; 分钟log.retention.minutes &gt; 小时log.retention.hours ）</strong>，但是并不是日志记录超过了设定的时间就立即删除，而是根据日志分段LogSegment中消息最大的时间戳来算，LogSegment中最大时间戳超过了设定的时间，这个LogSegment才会被删除（很好理解，<strong>因为一个LogSegment中有很多消息，但不是所有消息都是超过了设定的时间，只有所有消息都超过了设定的时间，才将这个LogSegment删除</strong>）。</li>
<li><strong>基于日志大小策略：</strong>能够检查整个分区副本日志大小是否超过设定的阈值，如果超过了，从日志文件中的第一个日志段开始寻找可以删除的日志分段集合（同理，如果有一个日志分段在被删和不被删之间反复横跳，也是不会被删的）。</li>
<li><strong>基于日志起始偏移量：</strong>判断依据是某日志分段 Segment 的下一个日志分段 Segment 的起始偏移量 baseOffset 是否小于等于 logStartOffset，若是，则可以删除此日志分段。</li>
</ul>
</li>
<li><strong>日志压缩（Log Compaction）：</strong>日志压缩对于相同 Key 不同 Value 的时候，只根据 Key 保留最后一个版本（即保留最新的Value）。</li>
</ul>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9.png"></p>
<p><a href="http://dockone.io/article/2434664">一篇文章彻底搞懂 Kafka 的存储架构</a></p>
<p><a href="https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html">Kafka文件存储机制那些事</a></p>
<p><a href="https://blog.csdn.net/qq_34412985/article/details/120380212">Kafka对PageCache的使用</a></p>
<h3 id="5-分区副本机制"><a href="#5-分区副本机制" class="headerlink" title="5. 分区副本机制"></a>5. 分区副本机制</h3><p>所谓的副本机制（Replication），也可以称之为备份机制，通常是指分布式系统在多台网络互联的机上保存有相同的数据拷贝。</p>
<p>Kafka 是有主题 Topic 概念的，而每个主题又进一步划分成若干个分区 Partition。副本 Replication 的概念实际上是在分区层级下定义的，每个分区配置有若干个副本。</p>
<p><strong>所谓副本（Replica），本质就是一个只能追加写消息的提交日志</strong>。根据 Kafka 副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些<strong>副本分散保存在不同的 Broker 上</strong>，从而能够对抗部分 Broker 宕机带来的数据不可用。</p>
<p><strong>Kafka 中分区的副本是基于领导者（Leader-based）的副本机制，生产者和消费者的所有请求由 Leader Replica 处理，Follower Replica 只负责异步地从 Leader Replica 中拉取数据同步，不对外提供服务。</strong></p>
<img src="Kafka Broker中的副本.png" alt="img" style="zoom: 33%;" />

<img src="Kafka副本角色.png" alt="img" style="zoom:33%;" />

<p>Leader Replica会成为 Kafka 集群的性能瓶颈，但是这种副本机制的好处是：</p>
<ul>
<li><strong>方便实现“Read-your-writes”：</strong>生产者写入后，消费者马上就能够获取到</li>
<li><strong>方便实现单调读（Monotonic Reads）</strong>：消费者多次消费消息时，不会存在从不同副本读取到不同数据的情况（因为都是从 Leader Replica中读）</li>
</ul>
<h4 id="5-1-In-sync-Replicas（ISR）"><a href="#5-1-In-sync-Replicas（ISR）" class="headerlink" title="5.1 In-sync Replicas（ISR）"></a>5.1 In-sync Replicas（ISR）</h4><p>ISR 中的副本都是与 Leader 同步的副本，相反，不在 ISR 中的追随者副本就被认为是与 Leader 不同步的。</p>
<p>ISR 是一个动态调整的集合，能否存在于 ISR 集合中的标准是<strong>Broker 端参数 replica.lag.time.max.ms 参数值，设定了 Follower 副本能够落后 Leader 副本的最长时间间隔</strong>，默认值是 10 秒，只要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 副本与 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息；否则，Follower 副本会被移动到 OSR 集合中。</p>
<h5 id="5-1-1-最少同步副本"><a href="#5-1-1-最少同步副本" class="headerlink" title="5.1.1 最少同步副本"></a>5.1.1 最少同步副本</h5><p><code>min.insync.replicas</code>参数能够再 Broker 或者主题级别进行配置，代表 ISR 列表中至少要有几个可用副本。当 ISR 列表中可用副本数量小于该值时，就认为整个分区处于不可用状态，此时客户端再向分区写入数据时就会抛出异常<code>NotEnoughReplicasExceptoin</code>。</p>
<h4 id="5-2-Out-sync-Replicas（OSR）"><a href="#5-2-Out-sync-Replicas（OSR）" class="headerlink" title="5.2 Out-sync Replicas（OSR）"></a>5.2 Out-sync Replicas（OSR）</h4><p>Kafka 把所有不在 ISR 中存活的副本都称为非同步副本（Out-sync Replicas）。</p>
<p>通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。<strong>Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举</strong>。</p>
<p>开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。</p>
<h4 id="5-3-元数据请求机制"><a href="#5-3-元数据请求机制" class="headerlink" title="5.3 元数据请求机制"></a>5.3 元数据请求机制</h4><p>在所有副本中，只有领导副本才能进行消息的读写处理。由于不同分区的领导副本可能在不同的 Broker 上，如果某个 Broker 收到了一个分区请求，但是该分区的领导副本并不在该 Broker 上，那么它就会向客户端返回一个 <code>Not a Leader for Partition</code> 的错误响应。为了解决这个问题，Kafka 提供了元数据请求机制。</p>
<p>首先<strong>集群中的每个 Broker 都会缓存所有主题的分区副本信息，客户端会定期发送发送元数据请求，然后将获取的元数据进行缓存</strong>。定时刷新元数据的时间间隔可以通过为客户端配置 <code>metadata.max.age.ms</code> 来进行指定。有了元数据信息后，客户端就知道了领导副本所在的 Broker，之后直接将读写请求发送给对应的 Broker 即可。</p>
<p>如果在定时请求的时间间隔内发生的分区副本的选举，则意味着原来缓存的信息可能已经过时了，此时还有可能会收到 <code>Not a Leader for Partition</code> 的错误响应，这种情况下客户端会再次求发出元数据请求，然后刷新本地缓存，之后再去正确的 Broker 上执行对应的操作。</p>
<img src="./Kafka 元数据请求机制.jpg" alt="img"  />



<h4 id="5-4-Leader-Replica-选举"><a href="#5-4-Leader-Replica-选举" class="headerlink" title="5.4 Leader Replica 选举"></a>5.4 Leader Replica 选举</h4><blockquote>
<p>AR（All Replica）就是所有副本，ISR 与 OSR 的并集，存的是 Broker ID</p>
</blockquote>
<p>副本 Leader 选举是由 Controller Leader 来处理的。只有在 ISR 集合中的副本才有资格参选，随后选取 AR 中排序靠前的作为 Leader Replica。</p>
<h5 id="5-4-1-优先副本"><a href="#5-4-1-优先副本" class="headerlink" title="5.4.1 优先副本"></a>5.4.1 优先副本</h5><p>优先副本即 AR 集合列表中的第 1 个副本，比如 AR [1, 2, 0]，那么分区优先副本即为 1。引入优先副本的概念是为了 所有分区的 Leader Replica 在所有 Broker 中均匀分布，避免消费者或者生产者的请求集中在某几个 Broker 中。</p>
<p>如果优先副本被选举为 Leader Replica，则该Leader 称为 <strong>Prefect Leader</strong>。</p>
<h5 id="5-4-2-Leader-Replica-自动平衡"><a href="#5-4-2-Leader-Replica-自动平衡" class="headerlink" title="5.4.2 Leader Replica 自动平衡"></a>5.4.2 Leader Replica 自动平衡</h5><p>正常情况下，Kafka 本身会把 Leader Replica 均匀地分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些 Broker 宕机，Leader Replica重新选举之后会导致所有 Topic 中的 Leader Replica 过于集中在其他部分几台 Broker 上，造成集群负载不均衡。所以 Kafka 提供了 Leader Replica 自动平衡的机制。</p>
<p>当 Broker 中 中存在的 Leader Replica 不是优先副本的时候，不平衡数就会加 1，当不平衡比率达到设定阈值的时候就会触发自动平衡。</p>
<p>其中，Broker 中有三个参数：</p>
<ul>
<li><strong>auto.leader.rebalance.enable：</strong>默认为 True，自动 Leader Replica 平衡，生产环境中，Leader Replica 重选举的代价比较大，可能会带来性能影响，建议设置为 False 关闭。</li>
<li><strong>leader.imbalance.per.broker.percentage：</strong>默认是 10%，每个 Broker 允许的不平衡的比例。如果每个 Broker 都超过了这个值，控制器会触发 Leader Replica的平衡。</li>
<li><strong>leader.imbalance.check.interval.seconds：</strong>默认值 300 秒，检查 Leader Replica 负载是否平衡的间隔时间。</li>
</ul>
<h4 id="5-5-副本数据同步"><a href="#5-5-副本数据同步" class="headerlink" title="5.5 副本数据同步"></a>5.5 副本数据同步</h4><blockquote>
<p>为了保证数据一致性，只有被所有同步副本（ISR中所有副本）都保存了的数据才能被客户端读取到，即高水位。在这里不讨论 Kafka 事务，因为事务还依靠 LSO（Log Stable Offset）来判断事务型消费者的可见性</p>
<p><strong>高水位和日志末端位移是副本的两个重要属性，每个副本都会有。但是 Leader 副本的高水位就是分区的高水位。</strong></p>
</blockquote>
<ul>
<li><strong>高水位 HW（High Watermark）：</strong>生产者已提交消息位移 offset + 1，高水位用于定义消息的可见性，用来标识分区下的哪些消息是可以被消费者消费的，同时帮助 Kafka 完成副本的同步。</li>
<li><strong>日志末端位移 LEO（Log End Offset）：</strong>副本下一条消息写入的位移值。</li>
</ul>
<img src="Kafka HW 和 LEO.png" alt="img"  />

<h5 id="5-5-1-高水位更新机制"><a href="#5-5-1-高水位更新机制" class="headerlink" title="5.5.1 高水位更新机制"></a>5.5.1 高水位更新机制</h5><blockquote>
<p>每个副本对象都保存一组 HW 值和 LEO 值。而 Leader 副本所在 Broker 除了保存自己 LEO 值，还会保存所有 Follower 副本的 LEO 值（为了帮助 Leader 副本确定自己的高水位，即分区高水位）。</p>
</blockquote>
<p>注意区分保存 HW 值和 LEO 值的位置，参考下图，分别有：</p>
<ul>
<li>Broker 0 上 Leader 副本 LEO 值</li>
<li>Broker 0 上 Leader 副本储存所有 Follower 的 LEO 值</li>
<li>Broker 1 上 Follower 副本 LEO 值</li>
<li>Broker 0 上 Leader 副本 HW 值</li>
<li>Broker 1 上 Follower 副本 HW 值</li>
</ul>
<img src="./Kafka HW 和 LEO 储存位置.png" alt="Kafka HW 和 LEO 储存位置"  />

<table>
<thead>
<tr>
<th align="center">更新对象</th>
<th>更新时机</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Broker 0 上 Leader 副本 LEO</td>
<td>Leader 副本接收到生产者发送的消息，写入到本地磁盘后，会更新其 LEO 值。</td>
</tr>
<tr>
<td align="center">Broker 0 上 远程副本 LEO</td>
<td>Follower 副本从 Leader 副本拉取消息时，会告诉 Leader 副本从哪个位移处开始拉取。Leader 副本会使用这个位移值来更新远程副本的 LEO。</td>
</tr>
<tr>
<td align="center">Broker 1 上 Follower 副本 LEO</td>
<td>Follower 副本从 Leader 副本拉取消息，写入到本地磁盘后，会更新其 LEO值。</td>
</tr>
<tr>
<td align="center">Broker 0 上 Leader 副本 HW</td>
<td>主要有两个更新时机：1. Leader 副本更新 LEO 后；2. 更新完远程副本 LEO 后。具体更新方法是：取 Leader 副本和所有 Leader 同步的远程副本 LEO 中的<strong>最小值</strong>。</td>
</tr>
<tr>
<td align="center">Broker 1 上 Follower 副本 HW</td>
<td>Follower 副本成功更新完 LEO 之后，会比较其 LEO 值与 Leader 副本发来的高水位值，并用两者的<strong>较小值</strong>去更新它自己的高水位。</td>
</tr>
</tbody></table>
<p>关于上述的与 Leader 副本保持同步，有两个判断条件：</p>
<ul>
<li>该远程 Follower 副本在 ISR 中。</li>
<li>该远程 Follower 副本 LEO 值落后于 Leader 副本 LEO 值的时间，不超过 Broker 端参数 replica.lag.time.max.ms 的值。</li>
</ul>
<p>乍一看，这两个条件好像是一回事，因为目前某个副本能否进入 ISR 就是靠第 2 个条件判断的。但有些时候，会发生这样的情况：即 Follower 副本已经“追上”了 Leader 的进度，却不在 ISR 中，比如某个刚刚重启回来的副本。如果 Kafka 只判断第 2 个条件的话，就可能出现某些副本具备了“进入 ISR”的资格，但却尚未进入到 ISR 中的情况。此时，分区高水位值就可能超过 ISR 中副本 LEO，而高水位 &gt; LEO 的情形是不被允许的。</p>
<h5 id="5-5-2-副本同步机制"><a href="#5-5-2-副本同步机制" class="headerlink" title="5.5.2 副本同步机制"></a>5.5.2 副本同步机制</h5><p>首先是初始状态。下面这张图中的 remote LEO 就是刚才的远程副本的 LEO 值。在初始状态时，所有值都是 0。</p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B1.png" alt="img"></p>
<p>当生产者给主题分区发送一条消息后，状态变更为：</p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B2.png" alt="img"></p>
<p>此时，Leader 副本成功将消息写入了本地磁盘，故 LEO 值被更新为 1。</p>
<p>Follower 再次尝试从 Leader 拉取消息。和之前不同的是，这次有消息可以拉取了，因此状态进一步变更为：</p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B3.png" alt="img"></p>
<p>这时，Follower 副本也成功地更新 LEO 为 1。此时，Leader 和 Follower 副本的 LEO 都是 1，但各自的高水位依然是 0，还没有被更新。<strong>它们需要在下一轮的拉取中被更新</strong>，如下图所示：</p>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B4.png" alt="img"></p>
<p>在新一轮的拉取请求中，由于位移值是 0 的消息已经拉取成功，因此 Follower 副本这次请求拉取的是位移值 &#x3D;1 的消息。Leader 副本接收到此请求后，更新远程副本 LEO 为 1，然后更新 Leader 高水位为 1。做完这些之后，它会将当前已更新过的高水位值 1 发送给 Follower 副本。Follower 副本接收到以后，也将自己的高水位值更新成 1。至此，一次完整的消息同步周期就结束了。事实上，Kafka 就是利用这样的机制，实现了 Leader 和 Follower 副本之间的同步。</p>
<h5 id="5-5-3-Leader-Epoch"><a href="#5-5-3-Leader-Epoch" class="headerlink" title="5.5.3 Leader Epoch"></a>5.5.3 Leader Epoch</h5><blockquote>
<p>上面的例子举了两个副本的例子，如果扩展到多个副本，可能会存在问题。首先 Leader 副本高水位更新和 Follower 副本高水位更新在时间上是岔开的。Follower 副本高水位的更新是拉取数据时 Leader 返回当时的高水位，而 Leader 的高水位由所有远程副本 LEO中的最小值决定的。这种错配会导致“数据丢失”或者“数据不一致”的问题。</p>
</blockquote>
<blockquote>
<p>引入了 Leader Epoch之后，故障后恢复不再根据 HW 进行截断，而是根据 Epoch 和 Leader 的 LEO。</p>
</blockquote>
<blockquote>
<p>具体的问题示例，查看后面链接中的例子</p>
</blockquote>
<p>Leader Epoch 解决的就是上述的问题，由两部分数据组成：</p>
<ul>
<li><strong>Epoch：</strong>一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li>
<li><strong>起始位移（Start Offset）：</strong>Leader 副本在其 Epoch 值上写入的首条消息的位移。</li>
</ul>
<p>举例来说，某个 Partition 有两个 Leader Epoch，分别为 (0, 0) 和 (1, 100) 。这意味该 Partion 历经一次 Leader 副本变更，版本号为 0 的 Leader 从 Offset&#x3D;0 处开始写入消息，共写入了 100 条。而版本号为 1 的 Leader 则从 Offset&#x3D;100 处开始写入消息。</p>
<p>每个副本的 Leader Epoch 信息既缓存在内存中，也会定期写入消息目录下的 leaderer-epoch-checkpoint 文件中。当一个 Follower 副本从故障中恢复重新加入 ISR 中，它将：</p>
<ol>
<li>向 Leader 发送 LeaderEpochRequest，请求中包含了 Follower 的 Epoch 信息；</li>
<li><strong>Leader 将返回该 Follower 所在 Epoch 的 Last Offset；</strong></li>
<li>如果 Leader 与 Follower 处于同一 Epoch，那么 Last Offset 显然等于 Leader LEO；</li>
<li>如果 Follower 的 Epoch 落后于Leader，则Last Offset等于Follower Epoch + 1所对应的 Start Offset。这可能有点难以理解，我们还是以 (0, 0) 和 (1, 100) 为例进行说明：Offset&#x3D;100 的消息既是 Epoch&#x3D;1 的 Start Offset，也是 Epoch&#x3D;0 的 Last Offset；</li>
<li><strong>Follower 接收响应后根据返回的 Last Offset 截断数据；</strong></li>
<li>在数据同步期间，只要 Follower 发现 Leader 返回的 Epoch 信息与自身不一致，便会随之更新 Leader Epoch 并写入磁盘。</li>
</ol>
<p><a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/23%20%20Kafka%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3.md">Kafka副本机制详解</a></p>
<p><a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/27%20%20%E5%85%B3%E4%BA%8E%E9%AB%98%E6%B0%B4%E4%BD%8D%E5%92%8CLeader%20Epoch%E7%9A%84%E8%AE%A8%E8%AE%BA.md">关于高水位和Leader Epoch的讨论</a></p>
<p><a href="https://www.cnblogs.com/koktlzz/p/14580109.html">Kafka：副本同步机制（HW&amp;Leader Epoch）</a></p>
<h3 id="6-Kafka事务原理"><a href="#6-Kafka事务原理" class="headerlink" title="6. Kafka事务原理"></a>6. Kafka事务原理</h3><blockquote>
<p>需要注意的几个点</p>
<ul>
<li>Kafka的事务机制，<strong>涉及到 Transactional producer 和 Transactional consumer</strong>, 两者配合使用，才能实现Producer端到Consumer端有且仅有一次的语义（end-to-end EOS）（而且Consumer端的下游业务也必须支持事务）</li>
<li>当然Kafka的Producer和Consumer是解耦的，也可以使用非Transactional的Consumer来消费Transactional的Producer生产的消息，但是此时就丢失了从生产者端到消费者端事务的支持</li>
<li><strong>通过事务机制，Kafka可以实现对多个Topic的多个Partition的原子性写入</strong>，即处于同一个事务内的所有消息，不管最终需要落地到哪个Topic的哪个Partition，最终结果都是要么全部写成功，要么全部写失败</li>
<li>Kafka的事务机制，在底层依赖于幂等性生产者，需要开启幂等性功能</li>
</ul>
</blockquote>
<p>为了支持事务机制，Kafka引入了两个新的组件：<strong>事务协调器Transaction Coordinator和Transaction log</strong></p>
<ul>
<li>事务协调器Transaction Coordinator是运行在Kafka Broker上的一个<strong>功能模块</strong>，不要和主题Topic的功能混淆</li>
<li><strong>Transaction log由一个主题<code>__transaction_state</code>实现，该主题存在多个分区，每个分区都有副本，所以就有Leader分区。</strong></li>
<li>由于Transaction Coordinator是Kafka Broker内部的一个模块，而Transaction log是Kafka中的一个内部Topic，所以Kafka能够通过内部的<strong>副本复制协议和Leader选举机制（Replication Protocol and Leader Election Processes）</strong>，来确保Transaction coordinator的可用性和事务状态Transaction state的持久性。</li>
<li>Transaction log内部主题Topic中储存的只是事务的最新状态和其相关元数据的信息，Kafka Producer生产的原始消息，仍然只是储存在Kafka Producer指定的Topic中。储存的事务状态Transaction state有：<code>Ongoing</code>、<code>Prepare commit</code>、<code>Completed</code>。</li>
</ul>
<h4 id="6-1-完整事务流程"><a href="#6-1-完整事务流程" class="headerlink" title="6.1 完整事务流程"></a>6.1 完整事务流程</h4><blockquote>
<p>事务包含两种信息：事务状态和原始消息</p>
<ul>
<li><p>事务状态记录在内部主题__transaction_state中</p>
</li>
<li><p>原始消息还是储存在用户主题中</p>
</li>
</ul>
</blockquote>
<p><img src="/2022/12/05/Kafka%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/KafkaTransaction.png" alt="img"></p>
<h4 id="6-2-生产者事务"><a href="#6-2-生产者事务" class="headerlink" title="6.2 生产者事务"></a>6.2 生产者事务</h4><blockquote>
<p>步骤标号参考&lt;完整事务流程&gt;图中的顺序标号</p>
</blockquote>
<blockquote>
<p>生产者端需要设置全局唯一Transaction ID，并且开启幂等性</p>
</blockquote>
<h5 id="6-2-1-寻找Transaction-Coordinator"><a href="#6-2-1-寻找Transaction-Coordinator" class="headerlink" title="6.2.1 寻找Transaction Coordinator"></a>6.2.1 寻找Transaction Coordinator</h5><p>Producer向任意一个Broker发送<strong>FindCoordinator请求</strong>，找到<strong>Transaction Coordinator</strong>所在的位置。</p>
<p>Broker根据生产者发送过来的<strong>Transaction ID取Hash值</strong>，并根据Hash值<strong>对__transaction_state主题的分区数</strong>取余，即<code>Hash(TID) % Partition num</code>， <strong>__transaction_state主题余数分区副本的Leader所在Broker中的Transaction Coordinator</strong>就负责该生产者的事务记录。</p>
<h5 id="6-2-2-获取PID"><a href="#6-2-2-获取PID" class="headerlink" title="6.2.2 获取PID"></a>6.2.2 获取PID</h5><blockquote>
<p>对于生产者来说，事务中需要保存两个参数，一个是PID，一个是Producer的Epoch</p>
</blockquote>
<p>Producer向Transaction Coordinator发送<strong>InitPidRequest请求</strong>以获取PID，该行为是同步阻塞的，会等待Kafka处理完异常的事务再返回。如果Transaction Coordinator是第一次收到包含该Transaction ID的InitPidRequest请求，它会<strong>将&lt;Transaction ID, PID&gt;存入到Transaction Log中，从而保证对应的关系被持久化</strong>，即使Producer或者Broker宕机也能根据TID返回一样的PID。此外，<strong>每个PID还维护着一个Epoch，Epoch也会返回给Producer</strong>。</p>
<p>每次Producer发送InitPidRequest请求时（就是建立Session的时候，只会执行一次），<strong>Transaction Coordinator会递增该PID对应的Epoch</strong>，并完成以下操作</p>
<ul>
<li>具有相同PID，但Epoch小于最新Epoch的其他僵尸Producer新开启的事务都会被拒绝（屏蔽僵尸Producer对事务的影响）</li>
<li>Commit或者Abort之前Producer未完成的事务</li>
</ul>
<h5 id="6-2-3-开启事务"><a href="#6-2-3-开启事务" class="headerlink" title="6.2.3 开启事务"></a>6.2.3 开启事务</h5><p>Kafka从0.11.0.0版本开始，提供<code>beginTransaction()</code>方法用于开启一个事务。<strong>调用该方法后，Producer本地会记录已经开启了事务，但<code>Transaction Coordinator</code>只有在Producer发送第一条消息后才认为事务已经开启。</strong></p>
<h5 id="6-2-4-事务发送"><a href="#6-2-4-事务发送" class="headerlink" title="6.2.4 事务发送"></a>6.2.4 事务发送</h5><p>在这一个阶段包含整个事务数据处理过程，并且包含多种请求（以下按请求顺序）：</p>
<ol>
<li><strong>AddPartitionsToTxnRequest</strong>：一个Producer可能会给多个 <strong>&lt;Topic, Partition&gt;</strong> 发送数据，在此之前，它需要先向Transaction Coordinator发送<code>AddPartitionsToTxnRequest</code>请求。Transaction Coordinator会将该 <strong>&lt;Transaction, Topic, Partition&gt;</strong> 存于Transaction Log内，并将其状态置为BEGIN（还会有事务超时时间的设置），如流程图4.1所示。有了该信息后，我们才可以在后续步骤中为每个 <strong>&lt;Topic, Partition&gt;</strong> 设置COMMIT或者ABORT标记（如流程图5.2所示）。</li>
<li><strong>ProduceRequest</strong>：就是生产者实际需要发送的消息，除了Topic、Partition、Key、Value的数据，该请求还包含了<strong>PID、Epoch、SeqNumber</strong>。（流程图4.2所示）</li>
<li><strong>AddOffsetsToTxnRequest</strong>：<code>sendOffsetsToTransaction</code>方法能够将<strong>多组消息的发送和消费放入同一批处理内</strong>，该方法会先判断当前事务中是否传入了相同的Group ID，如果是，则到下一个请求，不会发出<strong>AddOffsetsToTxnRequest</strong>请求；否则，生产者会向Transaction Coordinator发送<strong>AddOffsetsToTxnRequest</strong>请求，事务协调器会将<strong>事务中所有的&lt;Topic, Partition&gt;</strong> 存于Transaction Log中，并将其状态记为BEGIN，流程图4.3所示。</li>
<li><strong>TxnOffsetCommitRequest</strong>：Producer发送<strong>TxnOffsetCommitRequest</strong>请求给<strong>Consumer Coordinator</strong>，从而将本事务中包含的<strong>读操作相关</strong>的各个&lt;Topic， Partition&gt;的Offset持久化到内部的 <strong>__consumer_offsets主题</strong>中，如流程图4.4所示。<strong>Consumer Coordinator</strong>会通过PID和对应的epoch来验证是否允许该Producer的请求。<ul>
<li>写入 <strong>__consumer_offsets</strong>的Offset信息在当前事务Commit前对外是不可见的。也即在当前事务被Commit前，可认为该Offset尚未Commit，也即对应的消息尚未被完成处理。</li>
<li><strong>Consumer Coordinator</strong>并不会立即更新缓存中相应 <strong>&lt;Topic, Partition&gt;</strong> 的Offset，因为此时这些更新操作尚未被COMMIT或ABORT。</li>
</ul>
</li>
</ol>
<h5 id="6-2-5-Commit或Abort事务"><a href="#6-2-5-Commit或Abort事务" class="headerlink" title="6.2.5 Commit或Abort事务"></a>6.2.5 Commit或Abort事务</h5><blockquote>
<p> 数据写入完成之后，需要对事务进行Commit或者是Abort</p>
</blockquote>
<blockquote>
<p>Commit事务能够使得Producer写入的数据对下游Consumer可见；Abort事务能够使得Producer产生的数据对READ_COMMITTED等级的下游Consumer不可见</p>
</blockquote>
<p>Producer会发送<strong>EndTxnRequest</strong>请求，随后Transaction Coordinator会执行以下操作：</p>
<ul>
<li>向Transaction Log中写入<strong>PREPARE_COMMIT或者PREPARE_ABORT</strong>，流程图中5.1所示</li>
<li>事务协调器发出<strong>WriteTxnMarkerRequest</strong>请求至事务涉及到的各个分区的Leader，<strong>将COMMIT或ABORT信息以Transaction Marker的形式写入至用户数据日志以及Offset Log（__consumer_offsets）中</strong>，流程图5.2所示</li>
<li>待所有<strong>WriteTxnMarkerRequest</strong>请求响应后，事务协调器将<strong>COMPLETE_COMMIT或COMPLETE_ABORT信息</strong>写入Transaction Log中，表明该事务结束，流程图5.3所示（这个时候Transaction Log中关于该事务的消息都可以被移除，因为事务日志是以主题的方式储存的，所以也是会被定期删除）（<strong>COMPLETE_COMMIT或COMPLETE_ABORT信息的写入不需要等到所有副本的ACK，因为如果消息丢失，可以根据事务协议重发</strong>）</li>
</ul>
<h4 id="6-3-消费者事务"><a href="#6-3-消费者事务" class="headerlink" title="6.3 消费者事务"></a>6.3 消费者事务</h4><p>Kafka 消费者消费消息时可以指定具体的读隔离级别，当指定使用 read_committed 隔离级别时，在内部会使用存储在目标 topic-partition 中的 事务控制消息，来过滤掉没有提交的消息，包括回滚的消息和尚未提交的消息。</p>
<p>需要注意的是，过滤消息时，Kafka consumer 不需要跟 transactional coordinator 进行 rpc 交互，因为 topic 中存储的消息，包括正常的数据消息和控制消息，包含了足够的元数据信息来支持消息过滤。Kafka 消费者消费消息时也可以指定使用 read_uncommitted 隔离级别，此时目标 topic-partition 中的所有消息都会被返回，不会进行过滤。</p>
]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubeadm安装Kubernetes v1.26.1集群</title>
    <url>/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/</url>
    <content><![CDATA[<h2 id="1-版本信息"><a href="#1-版本信息" class="headerlink" title="1. 版本信息"></a>1. 版本信息</h2><table>
<thead>
<tr>
<th>软件名称</th>
<th>版本号</th>
</tr>
</thead>
<tbody><tr>
<td>Oracle Virtual Box</td>
<td>6.1.40 r154048 (Qt5.6.2)</td>
</tr>
<tr>
<td>iKuai 路由 ISO</td>
<td>3.6.3 x32 Build202204071133</td>
</tr>
<tr>
<td>CentOS7 系统 ISO</td>
<td>CentOS-7-x86_64-DVD-2009</td>
</tr>
<tr>
<td>containerd</td>
<td>github.com&#x2F;containerd&#x2F;containerd v1.6.15</td>
</tr>
<tr>
<td>runc</td>
<td>version 1.1.4</td>
</tr>
<tr>
<td>Kubernetes</td>
<td>v1.26.1</td>
</tr>
<tr>
<td>Calico</td>
<td>v3.25.0</td>
</tr>
<tr>
<td>Kubernetes Dashboard</td>
<td>v2.7.0</td>
</tr>
<tr>
<td>Kube-Prometheus</td>
<td>v0.12.0</td>
</tr>
<tr>
<td>Helm</td>
<td>v3.11.0</td>
</tr>
</tbody></table>
<h2 id="2-网络拓补"><a href="#2-网络拓补" class="headerlink" title="2. 网络拓补"></a>2. 网络拓补</h2><blockquote>
<p>网关包含两张网卡，一张用于内部局域网，一张用于万维网。</p>
</blockquote>
<table>
<thead>
<tr>
<th>名称</th>
<th>地址</th>
</tr>
</thead>
<tbody><tr>
<td>网关</td>
<td>192.168.137.80</td>
</tr>
<tr>
<td>master节点</td>
<td>192.168.137.81</td>
</tr>
<tr>
<td>node1节点</td>
<td>192.168.137.82</td>
</tr>
<tr>
<td>node2节点</td>
<td>192.168.137.83</td>
</tr>
</tbody></table>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230124232330494.png" alt="image-20230124232330494"></p>
<h2 id="3-虚拟机准备"><a href="#3-虚拟机准备" class="headerlink" title="3. 虚拟机准备"></a>3. 虚拟机准备</h2><h3 id="3-1-安装网关"><a href="#3-1-安装网关" class="headerlink" title="3.1 安装网关"></a>3.1 安装网关</h3><blockquote>
<p>网关需要设置两张网卡，连接方式分别是<strong>仅主机（Host-only）网络</strong>、<strong>网络地址转换NAT</strong>。其中仅主机（Host-only）网络用于与 k8s 集群虚机通信，NAT 网络用于访问外部网络。</p>
</blockquote>
<blockquote>
<p> 安装 ikuai 路由系统作为三台 k8s 虚拟机访问公网的出口，镜像文件从 <a href="https://www.ikuai8.com/component/download/">官网下载</a> 32位的镜像安装。</p>
</blockquote>
<blockquote>
<p> 路由虚拟机的规格设置成 <strong>1核1G内存</strong> 即可，因为只是用来做路由的，所以不需要太多的资源。</p>
</blockquote>
<blockquote>
<p> 注意虚拟机设置的时候需要开启 <strong>启用 PAE&#x2F;NX</strong>，设置路径在<code>设置-&gt;系统-&gt;处理器-&gt;扩展特性</code>。</p>
</blockquote>
<table>
<thead>
<tr>
<th>设备信息</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>CPU</td>
<td>1核</td>
</tr>
<tr>
<td>内存</td>
<td>1GB</td>
</tr>
<tr>
<td>磁盘大小</td>
<td>8GB</td>
</tr>
<tr>
<td>网卡1</td>
<td>MAC地址（08:00:27:CD:60:A8），NAT网络</td>
</tr>
<tr>
<td>网卡2</td>
<td>MAC地址（08:00:27:82:03:22），Host-Only网络</td>
</tr>
<tr>
<td>启用 PAE&#x2F;NX</td>
<td>设置路径<code>设置-&gt;系统-&gt;处理器-&gt;扩展特性</code></td>
</tr>
</tbody></table>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230119163334424.png" alt="image-20230119163334424"></p>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230119163722195.png" alt="image-20230119163722195"></p>
<h4 id="3-1-1-网关配置"><a href="#3-1-1-网关配置" class="headerlink" title="3.1.1 网关配置"></a>3.1.1 网关配置</h4><ol>
<li>设置网卡绑定，将 wan1 绑定到 NAT 网络的网卡，将 lan1绑定到 Host-Only 网络的网卡。以上图为例，<code>eth0 08:00:27:CD:60:A8</code>的网卡为 NAT 网络，<code>eth1 08:00:27:82:03:22</code>的网卡为 Host-Only 网络。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输入菜单编号：1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">set</span> wan1 eth0 <span class="comment"># 设置完 wan1 之后，就能够ping 通百度</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">set</span> lan1 eth1</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>设置 LAN 地址，即 Host-Only 网络的地址。<strong>注意，设置的地址要在 Host-Only 网络的网段内。不清楚所在网段，可以通过<code>ipconfig -all</code>命令查找VirtualBox Host-Only Ethernet Adapter网卡的信息</strong>。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ipconfig -all</span></span><br><span class="line">以太网适配器 以太网 4:</span><br><span class="line">   连接特定的 DNS 后缀 . . . . . . . :</span><br><span class="line">   描述. . . . . . . . . . . . . . . : VirtualBox Host-Only Ethernet Adapter</span><br><span class="line">   物理地址. . . . . . . . . . . . . : 0A-00-27-00-00-14</span><br><span class="line">   DHCP 已启用 . . . . . . . . . . . : 否</span><br><span class="line">   自动配置已启用. . . . . . . . . . : 是</span><br><span class="line">   本地链接 IPv6 地址. . . . . . . . : fe80::bb9d:751f:f896:d3b1%20(首选)</span><br><span class="line">   IPv4 地址 . . . . . . . . . . . . : 192.168.137.1(首选)   # 网段信息</span><br><span class="line">   子网掩码  . . . . . . . . . . . . : 255.255.255.0         # 网段信息</span><br><span class="line">   默认网关. . . . . . . . . . . . . :</span><br><span class="line">   DHCPv6 IAID . . . . . . . . . . . : 201981991</span><br><span class="line">   DHCPv6 客户端 DUID  . . . . . . . : 00-01-00-01-2A-D3-D5-99-E4-B9-7A-9A-15-DC</span><br><span class="line">   DNS 服务器  . . . . . . . . . . . : fec0:0:0:ffff::1%1</span><br><span class="line">                                       fec0:0:0:ffff::2%1</span><br><span class="line">                                       fec0:0:0:ffff::3%1</span><br><span class="line">   TCPIP 上的 NetBIOS  . . . . . . . : 已启用</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输入菜单编号：2    选择 设置LAN/WAN地址</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输入菜单编号：0    选择 设置LAN1地址</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">请输入lan1地址：192.168.137.80/255.255.255.0</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>设置完成后，即能够在本地主机上访问 Web 管理地址（用户名&#x2F;密码：admin&#x2F;admin）。</li>
</ol>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230119171403828.png" alt="image-20230119171403828"></p>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230119171242386.png" alt="image-20230119171242386"></p>
<h3 id="3-2-安装CentOS7"><a href="#3-2-安装CentOS7" class="headerlink" title="3.2 安装CentOS7"></a>3.2 安装CentOS7</h3><blockquote>
<p>!!!特别注意，在虚拟机网卡设置中<strong>必须要允许混杂模式</strong>，设置路径：<code>选择虚机-&gt;设置-&gt;网络-&gt;选择网卡-&gt;混杂模式-&gt;全部允许</code>。</p>
<p>允许混杂模式作用是当虚机网卡接收到目的地址不是自己IP地址的数据包，也允许交到Linux内核判断是否需要处理，否则数据包会直接在虚机层面被丢弃。</p>
</blockquote>
<blockquote>
<p>安装没有太多特别的操作，注意 k8s 要求机器至少为 <strong>2核2G内存</strong>。</p>
<p>使用最小化安装 CentOS即可，只需要用到命令行界面。</p>
</blockquote>
<table>
<thead>
<tr>
<th>设备信息</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>CPU</td>
<td>master节点为 4 核，node节点为 3 核</td>
</tr>
<tr>
<td>内存</td>
<td>master节点为 4GB，node节点为 3GB</td>
</tr>
<tr>
<td>磁盘大小</td>
<td>100GB</td>
</tr>
<tr>
<td>网卡1</td>
<td>Host-Only 网络</td>
</tr>
</tbody></table>
<ul>
<li>master 节点</li>
</ul>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230124233251532.png" alt="image-20230124233251532"></p>
<ul>
<li>node1 节点</li>
</ul>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230124233336642.png" alt="image-20230124233336642"></p>
<ul>
<li>node2 节点</li>
</ul>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230124233509813.png" alt="image-20230124233509813"></p>
<h4 id="3-2-1-网络配置"><a href="#3-2-1-网络配置" class="headerlink" title="3.2.1 网络配置"></a>3.2.1 网络配置</h4><blockquote>
<p>配置三台虚拟机的静态 IP 地址，并且将网关地址指向 ikuai 路由的 Host-Only 网络地址。</p>
</blockquote>
<blockquote>
<p>因为三台虚机使用的也是 Host-Only 网络，因此 IP 地址也必须在 Host-Only 网络网段。</p>
</blockquote>
<table>
<thead>
<tr>
<th>节点</th>
<th>IP 地址</th>
</tr>
</thead>
<tbody><tr>
<td>master</td>
<td>192.168.137.81&#x2F;24</td>
</tr>
<tr>
<td>node1</td>
<td>192.168.137.82&#x2F;24</td>
</tr>
<tr>
<td>node2</td>
<td>192.168.137.83&#x2F;24</td>
</tr>
<tr>
<td>网关</td>
<td>192.168.137.80</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">编辑master网络配置文件</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">不同网卡可能设备名称不一样，需要自己修改对应的配置文件，这里机器的设备名是enp0s3</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo vi /etc/sysconfig/network-scripts/ifcfg-enp0s3</span></span><br><span class="line">TYPE=Ethernet                 # 网卡类型：为以太网</span><br><span class="line">PROXY_METHOD=none             # 代理方式：关闭状态</span><br><span class="line">BROWSER_ONLY=no               # 只是浏览器：否</span><br><span class="line">BOOTPROTO=static              # 网卡的引导协议：DHCP/static</span><br><span class="line">DEFROUTE=yes                  # 默认路由：是</span><br><span class="line">IPV4_FAILURE_FATAL=no         # 是不开启IPV4致命错误检测：否</span><br><span class="line">IPV6INIT=yes                  # IPV6是否自动初始化: 是[不会有任何影响, 现在还没用到IPV6]</span><br><span class="line">IPV6_AUTOCONF=yes             # IPV6是否自动配置：是[不会有任何影响, 现在还没用到IPV6]</span><br><span class="line">IPV6_DEFROUTE=yes             # IPV6是否可以为默认路由：是[不会有任何影响, 现在还没用到IPV6]</span><br><span class="line">IPV6_FAILURE_FATAL=no         # 是不开启IPV6致命错误检测：否</span><br><span class="line">IPV6_ADDR_GEN_MODE=stable-privacy  # IPV6地址生成模型：stable-privacy [这只一种生成IPV6的策略]</span><br><span class="line">NAME=enp0s3                   # 网卡物理设备名称</span><br><span class="line">UUID=8e65b860-dd77-42e3-ba16-d26790ec6e2d  # 通用唯一识别码, 每一个网卡都会有</span><br><span class="line">DEVICE=enp0s3                 # 网卡设备名称, 必须和 `NAME` 值一样</span><br><span class="line">ONBOOT=yes                    # 是否开机启动</span><br><span class="line">IPADDR=192.168.137.81         # IPv4地址</span><br><span class="line">NETMASK=255.255.255.0         # 子网掩码</span><br><span class="line">GATEWAY=192.168.137.80        # 网关地址</span><br><span class="line">DNS1=8.8.8.8                  # DNS1设置，其实这里DNS也可以设置成ikuai网关的地址，不过需要在ikuai管理界面开启DNS加速服务并设置为UDP代理模式</span><br><span class="line">DNS2=8.8.8.8                  # DNS2设置</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启网络</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl restart network</span></span><br></pre></td></tr></table></figure>



<h2 id="4-前期准备"><a href="#4-前期准备" class="headerlink" title="4. 前期准备"></a>4. 前期准备</h2><blockquote>
<p>k8s对主机有硬性要求：</p>
<ul>
<li>至少 2核2GB内存</li>
<li>每台主机的 hostname、MAC地址、product_uuid都是唯一的</li>
<li>关闭 SWAP 功能</li>
<li>开放 k8s 用到的网络端口</li>
</ul>
</blockquote>
<h3 id="4-1-检查内核版本（必须）"><a href="#4-1-检查内核版本（必须）" class="headerlink" title="4.1 检查内核版本（必须）"></a>4.1 检查内核版本（必须）</h3><blockquote>
<p>由于使用 containerd 作为底层 CRI，而 containerd 要求 Linux 内核版本在 3.10 以上。</p>
</blockquote>
<ol>
<li>查看内核版本</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">内核版本为 3.10.0-1160.el7.x86_64</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">uname</span> -a</span></span><br><span class="line">Linux localhost.localdomain 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>载入ELRepo公钥</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>安装ELRepo仓库</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>载入 elrepo-kernel 元数据</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum --disablerepo=\* --enablerepo=elrepo-kernel repolist</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>查看可用的 rpm 内核包</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">lt: long term support 长期支持版本</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ml: main-line         主线版本</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum --disablerepo=\* --enablerepo=elrepo-kernel list kernel*</span></span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * elrepo-kernel: hkg.mirror.rackspace.com</span><br><span class="line">Installed Packages</span><br><span class="line">kernel.x86_64                           3.10.0-1160.el7                    @anaconda    </span><br><span class="line">kernel-tools.x86_64                     3.10.0-1160.el7                    @anaconda    </span><br><span class="line">kernel-tools-libs.x86_64                3.10.0-1160.el7                    @anaconda    </span><br><span class="line">Available Packages</span><br><span class="line">kernel-lt.x86_64                        5.4.229-1.el7.elrepo               elrepo-kernel   # 安装内核版本</span><br><span class="line">kernel-lt-devel.x86_64                  5.4.229-1.el7.elrepo               elrepo-kernel</span><br><span class="line">kernel-lt-doc.noarch                    5.4.229-1.el7.elrepo               elrepo-kernel</span><br><span class="line">kernel-lt-headers.x86_64                5.4.229-1.el7.elrepo               elrepo-kernel</span><br><span class="line">kernel-lt-tools.x86_64                  5.4.229-1.el7.elrepo               elrepo-kernel</span><br><span class="line">kernel-lt-tools-libs.x86_64             5.4.229-1.el7.elrepo               elrepo-kernel</span><br><span class="line">kernel-lt-tools-libs-devel.x86_64       5.4.229-1.el7.elrepo               elrepo-kernel</span><br><span class="line">kernel-ml.x86_64                        6.1.7-1.el7.elrepo                 elrepo-kernel</span><br><span class="line">kernel-ml-devel.x86_64                  6.1.7-1.el7.elrepo                 elrepo-kernel</span><br><span class="line">kernel-ml-doc.noarch                    6.1.7-1.el7.elrepo                 elrepo-kernel</span><br><span class="line">kernel-ml-headers.x86_64                6.1.7-1.el7.elrepo                 elrepo-kernel</span><br><span class="line">kernel-ml-tools.x86_64                  6.1.7-1.el7.elrepo                 elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs.x86_64             6.1.7-1.el7.elrepo                 elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs-devel.x86_64       6.1.7-1.el7.elrepo                 elrepo-kernel</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>安装相应版本的内核</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum --disablerepo=\* --enablerepo=elrepo-kernel install  kernel-lt.x86_64  -y</span></span><br></pre></td></tr></table></figure>

<ol start="7">
<li>删除旧版本内核工具包</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64  -y</span></span><br></pre></td></tr></table></figure>

<ol start="8">
<li>安装新版本内核工具包</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum --disablerepo=\* --enablerepo=elrepo-kernel install kernel-lt-tools.x86_64  -y</span></span><br></pre></td></tr></table></figure>

<ol start="9">
<li>查看内核插入顺序</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">默认新内核是从头插入，默认启动顺序也是从 0 开始（当前顺序还未生效）</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo awk -F \<span class="string">&#x27; &#x27;</span><span class="variable">$1</span>==<span class="string">&quot;menuentry &quot;</span> &#123;<span class="built_in">print</span> i++ <span class="string">&quot; : &quot;</span> <span class="variable">$2</span>&#125;<span class="string">&#x27; /etc/grub2.cfg</span></span></span><br><span class="line">0 : CentOS Linux (4.20.12-1.el7.elrepo.x86_64) 7 (Core)</span><br><span class="line">1 : CentOS Linux (3.10.0-957.5.1.el7.x86_64) 7 (Core)</span><br><span class="line">2 : CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core)</span><br><span class="line">3 : CentOS Linux (0-rescue-ca0f6fb3c5f24478abc0a2e275281d7a) 7 (Core)</span><br></pre></td></tr></table></figure>

<ol start="10">
<li>查看当前实际启动顺序</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到默认使用的还是旧内核</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo grub2-editenv list</span></span><br><span class="line">saved_entry=CentOS Linux (3.10.0-1160.el7.x86_64) 7 (Core)</span><br></pre></td></tr></table></figure>

<ol start="11">
<li>设置启动时默认使用新内核</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">0 表示 /etc/grub2.cfg 文件中的 0 : CentOS Linux (4.20.12-1.el7.elrepo.x86_64) 7 (Core)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">也可以使用 sudo grub2-set-default CentOS Linux (4.20.12-1.el7.elrepo.x86_64) 7 (Core) 指定</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo grub2-set-default 0</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo grub2-editenv list</span></span><br><span class="line">saved_entry=0</span><br></pre></td></tr></table></figure>

<ol start="12">
<li>重启并检查是否已经使用新内核</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">reboot</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">uname</span> -r</span></span><br><span class="line">5.4.229-1.el7.elrepo.x86_64</span><br></pre></td></tr></table></figure>

<ol start="13">
<li>确认能够重启成功后，就能够把就内核删除。重启时，GRUB中多余的启动项也就不见了</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">列出已安装的内核</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">rpm -qa | grep kernel</span></span><br><span class="line">kernel-3.10.0-1160.el7.x86_64</span><br><span class="line">kernel-lt-5.4.229-1.el7.elrepo.x86_64</span><br><span class="line">kernel-lt-tools-5.4.229-1.el7.elrepo.x86_64</span><br><span class="line">kernel-lt-tools-libs-5.4.229-1.el7.elrepo.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除旧内核</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum remove kernel-3.10.0-1160.el7.x86_64 -y</span></span><br></pre></td></tr></table></figure>



<h3 id="4-2配置Hostname（必须）"><a href="#4-2配置Hostname（必须）" class="headerlink" title="4.2配置Hostname（必须）"></a>4.2配置Hostname（必须）</h3><blockquote>
<p>k8s 会将主机的 hostname 作为节点的名称，所以不同节点的 hostname 需要不同。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在master主机上执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hostnamectl set-hostname k8s-master01</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在node1主机上执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hostnamectl set-hostname k8s-node01</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在node2主机上执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hostnamectl set-hostname k8s-node02</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看hostname</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hostname</span></span><br></pre></td></tr></table></figure>

<p>编辑 host 文件，使得各台主机间能够通过 hostname 访问（如果有自己搭建的 DNS 解析就可以不配）。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo vi /etc/hosts</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.137.81 k8s-master01</span><br><span class="line">192.168.137.82 k8s-node01</span><br><span class="line">192.168.137.83 k8s-node02</span><br></pre></td></tr></table></figure>



<h3 id="4-3-确认MAC地址及product-uuid（必须）"><a href="#4-3-确认MAC地址及product-uuid（必须）" class="headerlink" title="4.3 确认MAC地址及product_uuid（必须）"></a>4.3 确认MAC地址及product_uuid（必须）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确保 MAC 地址不同</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 08:00:27:d2:2a:9c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.137.81/24 brd 192.168.137.255 scope global noprefixroute enp0s3</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::604b:c311:f2b:89f8/64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确保每台机器 product_uuid 不同</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cat</span> /sys/class/dmi/id/product_uuid</span></span><br><span class="line">ca04e099-d4d9-8848-8cba-d2ae5af25dd3</span><br></pre></td></tr></table></figure>



<h3 id="4-4-关闭-SWAP（必须）"><a href="#4-4-关闭-SWAP（必须）" class="headerlink" title="4.4 关闭 SWAP（必须）"></a>4.4 关闭 SWAP（必须）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到主机上是有使用swap的</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">free -h</span></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           2.9G        140M        2.6G        8.5M        171M        2.6G</span><br><span class="line">Swap:          3.0G          0B        3.0G</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭 swap</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">取消 swap 挂载的时候会将 swap 内网逐步复制到内存中，swap 占用越大需要的时间越长</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo swapoff -a</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">永久关闭 swap，编辑/etc/fstab 文件注释掉swap</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo vi /etc/fstab</span></span><br><span class="line">/dev/mapper/centos-root /                       xfs     defaults        0 0</span><br><span class="line">UUID=651682c7-3cc0-40fd-99ea-0cfa9ae147be /boot xfs     defaults        0 0</span><br><span class="line">/dev/mapper/centos-home /home                   xfs     defaults        0 0</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 swap 挂载情况，没有输出则表明已经没有 swap 挂载</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">swapon -s</span></span><br></pre></td></tr></table></figure>



<h3 id="4-5-放通-iptables-及安装IPVS（必须）"><a href="#4-5-放通-iptables-及安装IPVS（必须）" class="headerlink" title="4.5 放通 iptables 及安装IPVS（必须）"></a>4.5 放通 iptables 及安装IPVS（必须）</h3><blockquote>
<p>如果没有安装 IPVS（IP Virtual Server），k8s 默认使用的是 iptables，性能方面有一点影响。</p>
</blockquote>
<ol>
<li>设置防火墙为iptables并且设置规则为空（即放通所有）。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install iptables iptables-services -y</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl start iptables</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl <span class="built_in">enable</span> iptables</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo iptables -F   <span class="comment"># 清空规则</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo service iptables save  <span class="comment"># 保存iptables配置</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到规则为空</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo iptables -L</span></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination  </span><br></pre></td></tr></table></figure>

<ol start="2">
<li>安装 IPVS 相关依赖包。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y ipvsadm ipset</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>添加 kube-proxy 需要 ipvs 加载的模块至脚本中。<a href="https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md">kube-proxy 使用 ipvs 模式要求</a>。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">内核4.19之前是 nf_conntrack_ipv4</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">内核4.19之后是 nf_conntrack</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/sysconfig/modules/ipvs.modules</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="string">!/bin/bash</span></span></span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">添加执行权限</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo chmod +x /etc/sysconfig/modules/ipvs.modules</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">执行脚本</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo /bin/bash /etc/sysconfig/modules/ipvs.modules</span></span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>查看对应模块是否已经加载成功。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsmod | grep -e ip_vs -e nf_conntrack</span></span><br><span class="line">ip_vs_sh               16384  0 </span><br><span class="line">ip_vs_wrr              16384  0 </span><br><span class="line">ip_vs_rr               16384  0 </span><br><span class="line">ip_vs                 155648  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class="line">nf_conntrack          147456  2 xt_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class="line">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class="line">libcrc32c              16384  3 nf_conntrack,xfs,ip_vs</span><br></pre></td></tr></table></figure>



<h3 id="4-6-设置时间同步服务器（可选）"><a href="#4-6-设置时间同步服务器（可选）" class="headerlink" title="4.6 设置时间同步服务器（可选）"></a>4.6 设置时间同步服务器（可选）</h3><blockquote>
<p>如果有条件的可以在 k8s 集群中设置 ntp 服务器，这样就不用依赖外部的时间同步服务器了。</p>
</blockquote>
<ol>
<li>安装相关软件包。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y ntp ntpdate</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>设置时区</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">timedatectl list-timezones | grep -i shang</span></span><br><span class="line">Asia/Shanghai</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo timedatectl set-timezone Asia/Shanghai</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>编辑 master 节点主机 ntp 配置文件。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在master主机中执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo vi /etc/chrony.conf</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">server 0.centos.pool.ntp.org iburst  注释掉</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">server 1.centos.pool.ntp.org iburst  注释掉</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">server 2.centos.pool.ntp.org iburst  注释掉</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">server 3.centos.pool.ntp.org iburst  注释掉</span></span><br><span class="line">server ntp1.aliyun.com iburst</span><br><span class="line">server ntp2.aliyun.com iburst</span><br><span class="line">server ntp3.aliyun.com iburst</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">允许本地网段从本主机同步时间</span></span><br><span class="line">allow 192.168.137.0/24</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置本主机时间的权重</span></span><br><span class="line">local stratum 10</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>设置 node 节点从 master 节点中同步时间。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在node1、node2主机上执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo vi /etc/chrony.conf</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">server 0.centos.pool.ntp.org iburst  注释掉</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">server 1.centos.pool.ntp.org iburst  注释掉</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">server 2.centos.pool.ntp.org iburst  注释掉</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">server 3.centos.pool.ntp.org iburst  注释掉</span></span><br><span class="line">server 192.168.137.81 iburst</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>在所有机器上重启 ntp 服务，并设置开机自启动。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl restart chronyd</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl <span class="built_in">enable</span> chronyd</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">写入硬件时钟</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">timedatectl set-local-rtc 0</span></span><br></pre></td></tr></table></figure>



<h3 id="4-7-关闭SELinux和防火墙（可选）"><a href="#4-7-关闭SELinux和防火墙（可选）" class="headerlink" title="4.7 关闭SELinux和防火墙（可选）"></a>4.7 关闭SELinux和防火墙（可选）</h3><blockquote>
<p>也可以选择放通 k8s 集群需要用到的端口，用到的端口可以在<a href="https://kubernetes.io/docs/reference/networking/ports-and-protocols/">官网</a>中查到</p>
</blockquote>
<h4 id="4-7-1-关闭-SELinux"><a href="#4-7-1-关闭-SELinux" class="headerlink" title="4.7.1 关闭 SELinux"></a>4.7.1 关闭 SELinux</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 SELinux 运行状态，Enforcing 表明已开启</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">getenforce</span></span><br><span class="line">Enforcing</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置文件永久关闭 SELinux</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo sed -i <span class="string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/&#x27;</span> /etc/selinux/config</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">因为修改配置文件要重启才生效，而可以使用 setenforce 0 临时关闭 SELinux</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo setenforce 0</span></span><br></pre></td></tr></table></figure>

<h4 id="4-7-2-关闭防火墙"><a href="#4-7-2-关闭防火墙" class="headerlink" title="4.7.2 关闭防火墙"></a>4.7.2 关闭防火墙</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看防火墙状态</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl status firewalld</span></span><br><span class="line">● firewalld.service - firewalld - dynamic firewall daemon</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: active (running) since Fri 2023-01-20 00:27:43 EST; 1h 2min ago</span><br><span class="line">     Docs: man:firewalld(1)</span><br><span class="line"> Main PID: 739 (firewalld)</span><br><span class="line">   CGroup: /system.slice/firewalld.service</span><br><span class="line">           └─739 /usr/bin/python2 -Es /usr/sbin/firewalld --nofork --nopid</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭防火墙</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl stop firewalld</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">取消开机自启动</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl <span class="built_in">disable</span> firewalld</span></span><br></pre></td></tr></table></figure>



<h3 id="4-8-修改YUM镜像源（可选）"><a href="#4-8-修改YUM镜像源（可选）" class="headerlink" title="4.8 修改YUM镜像源（可选）"></a>4.8 修改YUM镜像源（可选）</h3><blockquote>
<p>这里提供两个开源镜像站，只需要选择其中一个修改即可。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先备份原本镜像配置文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -R /etc/yum.repos.d /etc/yum.repos.d.bak</span></span><br></pre></td></tr></table></figure>

<h4 id="4-8-1-清华大学开源镜像站"><a href="#4-8-1-清华大学开源镜像站" class="headerlink" title="4.8.1 清华大学开源镜像站"></a>4.8.1 清华大学开源镜像站</h4><blockquote>
<p><a href="https://mirrors.tuna.tsinghua.edu.cn/">清华大学开源软件镜像站官网</a></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 7</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo sed -e <span class="string">&#x27;s|^mirrorlist=|#mirrorlist=|g&#x27;</span> \</span></span><br><span class="line"><span class="language-bash">         -e <span class="string">&#x27;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g&#x27;</span> \</span></span><br><span class="line"><span class="language-bash">         -i.bak \</span></span><br><span class="line"><span class="language-bash">         /etc/yum.repos.d/CentOS-*.repo</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">更新软件包缓存</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum makecache</span></span><br></pre></td></tr></table></figure>

<h4 id="4-8-2-阿里巴巴开源镜像站"><a href="#4-8-2-阿里巴巴开源镜像站" class="headerlink" title="4.8.2 阿里巴巴开源镜像站"></a>4.8.2 阿里巴巴开源镜像站</h4><blockquote>
<p><a href="https://developer.aliyun.com/mirror/">阿里巴巴开源镜像站官网</a>，吐槽一句阿里的官方帮助文档没有清华大学的写得好。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">对于 CentOS 7</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo sed -i -e <span class="string">&#x27;/mirrors.cloud.aliyuncs.com/d&#x27;</span> -e <span class="string">&#x27;/mirrors.aliyuncs.com/d&#x27;</span> /etc/yum.repos.d/CentOS-Base.repo</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">更新软件包缓存</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum makecache</span></span><br></pre></td></tr></table></figure>



<h2 id="5-Kubernetes-集群部署"><a href="#5-Kubernetes-集群部署" class="headerlink" title="5. Kubernetes 集群部署"></a>5. Kubernetes 集群部署</h2><blockquote>
<p>k8s 集群部署麻烦的点在于谷歌官方提供的镜像地址被墙了，所以无法直接安装。但是可以先在 cri 容器运行时中先把镜像下下来，然后重新打 tag，就能够正常安装 k8s。</p>
</blockquote>
<h3 id="5-1-容器运行时-CRI"><a href="#5-1-容器运行时-CRI" class="headerlink" title="5.1 容器运行时 CRI"></a>5.1 容器运行时 CRI</h3><blockquote>
<p>containerd 是从 Docker 项目中分离出来的，被捐赠给 CNCF，实现了 CRI（Container Runtime Interface）规范，为容器社区提供创建新容器解决方案的基础。</p>
</blockquote>
<blockquote>
<p>OCI (Open Container Initiative) 为了标准化和结构化容器接口，提出了两种规范：一种是运行时规范 (<em>runtime-spec</em>)，一种是镜像规范 (<em>image-spec</em>)。<strong>Runc 实现了 OCI 的运行时规范，负责生成和运行容器。而 OCI 的镜像规范，即镜像完整性、日志记录、容器文件系统等功能，则是由 Docker、Containerd等更高级的运行时负责。</strong>调用关系是：<code>Docker -&gt; Containerd -&gt; runC -&gt; Container</code>。</p>
</blockquote>
<blockquote>
<p>在早期的 k8s 版本中会内置一个 dockershim 组件，用于与 Docker 进行交互。但是从 Kubernetes v1.24 发行版本开始，dockershim 已经从 k8s 组件中移除，如果还想用 Docker 作为底层 CRI 的实现，需要另外安装 cri-dockerd。（但是其实安装 Docker 的时候，containerd 会一并安装，因为 Docker 底层依赖的还是 containerd）。</p>
</blockquote>
<h4 id="5-1-1-containerd-安装"><a href="#5-1-1-containerd-安装" class="headerlink" title="5.1.1 containerd 安装"></a>5.1.1 containerd 安装</h4><blockquote>
<p> CNI 插件会在 k8s 部署完之后安装的 Calico 中包含。</p>
</blockquote>
<blockquote>
<p>有两种方式安装 containerd，一种是从 Github 中下载包进行安装，一种是导入 docker-ce 的镜像仓库使用 yum 安装（安装containerd.io 包）。这里从 <a href="https://github.com/containerd/containerd/blob/main/docs/getting-started.md">containerd Github 页面</a> 中下载包进行安装。</p>
</blockquote>
<ol>
<li>安装 containerd。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ~ &amp;&amp; wget https://github.com/containerd/containerd/releases/download/v1.6.15/containerd-1.6.15-linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将文件安装到 /usr/local 目录下(不要修改安装目录，因为后续containerd.service脚本是写死安装目录的)</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo tar Czxvf /usr/local containerd-1.6.15-linux-amd64.tar.gz</span></span><br><span class="line">bin/</span><br><span class="line">bin/containerd-stress</span><br><span class="line">bin/containerd-shim</span><br><span class="line">bin/containerd-shim-runc-v1</span><br><span class="line">bin/containerd-shim-runc-v2</span><br><span class="line">bin/containerd</span><br><span class="line">bin/ctr</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>设置 containerd 服务开机自启动。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载服务配置文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ~ &amp;&amp; wget https://raw.githubusercontent.com/containerd/containerd/main/containerd.service</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">放置到/usr/lib/systemd/system 目录下</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> containerd.service /usr/lib/systemd/system/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl daemon-reload</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl start containerd</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl <span class="built_in">enable</span> containerd</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看containerd服务状态，running运行中</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl status containerd</span></span><br><span class="line">● containerd.service - containerd container runtime</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Fri 2023-01-20 21:10:25 CST; 14s ago</span><br><span class="line">     Docs: https://containerd.io</span><br><span class="line"> Main PID: 3857 (containerd)</span><br><span class="line">   CGroup: /system.slice/containerd.service</span><br><span class="line">           └─3857 /usr/local/bin/containerd</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>安装 runc。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ~ &amp;&amp; wget https://github.com/opencontainers/runc/releases/download/v1.1.4/runc.amd64</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo install -m 755 runc.amd64 /usr/local/sbin/runc</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>检查是否安装成功。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ctr --version</span></span><br><span class="line">ctr github.com/containerd/containerd v1.6.15</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">要用/usr/local/bin/ctr路径，因为root的PATH变量没有/usr/local</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">此外，因为/run/containerd/containerd.sock的权限是 srw-rw---- 1 root root</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所以要用root用户才有权限连接，否则会出现transport: error <span class="keyword">while</span> dialing: dial unix /run/containerd/containerd.sock: connect: permission denied</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo /usr/local/bin/ctr image <span class="built_in">ls</span></span></span><br><span class="line">REF TYPE DIGEST SIZE PLATFORMS LABELS</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>生成 containerd 的配置文件。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">mkdir</span> /etc/containerd -p</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /usr/local/bin/ &amp;&amp; ./containerd config default | sudo <span class="built_in">tee</span> /etc/containerd/config.toml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo vi /etc/containerd/config.toml</span></span><br><span class="line">---</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 确保 cri 不在 disabled_plugins 列表中</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 配置 runc 使用 SystemdCgroup</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3. 修改sandbox_image</span></span><br><span class="line">disabled_plugins = []</span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc]</span><br><span class="line">  ...</span><br><span class="line">  [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">    # SystemdCgroup = false</span><br><span class="line">    SystemdCgroup = true</span><br><span class="line">    </span><br><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;]</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">sandbox_image = <span class="string">&quot;registry.k8s.io/pause:3.6&quot;</span> 这个镜像地址是被墙的</span></span><br><span class="line">  sandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.6&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>重启 containerd 服务。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">默认读取/etc/containerd/config.toml配置文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl restart containerd</span></span><br></pre></td></tr></table></figure>



<h4 id="5-1-2-内核参数配置"><a href="#5-1-2-内核参数配置" class="headerlink" title="5.1.2 内核参数配置"></a>5.1.2 内核参数配置</h4><blockquote>
<p>需要开启 br_netfilter 模块，用于将网桥的流量转发至 iptables 链。</p>
<p>网桥流量的转发会影响 k8s service 将流量转发给同一 node 上的 pod。</p>
</blockquote>
<blockquote>
<p>详细解析可以参考博客 <a href="https://blog.csdn.net/qq_43684922/article/details/127333368">k8s 中为什么需要 br_netfilter 与 net.bridge.bridge-nf-call-iptables&#x3D;1</a>。</p>
</blockquote>
<ol>
<li>加载 overlay 和 br_netfilter 模块。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">开机加载模块</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/modules-load.d/k8s.conf</span></span></span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">立即加载模块</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo modprobe overlay</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo modprobe br_netfilter</span></span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>设置内核参数，设置ipv4流量转发，且经过网桥的流量都经过 iptables 处理。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启后生效</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/sysctl.d/k8s.conf</span></span></span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">立即生效</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo sysctl --system</span></span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>验证 overlay 和 br_netfilter 模块是否已经加载运行。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsmod | grep br_netfilter</span></span><br><span class="line">br_netfilter           28672  0</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsmod | grep overlay</span></span><br><span class="line">overlay               114688  0</span><br></pre></td></tr></table></figure>



<h3 id="5-2-安装-kubeadm-kubelet-kubectl"><a href="#5-2-安装-kubeadm-kubelet-kubectl" class="headerlink" title="5.2 安装 kubeadm, kubelet, kubectl"></a>5.2 安装 kubeadm, kubelet, kubectl</h3><blockquote>
<p>由于谷歌的仓库被墙了，因此这里使用阿里云的镜像仓库</p>
</blockquote>
<ol>
<li>添加镜像仓库源。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> &lt;&lt;<span class="string">EOF | sudo tee /etc/yum.repos.d/kubernetes.repo</span></span></span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo yum makecache -y</span></span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>安装kubeadm, kubelet, kubectl。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查版本信息，可以看到当前最新版本是1.26.1</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum list kubeadm kubectl kubelet</span></span><br><span class="line">Available Packages</span><br><span class="line">kubeadm.x86_64         1.26.1-0           kubernetes</span><br><span class="line">kubectl.x86_64         1.26.1-0           kubernetes</span><br><span class="line">kubelet.x86_64         1.26.1-0           kubernetes</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">gpg 检查失败时，使用yum install -y --nogpgcheck kubelet kubeadm kubectl安装</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>设置开机启动 kubelet。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo systemctl <span class="built_in">enable</span> kubelet</span></span><br></pre></td></tr></table></figure>

<h3 id="5-3-构建-k8s-集群"><a href="#5-3-构建-k8s-集群" class="headerlink" title="5.3 构建 k8s 集群"></a>5.3 构建 k8s 集群</h3><h4 id="5-3-1-准备集群需要的镜像"><a href="#5-3-1-准备集群需要的镜像" class="headerlink" title="5.3.1 准备集群需要的镜像"></a>5.3.1 准备集群需要的镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">版本号与k8s版本号相同</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm config images list --kubernetes-version=v1.26.1</span></span><br><span class="line">registry.k8s.io/kube-apiserver:v1.26.1</span><br><span class="line">registry.k8s.io/kube-controller-manager:v1.26.1</span><br><span class="line">registry.k8s.io/kube-scheduler:v1.26.1</span><br><span class="line">registry.k8s.io/kube-proxy:v1.26.1</span><br><span class="line">registry.k8s.io/pause:3.9</span><br><span class="line">registry.k8s.io/etcd:3.5.6-0</span><br><span class="line">registry.k8s.io/coredns/coredns:v1.9.3</span><br></pre></td></tr></table></figure>

<h4 id="5-3-2-kubeadm-初始化配置"><a href="#5-3-2-kubeadm-初始化配置" class="headerlink" title="5.3.2 kubeadm 初始化配置"></a>5.3.2 kubeadm 初始化配置</h4><blockquote>
<p>其实也可以用命令行追加参数的形式配置，但是使用配置文件的方式初始化集群比较方便调试。</p>
</blockquote>
<blockquote>
<p>此外，如果需要离线安装，只需要在 containerd 中准备好 k8s 需要的镜像即可(使用 ctr 命令)。</p>
</blockquote>
<blockquote>
<p>关于 kubeadm 配置文件详情可以在<a href="https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/">kubeadm Configuration (v1beta3)</a>中查看。</p>
</blockquote>
<ol>
<li><strong>在 master 主机</strong>生成 kubeadm 默认配置文件。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubeadm config <span class="built_in">print</span> init-defaults &gt; kubeadm-config.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cat</span> kubeadm-config.yaml</span></span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef  # 有需要的话可以修改连接集群的token</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 1.2.3.4       # 集群通告地址</span><br><span class="line">  bindPort: 6443                  # apiserver端口</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: unix:///var/run/containerd/containerd.sock</span><br><span class="line">  imagePullPolicy: IfNotPresent</span><br><span class="line">  name: node                      # 节点名称</span><br><span class="line">  taints: null                    # 污点</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns: &#123;&#125;</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: registry.k8s.io  # 镜像仓库地址</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: 1.26.0        # k8s 版本 </span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/12     # 集群内部虚拟网络，Pod统一访问入口</span><br><span class="line">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>修改 kubeadm-config.yaml 配置文件。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 添加KubeletConfiguration，并配置kubelet使用systemd驱动（官方推荐）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 修改集群通告地址advertiseAddress，即node节点从哪里寻找apiserver（即master节点）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3. 修改镜像源仓库地址imageRepository</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4. 修改节点名称name</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5. 添加CNI插件地址</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">6. 修改k8s部署版本kubernetesVersion</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">7. 添加KubeProxyConfiguration配置代理模式为ipvs</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi kubeadm-config.yaml</span></span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 192.168.137.81            # 修改集群通告地址advertiseAddress</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: unix:///var/run/containerd/containerd.sock</span><br><span class="line">  imagePullPolicy: IfNotPresent</span><br><span class="line">  name: k8s-master01                          # 修改节点名称name</span><br><span class="line">  taints: null</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns: &#123;&#125;</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers  # 修改镜像源仓库地址imageRepository</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: 1.26.1                     # 修改k8s部署版本kubernetesVersion</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">  podSubnet: 10.244.0.0/16                    # 添加CNI插件地址</span><br><span class="line">scheduler: &#123;&#125;</span><br><span class="line">---</span><br><span class="line">kind: KubeletConfiguration                    # 添加KubeletConfiguration</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line">---</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeProxyConfiguration                  # 添加KubeProxyConfiguration配置代理模式为ipvs</span><br><span class="line">mode: ipvs</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>初始化 master 节点。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果初始化过程出现问题，可以使用 sudo kubeadm reset -f 命令还原</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装完成后会有以下输出</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo kubeadm init --config=./kubeadm-config.yaml --upload-certs | <span class="built_in">tee</span> kubeadm-init.log</span></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.137.81:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:0bd9da58b2ec3a16024a29d419a55c915e5aa2f735e62ecf1c5490872a24d6a1</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>查看 k8s 下载的容器镜像。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s下载的容器镜像会在 containerd 的 k8s.io 命名空间中</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo /usr/local/bin/ctr namespace <span class="built_in">ls</span></span></span><br><span class="line">NAME    LABELS </span><br><span class="line">default        </span><br><span class="line">k8s.io</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下载下来的镜像</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo /usr/local/bin/ctr -n k8s.io image <span class="built_in">ls</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s 运行中的镜像</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo /usr/local/bin/ctr -n k8s.io container <span class="built_in">ls</span></span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>创建 kubectl 配置文件。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">之后就能看到集群状态了</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get node</span></span><br><span class="line">NAME           STATUS     ROLES           AGE   VERSION</span><br><span class="line">k8s-master01   NotReady   control-plane   42m   v1.26.1</span><br></pre></td></tr></table></figure>

<ol start="6">
<li><strong>在node主机</strong>中执行以下命令，加入至 k8s 集群。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubeadm init 初始化 master 节点之后中的输出</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo kubeadm <span class="built_in">join</span> 192.168.137.81:6443 --token abcdef.0123456789abcdef \</span></span><br><span class="line"><span class="language-bash">    --discovery-token-ca-cert-hash sha256:0bd9da58b2ec3a16024a29d419a55c915e5aa2f735e62ecf1c5490872a24d6a1</span></span><br></pre></td></tr></table></figure>

<ol start="7">
<li>查看集群状态，由于还未部署容器网络插件，所以所有节点的状态都是 NotReady。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get node -A</span></span><br><span class="line">NAME           STATUS     ROLES           AGE     VERSION</span><br><span class="line">k8s-master01   NotReady   control-plane   3m44s   v1.26.1</span><br><span class="line">k8s-node01     NotReady   &lt;none&gt;          2m14s   v1.26.1</span><br><span class="line">k8s-node02     NotReady   &lt;none&gt;          97s     v1.26.1</span><br></pre></td></tr></table></figure>



<h4 id="5-3-3-部署-Calico-容器网络插件"><a href="#5-3-3-部署-Calico-容器网络插件" class="headerlink" title="5.3.3 部署 Calico 容器网络插件"></a>5.3.3 部署 Calico 容器网络插件</h4><blockquote>
<p>容器网络插件有很多种，只需要部署其中一个即可。详情可以参照<a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">官方文档</a>。</p>
</blockquote>
<blockquote>
<p>Calico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。</p>
<p>Calico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。</p>
<p>此外，Calico 项目还实现了 Kubernetes 网络策略，提供ACL功能。</p>
</blockquote>
<ol>
<li>下载 calico 资源文件。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Tigera Calico operator 资源文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/tigera-operator.yaml</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">自定义配置资源文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/custom-resources.yaml</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>修改 pod 网络配置。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi custom-resources.yaml</span></span><br><span class="line">spec:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Configures Calico networking.</span></span><br><span class="line">  calicoNetwork:</span><br><span class="line">    # Note: The ipPools section cannot be modified post-install.</span><br><span class="line">    ipPools:</span><br><span class="line">    - blockSize: 26</span><br><span class="line">      cidr: 10.244.0.0/16          # 修改为podSubnet设置的地址</span><br><span class="line">      encapsulation: VXLANCrossSubnet</span><br><span class="line">      natOutgoing: Enabled</span><br><span class="line">      nodeSelector: all()</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>移除 master 节点上的污点。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kubectl taint nodes --all node-role.kubernetes.io/control-plane- node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>部署 Calico。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f tigera-operator.yaml</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl create -f custom-resources.yaml</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>查看 Calico 的所有 pod 是否都已经处于 Running 状态。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pods -n calico-system -o wide</span></span><br><span class="line">NAME                                       READY   STATUS    RESTARTS        AGE     IP               NODE           NOMINATED NODE   READINESS GATES</span><br><span class="line">calico-kube-controllers-6b7b9c649d-d9zxt   1/1     Running   0               24m     10.244.32.129    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-flght                          1/1     Running   0               24m     192.168.137.81   k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-kjkzt                          1/1     Running   0               24m     192.168.137.82   k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-node-qwqq4                          1/1     Running   0               24m     192.168.137.83   k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-677d9c67f8-5dp9w              1/1     Running   2 (5m53s ago)   23m     192.168.137.82   k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">calico-typha-677d9c67f8-tvh58              1/1     Running   0               24m     192.168.137.83   k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">csi-node-driver-jps9z                      2/2     Running   0               3m58s   10.244.85.193    k8s-node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">csi-node-driver-ns65f                      2/2     Running   0               14m     10.244.58.193    k8s-node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">csi-node-driver-ztdnt                      2/2     Running   0               16m     10.244.32.131    k8s-master01   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>查看 k8s 集群状态。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到所有节点都已经处于 Ready 状态了</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get node</span></span><br><span class="line">NAME           STATUS   ROLES           AGE   VERSION</span><br><span class="line">k8s-master01   Ready    control-plane   76m   v1.26.1</span><br><span class="line">k8s-node01     Ready    &lt;none&gt;          74m   v1.26.1</span><br><span class="line">k8s-node02     Ready    &lt;none&gt;          73m   v1.26.1</span><br></pre></td></tr></table></figure>

<h3 id="5-4-部署-Dashboard-服务"><a href="#5-4-部署-Dashboard-服务" class="headerlink" title="5.4 部署 Dashboard 服务"></a>5.4 部署 Dashboard 服务</h3><blockquote>
<p>Dashboard 是基于网页的 Kubernetes 用户界面。 你可以使用 Dashboard 将容器应用部署到 Kubernetes 集群中，也可以对容器应用排错，还能管理集群资源。 你可以使用 Dashboard 获取运行在集群中的应用的概览信息，也可以创建或者修改 Kubernetes 资源 （如 Deployment，Job，DaemonSet 等等）。 例如，你可以对 Deployment 实现弹性伸缩、发起滚动升级、重启 Pod 或者使用向导创建新的应用。</p>
<p>Dashboard 同时展示了 Kubernetes 集群中的资源状态信息和所有报错信息。</p>
</blockquote>
<blockquote>
<p><strong>使用 Dashboard 要注意用户权限问题，不然别人就能随意使用你的 k8s 集群</strong>。</p>
</blockquote>
<blockquote>
<p><strong>如果是在虚拟机上运行，需要允许混杂模式；如果是云供应商的云主机，需要确认云主机是否关闭了源&#x2F;目的 IP 检查的功能。</strong>否则会导致 k8s 集群的 nodeport 端口无法从别的 node 上访问。</p>
</blockquote>
<ol>
<li>下载资源文件。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>修改资源文件，使得外部网络能够访问 Dashboard 服务。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi recommended.yaml</span></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort             # Service 类型设置为 NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">      nodePort: 30001        # 向外部暴露 30001 端口</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>应用资源文件到 k8s 集群。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f recommended.yaml</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>查看 Dashboard 服务状态。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get pod -n kubernetes-dashboard</span></span><br><span class="line">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class="line">dashboard-metrics-scraper-7bc864c59-qn9q8   1/1     Running   0          16m</span><br><span class="line">kubernetes-dashboard-6c7ccbcf87-cpz46       1/1     Running   0          6s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl get svc -n kubernetes-dashboard</span></span><br><span class="line">NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">dashboard-metrics-scraper   ClusterIP   10.102.45.245   &lt;none&gt;        8000/TCP        17s</span><br><span class="line">kubernetes-dashboard        NodePort    10.97.112.165   &lt;none&gt;        443:30001/TCP   18s</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>通过 <a href="https://192.168.137.81:30001/">https://192.168.137.81:30001/</a> 访问 Dashboard 面板。</li>
</ol>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230121220733660.png" alt="image-20230121220733660"></p>
<ol start="6">
<li>创建 Dashboard 用户。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi dashboard-user.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f dashboard-user.yaml</span></span><br></pre></td></tr></table></figure>

<ol start="7">
<li>创建用户凭证 token。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl -n kubernetes-dashboard create token admin-user</span></span><br><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6Ii0zS1Izc0lPOWVQUE41akhRVndoSWh1eE5hRF8tVFJ5TGtTQ0ZvLVZvOHcifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNjc0MzE0MDgxLCJpYXQiOjE2NzQzMTA0ODEsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsInNlcnZpY2VhY2NvdW50Ijp7Im5hbWUiOiJhZG1pbi11c2VyIiwidWlkIjoiNGM0NGZkNjktZjc4Zi00M2VmLWFhYzAtZDE2ZmRkODIxNWIzIn19LCJuYmYiOjE2NzQzMTA0ODEsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDphZG1pbi11c2VyIn0.ooQ2muvXZFPu1oJ1J79EE_nDew03rSfOqnVVIj6GDUATTREGcehc9IzrmYb1FMx7nKFZLcCORRyLZLTmezUG6AAMVR26NyyDqemShIo5KU-Y1h8TQaLfuoPpGQa9IaFu7NlNAE01N2mFFT8vzN8-zFnhNjPhyTH8QpUWLQt6LRM7uhIdBvUNsbFuODXnlEa3uPpaSFP9wGXkR53T0TGInD_zC4QTZtxqjGyxGod_3gn8yogr_tuSndvpX1Fs5LgfBDKofC0bmiX7_ghqIQ7hgAZVAYPjbgtrIqGxd5xYDMuO6WN4mclHvQmqSPmk-WmNDOdXtRBxvAaxkwWSlznb_A</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果想要删除用户，使用以下命令</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl -n kubernetes-dashboard delete serviceaccount admin-user</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubectl -n kubernetes-dashboard delete clusterrolebinding admin-user</span></span><br></pre></td></tr></table></figure>

<ol start="8">
<li>使用生成的凭证 token 即可登录 Dashboard 页面。</li>
</ol>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/image-20230121221612439.png" alt="image-20230121221612439"></p>
<h3 id="5-5-部署-kube-prometheus-监控"><a href="#5-5-部署-kube-prometheus-监控" class="headerlink" title="5.5 部署 kube-prometheus 监控"></a>5.5 部署 kube-prometheus 监控</h3><blockquote>
<p>kube-prometheus 是一整套监控解决方案，它使用 Prometheus 采集集群指标，Grafana 做展示，包含如下组件:</p>
<ul>
<li>The <a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus Operator</a></li>
<li>Highly available <a href="https://prometheus.io/">Prometheus</a></li>
<li>Highly available <a href="https://github.com/prometheus/alertmanager">Alertmanager</a></li>
<li><a href="https://github.com/prometheus/node_exporter">Prometheus node-exporter</a></li>
<li><a href="https://github.com/kubernetes-sigs/prometheus-adapter">Prometheus Adapter for Kubernetes Metrics APIs</a></li>
<li><a href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics</a></li>
<li><a href="https://grafana.com/">Grafana</a></li>
</ul>
</blockquote>
<ol>
<li>下载 kube-prometheus 代码。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先安装 git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y git</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">克隆官方仓库</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> https://github.com/prometheus-operator/kube-prometheus.git</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> kube-prometheus</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切换到 release-0.12 版本分支</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git checkout release-0.12</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>替换镜像源。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到所有 quay.io 仓库的镜像</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">grep -nr <span class="string">&quot;quay.io&quot;</span> ./manifests</span></span><br><span class="line">./manifests/alertmanager-alertmanager.yaml:13:  image: quay.io/prometheus/alertmanager:v0.25.0</span><br><span class="line">./manifests/blackboxExporter-deployment.yaml:33:        image: quay.io/prometheus/blackbox-exporter:v0.23.0</span><br><span class="line">./manifests/blackboxExporter-deployment.yaml:88:        image: quay.io/brancz/kube-rbac-proxy:v0.14.0</span><br><span class="line">./manifests/kubeStateMetrics-deployment.yaml:56:        image: quay.io/brancz/kube-rbac-proxy:v0.14.0</span><br><span class="line">./manifests/kubeStateMetrics-deployment.yaml:82:        image: quay.io/brancz/kube-rbac-proxy:v0.14.0</span><br><span class="line">./manifests/nodeExporter-daemonset.yaml:39:        image: quay.io/prometheus/node-exporter:v1.5.0</span><br><span class="line">./manifests/nodeExporter-daemonset.yaml:75:        image: quay.io/brancz/kube-rbac-proxy:v0.14.0</span><br><span class="line">./manifests/prometheus-prometheus.yaml:21:  image: quay.io/prometheus/prometheus:v2.41.0</span><br><span class="line">./manifests/prometheusOperator-deployment.yaml:32:        - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.62.0</span><br><span class="line">./manifests/prometheusOperator-deployment.yaml:33:        image: quay.io/prometheus-operator/prometheus-operator:v0.62.0</span><br><span class="line">./manifests/prometheusOperator-deployment.yaml:56:        image: quay.io/brancz/kube-rbac-proxy:v0.14.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到所有 registry.k8s.io 仓库的镜像</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">grep -nr <span class="string">&quot;registry.k8s.io&quot;</span> ./manifests</span></span><br><span class="line">./manifests/kubeStateMetrics-deployment.yaml:35:        image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.7.0</span><br><span class="line">./manifests/prometheusAdapter-deployment.yaml:40:        image: registry.k8s.io/prometheus-adapter/prometheus-adapter:v0.10.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">替换quay.io 仓库镜像源为中科大镜像源 quay.mirrors.ustc.edu.cn</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i <span class="string">&#x27;s/quay.io/quay.mirrors.ustc.edu.cn/g&#x27;</span> $(grep -nrl <span class="string">&quot;quay.io&quot;</span> ./manifests)</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">替换 registry.k8s.io 仓库的镜像为阿里镜像源 registry.aliyuncs.com/google_containers</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sed -i <span class="string">&#x27;s/registry.k8s.io/registry.aliyuncs.com\/google_containers/g&#x27;</span> $(grep -nrl <span class="string">&quot;registry.k8s.io&quot;</span> ./manifests)</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">镜像也不一定全都有最新的</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果没有，就在每台机子上用 ctr -n k8s.io image pull doeker.io/仓库名:版本号 从 Docker hub 上拉取镜像</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">随后用 ctr -n k8s.io image tag 重新打tag</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>应用资源文件。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建命名空间和 CustomResourceDefinitions，然后等待操作完成</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply --server-side -f manifests/setup</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl <span class="built_in">wait</span> \</span></span><br><span class="line"><span class="language-bash">    --<span class="keyword">for</span> condition=Established \</span></span><br><span class="line"><span class="language-bash">    --all CustomResourceDefinition \</span></span><br><span class="line"><span class="language-bash">    --namespace=monitoring</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">应用其他资源文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl apply -f manifests/</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>访问 Prometheus 服务、 Grafana 页面或者 Alert Manager 服务。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Prometheus</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过 kubectl 的端口转发功能，能够将 svc 的端口绑定到集群主机的端口上，只能通过回环地址访问</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果想要通过外部访问，需要修改对应服务的 networkPolicy（或删除），并且修改对应的 svc 为 nodePort 类型</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 http://localhost:9090 访问</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl --namespace monitoring port-forward svc/prometheus-k8s 9090</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Grafana</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 http://localhost:3000 访问（用户名密码：admin/admin）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">模板可以使用 https://grafana.com/grafana/dashboards/13105</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl --namespace monitoring port-forward svc/grafana 3000</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Alert Manager</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用 http://localhost:9093 访问</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl --namespace monitoring port-forward svc/alertmanager-main 9093</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>kube-prometheus 移除命令。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">kubectl delete --ignore-not-found=<span class="literal">true</span> -f manifests/ -f manifests/setup</span></span><br></pre></td></tr></table></figure>



<h2 id="6-Helm-包管理工具"><a href="#6-Helm-包管理工具" class="headerlink" title="6.  Helm 包管理工具"></a>6.  Helm 包管理工具</h2><p><a href="http://helm.sh/">Helm</a> 是一个 Kubernetes 应用的包管理工具，用来管理 <a href="https://github.com/helm/charts">chart</a>—— 预先配置好的安装包资源，有点类似于 Ubuntu 的 APT 和 CentOS 中的 YUM。2019 年 11 月 13 日，<a href="https://helm.sh/blog/helm-3-released/">Helm 3 发布</a>，2020 年 4 月 30 日，从 CNCF 中<a href="https://helm.sh/blog/celebrating-helms-cncf-graduation/">毕业</a>。本文基于 Helm 3。</p>
<p>Helm chart 是用来封装 Kubernetes 原生应用程序的 YAML 文件，可以在你部署应用的时候自定义应用程序的一些 metadata，便与应用程序的分发。</p>
<p>Helm 和 chart 的主要作用是：</p>
<ul>
<li>应用程序封装</li>
<li>版本管理</li>
<li>依赖检查</li>
<li>便于应用程序分发</li>
</ul>
<p>Helm 可以安装本地或者远程的 chart，当 chart 安装到 Kubernetes 中后就会创建一个 release，每次更新该 chart 的配置并执行 <code>helm upgrade</code>， release 的版本数就会加 1。同一个 chart 可以部署多次。</p>
<p><img src="/2023/01/19/Kubeadm%E5%AE%89%E8%A3%85Kubernetes%20v1.26.1%E9%9B%86%E7%BE%A4/helm-chart.png" alt="Helm 架构图"></p>
<h3 id="6-1-Helm-安装"><a href="#6-1-Helm-安装" class="headerlink" title="6.1 Helm 安装"></a>6.1 Helm 安装</h3><blockquote>
<p>把官方的包下载解压下来就能够使用了。</p>
</blockquote>
<ol>
<li>下载官方二进制压缩包。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">wget https://get.helm.sh/helm-v3.11.0-linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>解压压缩包。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -zxvf helm-v3.11.0-linux-amd64.tar.gz</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>移动 helm 文件到 <code>/usr/local/bin</code>目录。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mv</span> linux-amd64/helm /usr/local/bin/helm</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>添加可用的 chart 仓库。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm repo add bitnami https://charts.bitnami.com/bitnami</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>查询可用的 chart。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">helm search repo bitnami</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux中的login shell和non-login shell</title>
    <url>/2022/10/10/Linux%E4%B8%AD%E7%9A%84login-shell%E5%92%8Cnon-login-shell/</url>
    <content><![CDATA[<h3 id="1-简要介绍"><a href="#1-简要介绍" class="headerlink" title="1. 简要介绍"></a>1. 简要介绍</h3><p>Shell是用于为用户提供与Linux内核交互的工具，比如sh、bash、zch等都是shell。当我们使用Linux的时候，一进入系统就有一堆的变量可以使用，那么这些变量从哪里来呢？在Linux启动的时候，会按一定的顺序读取配置文件，并且将这些配置文件中的环境变量设置到当前的shell中，所以我们才能使用这些环境变量中目录里面的命令。</p>
<p>因此我们就需要了解两个问题：</p>
<ul>
<li>Linux会按什么顺序读取哪些配置文件？</li>
<li>login shell和non-login shell有什么区别？</li>
</ul>
<h3 id="2-login-shell和non-login-shell的区别"><a href="#2-login-shell和non-login-shell的区别" class="headerlink" title="2. login shell和non-login shell的区别"></a>2. login shell和non-login shell的区别</h3><ul>
<li><strong>login shell</strong>：取得bash时需要完整的登录流程，就称为login shell。如：<ul>
<li>登录到ubuntu之后需要输入用户名和密码才能操作用户界面，这就是一个login shell</li>
<li>登录tty1~tty6时，也需要输入用户名和密码，这也是login sehll</li>
</ul>
</li>
<li><strong>non-login shell</strong>：取得bash时不需要重复登录。如：<ul>
<li>登录到ubuntu用户操作界面之后，通过鼠标打开的终端Terminal，就不需要输入用户名和密码，因此这就是non-login shell</li>
<li>或者在原本bash环境下再次使用bash这个命令，会建立一个新的bash子进程，也不用输入账号密码，哪这个bash子程序也是non-login shell</li>
</ul>
</li>
</ul>
<h3 id="3-login-shell"><a href="#3-login-shell" class="headerlink" title="3. login shell"></a>3. login shell</h3><blockquote>
<p>一般来说，login shell只会读取下面两个配置文件：</p>
<ul>
<li><strong>&#x2F;etc&#x2F;profile</strong>：系统整体的配置，一般尽量不要修改这个文件</li>
<li><strong><del>&#x2F;.bash_profile或</del>&#x2F;.bash_login或~&#x2F;.profile</strong>：属于用户个人配置（从~目录就能看出），需要修改自己的数据，就写入这些文件。（bash的login shell配置只会读取上面三个文件的其中一个，而读取的顺序则是依照上面的顺序）</li>
</ul>
</blockquote>
<h4 id="3-1-x2F-etc-x2F-profile公共配置内容"><a href="#3-1-x2F-etc-x2F-profile公共配置内容" class="headerlink" title="3.1 &#x2F;etc&#x2F;profile公共配置内容"></a>3.1 &#x2F;etc&#x2F;profile公共配置内容</h4><p><code>/etc/profile</code>文件中主要配置的环境变量包括：</p>
<ul>
<li>PATH：会根据UID来决定PATH变量中包不包含sbin的系统命令目录</li>
<li>MAIL：将用户配置的mailbox配置到<code>/var/spool/mail/账户名</code></li>
<li>USER：根据用户的账号配置这个变量内容</li>
<li>HOSTNAME：根据主机的hostname配置</li>
<li>HISTSIZE：历史命令的记录条数</li>
</ul>
<p>此外，<code>/etc/profile</code>文件还会按以下顺序读取外部配置文件：</p>
<ol>
<li><code>/etc/inputrc</code>：主要配置bash的热键、[tab]键需不需要有声音等</li>
<li><code>/etc/profile.d/*.sh</code>：只要在<code>/etc/profile.d/</code>目录内，并且文件扩展名为 .sh，用户具有读的权限，那么该文件就会被&#x2F;etc&#x2F;profile读取。主要包括：bash操作界面的颜色，ll与ls命令的命令别名、which的命令别名等。<strong>如果需要给所有用户配置一些共享的命令别名时，可以在这个目录底下创建扩展名为.sh的文件，并将需要的数据写入</strong></li>
<li><code>/etc/sysconfig/i18n</code>：这个文件是被<code>/etc/profile.d/lang.sh</code>文件调用，配置LANG变量，也就是bash默认使用什么语言</li>
</ol>
<h4 id="3-2-用户配置内容"><a href="#3-2-用户配置内容" class="headerlink" title="3.2 用户配置内容"></a>3.2 用户配置内容</h4><p>我们可以看下<code>~/.bash_profile</code>中的内容：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[junhao@localhost ~]$ cat ~/.bash_profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">.bash_profile</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Get the aliases and <span class="built_in">functions</span></span></span><br><span class="line">if [ -f ~/.bashrc ]; then</span><br><span class="line">    . ~/.bashrc</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">User specific environment and startup programs</span></span><br><span class="line"></span><br><span class="line">PATH=$PATH:$HOME/.local/bin:$HOME/bin</span><br><span class="line"></span><br><span class="line">export PATH</span><br><span class="line">[junhao@localhost ~]$ </span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以看到if判断语句中的一段，判断home目录下的文件<code>~/.bashrc</code>是不是存在，如果存在则读入<code>~/.bashrc</code>中的配置。</p>
<p>至于<code>~/.bash_login</code> 或<code>~/.profile</code>文件，前面提到过，bash的login shell只会读取上面三个文件中的其中一个，哪个文件存在就读取哪个文件，而最后读取的都是<code>~/.bashrc</code>中的配置。</p>
</blockquote>
<p>我们再看看<code>~/.bashrc</code>文件中的内容：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[junhao@localhost ~]$ cat ~/.bashrc</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">.bashrc</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Source global definitions</span></span><br><span class="line">if [ -f /etc/bashrc ]; then</span><br><span class="line">    . /etc/bashrc</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Uncomment the following line <span class="keyword">if</span> you don<span class="string">&#x27;t like systemctl&#x27;</span>s auto-paging feature:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> SYSTEMD_PAGER=</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">User specific aliases and <span class="built_in">functions</span></span></span><br><span class="line">[junhao@localhost ~]$ </span><br></pre></td></tr></table></figure>

<p>可以看到在<code>~/.bashrc</code>文件中，最后会读取<code>/etc/bashrc</code>文件中的配置，而<code>/etc/bashrc</code>也会读取<code>/etc/profile.d/*.sh</code>中的配置。</p>
<h4 id="3-3-总结"><a href="#3-3-总结" class="headerlink" title="3.3 总结"></a>3.3 总结</h4><p><img src="/2022/10/10/Linux%E4%B8%AD%E7%9A%84login-shell%E5%92%8Cnon-login-shell/login_shell.png" alt="login shell 的配置文件读取流程"></p>
<p>实线的方向是主线流程，虚线的方向则是被调用的配置文件，从上面的流程图可以看出，最终读取的配置文件是<code>~/.bashrc</code>，所以可以将用户特定的配置写入<code>~/.bashrc</code>文件中，而所有用户共用的配置写入<code>/etc/bashrc</code>文件中。</p>
<h3 id="4-non-login-shell"><a href="#4-non-login-shell" class="headerlink" title="4. non-login shell"></a>4. non-login shell</h3><blockquote>
<p>当获取non-login shell的时候，bash的配置文件仅仅会读取<code>~/.bashrc</code>文件中的内容</p>
</blockquote>
<p><code>~/.bashrc</code>中会调用<code>/etc/bashrc</code>，而<code>/etc/bashrc</code>主要负责：</p>
<ul>
<li>根据UID设置umask的值</li>
<li>根据UID设置命令行提示即PS1变量</li>
<li>调用<code>/etc/profile.d/*.sh</code>中的配置</li>
</ul>
<h3 id="5-其他相关的配置文件"><a href="#5-其他相关的配置文件" class="headerlink" title="5. 其他相关的配置文件"></a>5. 其他相关的配置文件</h3><ul>
<li><code>/etc/man.config</code>：配置man相关属性</li>
<li><code>~/.bash_history</code>：历史命令相关</li>
<li><code>~/.bash_logout</code>：注销bash时，需要执行的操作</li>
</ul>
]]></content>
      <categories>
        <category>Linux基础知识</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>LVS负载均衡实战</title>
    <url>/2022/08/18/LVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h3><p>LVS的作用就是用作<strong>四层</strong>的<strong>负载均衡</strong>，四层是指<code>TCP/IP</code>七层协议中的传输层。目的是请求按一定的<strong>调度策略</strong>把用户的请求分发到多台后端设备上。区别于nginx，nginx是七层的负载均衡，能够看到http协议，而LVS只能看到四层的协议，即TCP协议等，所以无法通过Http cookie处理session。</p>
<h3 id="2-简介"><a href="#2-简介" class="headerlink" title="2. 简介"></a>2. 简介</h3><p><a href="http://www.linuxvirtualserver.org/">LVS（Linux Virtual Server）</a>即Linux虚拟服务器，由章文嵩博士开发并已贡献给开源社区，用于构建高性能、高可用的Linux服务器集群，具有良好的可靠性、可扩展性和可操作性。</p>
<blockquote>
<p>LVS的高可用需要结合Keepalived，不然的话其实只有一个前端负载均衡节点负责着绑定到LVS上的IP流量，所以当这个前端负载均衡节点挂了之后，IP流量就无法分发到后端真实工作服务器上。Keepalived的作用就是保证前端负载均衡节点的高可用。</p>
</blockquote>
<h4 id="2-1-LVS的组成"><a href="#2-1-LVS的组成" class="headerlink" title="2.1 LVS的组成"></a>2.1 LVS的组成</h4><p>LVS主要由<code>ipvs</code>和<code>ipvsadm</code>两部分组成。</p>
<ol>
<li><code>ipvs(ip virtual server)</code>是工作在Linux内核态的四层负载均衡，是真正实现调度的程序，基于内核底层<code>netfilter</code>实现，通过<code>netfilter</code>的处理链上的钩子实现包的处理和转发。</li>
<li><code>ipvsadm</code>工作在用户空间，负责与ipvs之间的交互，为ipvs框架编写规则，定义谁是前端负载均衡节点，谁是后端的真实服务器</li>
</ol>
<h4 id="2-2-LVS的三种工作模式"><a href="#2-2-LVS的三种工作模式" class="headerlink" title="2.2 LVS的三种工作模式"></a>2.2 LVS的三种工作模式</h4><ul>
<li><p>VS&#x2F;NAT（Virtual Server via Network Address Translation）</p>
<ul>
<li>通过网络地址转换NAT实现</li>
<li>调度器重写请求报文的目标地址，将请求分派到后端的真实服务器</li>
<li>真实服务器将响应报文交给调度器，响应报文的源地址被重写，再转发给客户</li>
<li>请求和响应都经过调度器</li>
</ul>
</li>
<li><p>VS&#x2F;TUN（Virtual Server via IP Tunneling）</p>
<ul>
<li>通过IP隧道实现</li>
<li>请求报文到达调度器之后，通过IP隧道转发到后端真实服务器</li>
<li>真实服务器将响应报文直接返回给客户</li>
<li>调度器只处理请求报文</li>
</ul>
</li>
<li><p>VS&#x2F;DR（Virtual Server via Direct Routing）</p>
<ul>
<li>通过改写请求报文的MCA地址实现</li>
<li>请求报文到达调度器之后，改写报文的MAC地址，发送到后端真实服务器</li>
<li>真实服务器将响应报文直接返回给客户</li>
<li>调度器只处理请求报文</li>
</ul>
</li>
</ul>
<h5 id="2-2-1-三种模式的主要区别"><a href="#2-2-1-三种模式的主要区别" class="headerlink" title="2.2.1 三种模式的主要区别"></a>2.2.1 三种模式的主要区别</h5><table>
<thead>
<tr>
<th>模式与特点</th>
<th>NAT模式</th>
<th>TUN模式</th>
<th>DR模式</th>
</tr>
</thead>
<tbody><tr>
<td>服务器要求</td>
<td>服务器节点可以使用任何操作系统</td>
<td>必须支持IP隧道</td>
<td>服务器节点支持虚拟网卡设备，能够禁用设备的ARP响应</td>
</tr>
<tr>
<td>网络要求</td>
<td>拥有私有IP地址的局域网络</td>
<td>拥有合法IP地址的局域网或广域网</td>
<td>拥有合法IP地址的局域网，服务器节点与调度器必须在同一个网段</td>
</tr>
<tr>
<td>支持节点数</td>
<td>10到20个，根据调度器的处理能力而定</td>
<td>较高，可以支持100个服务节点</td>
<td>较高，可以支持100个服务节点</td>
</tr>
<tr>
<td>网关</td>
<td>调度器为服务器节点网关</td>
<td>服务器节点同自己的网关或者路由器连接，不经过负载均衡器</td>
<td>服务器节点同自己的网关或者路由器连接，不经过负载均衡器</td>
</tr>
<tr>
<td>IP要求</td>
<td>仅需要一个合法的IP地址作为调度器的VIP地址</td>
<td>除了VIP地址外，每个服务器需要有能够路由到客户端的IP地址</td>
<td>除了VIP地址外，每个服务器需要有能够路由到客户端的IP地址</td>
</tr>
<tr>
<td>特点</td>
<td>地址转换</td>
<td>封装IP</td>
<td>修改MAC地址</td>
</tr>
</tbody></table>
<h4 id="2-3-调度算法"><a href="#2-3-调度算法" class="headerlink" title="2.3 调度算法"></a>2.3 调度算法</h4><blockquote>
<p>只做简单介绍，其中缩写英文用于在ipvsadm命令中指定集群调度算法</p>
</blockquote>
<ul>
<li>轮询算法 <code>rr</code>（Round Robin）</li>
<li>加权轮询算法 <code>wrr</code> （Weighted Round Robin）</li>
<li>源地址哈希算法 <code>sh</code> （Source Hashing）</li>
<li>目标地址哈希算法 <code>dh</code> （Destination Hashing）</li>
<li>最少连接算法 <code>lc</code> （Least Connections）</li>
<li>加权最少连接算法 <code>wlc</code> （Weighted Least Connection）</li>
<li>最短期望延迟算法 <code>sed</code> （Shortest Expected Delay Scheduling）</li>
<li>最少队列算法 <code>nq</code> （Never Queue Scheduling）</li>
<li>基于局部的最少连接算法 <code>lblc</code> （Locality-Based Least Connections）</li>
<li>带复制的基于局部的最少连接算法 <code>lblcr</code> （Locality-Based Least Connections with Replication）</li>
<li>FO算法 <code>fo</code> （Weighted Fail Over）</li>
<li>OVF算法 <code>ovf</code> （Overflow-connection）</li>
</ul>
<h3 id="3-工作原理"><a href="#3-工作原理" class="headerlink" title="3. 工作原理"></a>3. 工作原理</h3><blockquote>
<p>重点理解报文包源和目的IP地址、源和目的MAC地址的变化</p>
</blockquote>
<h4 id="3-1-别称约定"><a href="#3-1-别称约定" class="headerlink" title="3.1 别称约定"></a>3.1 别称约定</h4><ul>
<li>服务器<ul>
<li>DS (Director Server)，指的是前端负载均衡器节点，即调度器</li>
<li>RS (Real Server)，后端真实的工作服务器</li>
</ul>
</li>
<li>IP地址<ul>
<li>CIP (Client IP)，访问客户端的 IP 地址</li>
<li>VIP (Virtual IP)，虚拟的 IP 地址，向外部直接面向用户请求，作为用户请求的目标的 IP 地址</li>
<li>DIP (Director IP)，主要用于和内部主机通讯的 IP 地址</li>
<li>RIP (Real Server IP)，后端服务器的 IP 地址</li>
</ul>
</li>
<li>netfilter的五个阶段<ul>
<li>PREROUTING</li>
<li>INPUT</li>
<li>OUTPUT</li>
<li>FORWARD</li>
<li>POSTROUTING</li>
</ul>
</li>
</ul>
<h4 id="3-2-LVS-x2F-NAT和FULLNAT"><a href="#3-2-LVS-x2F-NAT和FULLNAT" class="headerlink" title="3.2 LVS&#x2F;NAT和FULLNAT"></a>3.2 LVS&#x2F;NAT和FULLNAT</h4><p><img src="/2022/08/18/LVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%AE%9E%E6%88%98/LVS_NAT.png" alt="LVS_NAT"></p>
<blockquote>
<p>还有一种工作模式是LVS&#x2F;FULLNAT。在DS将请求报文转发给RS时（即第三步），LVS&#x2F;NAT模式只修改目标IP为RIP，而LVS&#x2F;FULLNAT则同时将CIP和VIP分别修改为DIP和RIP。NAT模式DS和RS都需要在同一个子网（因为RS的网关为DS），FULLNAT模式DS和RS只要能通信可以不在同一个子网。</p>
</blockquote>
<blockquote>
<p>NAT模式下，同一个物理网络的机器访问VIP会有数据流向的问题，详细分析请看最后一节。</p>
</blockquote>
<ol>
<li>Client报文请求到达DS，此时请求的数据报文会先到<code>netfilter</code>的<code>PREROUTEING</code>调用链，此时报文的<strong>源IP为CIP，目的IP为VIP</strong></li>
<li><code>PREROUTING</code>检查发现数据包的目标IP是本机，将数据包发送至<code>INPUT</code>调用链</li>
<li>IPVS对比数据包请求的服务是否为负载均衡集群服务。如果是，则修改数据包的目标IP地址为RS的RIP地址，然后将数据包发送至<code>POSTROUTING</code>调用链。此时，请求报文的<strong>源IP为CIP，目标IP为RIP</strong></li>
<li><code>POSTROUTING</code>链通过路由，将数据包发送给RS</li>
<li>RS接收到请求报文，开始构建响应报文返回给DS（因为DS是RS的网关，所以一定得经过DS）。此时响应报文的<strong>源IP为RIP，目标IP为CIP</strong></li>
<li>DS在将响应报文发送给Client前，会将源IP地址修改为自己的VIP地址，然后发送给Client。此时报文的<strong>源IP为VIP，目标IP为CIP</strong></li>
</ol>
<h4 id="3-3-LVS-x2F-TUN"><a href="#3-3-LVS-x2F-TUN" class="headerlink" title="3.3 LVS&#x2F;TUN"></a>3.3 LVS&#x2F;TUN</h4><p><img src="/2022/08/18/LVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%AE%9E%E6%88%98/LVS_TUN.png" alt="LVS_TUN"></p>
<blockquote>
<p>通过IP隧道时，在原有的IP报文外再次封装多一层IP首部，内层IP首部（源为CIP，目的为VIP），外层IP首部（源为DIP，目的为RIP）</p>
</blockquote>
<ol>
<li>Client报文请求到达DS，此时请求的数据报文会先到<code>netfilter</code>的<code>PREROUTEING</code>调用链，此时报文的<strong>源IP为CIP，目的IP为VIP</strong></li>
<li><code>PREROUTING</code>检查发现数据包的目标IP是本机，将数据包发送至<code>INPUT</code>调用链</li>
<li>IPVS对比数据包请求的服务是否为负载均衡集群服务。如果是，将整个请求包作为数据封装到一个新的IP报文中，新的封装报文<strong>源IP为DIP，目的IP为RIP</strong>。然后将新报文发送到<code>POSTROUTING</code>调用链</li>
<li><code>POSTROUTING</code>根据新封装报文的目的IP地址将报文路由到RS，此时新报文<strong>源IP为DIP，目的IP为RIP</strong></li>
<li>RS接收到报文之后，拆除掉外层的IP首部，会发现里面还有一层IP首部，而且目标IP是自己的lo接口VIP。此时，RS处理请求，将响应报文通过lo接口送给eth0网卡(与外网相接)，然后将报文路由到Client。此时<strong>源IP为VIP，目的IP为CIP</strong></li>
<li>响应报文最终路由到Client</li>
</ol>
<h4 id="3-3-LVS-x2F-DR"><a href="#3-3-LVS-x2F-DR" class="headerlink" title="3.3 LVS&#x2F;DR"></a>3.3 LVS&#x2F;DR</h4><p><img src="/2022/08/18/LVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%AE%9E%E6%88%98/LVS_DR.png" alt="LVS_DR"></p>
<blockquote>
<p>DS与RS必须在同一个物理网络中</p>
</blockquote>
<ol>
<li>Client报文请求到达DS，此时请求的数据报文会先到<code>netfilter</code>的<code>PREROUTEING</code>调用链，此时报文的<strong>源IP为CIP，目的IP为VIP</strong></li>
<li><code>PREROUTING</code>检查发现数据包的目标IP是本机，将数据包发送至<code>INPUT</code>调用链</li>
<li>IPVS对比数据包请求的服务是否为负载均衡集群服务。如果是，则将请求报文中的<strong>源MAC地址修改为DIP的MAC地址，将目标MAC地址修改为RIP的MAC地址</strong>，然后将数据包发送至<code>POSTROUTING</code>调用链。此时的源IP和目的IP均未修改，仅修改了源MAC地址和目的MAC地址</li>
<li>由于DS和RS在同一个网络中，所以是通过数据链路层来传输。<code>POSTROUTING</code>检查目标MAC地址为RIP的MAC地址，那么此时数据包将会通过交换机发送至RS（因为在同一个网段，所以不会发送到网关，而是发送到内部网络中）</li>
<li>RS接收到报文之后，发现MAC地址为自己的MAC地址，接收此报文并转交给上层协议。处理完成后，响应报文通过lo接口的VIP传送给eth0网卡向外发出。此时，响应报文的<strong>源IP为VIP，目的IP为CIP</strong></li>
<li>响应报文最终路由到Client</li>
</ol>
<blockquote>
<p>其中第3、5步是最为关键的，三个问题：</p>
<ul>
<li>DS如何知道RS的MAC地址</li>
<li>RS如何接收目标IP为VIP的报文</li>
<li>如何保证RS在源IP为VIP的情况下，将响应报文发送至外网</li>
</ul>
</blockquote>
<blockquote>
<p>第一个问题：DS如何知道RS的MAC地址？</p>
<ul>
<li>这个问题比较简单，因为DS必须要知道管理的RS的RIP地址，所以用ARP协议发送一个带有RIP的广播包。RS接收到这个广播包之后，打开并查看其中的IP是自己的RIP，就发送一个响应包，目的MAC地址是DS网卡接口的，而源MAC地址是RS网卡接口的。</li>
</ul>
</blockquote>
<blockquote>
<p>第二个问题：RS如何接收目标IP为VIP的报文</p>
<ul>
<li>要解决这个问题需要借助回环接口。在回环接口上配置VIP，在eth0上设置arp_ignore&#x3D;1。</li>
<li>首先，RS通过请求报文中的目的MAC地址接收到报文后，会将其交给上层协议，即网络层，然后回判断目的IP地址是不是自己。正常情况下，这里的目的IP地址是VIP，但是我RS的网络接口地址是RIP，对不上，会不处理。</li>
<li>于是需要配一个VIP地址到接口上。配到哪里呢？如果是配到eth0上，那在内部网络中使用ARP协议查找DS时，RS的eth0接口也会将自己的MAC地址返回，那不是发生IP冲突了？因此需要回环接口。<strong>回环接口是个逻辑接口，没有MAC地址，不会接收到ARP请求，因此也不会发送ARP响应，但是能够接收到IP数据报文</strong>。所以应该将VIP配置在回环接口上，但是有一个问题是，在默认arp_ignore&#x3D;0（代表回应任何网络接口上对任何本地IP地址的ARP查询请求）的情况下，eth0接口收到了对回环接口上的VIP地址的ARP请求，会将自己eth0接口的MAC地址响应出去，同样会发生IP冲突。所以需要将arg_ignore设置为1，即只响应目标IP地址为绑定在本接口的IP地址的ARP查询请求。如果有多张网卡，多张网卡都需要设置为1。</li>
</ul>
</blockquote>
<blockquote>
<p>第三个问题：如何保证RS在源IP为VIP的情况下，将响应报文发送至外网</p>
<ul>
<li>为什么会有这个问题呢？因为linux默认是使用IP报文的源IP作为ARP查询请求中的源IP地址，那么当RS发出ARP查询请求寻找能到达Client的网关MAC地址时，内部网络中的交换机会记录ARP查询请求中VIP地址和MAC地址作为以后转发接口使用，这样就会跟DS中配置的VIP网卡的MAC地址冲突了。</li>
<li>咋办呢？配置eth0接口的arp_announce为2。arp_announce &#x3D; 0 (默认)表示在任意网络接口上的任何本地地址；arp_announce&#x3D; 2 表示对查询目标使用最适当的本地地址，此模式下将忽略这个IP数据包的源地址并尝试选择与能跟该地址通信的本地地址。优先选择所有网络接口的子网中外出访问子网中包含该目标 IP 地址的本地地址；如果没有合适的地址被发现，将选择当前的发送网络接口或其他的有可能接受到该 ARP 回应的网络接口来进行发送。</li>
</ul>
</blockquote>
<h3 id="4-集群部署"><a href="#4-集群部署" class="headerlink" title="4. 集群部署"></a>4. 集群部署</h3><blockquote>
<p>主要了解ipvsadm命令的使用，以及实际的路由规则</p>
</blockquote>
<h4 id="4-1-环境信息"><a href="#4-1-环境信息" class="headerlink" title="4.1 环境信息"></a>4.1 环境信息</h4><ul>
<li>操作系统：Centos 7</li>
<li>内核版本： 3.10.0-1160.el7.x86_64</li>
<li>LVS工作模式：NAT</li>
<li>网络信息</li>
</ul>
<table>
<thead>
<tr>
<th>主机地址</th>
<th>Director Server 01</th>
<th>Real Server 01</th>
<th>Real Server 02</th>
</tr>
</thead>
<tbody><tr>
<td>IP</td>
<td>172.23.118.10（内网IP）<br />192.23.118.13（VIP，对外访问）</td>
<td>172.23.118.11（RIP）</td>
<td>172.23.118.12（RIP）</td>
</tr>
<tr>
<td>端口</td>
<td>80</td>
<td>80</td>
<td>80</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>需要事先将RS的默认网关设置为DS的内网地址172.23.118.10</strong>（反正要保证RS对客户端的响应能够先到达DS）</p>
<p>其实这里DS的内网IP和VIP可以设置成同一个，但是通常在生产环境中，为了对外提供LVS集群服务，需要一个外网IP作为VIP</p>
<p>我这里把DS的VIP绑定在了另外一个网卡上</p>
</blockquote>
<h4 id="4-2-LVS安装"><a href="#4-2-LVS安装" class="headerlink" title="4.2 LVS安装"></a>4.2 LVS安装</h4><p>Linux内核2.4版本以上基本都支持LVS，即已经有了<code>ipvs</code>，所以要想使用LVS只需要再装一个LVS管理工具<code>ipvsadm</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install ipvsadm -y</span><br></pre></td></tr></table></figure>



<h4 id="4-3-Nginx安装"><a href="#4-3-Nginx安装" class="headerlink" title="4.3 Nginx安装"></a>4.3 Nginx安装</h4><p>安装nginx主要是为了方便测试请求被路由到那台服务器上</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所有机器上执行</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装epel源</span></span><br><span class="line">sudo yum install -y epel-release</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装nginx</span></span><br><span class="line">sudo yum install nginx -y</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动nginx服务，默认80端口</span></span><br><span class="line">sudo servcie start nginx</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在DS上执行</span></span><br><span class="line">echo &#x27;DS01&#x27; | sudo tee /usr/share/nginx/html/index.html</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在RS01上执行</span></span><br><span class="line">echo &#x27;RS01&#x27; | sudo tee /usr/share/nginx/html/index.html</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在RS02上执行</span></span><br><span class="line">echo &#x27;RS02&#x27; | sudo tee /usr/share/nginx/html/index.html</span><br></pre></td></tr></table></figure>



<h4 id="4-4-关闭linux防火墙"><a href="#4-4-关闭linux防火墙" class="headerlink" title="4.4 关闭linux防火墙"></a>4.4 关闭linux防火墙</h4><p>不然无法从DS访问到RS的80端口。在生产环境下，通常只放开需要的端口。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭linux防火墙</span></span><br><span class="line">sudo systemctl stop firewalld</span><br></pre></td></tr></table></figure>



<h4 id="4-5-配置LVS"><a href="#4-5-配置LVS" class="headerlink" title="4.5 配置LVS"></a>4.5 配置LVS</h4><p>开始设置LVS集群</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ipvsadm常用配置参数</span></span><br><span class="line">-A     添加虚拟服务VIP</span><br><span class="line">-D     删除虚拟服务VIP</span><br><span class="line">-L     查看虚拟服务VIP</span><br><span class="line">-C     清除所有虚拟服务VIP</span><br><span class="line"></span><br><span class="line">-t     指定虚拟服务及端口 VIP:Port</span><br><span class="line">-r     指定真实服务及端口 RS:Port </span><br><span class="line">-s     指定算法，rr（轮询）、wrr（加权轮询）、lc（最少连接）、sh（源地址散列）、dh(目标地址散列) 等等</span><br><span class="line">-w     指定权重</span><br><span class="line">-m     指定转发模式为NAT</span><br><span class="line">-g     指定转发模式为DR</span><br><span class="line">-i     指定转发模式为IP隧道</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在DS01上执行</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">开启IP数据包转发功能</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以下命令只是暂时开启转发，重启后会失效</span></span><br><span class="line">echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">清除先前所有的ipvs配置信息</span></span><br><span class="line">sudo ipvsadm -C</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加一个LVS集群并且指定调度算法</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-A:添加集群 -t:VIP和端口 -s:调度算法</span></span><br><span class="line">sudo ipvsadm -A -t 192.23.118.13:80 -s rr</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">向LVS集群中添加真实服务器</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-a:添加真实服务器 -t:VIP和端口 -r:RIP和端口 -m:NAT模式 -w:转发权重</span></span><br><span class="line">sudo ipvsadm -a -t 192.23.118.13:80 -r 172.23.118.11:80 -m -w 1</span><br><span class="line">sudo ipvsadm -a -t 192.23.118.13:80 -r 172.23.118.12:80 -m -w 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以查看路由信息</span></span><br><span class="line">sudo watch ipvsadm -L -n -c</span><br></pre></td></tr></table></figure>



<h4 id="4-6-结果"><a href="#4-6-结果" class="headerlink" title="4.6 结果"></a>4.6 结果</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看LVS集群信息</span></span><br><span class="line">[junhao@localhost ~]$ sudo ipvsadm --list</span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">RemoteAddress:Port           Forward Weight ActiveConn InActConn</span></span><br><span class="line">TCP  192.23.118.13:http rr</span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">172.23.118.11:http           Masq    1      0          0</span>         </span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">172.23.118.12:http           Masq    1      0          0</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">访问LVS集群VIP</span></span><br><span class="line">[junhao@localhost ~]$ curl 192.23.118.13</span><br><span class="line">RS02</span><br><span class="line">[junhao@localhost ~]$ curl 192.23.118.13</span><br><span class="line">RS01</span><br><span class="line">[junhao@localhost ~]$ curl 192.23.118.13</span><br><span class="line">RS02</span><br><span class="line">[junhao@localhost ~]$ curl 192.23.118.13</span><br><span class="line">RS01</span><br><span class="line">[junhao@localhost ~]$ curl 192.23.118.13</span><br><span class="line">RS02</span><br></pre></td></tr></table></figure>



<h4 id="4-7-操作过程中的一些问题"><a href="#4-7-操作过程中的一些问题" class="headerlink" title="4.7 操作过程中的一些问题"></a>4.7 操作过程中的一些问题</h4><ul>
<li>在RS中会无法访问VIP（即内网中无法访问VIP）</li>
</ul>
<p>其实问题的本质跟着请求的源地址和目的地址走一遍就知道了，在RS1中发出请求（RIP1，VIP）。请求是能够到达DS的，LVS进行负载均衡后请求变为（RIP1，RIP），<strong>注意这里LVS只改变了目标地址，不改变源地址</strong>，请求被分配到随便一台真实服务器，RS1、RS2都可以。然后真实服务器接收到请求，处理之后根据源地址RIP1发出响应，<strong>注意这里因为RS1和RS2都在一个网段，所以响应发出后不会经过网关，即DS，而是在内网中发到RS1</strong>。然后没经过DS处理的响应（RIP，RIP1）就回到RS1中，然后<strong>RS1发现响应的源地址和目标地址与自己发出的请求（RIP1，VIP）不一致，就会把这个响应丢弃，而期望的响应是（VIP，RIP1）</strong>。所以在RS1中就无法访问VIP。</p>
<ul>
<li>IP转发的配置好像没用</li>
</ul>
<p>在实际操作过程中，试着把ip_forward设置成0再curl，但是也能通，没啥问题，这是因为把VIP绑定在了网卡上，所以肯定是能接收到的。然后试着把VIP解绑，即不绑定在任何网卡上，但是这个时候网络就不通了，即使ip_forward设置成1也不行，不清楚原因。</p>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux常用网络命令</title>
    <url>/2023/07/20/Linux%E5%B8%B8%E7%94%A8%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h4 id="netstat"><a href="#netstat" class="headerlink" title="netstat"></a>netstat</h4><h4 id="telnet"><a href="#telnet" class="headerlink" title="telnet"></a>telnet</h4><h4 id="traceroute"><a href="#traceroute" class="headerlink" title="traceroute"></a>traceroute</h4><h4 id="nslookup"><a href="#nslookup" class="headerlink" title="nslookup"></a>nslookup</h4><h4 id="nc"><a href="#nc" class="headerlink" title="nc"></a>nc</h4><h4 id="curl-x2F-wget"><a href="#curl-x2F-wget" class="headerlink" title="curl&#x2F;wget"></a>curl&#x2F;wget</h4><h4 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h4><h4 id="lsof"><a href="#lsof" class="headerlink" title="lsof"></a>lsof</h4><h4 id="arping"><a href="#arping" class="headerlink" title="arping"></a>arping</h4><h4 id="dig"><a href="#dig" class="headerlink" title="dig"></a>dig</h4><h4 id="ss"><a href="#ss" class="headerlink" title="ss"></a>ss</h4><h4 id="ip"><a href="#ip" class="headerlink" title="ip"></a>ip</h4>]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL储存过程游标使用踩坑（NOT FOUND）</title>
    <url>/2022/08/30/MySQL%E5%82%A8%E5%AD%98%E8%BF%87%E7%A8%8B%E6%B8%B8%E6%A0%87%E4%BD%BF%E7%94%A8%E8%B8%A9%E5%9D%91%EF%BC%88NOT-FOUND%EF%BC%89/</url>
    <content><![CDATA[<h3 id="1-具体问题"><a href="#1-具体问题" class="headerlink" title="1. 具体问题"></a>1. 具体问题</h3><p>在使用游标的过程中，通常都会使用未找到（NOT FOUND或者SQLSTATE ‘02000’）的条件来标识游标的结束。</p>
<p>即定义一个变量finished初始化为FALSE，并且定义一个事件处理程序处理NOT FOUND异常（FETCH时，游标已经达到末尾）将变量finished设置为TRUE，并通过检查变量finished来结束循环。</p>
<h3 id="2-问题原因"><a href="#2-问题原因" class="headerlink" title="2. 问题原因"></a>2. 问题原因</h3><p>坑就在这个NOT FOUNT异常，作用范围是整个储存过程。当FETCH获取下一行数据为空时，会抛出NOT FOUND异常。但是！但是！当使用普通的SELECT语句时，查询为空也会抛出NOT FOUND异常，就会触发设定好的NOT FOUND异常处理程序，所以如果遍历游标的循环体内如果存在查询为空，会导致循环提前退出。</p>
<h3 id="3-复现"><a href="#3-复现" class="headerlink" title="3. 复现"></a>3. 复现</h3><h4 id="3-1-相关的表"><a href="#3-1-相关的表" class="headerlink" title="3.1 相关的表"></a>3.1 相关的表</h4><ul>
<li>inst（inst_id, tenant_id, user_id）</li>
<li>data_resource(resource_id, inst_id)</li>
</ul>
<h4 id="3-2-错误示例"><a href="#3-2-错误示例" class="headerlink" title="3.2 错误示例"></a>3.2 错误示例</h4><p>这里在游标循环里面使用inst_id查询了关联表data_resource，但是当data_resource表中没有这条数据的时候就会出现NOT FOUND异常，将finished设置为TRUE，提前结束游标循环。如，本来是要显示inst_id为1、2、3这三行，但是当inst_id&#x3D;2时，data_resource表查询为空，就只显示inst_id为1这一行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 设置分隔符为$$</span><br><span class="line">DELIMITER $$</span><br><span class="line">CREATE PROCEDURE select_data_resource()</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE v_inst_id VARCHAR(128);</span><br><span class="line">    DECLARE v_tenant_id BIGINT;</span><br><span class="line">    DECLARE v_user_id BIGINT;</span><br><span class="line">    DECLARE v_resource_id BIGINT;</span><br><span class="line">    -- 定义游标循环结束条件</span><br><span class="line">    DECLARE finished INT DEFAULT FALSE;</span><br><span class="line">    -- 定义游标</span><br><span class="line">    DECLARE my_cursor CURSOR FOR (SELECT inst_id, tenant_id, user_id FROM inst);</span><br><span class="line">    -- 定义NOT FOUND结束处理程序</span><br><span class="line">    DECLARE CONTINUE HANDLER FOR NOT FOUND SET finished = TRUE;</span><br><span class="line">    </span><br><span class="line">    -- 开始使用游标</span><br><span class="line">    OPEN my_cursor;</span><br><span class="line">        foreach_inst: LOOP</span><br><span class="line">        FETCH my_cursor INTO v_inst_id, v_tenant_id, v_user_id;</span><br><span class="line">            -- 判断游标是否已经达到末尾</span><br><span class="line">            IF finished = TRUE THEN</span><br><span class="line">                LEAVE foreach_inst_id; -- 游标已经到达末尾，结束循环</span><br><span class="line">            END IF;</span><br><span class="line">            -- 显示当前行</span><br><span class="line">            SELECT v_inst_id, v_tenant_id, v_user_id;</span><br><span class="line">            -- 问题行！！！！</span><br><span class="line">            SELECT resource_id INTO v_resource_id FROM data_resource WHERE inst_id = v_inst_id;</span><br><span class="line">            -- 后续使用变量v_resource_id进行其他操作</span><br><span class="line">        -- 回到标签foreach_inst</span><br><span class="line">        END LOOP foreach_inst;</span><br><span class="line">    -- 关闭游标</span><br><span class="line">    CLOSE my_cursor;</span><br><span class="line">END $$</span><br><span class="line">-- 重新设置分隔符为;</span><br><span class="line">DELIMITER ;</span><br><span class="line"></span><br><span class="line">CALL select_data_resource();</span><br><span class="line">DROP PROCEDURE select_data_resource;</span><br></pre></td></tr></table></figure>



<h4 id="3-3-正确示例"><a href="#3-3-正确示例" class="headerlink" title="3.3 正确示例"></a>3.3 正确示例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 设置分隔符为$$</span><br><span class="line">DELIMITER $$</span><br><span class="line">CREATE PROCEDURE select_data_resource()</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE v_inst_id VARCHAR(128);</span><br><span class="line">    DECLARE v_tenant_id BIGINT;</span><br><span class="line">    DECLARE v_user_id BIGINT;</span><br><span class="line">    DECLARE v_resource_id BIGINT;</span><br><span class="line">    -- 定义游标循环结束条件</span><br><span class="line">    DECLARE finished INT DEFAULT FALSE;</span><br><span class="line">    -- 定义游标</span><br><span class="line">    DECLARE my_cursor CURSOR FOR (SELECT inst_id, tenant_id, user_id FROM inst);</span><br><span class="line">    -- 定义NOT FOUND结束处理程序</span><br><span class="line">    DECLARE CONTINUE HANDLER FOR NOT FOUND SET finished = TRUE;</span><br><span class="line">    </span><br><span class="line">    -- 开始使用游标</span><br><span class="line">    OPEN my_cursor;</span><br><span class="line">        foreach_inst: LOOP</span><br><span class="line">        FETCH my_cursor INTO v_inst_id, v_tenant_id, v_user_id;</span><br><span class="line">            -- 判断游标是否已经达到末尾</span><br><span class="line">            IF finished = TRUE THEN</span><br><span class="line">                LEAVE foreach_inst_id; -- 游标已经到达末尾，结束循环</span><br><span class="line">            END IF;</span><br><span class="line">            -- 显示当前行</span><br><span class="line">            SELECT v_inst_id, v_tenant_id, v_user_id;</span><br><span class="line">            -- 问题行！！！！</span><br><span class="line">            -- SELECT resource_id INTO v_resource_id FROM data_resource WHERE inst_id = v_inst_id;</span><br><span class="line">            SET v_resource_id = (SELECT resource_id FROM data_resource WHERE inst_id = v_inst_id);</span><br><span class="line">            -- 后续使用变量v_resource_id进行其他操作</span><br><span class="line">        -- 回到标签foreach_inst</span><br><span class="line">        END LOOP foreach_inst;</span><br><span class="line">    -- 关闭游标</span><br><span class="line">    CLOSE my_cursor;</span><br><span class="line">END $$</span><br><span class="line">-- 重新设置分隔符为;</span><br><span class="line">DELIMITER ;</span><br><span class="line"></span><br><span class="line">CALL select_data_resource();</span><br><span class="line">DROP PROCEDURE select_data_resource;</span><br></pre></td></tr></table></figure>



<h3 id="4-解决办法"><a href="#4-解决办法" class="headerlink" title="4. 解决办法"></a>4. 解决办法</h3><ul>
<li>保证循环中的查询不会出现 NOT FOUND 异常</li>
<li>使用<code>SET variable = (SELECT cloumn FROM table);</code> 来设置变量，替代<code>SELECT cloumn INTO variable FROM table;</code> 的方式</li>
</ul>
]]></content>
      <categories>
        <category>日常踩坑</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL知识总结</title>
    <url>/2022/12/05/MySQL%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h3 id="1-MyISAM和InnoDB的区别"><a href="#1-MyISAM和InnoDB的区别" class="headerlink" title="1. MyISAM和InnoDB的区别"></a>1. MyISAM和InnoDB的区别</h3><ul>
<li><p>MyISAM</p>
<ul>
<li>不支持事务、崩溃恢复</li>
<li>不支持行锁，只支持表锁</li>
<li>不支持外键</li>
<li>主键索引中叶子节点储存的不是数据记录，而是记录的内存地址，因此MyISAM的数据文件分为索引文件和数据文件</li>
</ul>
</li>
<li><p>InnoDB</p>
<ul>
<li>支持事务，崩溃恢复，有redo log</li>
<li>支持表锁、行级锁，通过MVCC和Next-key Lock在可重复读的隔离级别下解决幻读的问题</li>
<li>支持外键</li>
<li>InnoDB的主键索引是聚簇索引，所以数据文件只有一个</li>
</ul>
</li>
</ul>
<h3 id="2-索引"><a href="#2-索引" class="headerlink" title="2. 索引"></a>2. 索引</h3><blockquote>
<p>以 InnoDB 的一个整数字段索引为例，N叉B+树的N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p>
</blockquote>
<h4 id="索引类型（分类角度）"><a href="#索引类型（分类角度）" class="headerlink" title="索引类型（分类角度）"></a>索引类型（分类角度）</h4><ul>
<li><p><strong>主键索引</strong>：一种<strong>特殊的唯一索引</strong>，一个表只能有一个主键，<strong>不允许有空值</strong>，主键索引的记录在物理存储上的方式跟数据库引擎的实现有关，MyISAM中主键索引B+树的叶子节点储存的是记录的物理地址（所以数据库的数据文件分为索引文件和数据文件），而InnoDB中主键索引B+树的叶子节点储存了记录的所有字段值。</p>
</li>
<li><p><strong>普通索引</strong>：就是普通的索引。</p>
</li>
<li><p><strong>唯一索引</strong>：字段唯一，能够<strong>允许NULL值</strong>，就是只要是NULL就认为是不一样的，在InnoDB中NULL值储存在B+树的最左边。</p>
</li>
<li><p><strong>前缀索引</strong>：指对字符类型字段的前几个字符或对二进制类型字段的前几个bytes建立的索引，而不是在整个字段上建索引。前缀索引可以建立在类型为char、varchar、binary、varbinary的列上，可以大大减少索引占用的存储空间，也能提升索引的查询效率。</p>
</li>
<li><p><strong>全文索引</strong>：与搜索引擎相关，都是需要分词，然后根据关键字中的词频和重要性进行排序。</p>
</li>
<li><p><strong>联合索引</strong>：由多个字段组合形成的索引。</p>
</li>
</ul>
<h4 id="聚簇索引与非聚簇索引（物理储存角度）"><a href="#聚簇索引与非聚簇索引（物理储存角度）" class="headerlink" title="聚簇索引与非聚簇索引（物理储存角度）"></a>聚簇索引与非聚簇索引（物理储存角度）</h4><ul>
<li><p><strong>聚簇索引</strong>：记录的物理储存顺序与列值（一般是主键的一列）的逻辑顺序相同，一个表中只有一个聚簇索引（因为聚簇索引的记录在物理储存上是有序的，所以当按照主键遍历的时候，相邻的主键都在同一块内存页中，能够减少缺页中断，提高查询效率）。</p>
</li>
<li><p><strong>非聚簇索引</strong>（二级索引、辅助索引）：与聚簇索引相反，如果记录的物理储存顺序与列值的逻辑顺序不一样，那么就是非聚簇索引，一个表中可以有多个非聚簇索引。</p>
</li>
</ul>
<h4 id="B-树索引和哈希索引（数据结构角度）"><a href="#B-树索引和哈希索引（数据结构角度）" class="headerlink" title="B+树索引和哈希索引（数据结构角度）"></a>B+树索引和哈希索引（数据结构角度）</h4><ul>
<li><p><strong>B+树索引</strong>：B+树是多叉平衡树，所以能够快速搜索到记录的位置，B+树的特点是非叶子节点不储存数据，叶子节点储存数据，最后所有叶子节点组成一条有序的双向链表，<strong>因为非叶子节点不储存数据，所以单个非叶子节点能够储存大量的索引数据，而由于这些索引数据是经常被访问的，所以能够常驻在内存中，减少缺页中断（或SWAP）带来的性能消耗</strong>。</p>
</li>
<li><p><strong>B树索引</strong>：B树叶子节点也储存数据，而且所有叶子节点不会组成有序链表。</p>
</li>
<li><p><strong>哈希索引</strong>：经过哈希函数能够快速找到记录的位置，不需要进行搜索（哈希冲突解决的办法）</p>
</li>
</ul>
<h4 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h4><blockquote>
<p>InnoDB引擎支持自适应哈希索引，是数据库自动优化，只能选择开启或者关闭。</p>
</blockquote>
<p>因为当使用辅助索引进行查找的时候，如果并不是覆盖索引，就需要<strong>回表</strong>到主键索引中找到记录的所有数据，如果这种查询的次数变多，那么InnoDB就会自动创建自适应哈希索引，<strong>提高在通过辅助索引查找到主键Id的时候，再回表的查询速度</strong>。（即通过辅助索引查找到主键Id，然后通过主键Id的哈希索引直接找到记录的位置）。</p>
<p>根据一些资料的统计，读取和写入速度可以提高2倍，辅助索引的连接操作性能可以提高5倍。</p>
<p><a href="https://juejin.cn/post/6844903888080863245">自适应哈希索引(Adaptive Hash Index, AHI)</a></p>
<h4 id="主键索引就是聚簇索引吗？"><a href="#主键索引就是聚簇索引吗？" class="headerlink" title="主键索引就是聚簇索引吗？"></a>主键索引就是聚簇索引吗？</h4><p><strong>不是</strong>！！！在InnoDB中主键的确是按聚簇索引的方式组织的，但是在MyISAM里面主键<strong>不是</strong>聚簇索引，sql server中还可以显示的指定聚簇索引。</p>
<p>InnoDB中如果没有定义主键，Innodb会选择非空的唯一索引代替。如果没有这样的索引，Innodb会隐式的定义一个主键来作为聚簇索引。</p>
<p><a href="https://www.cnblogs.com/lice-blog/p/11569443.html">主键索引就是聚集索引吗？</a></p>
<h4 id="什么是联合索引、覆盖索引、索引最左匹配原则"><a href="#什么是联合索引、覆盖索引、索引最左匹配原则" class="headerlink" title="什么是联合索引、覆盖索引、索引最左匹配原则"></a>什么是联合索引、覆盖索引、索引最左匹配原则</h4><ul>
<li><p><strong>联合索引</strong>：由多个字段组合形成的索引</p>
</li>
<li><p><strong>覆盖索引</strong>：查询的字段会被索引覆盖到，就<strong>不需要回表</strong>根据主键Id查询其他字段，<strong>单个字段的索引</strong>和<strong>联合索引</strong>都能实现覆盖索引的功能。所以说覆盖索引并不是一种真正的索引，是查询的时候用到的索引覆盖到了所有需要查询的字段。</p>
</li>
<li><p><strong>索引最左匹配原则</strong>：对于一个联合索引（a, b, c, d），如果查询的时候指定了查询条件<code>a = 1 AND b = 2 AND c &gt; 4 AND d &lt; 5</code>，因为索引整体上是按<code>a,b,c,d</code>来排序的（即先按a排序，a相等的时候按b排序，以此类推），所以<strong>当a和b指定了确切的值的时候，记录在c上是有序的，但是在d上就不确认了</strong>。当联合索引遇到范围查询（&gt;，&lt;，between，like）最左匹配就不能进一步匹配了。（当然MySQL会优化查询的顺序比如，<code>d &lt; 5 AND b = 2 AND c &gt; 4 AND a = 1</code> 会优化为<code>a = 1 AND b = 2 AND c &gt; 4 AND d &lt; 5</code>）</p>
</li>
</ul>
<h4 id="说一下索引下推"><a href="#说一下索引下推" class="headerlink" title="说一下索引下推"></a>说一下索引下推</h4><blockquote>
<p>索引下推可以在索引遍历过程中（引擎层），对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p>
</blockquote>
<p>对于一个联合索引<strong>（name, age）</strong>和一个SQL语句</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from tuser where name like &#x27;张%&#x27; and age = 10 and ismale = 1;</span><br></pre></td></tr></table></figure>

<ul>
<li>如果没有索引下推，因为最左匹配原则，所以只会用到<code>name</code>的索引，所以在引擎层会找到所有<code>name like &#39;张%&#39;</code>的主键并返回给server层，然后逐个回表判断</li>
<li>如果有索引下推，即使有最左匹配原则，也会将索引能用到的<code>age = 10</code>放到引擎层进行判断，引擎层根据索引判断，只返回<code>name like &#39;张%&#39; and age = 10</code>的主键，这样过滤了不符合的部分数据，就能减少回表的次数</li>
</ul>
<h3 id="3-事务"><a href="#3-事务" class="headerlink" title="3. 事务"></a>3. 事务</h3><h4 id="事务的四大特性（ACID）"><a href="#事务的四大特性（ACID）" class="headerlink" title="事务的四大特性（ACID）"></a>事务的四大特性（ACID）</h4><ol>
<li>原子性：一个事务是最小执行单位，事务中的动作要么都做，要么都不做</li>
<li>一致性：执行事务之后，数据保持一致，多个事务对同一个数据读取的结果是相同的</li>
<li>隔离性：并发访问数据库的时候，各个事务之间不会相互影响</li>
<li>持久性：一个事务被提交之后，对数据库的修改是持久的，即使数据库发生故障也不会有影响</li>
</ol>
<h4 id="可能出现的问题"><a href="#可能出现的问题" class="headerlink" title="可能出现的问题"></a>可能出现的问题</h4><ol>
<li><strong>脏读</strong>：事务A能够读到事务B还没提交的数据</li>
<li><strong>不可重复读</strong>：对于读取一行数据，一个事务中两次读到的数据不一样</li>
<li><strong>幻读</strong>：对于读取多行数据，一个事务中第二次读到的行数比第一次读到的行数要多</li>
<li><strong>丢失修改</strong>：ABA问题，事务A读取记录R为20，将R-1&#x3D;19后写入数据库，事务B也执行一样的操作，但是最后数据库中的记录是R&#x3D;19，事务A的操作被事务B覆盖（这种是程序逻辑本身的问题，所以需要对需要修改的数据加锁&#x2F;版本号&#x2F;旧值比较）</li>
</ol>
<h4 id="隔离等级"><a href="#隔离等级" class="headerlink" title="隔离等级"></a>隔离等级</h4><ol>
<li><p><strong>读未提交</strong>：一个事务还没提交，其变更就能被其他事务看到</p>
</li>
<li><p><strong>读已提交</strong>：一个事务提交之后，其变更才能被其他事务看到，能够解决脏读的问题</p>
</li>
<li><p><strong>可重复读</strong>：一个事务执行过程中，对同一字段的多次读取结果是一样的，除非数据是被自己事务本身修改，能够解决不可重复读的问题，但是幻读仍然有可能发生<strong>（InnoDB通过MVCC和Next-key Lock在可重复读的隔离级别下解决了幻读的问题）</strong></p>
</li>
<li><p><strong>串行化</strong>：所有事务都是串行执行的，完全服从ACID的隔离级别，能解决所有问题</p>
</li>
</ol>
<h3 id="4-锁-、间隙锁、Next-Key-Lock"><a href="#4-锁-、间隙锁、Next-Key-Lock" class="headerlink" title="4. 锁 、间隙锁、Next-Key Lock"></a>4. 锁 、间隙锁、Next-Key Lock</h3><ul>
<li><p><strong>全局锁</strong>：对整个数据库加锁（Flush tables with read lock），典型应用场景是做全库逻辑备份（如果使用InnoDB，则使用mysqldump备份数据库的时候，有MVCC的支持，就不用加全局锁了）</p>
</li>
<li><p><strong>表级锁</strong>：又分为<strong>表锁</strong>和<strong>元数据锁（metadata lock， MDL）</strong></p>
<ul>
<li>元数据锁：锁住表结构，在访问一个表的时候会被自动加上，事务中的MDL锁会在语句执行开始时申请，但是语句结束后并不会马上释放，而是等到整个事务提交后才会释放</li>
</ul>
</li>
<li><p><strong>行锁</strong>：锁住一行，在InnoDB的事务中，行锁是在语句执行的时候加上，但是要等到事务结束才会释放（<strong>两阶段锁协议</strong>）</p>
<ul>
<li>行锁可能出现死锁的一种情况，事务A执行了第一条语句，事务B执行了第一条语句，两个事务分别获得了不同的行锁</li>
<li>解决行锁死锁的方法， <strong>1. 等待超时（innodb_lock_wait_timeout）</strong>，<strong>2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务（innodb_deadlock_detect &#x3D; on）</strong></li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 事务A</span></span><br><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 事务B</span></span><br><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>间隙锁（Gap Lock）</strong>:锁住两个值之间的空隙，前开后开区间，如6个值，有7个空隙，包括（-∞，num）和（num, +∞）<ul>
<li><strong>跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作</strong></li>
<li>间隙锁死锁的例子<ul>
<li>session A 执行 select … for update 语句，由于 id&#x3D;9 这一行并不存在，因此会加上间隙锁 (5,10);</li>
<li>session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；</li>
<li>session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；</li>
<li>session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2022/12/05/MySQL%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E9%97%B4%E9%9A%99%E9%94%81%E6%AD%BB%E9%94%81.png" alt="image-20220906104804761"></p>
<ul>
<li><strong>Next-key Lock</strong>：Inno加锁的<strong>基本单位</strong>，<strong>为的就是解决幻读</strong>，行锁<code>b</code>和间隙锁<code>(a, b)</code>加在一起，就是一个<strong>Next-key Lock</strong>，是前开后闭区间<code>(a, b]</code></li>
</ul>
<h3 id="5-多版本并发控制MVCC"><a href="#5-多版本并发控制MVCC" class="headerlink" title="5. 多版本并发控制MVCC"></a>5. 多版本并发控制MVCC</h3><blockquote>
<p>MVCC加上Next-key Lock就能够解决幻读的问题。单单MVCC只能解决可重复读，当前读的情况下，还是会出现幻读</p>
</blockquote>
<blockquote>
<p>在MVCC中，非锁定读（普通select）是不用加锁的，但是锁定读(select … for update &#x2F; select … lock in share mode &#x2F; update &#x2F; insert &#x2F; delete)的时候会用锁</p>
</blockquote>
<blockquote>
<p>InnoDB中，每条记录在更新的时候都会同时记录一条回滚操作，因此能得到上一个状态的值。（这个回滚日志<code>undolog</code>会在不需要的时候才删除，即当前所有事务中的最小版本号大于回滚日志的版本号）</p>
</blockquote>
<h4 id="标识ID"><a href="#标识ID" class="headerlink" title="标识ID"></a>标识ID</h4><ul>
<li><strong>每个事务</strong>都有一个唯一的<strong>事务ID（transaction id）</strong>，每个事务开始前向InnoDB的事务系统申请，严格递增</li>
<li><strong>每行数据</strong>都有多个版本<strong>row trx_id</strong>，每次事务更新数据的时候，都会生成一个新的数据版本，并把<strong>事务ID</strong>赋值给<strong>row trx_id</strong>，旧的数据版本能够通过回滚日志得到</li>
</ul>
<p><img src="/2022/12/05/MySQL%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/MVCC.png" alt="image-20220905203039546"></p>
<h4 id="详细过程"><a href="#详细过程" class="headerlink" title="详细过程"></a>详细过程</h4><blockquote>
<p>核心是通过版本控制来获得一个一致性视图，但是当事务更新数据的时候，只能用当前读，如果当前记录的行锁被其他事务占用，就只能进入锁等待。</p>
</blockquote>
<ol>
<li><strong>当前事务开始时</strong>，构造一个<strong>数组</strong>用于保存当前事务启动瞬间<strong>活跃</strong>的<strong>所有事务ID</strong>（即启动了，但是还没有提交）</li>
<li>数组里面事务ID的<strong>最小值记为低水位</strong>，<strong>事务ID的最大值+1记为高水位</strong>，数组和高水位就组成了当前事务的一致性视图（read-view）</li>
<li>对于<strong>一个数据记录</strong>的<strong>row trx_id</strong>来说，有以下几种可能<ul>
<li><strong>row trx_id小于低水位</strong>，落在绿色部分，表示这个版本的数据是已经提交的，或者是当前事务自己生成的，所以数据<strong>可见</strong></li>
<li><strong>row trx_id大于高水位</strong>，落在红色部分，表示这个版本的数据是由未来的事务生成的，<strong>不可见</strong></li>
<li>如果落在黄色部分：<ul>
<li><strong>row trx_id在数组中</strong>，表示这个版本是由未提交的事务生成的，<strong>不可见</strong></li>
<li><strong>row trx_id不在数组中</strong>，表示这个版本的数据是由已提交的事务生成的，<strong>可见</strong>（因为低水位和高水位表示的只是一个区间，这个区间中有已经提交的事务和未提交的事务，数组中的是未提交的事务，而当前的事务ID大于高水位，<strong>row trx_id</strong>落在这个区间内已提交的事务，哪当然是可见的）</li>
</ul>
</li>
</ul>
</li>
<li><strong>当前读</strong>：<strong>更新数据都是先读后写的</strong>，而这个读，只能<strong>读已经提交完成的最新版本</strong></li>
<li>如果是更新&#x2F;删除&#x2F;插入这些锁定读的事务呢？<strong>两阶段锁协议</strong>，需要等到获得锁的事务结束了，释放锁，才能继续<strong>当前读</strong>，继续后面的操作</li>
</ol>
<p><img src="/2022/12/05/MySQL%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/MVCC%E6%B0%B4%E4%BD%8D.png" alt="image-20220905225008836"></p>
<h4 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h4><p>MVCC也会出现ABA问题，因为只有在锁定读的时候才会加锁，所以可能会出现ABA问题，一个简单的例子，事务A读取了记录R数值为1，之后事务B也读取这个记录R数值为1，之后事务AB都想要将记录R+1后更新，那么最后结果就会变成2，但是期望是3。ABA问题是编程问题，所以可以使用select … lock for update来锁住想要更新的表，这样只有获取到锁的事务才能进行操作。或者加一个旧值&#x2F;版本号进行判断，只有当旧值&#x2F;版本号一样的时候才更新（但是修改失败需要有重试机制）。</p>
<h3 id="6-binlog、redolog"><a href="#6-binlog、redolog" class="headerlink" title="6. binlog、redolog"></a>6. binlog、redolog</h3><h4 id="binlog（归档日志）"><a href="#binlog（归档日志）" class="headerlink" title="binlog（归档日志）"></a>binlog（归档日志）</h4><blockquote>
<p>binlog的主要作用是用于备份，以及主从同步</p>
</blockquote>
<blockquote>
<p>binlog的写是追加写，所以不会覆盖以前的数据</p>
</blockquote>
<p>三种数据格式：</p>
<ul>
<li>statement – 记录执行的SQL语句，简洁，但是主库与从库执行同一条语句的结果可能不一样，如NOW()</li>
<li>row – 记录真实数据的变化，可靠，主从库执行结果一样，但是占空间</li>
<li>mixed – 前两种的混合，MySQL自己判断如果会引起主备不一致的时候，就用row格式，否则用statement</li>
</ul>
<h4 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a>redo log（重做日志）</h4><blockquote>
<p>redolog主要的作用是用于崩溃恢复，固定大小，循环写，可以比如可以配置一组4个文件，每个文件大小1GB，从头开始写，写到末尾又回到开头循环写。</p>
</blockquote>
<ul>
<li><p><strong>write pos</strong>：表示当前写记录的位置，一边写一边后移</p>
</li>
<li><p><strong>check point</strong>：check point之前的数据都是已经落盘（flush到磁盘）上的，write pos大于check point，write pos 与check point之间的数据表示在内存页上，但是还没落盘的数据</p>
</li>
</ul>
<h4 id="缓冲结构"><a href="#缓冲结构" class="headerlink" title="缓冲结构"></a>缓冲结构</h4><blockquote>
<p>崩溃分为数据库崩溃和操作系统崩溃，数据库崩溃只会影响MySQL中的缓存（丢失这一部分，已经调用write写入到操作系统缓存中的则是正常的），操作系统崩溃则是影响数据的落盘（无法恢复）</p>
</blockquote>
<ul>
<li><p><strong>buffer pool</strong>：MySQL中用于缓存页的地方，有脏页以及干净页，脏页落盘需要flush，干净页不用</p>
</li>
<li><p><strong>change buffer</strong>：buffer pool内的一部分，<strong>主要用于记录页面数据的变化</strong>，如果一个<strong>数据页已经在内存</strong>中，则可以直接修改这个内存数据页然后变成脏页；但是如果一个<strong>数据页不在内存中，在磁盘中</strong>，则可以将更新操作写到change buffer中，这样能够避免将数据页从磁盘中读取到内存中，<strong>减少磁盘的随机读IO，适用于多写少读</strong>，当要读取这个数据页的数据时，再将从磁盘中读取的数据执行change buffer中的操作就能得到最新的数据。</p>
</li>
<li><p><strong>redolog buffer</strong>：可以认为也是buffer pool中的一部分，事务执行过程中更新数据的日志都得先保存起来，但是又不能在还没commit的时候写入到redo log文件中，所以先用redolog buffer来存redo日志。</p>
</li>
<li><p><strong>操作系统的缓存 os cache</strong>：调用操作系统的write函数并不会将数据直接写入磁盘，而是先写入系统的缓冲池中，系统自己判断何时将数据flush进磁盘，<strong>数据库崩溃不会影响到这部分的数据，操作系统崩溃才会影响</strong>。</p>
</li>
</ul>
<h4 id="二阶段提交"><a href="#二阶段提交" class="headerlink" title="二阶段提交"></a>二阶段提交</h4><p>redo log是InnoDB引擎特有，用于提供崩溃恢复的功能，而二阶段提交涉及到<code>binlog(归档日志)</code>还有<code>redolog(重做日志)</code>，即server层与引擎层之间的交互。</p>
<p><strong>两阶段提交的作用</strong>：保证MySQL数据库中的记录与磁盘中的记录一致</p>
<p><strong>方法流程</strong>：</p>
<ul>
<li>执行器调用引擎的API接口(未写<code>binlog</code>)，写入一行数据</li>
<li>InnoDB引擎把数据保存在内存中，同时记录<code>redolog</code>，此时<code>redolog </code>进入<code>prepare状态</code>，然后告诉执行器，执行完成可以随时提交</li>
<li>执行器收到通知后记录<code>binlog</code>，然后调用InnoDB引擎接口说已经写完<code>binlog</code></li>
<li>InnoDB写<code>redolog</code>为<code>commit状态</code></li>
<li>更新完成</li>
</ul>
<p><strong>为什么要这样子？</strong></p>
<ul>
<li>假设<strong>先写redolog并设为commit状态，然后写binlog</strong>，那么写完<code>redolog</code>之后，机器挂了，<code>binlog</code>日志没有被写入。机器重启后，会通过<code>redolog</code>恢复数据，但是<code>binlog</code>没有记录这一条数据，那么后续机器根据<code>binlog</code><strong>备份</strong>或者<strong>主从同步</strong>的时候，就会丢失这一条数据。</li>
<li>假设<strong>先写binlog，然后写redolog</strong>，那么当<code>binlog</code>写完的时候，机器异常重启了，但是由于没有这条<code>redolog</code>，所以机器无法恢复这一条记录，但是<code>binlog</code>里面多出这一条数据，哪备份或者主从同步的时候也会出现同样的问题。</li>
<li><strong>二阶段提交如何保证一致性？</strong>假设极端的状态是<code>redolog</code>已经处于<strong>prepare状态</strong>，<code>binlog</code>也已经写完了，这个时候发生异常重启，就要依赖MySQL的处理机制<ul>
<li>判断<code>redolog</code>是否完整(<strong>commit状态</strong>)，如果是完整的，就能立即提交</li>
<li>如果<code>redolog</code>只是<code>prepare</code>状态，但<strong>不是commit状态</strong>，这个时候就判断<code>binlog</code>是否完整，如果完整就提交<code>redolog</code>，不完整就回滚事务</li>
</ul>
</li>
</ul>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485097&idx=1&sn=84c89da477b1338bdf3e9fcd65514ac1&chksm=cea24962f9d5c074d8d3ff1ab04ee8f0d6486e3d015cfd783503685986485c11738ccb542ba7&token=79317275&lang=zh_CN%23rd">一条SQL语句在MySQL中如何执行的</a></p>
<h3 id="7-主从模式"><a href="#7-主从模式" class="headerlink" title="7. 主从模式"></a>7. 主从模式</h3><h4 id="详细流程"><a href="#详细流程" class="headerlink" title="详细流程"></a>详细流程</h4><ol>
<li>在备库B上通过<strong>change master</strong>命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量</li>
<li>在备库B上执行<strong>start slave</strong>命令，这个时候备库会启动两个线程，一个是<strong>io_thread</strong>，另一个是<strong>sql_thread</strong>。<strong>io_thread负责与主库A建立连接，获取binlog</strong></li>
<li>主库A校验完备库B传来的参数之后，按照请求的位置读取binlog通过<strong>dump_thread</strong>线程发给备库B</li>
<li>备库B拿到binlog之后，写到本地文件，称为<strong>中转日志（relay log）</strong></li>
<li>备库B中的<strong>sql_thread读取中转日志，解析日志理的命令，并执行</strong></li>
</ol>
<p><img src="/2022/12/05/MySQL%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B.png" alt="image-20220906144751652"></p>
<h4 id="循环复制问题"><a href="#循环复制问题" class="headerlink" title="循环复制问题"></a>循环复制问题</h4><blockquote>
<p>一般来说都是双Master结构，即节点A和节点B之间互为主从关系</p>
</blockquote>
<blockquote>
<p>但是这样会产生一个问题，就是节点A更新了一条语句，并将binlog发给节点B，节点B更新之后又将binlog发给节点A执行</p>
</blockquote>
<p><strong>解决方法</strong></p>
<p>设置server id</p>
<ol>
<li>规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系</li>
<li>一个备库收到binlog并且在重放过程中，要生成与原binlog的server id相同的新binlog</li>
<li>备库收到主库发过来的binlog记录，先判断server id是不是跟自己的一样，一样表示这个日志是自己生成的，则直接丢弃；不一样表示不是自己生成的，重做这个日志</li>
</ol>
<p><img src="/2022/12/05/MySQL%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2.png" alt="image-20220906145810695"></p>
<h3 id="8-inner-join、left-join、right-join、full-join"><a href="#8-inner-join、left-join、right-join、full-join" class="headerlink" title="8. inner join、left join、right join、full join"></a>8. inner join、left join、right join、full join</h3><ul>
<li><p><strong>inner join</strong>：等同于平时使用<code>，</code>连接两个表，内连接，交集</p>
</li>
<li><p><strong>left join</strong>：返回左表的全部数据</p>
</li>
<li><p><strong>right join</strong>：返回右表的全部数据</p>
</li>
<li><p><strong>full join</strong>：返回左右两个表的所有数据，并集</p>
</li>
</ul>
<p><img src="/2022/12/05/MySQL%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/join.png" alt="image-20220906162852592"></p>
<h4 id="on和where的区别"><a href="#on和where的区别" class="headerlink" title="on和where的区别"></a>on和where的区别</h4><ul>
<li><p><strong>on</strong>：在生成临时表时使用的条件，不管on中的条件，都会返回left join &#x2F; right join &#x2F; full join时，左边&#x2F;右边&#x2F;两边表中的记录</p>
</li>
<li><p><strong>where</strong>：临时表生成好后，对临时表进行过滤，所有条件不为真的记录都被过滤掉</p>
</li>
</ul>
<p><a href="https://www.runoob.com/w3cnote/sql-different-on-and-where.html">SQL 中 on 条件与 where 条件的区别</a></p>
<h3 id="9-小表驱动大表"><a href="#9-小表驱动大表" class="headerlink" title="9. 小表驱动大表"></a>9. 小表驱动大表</h3><blockquote>
<p>select * from t1 straight_join t2 on (t1.a &#x3D; t2.a); 能够让MySQL使用固定的连接方式执行查询，t1是驱动表、t2是被驱动表</p>
</blockquote>
<blockquote>
<p>小表是指两个表按照各自的条件过滤之后，参与join的各个字段的<strong>总数据量</strong>小的表</p>
</blockquote>
<p>驱动与被驱动：按照驱动表t1的数据到被驱动表t2中逐条查找数据，驱动表是外层循环，被驱动表是内层循环</p>
<p>Index Nested-Loop Join：能够用上被驱动表的索引</p>
<p>Simple Nested-Loop Join：不能用索引的情况下，就是两层循环</p>
<p>Block Nested-Loop Join：先将驱动表数据放入join buffer中，再根据被驱动表与join buffer中的数据对比</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring validation使用及校验异常处理</title>
    <url>/2022/09/14/Spring-validation%E4%BD%BF%E7%94%A8%E5%8F%8A%E6%A0%A1%E9%AA%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h3 id="1-作用"><a href="#1-作用" class="headerlink" title="1. 作用"></a>1. 作用</h3><blockquote>
<p>Spring validation能够用来校验前端传到后端的参数，并且当参数不符合规则时抛出异常信息</p>
</blockquote>
<blockquote>
<p><code>Java API</code>规范(<code>JSR303</code>)定义了<code>Bean</code>校验的标准<code>validation-api</code>，但没有提供实现。<code>hibernate validation</code>是对这个规范的实现，并增加了校验注解如<code>@Email</code>、<code>@Length</code>等。<code>Spring Validation</code>是对<code>hibernate validation</code>的二次封装，用于支持<code>spring mvc</code>参数自动校验。</p>
</blockquote>
<h3 id="2-引入依赖"><a href="#2-引入依赖" class="headerlink" title="2. 引入依赖"></a>2. 引入依赖</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-validation<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"># 或者</span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.hibernate<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hibernate-validator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="3-常用注解"><a href="#3-常用注解" class="headerlink" title="3. 常用注解"></a>3. 常用注解</h3><h4 id="3-1-Valid和-Validated区别"><a href="#3-1-Valid和-Validated区别" class="headerlink" title="3.1 @Valid和@Validated区别"></a>3.1 @Valid和@Validated区别</h4><table>
<thead>
<tr>
<th>区别</th>
<th>@Valid</th>
<th>@Validated</th>
</tr>
</thead>
<tbody><tr>
<td>提供者</td>
<td>JSR-303规范</td>
<td>Spring</td>
</tr>
<tr>
<td><strong>是否支持分组</strong></td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>标注位置</td>
<td>METHOD, FIELD, CONSTRUCTOR, PARAMETER, TYPE_USE</td>
<td>TYPE, METHOD, PARAMETER</td>
</tr>
<tr>
<td><strong>嵌套校验</strong></td>
<td>支持</td>
<td>不支持</td>
</tr>
</tbody></table>
<h4 id="3-2-对象"><a href="#3-2-对象" class="headerlink" title="3.2 对象"></a>3.2 对象</h4><table>
<thead>
<tr>
<th align="left">注解</th>
<th>comment</th>
<th>version</th>
</tr>
</thead>
<tbody><tr>
<td align="left">@Null</td>
<td>对象，为空</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td align="left">@NotNull</td>
<td>对象，不为空</td>
<td>Bean Validation 1.0</td>
</tr>
</tbody></table>
<h4 id="3-3-布尔"><a href="#3-3-布尔" class="headerlink" title="3.3 布尔"></a>3.3 布尔</h4><table>
<thead>
<tr>
<th>注解</th>
<th>comment</th>
<th>version</th>
</tr>
</thead>
<tbody><tr>
<td>@AssertTrue</td>
<td>布尔，为True</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@AssertFalse</td>
<td>布尔，为False</td>
<td>Bean Validation 1.0</td>
</tr>
</tbody></table>
<h4 id="3-4-数字"><a href="#3-4-数字" class="headerlink" title="3.4 数字"></a>3.4 数字</h4><table>
<thead>
<tr>
<th>注解</th>
<th>comment</th>
<th>version</th>
</tr>
</thead>
<tbody><tr>
<td>@Min(value)</td>
<td>数字，最小为value</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@Max(value)</td>
<td>数字，最大为value</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@DecimalMin(value)</td>
<td>数字，最小为value</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@DecimalMax(value)</td>
<td>数字，最大为value</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@Size(max, min)</td>
<td>min&lt;&#x3D;value&lt;&#x3D;max</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@Range</td>
<td>数字，某个范围内</td>
<td>Hibernate Validation</td>
</tr>
<tr>
<td>@Digits (integer, fraction)</td>
<td>数字，某个范围内</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@Positive</td>
<td>数字，正数</td>
<td>Bean Validation 2.0</td>
</tr>
<tr>
<td>@PositiveOrZero</td>
<td>数字，正数或0</td>
<td>Bean Validation 2.0</td>
</tr>
<tr>
<td>@Negative</td>
<td>数字，负数</td>
<td>Bean Validation 2.0</td>
</tr>
<tr>
<td>@NegativeOrZero</td>
<td>数字，负数或0</td>
<td>Bean Validation 2.0</td>
</tr>
</tbody></table>
<h4 id="3-5-字符串"><a href="#3-5-字符串" class="headerlink" title="3.5 字符串"></a>3.5 字符串</h4><table>
<thead>
<tr>
<th>注解</th>
<th>comment</th>
<th>version</th>
</tr>
</thead>
<tbody><tr>
<td>@Length</td>
<td>字符串，字符长度</td>
<td>Hibernate Validation</td>
</tr>
<tr>
<td>@Pattern(value)</td>
<td>字符串，正则校验</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@Email</td>
<td>字符串，邮箱类型</td>
<td>Bean Validation 2.0</td>
</tr>
<tr>
<td>@NotBlank</td>
<td>字符串，不为空字符串</td>
<td>Bean Validation 2.0</td>
</tr>
</tbody></table>
<h4 id="3-6-日期"><a href="#3-6-日期" class="headerlink" title="3.6 日期"></a>3.6 日期</h4><table>
<thead>
<tr>
<th>注解</th>
<th>comment</th>
<th>version</th>
</tr>
</thead>
<tbody><tr>
<td>@Past</td>
<td>日期，过去的日期</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@Future</td>
<td>日期，将来的日期</td>
<td>Bean Validation 1.0</td>
</tr>
<tr>
<td>@PastOrPresent（时间）</td>
<td>过去或者现在</td>
<td>Bean Validation 2.0</td>
</tr>
<tr>
<td>@FutureOrPresent（时间）</td>
<td>将来或者现在</td>
<td>Bean Validation 2.0</td>
</tr>
</tbody></table>
<h4 id="3-7-集合"><a href="#3-7-集合" class="headerlink" title="3.7 集合"></a>3.7 集合</h4><table>
<thead>
<tr>
<th>注解</th>
<th>comment</th>
<th>version</th>
</tr>
</thead>
<tbody><tr>
<td>@NotEmpty</td>
<td>集合，不为空</td>
<td>Bean Validation 2.0</td>
</tr>
</tbody></table>
<h3 id="4-使用示例"><a href="#4-使用示例" class="headerlink" title="4. 使用示例"></a>4. 使用示例</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.springvalidationdemo.controller.dto;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.validator.constraints.Length;</span><br><span class="line"><span class="keyword">import</span> javax.validation.constraints.*;</span><br><span class="line"><span class="keyword">import</span> java.time.LocalDateTime;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserDTO</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotNull</span></span><br><span class="line">    <span class="keyword">private</span> Long userId;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotBlank</span></span><br><span class="line">    <span class="meta">@Length(max = 32)</span></span><br><span class="line">    <span class="meta">@Pattern(regexp = &quot;^[\\\\u4E00-\\\\u9FA5A-Za-z0-9\\\\*]*$&quot;, message = &quot;用户昵称限制：最多20字符，包含文字、字母和数字&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String userName;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotBlank</span></span><br><span class="line">    <span class="meta">@Pattern(regexp = &quot;^((17[0-9])|(14[0-9])|(13[0-9])|(15[^4,\\D])|(18[0,5-9]))\\d&#123;8&#125;$&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String mobile;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> String sex;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotBlank</span></span><br><span class="line">    <span class="meta">@Email</span></span><br><span class="line">    <span class="keyword">private</span> String email;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Future</span></span><br><span class="line">    <span class="keyword">private</span> LocalDateTime createdTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.springvalidationdemo.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.example.springvalidationdemo.controller.dto.UserDTO;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.support.DefaultMessageSourceResolvable;</span><br><span class="line"><span class="keyword">import</span> org.springframework.validation.BindingResult;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.validation.Valid;</span><br><span class="line"><span class="keyword">import</span> java.util.stream.Collectors;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/validation&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ValidationController</span> &#123;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="meta">@PostMapping(value = &quot;/user1&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addUser1</span><span class="params">(<span class="meta">@Valid</span> <span class="meta">@RequestBody</span> UserDTO userDTO, BindingResult bindingResult)</span>&#123;</span><br><span class="line"><span class="comment">//        使用BindingResult就算绑定出错，也会进入controller方法</span></span><br><span class="line">        log.error(bindingResult.getAllErrors().stream().map(DefaultMessageSourceResolvable::getDefaultMessage).collect(Collectors.joining(<span class="string">&quot;\n&quot;</span>)));</span><br><span class="line">        log.info(<span class="string">&quot;addUser1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping(value = &quot;/user2&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addUser2</span><span class="params">(<span class="meta">@Valid</span> <span class="meta">@RequestBody</span> UserDTO userDTO)</span>&#123;</span><br><span class="line"><span class="comment">//        绑定错误时，不会进入controller方法，会抛出异常</span></span><br><span class="line">        log.info(<span class="string">&quot;addUser2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4-1-绑定结果处理"><a href="#4-1-绑定结果处理" class="headerlink" title="4.1 绑定结果处理"></a>4.1 绑定结果处理</h4><blockquote>
<p>三种方法：</p>
<ul>
<li><p>统一全局异常处理</p>
</li>
<li><p>控制器特定异常处理</p>
</li>
<li><p>使用BindingResult对象封装异常信息，BindingResult对象需要<strong>紧跟</strong>在@Validation&#x2F;@Valid注解对象的后面</p>
</li>
</ul>
</blockquote>
<blockquote>
<p>如果只是使用validation注解，在参数绑定时，不符合规则会抛出<code>MethodArgumentNotValidException</code>或者<code>ConstraintViolationException</code>异常</p>
</blockquote>
<h5 id="4-1-1-统一全局异常处理"><a href="#4-1-1-统一全局异常处理" class="headerlink" title="4.1.1 统一全局异常处理"></a>4.1.1 统一全局异常处理</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RestControllerAdvice</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ValidationExceptionHandler</span> &#123;</span><br><span class="line">    <span class="comment">// 使用@Valid或者@Validated校验传入‘对象’的‘属性’时，校验失败后抛出的异常是MethodArgumentNotValidException</span></span><br><span class="line">    <span class="meta">@ExceptionHandler(MethodArgumentNotValidException.class)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleMethodArgumentNotValidException</span><span class="params">(HttpServletResponse response, MethodArgumentNotValidException exception)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        log.info(<span class="string">&quot;handleMethodArgumentNotValidException&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">message</span> <span class="operator">=</span> exception.getBindingResult().getAllErrors().stream().map(DefaultMessageSourceResolvable::getDefaultMessage).collect(Collectors.joining(<span class="string">&quot;\n&quot;</span>));</span><br><span class="line">        log.error(message);</span><br><span class="line">        <span class="type">ServletOutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> response.getOutputStream();</span><br><span class="line">        outputStream.write(message.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        response.setStatus(HttpServletResponse.SC_BAD_REQUEST);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Spring validation方法入参上对‘单个参数’进行校验，校验失败时会抛出ConstraintViolationException异常</span></span><br><span class="line">    <span class="meta">@ExceptionHandler(ConstraintViolationException.class)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleConstraintViolationException</span><span class="params">(HttpServletResponse response, ConstraintViolationException exception)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        log.info(<span class="string">&quot;handleConstraintViolationException&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">message</span> <span class="operator">=</span> exception.getConstraintViolations().stream().map(ConstraintViolation::getMessage).collect(Collectors.joining(<span class="string">&quot;\n&quot;</span>));</span><br><span class="line">        log.error(message);</span><br><span class="line">        <span class="type">ServletOutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> response.getOutputStream();</span><br><span class="line">        outputStream.write(message.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        response.setStatus(HttpServletResponse.SC_BAD_REQUEST);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-1-2-控制器特定异常处理"><a href="#4-1-2-控制器特定异常处理" class="headerlink" title="4.1.2 控制器特定异常处理"></a>4.1.2 控制器特定异常处理</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/validation&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ValidationController</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@ExceptionHandler(Exception.class)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleException</span><span class="params">(Exception e)</span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;handleException&quot;</span>);</span><br><span class="line">        log.error(e.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-1-3-使用BindingResult对象封装异常信息"><a href="#4-1-3-使用BindingResult对象封装异常信息" class="headerlink" title="4.1.3 使用BindingResult对象封装异常信息"></a>4.1.3 使用BindingResult对象封装异常信息</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/validation&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ValidationController</span> &#123;</span><br><span class="line">    <span class="meta">@PostMapping(value = &quot;/user1&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addUser1</span><span class="params">(<span class="meta">@Valid</span> <span class="meta">@RequestBody</span> UserDTO userDTO, BindingResult bindingResult)</span>&#123;</span><br><span class="line"><span class="comment">//        使用BindingResult就算绑定出错，也会进入controller方法</span></span><br><span class="line">        log.error(bindingResult.getAllErrors().stream().map(DefaultMessageSourceResolvable::getDefaultMessage).collect(Collectors.joining(<span class="string">&quot;\n&quot;</span>)));</span><br><span class="line">        log.info(<span class="string">&quot;addUser1&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="4-2-Spring-validation方法参数级别的校验"><a href="#4-2-Spring-validation方法参数级别的校验" class="headerlink" title="4.2 Spring validation方法参数级别的校验"></a>4.2 Spring validation方法参数级别的校验</h4><blockquote>
<p>JSR和Hibernate validator的校验只能对Object的属性进行校验，不能对单个的参数进行校验，spring 在此基础上进行了扩展，添加了MethodValidationPostProcessor拦截器，可以实现对方法参数的校验</p>
</blockquote>
<p>实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1. 实例化MethodValidationPostProcessor(这一步Spring Boot已经自动创建了，不必自己手动创建)</span></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> MethodValidationPostProcessor <span class="title function_">methodValidationPostProcessor</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MethodValidationPostProcessor</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.在所要实现方法参数校验的类上面添加@Validated注解，不能是@Valid</span></span><br><span class="line"><span class="meta">@Validated</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/validation&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ValidationController</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.在方法上面添加校验规则</span></span><br><span class="line"><span class="meta">@GetMapping(value = &quot;/user/&#123;id&#125;&quot;)</span></span><br><span class="line"><span class="keyword">public</span> User <span class="title function_">getUser2</span><span class="params">(<span class="meta">@Min(value = 10)</span> <span class="meta">@PathVariable(&quot;id&quot;)</span> Long userId)</span>&#123;</span><br><span class="line">    <span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">    user.setUserId(userId);</span><br><span class="line">    <span class="keyword">return</span> user;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4. 校验失败时，会抛出ConstraintViolationException异常</span></span><br></pre></td></tr></table></figure>



<h4 id="4-3-使用-Validator编程式校验"><a href="#4-3-使用-Validator编程式校验" class="headerlink" title="4.3 使用 Validator编程式校验"></a>4.3 使用 Validator编程式校验</h4><blockquote>
<p>有的时候我们想在代码里面自己手动对对象参数进行校验，可以使用<code>Validation.buildDefaultValidatorFactory()</code>获取<code>ValidatorFactory</code>，通过<code>factory.getValidator()</code>获取对应的校验器<code>Validator</code></p>
</blockquote>
<p>使用方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">validateUser</span><span class="params">(UserDTO userDTO)</span>&#123;</span><br><span class="line">    <span class="type">ValidatorFactory</span> <span class="variable">factory</span> <span class="operator">=</span> Validation.buildDefaultValidatorFactory();</span><br><span class="line">        <span class="type">Validator</span> <span class="variable">validator</span> <span class="operator">=</span> factory.getValidator();</span><br><span class="line">        Set&lt;ConstraintViolation&lt;UserDTO&gt;&gt; validate = validator.validate(userDTO);</span><br><span class="line">        <span class="type">String</span> <span class="variable">message</span> <span class="operator">=</span> validate.stream().map(ConstraintViolation::getMessage).collect(Collectors.joining(<span class="string">&quot;\n&quot;</span>));</span><br><span class="line">        System.out.println(message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="4-4-校验模式"><a href="#4-4-校验模式" class="headerlink" title="4.4 校验模式"></a>4.4 校验模式</h4><h5 id="4-4-1-普通模式（默认）"><a href="#4-4-1-普通模式（默认）" class="headerlink" title="4.4.1 普通模式（默认）"></a>4.4.1 普通模式（默认）</h5><blockquote>
<p>在普通模式下，会校验完所有的属性，然后返回所有验证失败的信息</p>
</blockquote>
<h5 id="4-4-2-快速失败模式"><a href="#4-4-2-快速失败模式" class="headerlink" title="4.4.2 快速失败模式"></a>4.4.2 快速失败模式</h5><blockquote>
<p>快速失败模式下，只要有一个参数校验失败，会立马返回验证失败信息，不再校验后面的参数</p>
</blockquote>
<p>配置方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> Validator <span class="title function_">validator</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">ValidatorFactory</span> <span class="variable">validatorFactory</span> <span class="operator">=</span> Validation.byProvider(HibernateValidator.class)</span><br><span class="line">            .configure()</span><br><span class="line">            <span class="comment">// 快速失败模式</span></span><br><span class="line">            .failFast(<span class="literal">true</span>)</span><br><span class="line">            .buildValidatorFactory();</span><br><span class="line">    <span class="keyword">return</span> validatorFactory.getValidator();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="4-5-自定义校验注解"><a href="#4-5-自定义校验注解" class="headerlink" title="4.5 自定义校验注解"></a>4.5 自定义校验注解</h4><blockquote>
<p>虽然jSR303和Hibernate Validtor 已经提供了很多校验注解，但是当面对复杂参数校验时，还是不能满足我们的要求，这时候我们就需要自定义校验注解</p>
</blockquote>
<blockquote>
<p>步骤：</p>
<ul>
<li>自定义约束注解</li>
<li>实现ConstraintValidator接口</li>
</ul>
</blockquote>
<h5 id="4-5-1-自定义约束注解"><a href="#4-5-1-自定义约束注解" class="headerlink" title="4.5.1 自定义约束注解"></a>4.5.1 自定义约束注解</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义参数校验注解</span></span><br><span class="line"><span class="comment"> * 列表中不允许有null元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Target(&#123;ANNOTATION_TYPE, METHOD, ElementType.FIELD&#125;)</span></span><br><span class="line"><span class="meta">@Retention(RUNTIME)</span></span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Constraint(validatedBy = ListNoNullValidator.class)</span> <span class="comment">//指定了注解的验证实现类为ListNoNullValidator</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> ListNoNull &#123;</span><br><span class="line">    </span><br><span class="line">    String <span class="title function_">message</span><span class="params">()</span> <span class="keyword">default</span> <span class="string">&quot;List集合中不能含有null元素&quot;</span>;</span><br><span class="line">    </span><br><span class="line">    Class&lt;?&gt;[] groups() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">    </span><br><span class="line">    Class&lt;? <span class="keyword">extends</span> <span class="title class_">Payload</span>&gt;[] payload() <span class="keyword">default</span> &#123;&#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 定义List，为了让Bean的一个属性上可以添加多套规则</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Target(&#123;METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER&#125;)</span></span><br><span class="line">    <span class="meta">@Retention(RUNTIME)</span></span><br><span class="line">    <span class="meta">@Documented</span></span><br><span class="line">    <span class="meta">@interface</span> List &#123;</span><br><span class="line">        ListNoNull[] value();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-5-2-实现ConstraintValidator接口"><a href="#4-5-2-实现ConstraintValidator接口" class="headerlink" title="4.5.2 实现ConstraintValidator接口"></a>4.5.2 实现ConstraintValidator接口</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ListNoNullValidator</span> <span class="keyword">implements</span> <span class="title class_">ConstraintValidator</span>&lt;ListNoNull, List&gt; &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 实现具体的验证逻辑</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isValid</span><span class="params">(List list, ConstraintValidatorContext constraintValidatorContext)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(list == <span class="literal">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(Object object : list)&#123;</span><br><span class="line">            <span class="comment">// 如果List集合中存在null元素，校验失败</span></span><br><span class="line">            <span class="keyword">if</span>(object == <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证前做的初始化工作</span></span><br><span class="line">    <span class="comment">// 默认是没有操作</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">(ListNoNull constraintAnnotation)</span> &#123;</span><br><span class="line">        ConstraintValidator.<span class="built_in">super</span>.initialize(constraintAnnotation);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="4-6-分组校验"><a href="#4-6-分组校验" class="headerlink" title="4.6 分组校验"></a>4.6 分组校验</h4><blockquote>
<p>在实际项目中，增加和修改时对参数的验证方式可能不一样，如保存User的时候，userId时可以为空的，但是在更新User的时候，userId不能为空，所以就需要分组校验。</p>
</blockquote>
<blockquote>
<p>Spring validation支持分组校验，需要使用@Validated，不能使用@Valid</p>
</blockquote>
<blockquote>
<p>步骤：</p>
<ul>
<li>定义空接口表示分组</li>
<li>约束注解上声明适用的分组信息</li>
<li>@Validated注解上指定校验分组</li>
</ul>
</blockquote>
<h5 id="4-6-1-定义空接口表示分组"><a href="#4-6-1-定义空接口表示分组" class="headerlink" title="4.6.1 定义空接口表示分组"></a>4.6.1 定义空接口表示分组</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 可以定义一个继承Default的接口，这样分组校验的时候，没有设定分组的参数也会一起校验</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 保存的时候校验分组</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Save</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 更新的时候校验分组</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Update</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-6-2-约束注解上声明适用的分组信息"><a href="#4-6-2-约束注解上声明适用的分组信息" class="headerlink" title="4.6.2 约束注解上声明适用的分组信息"></a>4.6.2 约束注解上声明适用的分组信息</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserDTO</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@NotNull(groups = Update.class)</span></span><br><span class="line">    <span class="keyword">private</span> Long userId;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotBlank</span></span><br><span class="line">    <span class="meta">@Length(max = 32)</span></span><br><span class="line">    <span class="keyword">private</span> String userName;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotBlank</span></span><br><span class="line">    <span class="meta">@Email(groups = &#123;Save.class, Update.class&#125;)</span></span><br><span class="line">    <span class="keyword">private</span> String email;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 保存的时候校验分组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Save</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 更新的时候校验分组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Update</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-6-3-Validated注解上指定校验分组"><a href="#4-6-3-Validated注解上指定校验分组" class="headerlink" title="4.6.3@Validated注解上指定校验分组"></a>4.6.3@Validated注解上指定校验分组</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// javax.validation.groups.Default表示默认没有指定分组的验证规则</span></span><br><span class="line"><span class="meta">@PostMapping(value = &quot;/user3&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addUser3</span><span class="params">(<span class="meta">@Validated(&#123;UserDTO.Update.class, Default.class&#125;)</span> <span class="meta">@RequestBody</span> UserDTO userDTO)</span>&#123;</span><br><span class="line">    log.info(<span class="string">&quot;addUser3&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="4-7-嵌套校验"><a href="#4-7-嵌套校验" class="headerlink" title="4.7 嵌套校验"></a>4.7 嵌套校验</h4><blockquote>
<p>必须使用@Valid注解才能使用嵌套校验</p>
</blockquote>
<blockquote>
<p>前面的示例中，校验的属性都是基本数据类型或者String类型，如果某个属性是对象，则可以使用嵌套校验，对象属性上使用@Valid注解表明嵌套校验</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserDTO</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@NotNull</span></span><br><span class="line">    <span class="keyword">private</span> Long userId;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotBlank</span></span><br><span class="line">    <span class="meta">@Length(max = 32)</span></span><br><span class="line">    <span class="keyword">private</span> String userName;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@NotNull</span></span><br><span class="line">      <span class="meta">@Valid</span></span><br><span class="line">    <span class="keyword">private</span> Item item;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Data</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Item</span>&#123;</span><br><span class="line">        <span class="meta">@NotNull</span></span><br><span class="line">        <span class="keyword">private</span> Long itemId;</span><br><span class="line">        </span><br><span class="line">        <span class="meta">@NotBlank</span></span><br><span class="line">        <span class="keyword">private</span> String itemName;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="5-Spring-validation原理"><a href="#5-Spring-validation原理" class="headerlink" title="5. Spring-validation原理"></a>5. Spring-validation原理</h3><blockquote>
<p>无论是哪种方式，最终都是调用<code>Hibernate Validator</code>进行真正的校验处理，Spring只是做了一层封装</p>
</blockquote>
<h4 id="5-1-基于RequestBody的参数校验"><a href="#5-1-基于RequestBody的参数校验" class="headerlink" title="5.1 基于RequestBody的参数校验"></a>5.1 基于RequestBody的参数校验</h4><p>在Spring-MVC中，<code>RequestResponseBodyMethodProcessor</code>是用于解析<code>@RequestBody</code>标注的参数以及处理<code>@ResponseBody</code>标注方法的返回值的。显然执行参数校验的逻辑肯定在解析参数的方法<code>resolveArgument()</code>中。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RequestResponseBodyMethodProcessor</span> <span class="keyword">extends</span> <span class="title class_">AbstractMessageConverterMethodProcessor</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">resolveArgument</span><span class="params">(MethodParameter parameter, <span class="meta">@Nullable</span> ModelAndViewContainer mavContainer,</span></span><br><span class="line"><span class="params">            NativeWebRequest webRequest, <span class="meta">@Nullable</span> WebDataBinderFactory binderFactory)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">    parameter = parameter.nestedIfOptional();</span><br><span class="line">    <span class="comment">// 将请求参数封装到对象</span></span><br><span class="line">    <span class="type">Object</span> <span class="variable">arg</span> <span class="operator">=</span> readWithMessageConverters(webRequest, parameter, parameter.getNestedGenericParameterType());</span><br><span class="line">    <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Conventions.getVariableNameForParameter(parameter);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (binderFactory != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="type">WebDataBinder</span> <span class="variable">binder</span> <span class="operator">=</span> binderFactory.createBinder(webRequest, arg, name);</span><br><span class="line">        <span class="keyword">if</span> (arg != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 校验数据</span></span><br><span class="line">            validateIfApplicable(binder, parameter);</span><br><span class="line">            <span class="keyword">if</span> (binder.getBindingResult().hasErrors() &amp;&amp; isBindExceptionRequired(binder, parameter)) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">MethodArgumentNotValidException</span>(parameter, binder.getBindingResult());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (mavContainer != <span class="literal">null</span>) &#123;</span><br><span class="line">            mavContainer.addAttribute(BindingResult.MODEL_KEY_PREFIX + name, binder.getBindingResult());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> adaptArgumentIfNecessary(arg, parameter);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，<code>resolveArgument()</code>调用了<code>validateIfApplicable()</code>进行参数校验。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">validateIfApplicable</span><span class="params">(WebDataBinder binder, MethodParameter parameter)</span> &#123;</span><br><span class="line">    <span class="comment">// 获取所有注解</span></span><br><span class="line">    Annotation[] annotations = parameter.getParameterAnnotations();</span><br><span class="line">    <span class="keyword">for</span> (Annotation ann : annotations) &#123;</span><br><span class="line">        <span class="comment">// 判断有没有@Valid或者@Validated注解或者以Valid开头的注解</span></span><br><span class="line">        Object[] validationHints = ValidationAnnotationUtils.determineValidationHints(ann);</span><br><span class="line">        <span class="keyword">if</span> (validationHints != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 执行校验</span></span><br><span class="line">            binder.validate(validationHints);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Nullable</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Object[] determineValidationHints(Annotation ann) &#123;</span><br><span class="line">    Class&lt;? <span class="keyword">extends</span> <span class="title class_">Annotation</span>&gt; annotationType = ann.annotationType();</span><br><span class="line">    <span class="type">String</span> <span class="variable">annotationName</span> <span class="operator">=</span> annotationType.getName();</span><br><span class="line">    <span class="comment">// 注解为@Valid</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="string">&quot;javax.validation.Valid&quot;</span>.equals(annotationName)) &#123;</span><br><span class="line">        <span class="keyword">return</span> EMPTY_OBJECT_ARRAY;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 获取@Validated注解</span></span><br><span class="line">    <span class="type">Validated</span> <span class="variable">validatedAnn</span> <span class="operator">=</span> AnnotationUtils.getAnnotation(ann, Validated.class);</span><br><span class="line">    <span class="keyword">if</span> (validatedAnn != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">hints</span> <span class="operator">=</span> validatedAnn.value();</span><br><span class="line">        <span class="keyword">return</span> convertValidationHints(hints);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (annotationType.getSimpleName().startsWith(<span class="string">&quot;Valid&quot;</span>)) &#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">hints</span> <span class="operator">=</span> AnnotationUtils.getValue(ann);</span><br><span class="line">        <span class="keyword">return</span> convertValidationHints(hints);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">validate</span><span class="params">(Object... validationHints)</span> &#123;</span><br><span class="line">    <span class="type">Object</span> <span class="variable">target</span> <span class="operator">=</span> getTarget();</span><br><span class="line">    Assert.state(target != <span class="literal">null</span>, <span class="string">&quot;No target to validate&quot;</span>);</span><br><span class="line">    <span class="type">BindingResult</span> <span class="variable">bindingResult</span> <span class="operator">=</span> getBindingResult();</span><br><span class="line">    <span class="comment">// Call each validator with the same binding result</span></span><br><span class="line">    <span class="comment">// 调用所有注册的validator验证绑定结果</span></span><br><span class="line">    <span class="keyword">for</span> (Validator validator : getValidators()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!ObjectUtils.isEmpty(validationHints) &amp;&amp; validator <span class="keyword">instanceof</span> SmartValidator) &#123;</span><br><span class="line">            ((SmartValidator) validator).validate(target, bindingResult, validationHints);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (validator != <span class="literal">null</span>) &#123;</span><br><span class="line">            validator.validate(target, bindingResult);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="5-2-方法参数级别的校验"><a href="#5-2-方法参数级别的校验" class="headerlink" title="5.2 方法参数级别的校验"></a>5.2 方法参数级别的校验</h4><blockquote>
<p>方法参数级别的校验能够用于任何Spring Bean的方法上，比如Controller或者Service等。<strong>其底层原理是<code>AOP</code>，通过<code>MethodValidationPostProcessor</code>动态注册<code>AOP</code>切面，然后使用<code>MethodValidationInterceptor</code>对切点方法织入增强</strong>。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MethodValidationPostProcessor</span> <span class="keyword">extends</span> <span class="title class_">AbstractBeanFactoryAwareAdvisingPostProcessor</span></span><br><span class="line">        <span class="keyword">implements</span> <span class="title class_">InitializingBean</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">afterPropertiesSet</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 为所有@Validated标注的Bean创建切面</span></span><br><span class="line">        <span class="type">Pointcut</span> <span class="variable">pointcut</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AnnotationMatchingPointcut</span>(<span class="built_in">this</span>.validatedAnnotationType, <span class="literal">true</span>);</span><br><span class="line">        <span class="comment">// 创建Advice进行增强</span></span><br><span class="line">        <span class="built_in">this</span>.advisor = <span class="keyword">new</span> <span class="title class_">DefaultPointcutAdvisor</span>(pointcut, createMethodValidationAdvice(<span class="built_in">this</span>.validator));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建Advice，本质是一个方法拦截器</span></span><br><span class="line">    <span class="keyword">protected</span> Advice <span class="title function_">createMethodValidationAdvice</span><span class="params">(<span class="meta">@Nullable</span> Validator validator)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (validator != <span class="literal">null</span> ? <span class="keyword">new</span> <span class="title class_">MethodValidationInterceptor</span>(validator) : <span class="keyword">new</span> <span class="title class_">MethodValidationInterceptor</span>());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MethodValidationInterceptor</span> <span class="keyword">implements</span> <span class="title class_">MethodInterceptor</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="meta">@Nullable</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">invoke</span><span class="params">(MethodInvocation invocation)</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line">        <span class="comment">// Avoid Validator invocation on FactoryBean.getObjectType/isSingleton</span></span><br><span class="line">        <span class="comment">// 避免在get属性方法或者isSingleton方法上调用验证器</span></span><br><span class="line">        <span class="keyword">if</span> (isFactoryBeanMetadataMethod(invocation.getMethod())) &#123;</span><br><span class="line">            <span class="keyword">return</span> invocation.proceed();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取分组信息</span></span><br><span class="line">        Class&lt;?&gt;[] groups = determineValidationGroups(invocation);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Standard Bean Validation 1.1 API</span></span><br><span class="line">        <span class="type">ExecutableValidator</span> <span class="variable">execVal</span> <span class="operator">=</span> <span class="built_in">this</span>.validator.forExecutables();</span><br><span class="line">        <span class="type">Method</span> <span class="variable">methodToValidate</span> <span class="operator">=</span> invocation.getMethod();</span><br><span class="line">        Set&lt;ConstraintViolation&lt;Object&gt;&gt; result;</span><br><span class="line"></span><br><span class="line">        <span class="type">Object</span> <span class="variable">target</span> <span class="operator">=</span> invocation.getThis();</span><br><span class="line">        Assert.state(target != <span class="literal">null</span>, <span class="string">&quot;Target must not be null&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 方法入参校验，最终还是委托给Hibernate Validator来校验</span></span><br><span class="line">            result = execVal.validateParameters(target, methodToValidate, invocation.getArguments(), groups);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (IllegalArgumentException ex) &#123;</span><br><span class="line">            <span class="comment">// Probably a generic type mismatch between interface and impl as reported in SPR-12237 / HV-1011</span></span><br><span class="line">            <span class="comment">// Let&#x27;s try to find the bridged method on the implementation class...</span></span><br><span class="line">            methodToValidate = BridgeMethodResolver.findBridgedMethod(</span><br><span class="line">                    ClassUtils.getMostSpecificMethod(invocation.getMethod(), target.getClass()));</span><br><span class="line">            result = execVal.validateParameters(target, methodToValidate, invocation.getArguments(), groups);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!result.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">// 抛出ConstraintViolationException异常</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">ConstraintViolationException</span>(result);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 真正的方法调用</span></span><br><span class="line">        <span class="type">Object</span> <span class="variable">returnValue</span> <span class="operator">=</span> invocation.proceed();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对返回值做校验</span></span><br><span class="line">        result = execVal.validateReturnValue(target, methodToValidate, returnValue, groups);</span><br><span class="line">        <span class="keyword">if</span> (!result.isEmpty()) &#123;</span><br><span class="line">            <span class="comment">// 抛出ConstraintViolationException异常</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">ConstraintViolationException</span>(result);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> returnValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>WebRTC简介</title>
    <url>/2023/08/03/WebRTC%E7%AE%80%E4%BB%8B/</url>
    <content><![CDATA[<h3 id="WebRTC是什么，能做什么？"><a href="#WebRTC是什么，能做什么？" class="headerlink" title="WebRTC是什么，能做什么？"></a>WebRTC是什么，能做什么？</h3>]]></content>
      <categories>
        <category>WebRTC</category>
      </categories>
      <tags>
        <tag>WebRTC</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot中使用Zookeeper进行服务发现</title>
    <url>/2022/12/05/SpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8Zookeeper%E8%BF%9B%E8%A1%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="1-什么是服务发现"><a href="#1-什么是服务发现" class="headerlink" title="1. 什么是服务发现"></a>1. 什么是服务发现</h2><p>首先引入三个角色，分别是服务提供者、服务消费者、服务中介。一个 HTTP 服务器既可以是服务提供者，也可以是服务消费者。</p>
<ul>
<li>服务提供者：简单来说就是一个 HTTP 服务器，向外提供 API 服务。</li>
<li>服务消费者：其实就是一个程序，需要访问服务提供者提供的 API 服务来处理业务逻辑。</li>
<li>服务中介：联系服务提供者和服务消费者的桥梁，服务提供者将自己提供的服务地址注册到服务中介，服务消费者可以从服务中介里查找需要的服务提供者地址。</li>
</ul>
<p><img src="/2022/12/05/SpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8Zookeeper%E8%BF%9B%E8%A1%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/v2-c5e1d05128694eaffc043d1acf1cab41_r.jpg" alt="img"></p>
<h2 id="2-为什么需要服务发现"><a href="#2-为什么需要服务发现" class="headerlink" title="2. 为什么需要服务发现"></a>2. 为什么需要服务发现</h2><p>服务实例的网络位置（IP地址 + 端口）都是动态分配的，由于扩展、失败和升级，服务实例会经常动态改变。如果一个服务的地址经常发生变化，那么使用这个服务的客户端也要修改自己的配置文件以配置新的服务地址。频繁的变更会导致运维非常困难，因此客户端需要一种服务发现机制，以动态地获取到服务实例的网络位置。</p>
<h2 id="3-常见的服务发现开源组件"><a href="#3-常见的服务发现开源组件" class="headerlink" title="3. 常见的服务发现开源组件"></a>3. 常见的服务发现开源组件</h2><p>服务发现开源组件就相当于服务中介，常见的有：</p>
<ul>
<li>etcd：一个用于共享配置和服务发现的高可用、分布式和一致的键值存储。使用了 etcd 的两个著名项目分别为 Kubernetes 和 Cloud Foundry。</li>
<li>Consul：一个用于发现和配置服务的工具。它提供了一个 API，可用于客户端注册与发现服务。Consul 可对服务进行健康检查，以确定服务的可用性。</li>
<li>Apache Zookeeper：一个被广泛应用于分布式应用的高性能协调服务。Apache ZooKeeper 最初是 Hadoop 的一个子项目，但现在已经成为一个独立的顶级项目。</li>
<li>Eureka：Netflix 开发的服务发现框架，本身是一个基于 REST 的服务，主要用于定位运行在 AWS 域中的中间层服务，以达到负载均衡和中间层服务故障转移的目的。</li>
<li>Nacos：是阿里巴巴开源的一款支持服务注册与发现，配置管理以及微服务管理的组件。</li>
</ul>
<p>需要知道的是，其实服务注册中心就是一个中介，来储存服务提供者的信息，因此其实 MySQL 或者 Redis 等数据库都能用作服务注册中心，只不过需要自己维护服务发现的功能，而上面提到的这些组件都提供了易用的服务发现 API ，更加适合快速开发。</p>
<h2 id="4-Zookeeper-服务发现原理"><a href="#4-Zookeeper-服务发现原理" class="headerlink" title="4. Zookeeper 服务发现原理"></a>4. Zookeeper 服务发现原理</h2><p>Zookeeper 的服务注册与发现，主要应用的是 Zookeeper 的 Znode 数据模型和 Watcher 机制，主要分为以下几个步骤：</p>
<ul>
<li>服务注册：服务提供者启动时，会向 Zookeeper 服务端注册服务信息，即会在 Zookeeper 服务器上创建一个服务节点，并在节点上储存服务的相关数据（如服务提供者的 IP 地址、端口、UUID等）。Zookeeper 注册中心和服务提供者之间会建立一个 Socket 长连接，Zookeeper 注册中心定时向每个服务提供者发送心跳数据包，如果服务提供者没响应，会剔除该服务实例，并且发送通知。</li>
<li>服务发现：服务消费者启动时，会根据本身依赖的服务信息，向 Zookeeper 服务端获取注册的服务信息并设置 Watcher。服务消费者获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时，根据从 Zookeeper 注册中心获取到的注册信息调用服务。</li>
<li>服务通知：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper 服务注册中心的对应服务节点会被删除，因为服务消费者在获取服务信息的时候在对应节点上设置了 Watcher。因此节点被删除后，会触发对应的 Wathcer 事件，Zookeeper 注册中心会异步向所有监听该节点事件的服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。</li>
</ul>
<p><strong>但是一般来说，不建议使用 Zookeeper 作为服务发现注册中心</strong>，因为 Zookeeper 在 CAP 理论中支持的是 CP，即一致性和分区可用性。如果 Zookeeper 服务的 Leader 宕机，则需要重新选举 Leader，这个过程通常需要 30 到 120 秒，选举过程会导致集群不可用，注册服务也有可能会暂时不可用。而对于微服务架构来说，大部分时候强调更多是 AP。Zookeeper 更适合做分布式协调服务。</p>
<h2 id="5-Spring-Boot-服务发现实战"><a href="#5-Spring-Boot-服务发现实战" class="headerlink" title="5. Spring Boot 服务发现实战"></a>5. Spring Boot 服务发现实战</h2><blockquote>
<p>前置条件：安装好 Zookeeper，可以使用<a href="https://github.com/vran-dev/PrettyZoo">可视化工具PrettyZoo</a>进行查看。</p>
</blockquote>
<h3 id="5-1-服务提供者"><a href="#5-1-服务提供者" class="headerlink" title="5.1 服务提供者"></a>5.1 服务提供者</h3><blockquote>
<p>服务提供者只是将自己的访问名称以及 IP 地址和端口注册到注册中心，所以并不会选择性的向外提供接口。如果某些接口不希望被外部访问，需要自己进行权限控制。</p>
</blockquote>
<p>创建一个 SpringBoot 项目，首先确保应用能够正常启动。</p>
<h4 id="5-1-1-引入依赖包"><a href="#5-1-1-引入依赖包" class="headerlink" title="5.1.1 引入依赖包"></a>5.1.1 引入依赖包</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.1.3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<h4 id="5-1-2-配置文件"><a href="#5-1-2-配置文件" class="headerlink" title="5.1.2 配置文件"></a>5.1.2 配置文件</h4><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">application:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">HelloWorld</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">zookeeper:</span> <span class="comment"># 其他配置可以查看ZookeeperProperties.class和ZookeeperDiscoveryProperties.class文件得知</span></span><br><span class="line">      <span class="attr">connect-string:</span> <span class="string">localhost:2181</span> </span><br><span class="line">      <span class="attr">discovery:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">true</span> <span class="comment"># 或者可以通过在启动类中添加注解@EnableDiscoveryClient启用服务发现</span></span><br><span class="line">        <span class="comment"># 如果碰到多个网卡的情况，可以通过 preferIpAddress 和 instanceIpAddress 指定服务发现的地址</span></span><br><span class="line">        <span class="comment">#preferIpAddress: true</span></span><br><span class="line">        <span class="comment">#instanceIpAddress: ip 地址</span></span><br></pre></td></tr></table></figure>

<h4 id="5-1-3-增加-REST-服务"><a href="#5-1-3-增加-REST-服务" class="headerlink" title="5.1.3 增加 REST 服务"></a>5.1.3 增加 REST 服务</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ljh.zookeeperdiscovery.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">IHelloApi</span> &#123;</span><br><span class="line">    <span class="meta">@GetMapping(value = &quot;/helloworld&quot;)</span></span><br><span class="line">    String <span class="title function_">helloWorld</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/&quot;)</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloController</span> <span class="keyword">implements</span> <span class="title class_">IHelloApi</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">helloWorld</span><span class="params">()</span>&#123;</span><br><span class="line">        log.debug(<span class="string">&quot;Receive request from outer!&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;HelloWorld&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-观察-Zookeeper-注册信息"><a href="#5-2-观察-Zookeeper-注册信息" class="headerlink" title="5.2 观察 Zookeeper 注册信息"></a>5.2 观察 Zookeeper 注册信息</h3><p>可以看到 SpringBoot 已经自动将信息注册到 Zookeeper 中。其中，<code>/services/HelloWorld</code>中的 HelloWorld 就是是应用名称，作为路由地址，在其他服务中就可以像使用域名一样使用这个名字来寻找 IP 地址。在这个 node 节点中，因为我 zk 使用的是 docker 部署的，所以 address 显示的是<code>host.docker.internal</code>，正常来说应该显示的是服务的 IP 地址。</p>
<p><img src="/2022/12/05/SpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8Zookeeper%E8%BF%9B%E8%A1%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20221227112048184.png" alt="image-20221227112048184"></p>
<h3 id="5-3-服务消费者"><a href="#5-3-服务消费者" class="headerlink" title="5.3 服务消费者"></a>5.3 服务消费者</h3><p>既然服务提供者已经将服务注册到 Zookeeper 中，下一步就是考虑怎么使用这个服务了。</p>
<p>在 Spring Boot 中能够通过很多种方法进行服务调用，包括 OpenFeign 和 RestTemplate。下面将使用 OpenFeign 调用服务提供者提供的服务。</p>
<h4 id="5-3-1-引入依赖"><a href="#5-3-1-引入依赖" class="headerlink" title="5.3.1 引入依赖"></a>5.3.1 引入依赖</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.1.5&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.1.3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<h4 id="5-3-2-配置文件"><a href="#5-3-2-配置文件" class="headerlink" title="5.3.2 配置文件"></a>5.3.2 配置文件</h4><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8081</span></span><br><span class="line"></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">application:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">consumer1</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">zookeeper:</span></span><br><span class="line">      <span class="attr">discovery:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">connect-string:</span> <span class="string">localhost:2181</span> </span><br></pre></td></tr></table></figure>

<h4 id="5-3-3-引入服务接口"><a href="#5-3-3-引入服务接口" class="headerlink" title="5.3.3 引入服务接口"></a>5.3.3 引入服务接口</h4><ul>
<li>IHelloApi 是服务提供者中定义的接口，直接复用接口能够避免重新定义</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ljh.zookeeperdiscovery2.api;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.cloud.openfeign.FeignClient;</span><br><span class="line"></span><br><span class="line"><span class="meta">@FeignClient(name = &quot;HelloWorld&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">IHelloClient</span> <span class="keyword">extends</span> <span class="title class_">IHelloApi</span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>定义一个用于测试的请求方法：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ljh.zookeeperdiscovery2.controller;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.ljh.zookeeperdiscovery2.api.IHelloClient;</span><br><span class="line"><span class="keyword">import</span> lombok.extern.slf4j.Slf4j;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestController</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    IHelloClient helloClient;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@GetMapping(value = &quot;/test&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">test</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> helloClient.helloWorld(); </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-3-4-测试结果"><a href="#5-3-4-测试结果" class="headerlink" title="5.3.4 测试结果"></a>5.3.4 测试结果</h4><img src="image-20230103113801220.png" alt="image-20230103113801220" style="zoom:50%;" />



<h2 id="6-spring-cloud-zookeeper-源码分析"><a href="#6-spring-cloud-zookeeper-源码分析" class="headerlink" title="6. spring-cloud-zookeeper 源码分析"></a>6. spring-cloud-zookeeper 源码分析</h2><blockquote>
<p>关于 spring-cloud-zookeeper 的源码，需要带着以下三个问题进行分析：</p>
<ul>
<li>需要<strong>注册什么内容</strong>到服务中心？</li>
<li><strong>如何将服务注册</strong>到服务中心？</li>
<li>Spring Boot 在<strong>什么时候</strong>将服务注册到服务中心？</li>
</ul>
<p>阅读源码需要带着以上问题，一个一个的去看，才不会被细节性的东西所带偏，关注主要的功能代码。</p>
</blockquote>
<h3 id="6-1-关于-Apache-Curator"><a href="#6-1-关于-Apache-Curator" class="headerlink" title="6.1 关于 Apache Curator"></a>6.1 关于 Apache Curator</h3><p>Apache Curator 是 Apache Zookeeper 的 Java&#x2F;JVM 客户端库，包含一个高级 API 框架和实用程序，能够更加简便、可靠地使用 Apache Zookeeper。简单来说就是对 Zookeeper 得原生 API 进一步的简化，封装了一些常用的功能，比如说各种分布式锁、Leader 选举以及缓存等，其中就包括服务注册的功能。</p>
<p>spring-cloud-zookeeper 底层其实也是用的 Apache Curator 进行服务注册，只不过在其基础之上，融入到 Spring Boot 的自动配置体系中。关于 Apache Curator 服务注册的使用方法，请<a href="https://curator.apache.org/curator-x-discovery/index.html">查看官网</a>。</p>
<p>根据 Curator 官网中的介绍，要使用服务注册，需要构建一个服务实例 <code>ServiceInstance</code>。一个<code>ServiceInstance</code>代表着一个服务提供者，封装了服务提供者的信息。</p>
<p>而<code>ServiceInstance</code>由<code>ServiceProvider</code>进行创建，<code>ServiceProvider</code>封装特定的命名服务以及服务的负载均衡策略。</p>
<p><code>ServiceProvider</code>又需要通过<code>ServiceProviderBuilder</code>进行构建，<code>ServiceProviderBuilder</code>需要通过<code>ServiceDiscovery</code>获取，<code>ServiceDiscovery</code>通过<code>ServiceDiscoveryBuilder</code>构建。调用<code>ServiceDiscovery</code>的<code>start()</code>方法开始启用服务，<code>close()</code>方法注销服务。</p>
<p><strong>总体的链路是：<code>ServiceInstance</code>  &lt;- <code>ServiceProvider</code> &lt;- <code>ServiceProviderBuilder</code> &lt;- <code>ServiceDiscovery</code> &lt;- <code>ServiceDiscoveryBuilder</code></strong></p>
<p>通常，将服务提供者的信息传入到 <code>ServiceDiscovery</code>  的构造函数的时候，它会自动注册&#x2F;注销服务，但是如果想要自己手动进行注册，可以使用<code>ServiceDiscovery</code>的<code>public void registerService(ServiceInstance&lt;T&gt; service)</code>方法。</p>
<h3 id="6-2-在哪里创建的-ServiceInstance"><a href="#6-2-在哪里创建的-ServiceInstance" class="headerlink" title="6.2 在哪里创建的 ServiceInstance"></a>6.2 在哪里创建的 ServiceInstance</h3><blockquote>
<p>从现在开始，我们分析源码的主要流程</p>
</blockquote>
<p>从上面一小节我们可以知道，spring-cloud-zookeeper 最底层其实使用的还是 Apache Curator框架。那就需要寻找是在哪里创建的 ServiceInstance。</p>
<p><strong>spring-cloud-zookeeper 的关键配置类是 <code>ZookeeperAutoServiceRegistrationAutoConfiguration.java</code></strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ZookeeperAutoServiceRegistrationAutoConfiguration</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ZookeeperAutoServiceRegistration <span class="title function_">zookeeperAutoServiceRegistration</span><span class="params">(</span></span><br><span class="line"><span class="params">            ZookeeperServiceRegistry registry, ZookeeperRegistration registration,</span></span><br><span class="line"><span class="params">            ZookeeperDiscoveryProperties properties)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ZookeeperAutoServiceRegistration</span>(registry, registration, properties);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@ConditionalOnMissingBean(ZookeeperRegistration.class)</span></span><br><span class="line">    <span class="keyword">public</span> ServiceInstanceRegistration <span class="title function_">serviceInstanceRegistration</span><span class="params">(</span></span><br><span class="line"><span class="params">            ApplicationContext context, ZookeeperDiscoveryProperties properties)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">appName</span> <span class="operator">=</span> context.getEnvironment().getProperty(<span class="string">&quot;spring.application.name&quot;</span>,</span><br><span class="line">                <span class="string">&quot;application&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">host</span> <span class="operator">=</span> properties.getInstanceHost();</span><br><span class="line">        <span class="keyword">if</span> (!StringUtils.hasText(host)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;instanceHost must not be empty&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        properties.getMetadata().put(StatusConstants.INSTANCE_STATUS_KEY, properties.getInitialStatus());</span><br><span class="line"></span><br><span class="line">        <span class="type">ZookeeperInstance</span> <span class="variable">zookeeperInstance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ZookeeperInstance</span>(context.getId(),</span><br><span class="line">                appName, properties.getMetadata());</span><br><span class="line">        <span class="comment">// 重点！获取ServiceInstance的构建器</span></span><br><span class="line">        <span class="type">RegistrationBuilder</span> <span class="variable">builder</span> <span class="operator">=</span> ServiceInstanceRegistration.builder().address(host)</span><br><span class="line">                .name(appName).payload(zookeeperInstance)</span><br><span class="line">                .uriSpec(properties.getUriSpec());</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (properties.getInstanceSslPort() != <span class="literal">null</span>) &#123;</span><br><span class="line">            builder.sslPort(properties.getInstanceSslPort());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (properties.getInstanceId() != <span class="literal">null</span>) &#123;</span><br><span class="line">            builder.id(properties.getInstanceId());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO add customizer?</span></span><br><span class="line">        <span class="comment">// 构建ServiceInstanceRegistration实例</span></span><br><span class="line">        <span class="keyword">return</span> builder.build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上面可以看出，配置类中主要是创建了两个 Bean 实例，一个是 <code>ZookeeperAutoServiceRegistration</code>，一个是<code>ServiceInstanceRegistration</code>。看到<code>ServiceInstanceRegistration</code>跟<code>ServiceInstance</code>命名方式那么像，肯定是有什么关联，点进去看看。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ServiceInstanceRegistration</span> <span class="keyword">implements</span> <span class="title class_">ZookeeperRegistration</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> RegistrationBuilder <span class="title function_">builder</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 调用了Curator框架的ServiceInstance&lt;T&gt;.builder()静态方法，得到一个ServiceInstanceBuilder&lt;T&gt;构建器</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RegistrationBuilder</span>(ServiceInstance.&lt;ZookeeperInstance&gt;builder());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;Error creating ServiceInstanceBuilder&quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="image-20230103145025431.png" alt="image-20230103145025431" style="zoom:50%;" />

<p>从类的结构关系中可以看到，<code>ServiceInstanceRegistration类</code>中包含着一个<code>ServiceInstance</code>的域。这里的<code>ZookeeperInstance类</code>是服务提供者的一些额外信息，主要是辅助 Spring Boot 的服务发现功能，储存在 payload 信息中。</p>
<p><code>ZookeeperAutoServiceRegistrationAutoConfiguration类</code>中的<code>serviceInstanceRegistration(ApplicationContext context, ZookeeperDiscoveryProperties properties)</code>方法中注入了<strong>应用的上下文信息</strong>以及 <strong>Zookeeper服务发现的属性配置信息</strong>，就是为了构建 <code>ServiceInstance</code>。</p>
<p><code>RegistrationBuilder类</code>是<code>ServiceInstanceRegistration类</code>的静态内部类。在调用<code>ServiceInstanceRegistration.builder()</code>方法的时候，调用了<code>ServiceInstance&lt;T&gt;.builder()</code>静态方法，创建了一个<code>ServiceInstanceBuilder&lt;T&gt;</code>用于构建服务提供者的所有信息。</p>
<p>当调用<code>RegistrationBuilder类</code>的<code>build()</code>方法时，创建一个<code>ServiceInstanceRegistration类</code>实例并返回：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">RegistrationBuilder</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> ServiceInstanceRegistration <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 创建ServiceInstanceRegistration实例，并将ServiceInstanceBuilder&lt;T&gt;构建器传入</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ServiceInstanceRegistration</span>(<span class="built_in">this</span>.builder);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>此时，<code>ServiceInstanceRegistration实例</code>中包含着<code>ServiceInstanceBuilder&lt;ZookeeperInstance&gt; builder</code>构建器的信息，当调用<code>getServiceInstance()</code>方法的时候，就会通过构建器构建<code>ServiceInstance</code>实例并返回：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ServiceInstanceRegistration</span> <span class="keyword">implements</span> <span class="title class_">ZookeeperRegistration</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> ServiceInstance&lt;ZookeeperInstance&gt; <span class="title function_">getServiceInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.serviceInstance == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 通过ServiceInstanceBuilder&lt;T&gt;构建器构建ServiceInstance实例</span></span><br><span class="line">            build();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.serviceInstance;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.serviceInstance = <span class="built_in">this</span>.builder.build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>至此，就能够明白第一个问题，需要注册什么内容到服务中心？并且在哪里进行创建。</p>
<h3 id="6-3-如何将服务注册到服务中心"><a href="#6-3-如何将服务注册到服务中心" class="headerlink" title="6.3 如何将服务注册到服务中心"></a>6.3 如何将服务注册到服务中心</h3><blockquote>
<p>在 6.1 小节中我们知道，Curator 框架可以通过调用<code>ServiceDiscovery</code> 的<code>start()</code>方法或者是<code>registerService()</code>方法进行服务注册。那我们就需要寻找一下在哪里调用的<code>start()</code>方法或者是<code>registerService()</code>方法。</p>
</blockquote>
<p>依然是看到<strong>自动配置类<code>ZookeeperAutoServiceRegistrationAutoConfiguration.java</code></strong> ，其中另外一个注入的 Bean 实例是 <code>ZookeeperAutoServiceRegistration</code>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ZookeeperAutoServiceRegistration</span> <span class="keyword">extends</span> <span class="title class_">AbstractAutoServiceRegistration</span>&lt;ZookeeperRegistration&gt;&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">register</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!<span class="built_in">this</span>.properties.isRegister()) &#123;</span><br><span class="line">            log.debug(<span class="string">&quot;Registration disabled.&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.registration.getPort() == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">this</span>.registration.setPort(getPort().get());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">super</span>.register();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，<code>ZookeeperAutoServiceRegistration类</code>中有一个<code>register()</code>方法，非常像是服务注册的逻辑，其中调用了父类的<code>register()</code>方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">AbstractAutoServiceRegistration</span>&lt;R <span class="keyword">extends</span> <span class="title class_">Registration</span>&gt; <span class="keyword">implements</span> <span class="title class_">AutoServiceRegistration</span>, ApplicationContextAware, ApplicationListener&lt;WebServerInitializedEvent&gt; &#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">register</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.serviceRegistry.register(getRegistration());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里<code>this.serviceRegistry.register()</code>实际调用的是<code>ZookeeperServiceRegistry实例</code>的<code>register()</code>方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ZookeeperServiceRegistry</span> <span class="keyword">implements</span> <span class="title class_">ServiceRegistry</span>&lt;ZookeeperRegistration&gt;, SmartInitializingSingleton, Closeable &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">register</span><span class="params">(ZookeeperRegistration registration)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 实际调用ServiceDiscovery的registerService()方法进行服务注册</span></span><br><span class="line">            getServiceDiscovery().registerService(registration.getServiceInstance());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            rethrowRuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>getServiceDiscovery().registerService()</code>就是实际调用<code>ServiceDiscovery类</code>的<code>registerService()</code>方法进行服务注册。</p>
<blockquote>
<p>由此，引出了三个问题：</p>
<ul>
<li><code>registration.getServiceInstance()</code>是从哪里来的？</li>
<li>怎么就调用到了<code>ZookeeperServiceRegistry实例</code>的<code>register()</code>方法？</li>
<li><code>ServiceDiscovery</code>是在哪里进行构建的？</li>
</ul>
</blockquote>
<blockquote>
<p><strong>第一个问题</strong>比较简单，在<code>ZookeeperAutoServiceRegistrationAutoConfiguration配置类</code>中构建<code>ZookeeperAutoServiceRegistration实例Bean</code>的时候，传入了一个<code>ZookeeperRegistration实例Bean</code>，而6.2 小节中创建的<code>ServiceInstanceRegistration实例Bean</code>实现了<code>ZookeeperRegistration接口</code>，而调用<code>getServiceInstance()</code>就能获取到 <strong><code>ServiceInstance实例</code></strong> 。</p>
</blockquote>
<blockquote>
<p><strong>第二和第三个问题是一起的</strong>，<code>zookeeperAutoServiceRegistration()</code>方法中注入了一个<code>ZookeeperServiceRegistry实例Bean</code>作为<code>ZookeeperAutoServiceRegistration构造函数</code>的入参。这个<code>ZookeeperServiceRegistry实例Bean</code>是在<code>ZookeeperServiceRegistryAutoConfiguration配置类</code>中创建的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ZookeeperServiceRegistryAutoConfiguration</span> <span class="keyword">implements</span> <span class="title class_">ApplicationContextAware</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@ConditionalOnBean(ServiceDiscovery.class)</span></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> ZookeeperServiceRegistry <span class="title function_">zookeeperServiceRegistry</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ZookeeperServiceRegistry</span>(<span class="built_in">this</span>.context.getBean(ServiceDiscovery.class));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而这里通过 Spring 应用上下文获取的 <code>ServiceDiscovery实例Bean</code>是在<code>CuratorServiceDiscoveryAutoConfiguration配置类</code>中创建的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CuratorServiceDiscoveryAutoConfiguration</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@ConditionalOnMissingBean(ServiceDiscoveryCustomizer.class)</span></span><br><span class="line">    <span class="keyword">public</span> DefaultServiceDiscoveryCustomizer <span class="title function_">defaultServiceDiscoveryCustomizer</span><span class="params">(</span></span><br><span class="line"><span class="params">            CuratorFramework curator, ZookeeperDiscoveryProperties properties,</span></span><br><span class="line"><span class="params">            InstanceSerializer&lt;ZookeeperInstance&gt; serializer)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DefaultServiceDiscoveryCustomizer</span>(curator, properties, serializer);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@ConditionalOnMissingBean</span></span><br><span class="line">    <span class="keyword">public</span> InstanceSerializer&lt;ZookeeperInstance&gt; <span class="title function_">deprecatedInstanceSerializer</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">JsonInstanceSerializer</span>&lt;&gt;(ZookeeperInstance.class);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="meta">@ConditionalOnMissingBean</span></span><br><span class="line">    <span class="keyword">public</span> ServiceDiscovery&lt;ZookeeperInstance&gt; <span class="title function_">curatorServiceDiscovery</span><span class="params">(ServiceDiscoveryCustomizer customizer)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> customizer.customize(ServiceDiscoveryBuilder.builder(ZookeeperInstance.class));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再继续下去就不分析了，其实就是获取配置文件中 Zookeeper 的信息，创建 CuratorFramework 的连接，以及指定 payload 的序列化器。如果想要设置服务发现节点的 ACL 权限可以自己创建一个实例 Bean 替换默认的 CuratorFramework  连接，或者替换其他实例Bean 进行自定义设置。</p>
</blockquote>
<h3 id="6-4-Spring-Boot-在什么时候将服务注册到服务中心"><a href="#6-4-Spring-Boot-在什么时候将服务注册到服务中心" class="headerlink" title="6.4 Spring Boot 在什么时候将服务注册到服务中心"></a>6.4 Spring Boot 在<strong>什么时候</strong>将服务注册到服务中心</h3><p>我们看到<code>ZookeeperAutoServiceRegistration类</code>的继承关系示意图，可以得知<code>ZookeeperAutoServiceRegistration类</code>实现了<code>ApplicationListener&lt;WebServerInitializedEvent&gt;</code>监听器接口，所以当 WebServer 服务准备完成的时候会产生<code>WebServerInitializedEvent事件</code>，并且 Spring 会自动调用其<code>onApplicationEvent()</code>方法。</p>
<p><img src="/2022/12/05/SpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8Zookeeper%E8%BF%9B%E8%A1%8C%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/image-20230103221232863.png" alt="image-20230103221232863"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">AbstractAutoServiceRegistration</span>&lt;R <span class="keyword">extends</span> <span class="title class_">Registration</span>&gt; <span class="keyword">implements</span> <span class="title class_">AutoServiceRegistration</span>, ApplicationContextAware, ApplicationListener&lt;WebServerInitializedEvent&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onApplicationEvent</span><span class="params">(WebServerInitializedEvent event)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.bind(event);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Deprecated</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">bind</span><span class="params">(WebServerInitializedEvent event)</span> &#123;</span><br><span class="line">        <span class="type">ApplicationContext</span> <span class="variable">context</span> <span class="operator">=</span> event.getApplicationContext();</span><br><span class="line">        <span class="keyword">if</span> (!(context <span class="keyword">instanceof</span> ConfigurableWebServerApplicationContext) || !<span class="string">&quot;management&quot;</span>.equals(((ConfigurableWebServerApplicationContext)context).getServerNamespace())) &#123;</span><br><span class="line">            <span class="built_in">this</span>.port.compareAndSet(<span class="number">0</span>, event.getWebServer().getPort());</span><br><span class="line">            <span class="built_in">this</span>.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!<span class="built_in">this</span>.isEnabled()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">                logger.debug(<span class="string">&quot;Discovery Lifecycle disabled. Not starting&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (!<span class="built_in">this</span>.running.get()) &#123;</span><br><span class="line">                <span class="built_in">this</span>.context.publishEvent(<span class="keyword">new</span> <span class="title class_">InstancePreRegisteredEvent</span>(<span class="built_in">this</span>, <span class="built_in">this</span>.getRegistration()));</span><br><span class="line">                <span class="comment">// 调用子类ZookeeperAutoServiceRegistration的注册方法，关联6.3小节</span></span><br><span class="line">                <span class="built_in">this</span>.register();</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">this</span>.shouldRegisterManagement()) &#123;</span><br><span class="line">                    <span class="built_in">this</span>.registerManagement();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="built_in">this</span>.context.publishEvent(<span class="keyword">new</span> <span class="title class_">InstanceRegisteredEvent</span>(<span class="built_in">this</span>, <span class="built_in">this</span>.getConfiguration()));</span><br><span class="line">                <span class="built_in">this</span>.running.compareAndSet(<span class="literal">false</span>, <span class="literal">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="7-小结"><a href="#7-小结" class="headerlink" title="7. 小结"></a>7. 小结</h2><p>关于 spring-cloud-zookeeper 的源码为什么那么复杂，老母猪戴奶罩一套又一套的，主要还是因为除了支持 zookeeper 能做服务发现以外，还支持 Eureka、Consul 这些作为注册中心，所以需要提供一个比较通用的接口， 这些通用的接口就是定义在 spring-cloud-commons包里。</p>
<p>关于看源码，如果是比较简单的框架直接看没什么问题，但是如果规模比较大的框架，还是要先有个大概的概念再去看，思路会清楚很多，所以还是要多长自己的见识，一味的只看源码其实也没啥用，无头苍蝇，哪里都不着调。</p>
]]></content>
      <categories>
        <category>Zookeeper</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>python包安装与卸载</title>
    <url>/2022/08/17/python%E5%8C%85%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/</url>
    <content><![CDATA[<h3 id="1-python包安装方式"><a href="#1-python包安装方式" class="headerlink" title="1. python包安装方式"></a>1. python包安装方式</h3><ol>
<li><p>setup.py方式</p>
</li>
<li><p>pip方式（推荐）</p>
</li>
<li><p>easy_install方式</p>
</li>
</ol>
<blockquote>
<p> python常用的包管理器是pip和easy_install，他们会从PyPI源里面搜索模块并自动下载安装，通常pip在安装python时会一并安装，而easy_install会在安装setuptools之后安装好</p>
</blockquote>
<blockquote>
<p>PyPI是Python官方的第三方模块仓库，供所有开发者下载或上传代码</p>
</blockquote>
<blockquote>
<p>事前约定：安装模块名是<code>module</code>，模块名可以到PyPI源里面寻找，<code>version</code>代指模块版本号</p>
</blockquote>
<h3 id="2-setup-py方式"><a href="#2-setup-py方式" class="headerlink" title="2. setup.py方式"></a>2. setup.py方式</h3><blockquote>
<p>setup.py是源码安装，通常用于离线环境中，在PyPI上下载源码后解压，里面会有setup.py文件，编译构建通常需要setuptools和wheel模块。</p>
</blockquote>
<h4 id="2-1-安装模块"><a href="#2-1-安装模块" class="headerlink" title="2.1 安装模块"></a>2.1 安装模块</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">构建</span></span><br><span class="line">python setup.py build</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装, 不执行build直接执行install也行，因为install会先build再安装</span></span><br><span class="line">python setup.py install</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">记录安装文件路径</span></span><br><span class="line">python setup.py install --record=install.log</span><br></pre></td></tr></table></figure>

<h4 id="2-2-卸载模块"><a href="#2-2-卸载模块" class="headerlink" title="2.2 卸载模块"></a>2.2 卸载模块</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">因为setup.py安装不像pip等包管理器管理，因此卸载的时候需要在安装的时候记录文件路径，卸载的时候直接删除文件</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确保install.log文件中没有`/*`路径，不然问题贼大</span></span><br><span class="line">cat install.log | xargs rm -rf</span><br></pre></td></tr></table></figure>

<h4 id="2-3-打包模块"><a href="#2-3-打包模块" class="headerlink" title="2.3 打包模块"></a>2.3 打包模块</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打包的文件都在目录下的dist文件夹中</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">tar.gz格式，就是简单的将源文件打包，未编译构建</span></span><br><span class="line">python setup.py sdist</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">egg格式，也是将源文件打包，未编译构建，但是扩展名变成egg。这个格式由setuptools模块引入。</span></span><br><span class="line">python setup.py bdist_egg</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">whl格式(推荐)，wheel包，也是压缩文件，经过编译构建后，能够分发到各个平台。由wheel模块引入，需要先安装wheel模块。</span></span><br><span class="line">python setup.py bdist_wheel</span><br></pre></td></tr></table></figure>



<h3 id="3-pip方式"><a href="#3-pip方式" class="headerlink" title="3. pip方式"></a>3. pip方式</h3><blockquote>
<p>pip也能以磁盘文件中安装模块，指定模块名时指定文件路径即可（whl或gee格式）</p>
</blockquote>
<blockquote>
<p>pip命令还有pip3，pip3指的是python3的pip。不确定pip安装的是python2还是python3模块的时候，可以使用pip3指定为python3的模块，或者使用<code>python -m pip list</code>根据使用的python指定pip版本</p>
</blockquote>
<h4 id="3-1-安装模块"><a href="#3-1-安装模块" class="headerlink" title="3.1 安装模块"></a>3.1 安装模块</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install module</span><br><span class="line">pip install module==version     # 安装指定版本</span><br><span class="line">python2 -m pip install module</span><br><span class="line">python3 -m pip install module</span><br></pre></td></tr></table></figure>

<h4 id="3-2-卸载模块"><a href="#3-2-卸载模块" class="headerlink" title="3.2 卸载模块"></a>3.2 卸载模块</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip uninstall module</span><br><span class="line">python2 -m pip uninstall module</span><br><span class="line">python3 -m pip uninstall module</span><br></pre></td></tr></table></figure>

<h4 id="3-3-镜像源"><a href="#3-3-镜像源" class="headerlink" title="3.3 镜像源"></a>3.3 镜像源</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">可以使用 &#x27;-i&#x27; 参数指定镜像源，加速下载，或在pip.conf文件中永久修改镜像源</span><br><span class="line">阿里云         https://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">中国科技大学    https://pypi.mirrors.ustc.edu.cn/simple/</span><br><span class="line">豆瓣(douban)   http://pypi.douban.com/simple/</span><br><span class="line">清华大学        https://pypi.tuna.tsinghua.edu.cn/simple/</span><br></pre></td></tr></table></figure>



<h3 id="4-easy-install方式"><a href="#4-easy-install方式" class="headerlink" title="4. easy_install方式"></a>4. easy_install方式</h3><h4 id="4-1-安装easy-install"><a href="#4-1-安装easy-install" class="headerlink" title="4.1 安装easy_install"></a>4.1 安装easy_install</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1. 通过引导程序ez_setup.py安装</span></span><br><span class="line">wget http://peak.telecommunity.com/dist/ez_setup.py</span><br><span class="line">python ez_setup.py</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 安装setuptools后自动安装（pip或setup.py方法安装）</span></span><br></pre></td></tr></table></figure>

<h4 id="4-2-安装模块"><a href="#4-2-安装模块" class="headerlink" title="4.2 安装模块"></a>4.2 安装模块</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">easy_install module</span><br><span class="line">easy_install module==version   # 安装指定版本</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定镜像源安装</span></span><br><span class="line">esay_install -i `镜像源` module </span><br></pre></td></tr></table></figure>

<h4 id="4-3-卸载模块"><a href="#4-3-卸载模块" class="headerlink" title="4.3 卸载模块"></a>4.3 卸载模块</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">easy_install -m module</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>python模块加载顺序</title>
    <url>/2022/08/17/python%E6%A8%A1%E5%9D%97%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F/</url>
    <content><![CDATA[<blockquote>
<p>结论：工程自定义包 -&gt; 工程py文件 -&gt; 系统路径 </p>
<p>所以如果在工程中自己创建了跟系统&#x2F;第三方模块重名的模块时，则无法加载系统&#x2F;第三方模块</p>
</blockquote>
<p>python出于性能考虑，每个模块在每个解释器会话中只导入一遍，所以如果程序运行过程中，你修改了自定义模块，那么需要重启解释器（即重启程序）或者使用<code>reload(moduleName)</code>重新加载模块（不用重启）</p>
<h3 id="1-查看模块加载路径"><a href="#1-查看模块加载路径" class="headerlink" title="1. 查看模块加载路径"></a>1. 查看模块加载路径</h3><blockquote>
<p>python解析器会从脚本执行目录、所有已安装内置模块和第三方模块中寻找导入的模块，按照sys.path中的路径顺序进行查找</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看sys.path</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sys</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sys.path</span><br><span class="line">[<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;/usr/lib64/python27.zip&#x27;</span>, <span class="string">&#x27;/usr/lib64/python2.7&#x27;</span>, <span class="string">&#x27;/usr/lib64/python2.7/plat-linux2&#x27;</span>, <span class="string">&#x27;/usr/lib64/python2.7/lib-tk&#x27;</span>, <span class="string">&#x27;/usr/lib64/python2.7/lib-old&#x27;</span>, <span class="string">&#x27;/usr/lib64/python2.7/lib-dynload&#x27;</span>, <span class="string">&#x27;/usr/lib64/python2.7/site-packages&#x27;</span>, <span class="string">&#x27;/usr/lib/python2.7/site-packages&#x27;</span>]</span><br><span class="line"><span class="comment"># 这里的列表中的第一个&#x27;&#x27;代表着当前目录，如果是使用文件执行，则是显示的脚本所在目录</span></span><br><span class="line"><span class="comment"># 可以通过sys.path.append(&#x27;/Users/michael/my_py_scripts&#x27;)临时添加搜索目录</span></span><br><span class="line"><span class="comment"># 或将目录添加到shell环境变量PYTHONPATH中</span></span><br></pre></td></tr></table></figure>



<h3 id="2-自定义模块加载"><a href="#2-自定义模块加载" class="headerlink" title="2. 自定义模块加载"></a>2. 自定义模块加载</h3><ol>
<li>导入一个叫<code>spam</code>的模块时，解释器先在当前目录中搜索名为<code>spam.py</code>的文件，import语句导入<code>spam.py</code>文件时，顺序执行其中的语句</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">目录结构</span><br><span class="line">projects/</span><br><span class="line">    test.py   # 内容 import spam</span><br><span class="line">    spam.py   # 内容 print(&quot;this is spam.py&quot;)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python test.py</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">结果</span></span><br><span class="line">this is spam.py</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>目录下存在<code>spam</code>包时，则优先调用<code>spam</code>包，不加载<code>spam.py</code>。加载包内文件时，先执行<code>__init__.py</code>再加载包内文件内容</strong></li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">目录结构</span><br><span class="line">projects/</span><br><span class="line">    test.py   # 内容 import spam</span><br><span class="line">    spam.py   # 内容 print(&quot;this is spam.py&quot;)</span><br><span class="line">    spam/ </span><br><span class="line">        __init__.py  # 内容 print(&quot;this is spam/__init__.py&quot;)</span><br><span class="line">        sub.py        # 内容 print(&quot;this is spam/sub.py&quot;)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python test.py</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">结果</span></span><br><span class="line">this is spam/__init__.py</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改test.py</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;import spam.sub&quot;</span> &gt; test.py</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python test.py</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">结果</span></span><br><span class="line">this is spam/__init__.py</span><br><span class="line">this is spam/sub.py</span><br></pre></td></tr></table></figure>



<h3 id="3-查看第三方模块的所在路径"><a href="#3-查看第三方模块的所在路径" class="headerlink" title="3. 查看第三方模块的所在路径"></a>3. 查看第三方模块的所在路径</h3><p>哪如果想知道导入的第三方模块具体文件在哪里咋办呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> imp</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>imp.find_module(<span class="string">&quot;paramiko&quot;</span>)</span><br><span class="line">(<span class="literal">None</span>, <span class="string">&#x27;/usr/local/lib/python3.6/site-packages/paramiko&#x27;</span>, (<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="number">5</span>))</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>【Logback+Spring-AOP】日志链路跟踪</title>
    <url>/2023/03/09/%E3%80%90Logback-Spring-AOP%E3%80%91%E6%97%A5%E5%BF%97%E9%93%BE%E8%B7%AF%E8%B7%9F%E8%B8%AA/</url>
    <content><![CDATA[<h3 id="1-日志跟踪"><a href="#1-日志跟踪" class="headerlink" title="1. 日志跟踪"></a>1. 日志跟踪</h3><blockquote>
<p>日志跟踪对于问题的排查和数据流转的路径分析是非常重要的，有了日志链路追踪体系可以有效且快速地定位问题。</p>
</blockquote>
<p>常用方案：</p>
<ul>
<li><strong>MDC（Mapped Diagnostic Context，映射调试上下文）</strong>：SLF4J 提供的一种轻量级日志跟踪工具（Log4j、Logback、Log4j2等日志框架都支持）。在多线程的情况下，多个请求会在同一时间段产生大量的日志记录，难以跟踪特定请求的日志信息。因此引出了 <code>trace-id</code>，在开始处理请求时，生成全局唯一的请求 ID， 在执行链路上带上此唯一 ID。</li>
<li><strong>ELK（Elasticsearch 、Logstash、 Kibana）</strong>：基于日志的追踪系统，Logstash 通过收集程序运行时产生的日志，按特定的规则进行分割处理后存到 Elasticsearch ，Kibana 负责日志可视化。某种程度上，也需要依赖 MDC 区分不同的请求。</li>
</ul>
<h3 id="2-MDC-介绍"><a href="#2-MDC-介绍" class="headerlink" title="2 . MDC 介绍"></a>2 . MDC 介绍</h3><h4 id="2-1-SLF4J-的-MDC"><a href="#2-1-SLF4J-的-MDC" class="headerlink" title="2.1 SLF4J 的 MDC"></a>2.1 SLF4J 的 MDC</h4><p><strong>Sl4fj 的 MDC 模式主要的门面类是 MDC.java，但是最核心的接口类是 MDCAdapter。</strong>其中最重要的是<code>static代码块</code>里面的逻辑，由各个日志框架实现<code>StaticMDCBinder</code>类，并且获取<code>MDCAdapter</code>的实现类。</p>
<p>SLF4J 本身不提供传递 traceId 的能力，真正提供能力的是 MDCAdapter 接口的实现。比如：Logback 的实现是 LogbackMDCAdapter，Log4j 的实现是 Log4jMDCAdapter。SLF4J 内部的 NOPMDCAdapter 类和 BasicMDCAdapter 属于空实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.slf4j;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.Closeable;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.slf4j.helpers.NOPMDCAdapter;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.helpers.BasicMDCAdapter;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.helpers.Util;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.impl.StaticMDCBinder;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.spi.MDCAdapter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MDC</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">NULL_MDCA_URL</span> <span class="operator">=</span> <span class="string">&quot;http://www.slf4j.org/codes.html#null_MDCA&quot;</span>;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">NO_STATIC_MDC_BINDER_URL</span> <span class="operator">=</span> <span class="string">&quot;http://www.slf4j.org/codes.html#no_static_mdc_binder&quot;</span>;</span><br><span class="line">    <span class="keyword">static</span> MDCAdapter mdcAdapter;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MDCCloseable</span> <span class="keyword">implements</span> <span class="title class_">Closeable</span> &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> String key;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="title function_">MDCCloseable</span><span class="params">(String key)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.key = key;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">            MDC.remove(<span class="built_in">this</span>.key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">MDC</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> MDCAdapter <span class="title function_">bwCompatibleGetMDCAdapterFromBinder</span><span class="params">()</span> <span class="keyword">throws</span> NoClassDefFoundError &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> StaticMDCBinder.getSingleton().getMDCA();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoSuchMethodError nsme) &#123;</span><br><span class="line">            <span class="comment">// binding is probably a version of SLF4J older than 1.7.14</span></span><br><span class="line">            <span class="keyword">return</span> StaticMDCBinder.SINGLETON.getMDCA();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mdcAdapter = bwCompatibleGetMDCAdapterFromBinder();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NoClassDefFoundError ncde) &#123;</span><br><span class="line">            mdcAdapter = <span class="keyword">new</span> <span class="title class_">NOPMDCAdapter</span>();</span><br><span class="line">            <span class="type">String</span> <span class="variable">msg</span> <span class="operator">=</span> ncde.getMessage();</span><br><span class="line">            <span class="keyword">if</span> (msg != <span class="literal">null</span> &amp;&amp; msg.contains(<span class="string">&quot;StaticMDCBinder&quot;</span>)) &#123;</span><br><span class="line">                Util.report(<span class="string">&quot;Failed to load class \&quot;org.slf4j.impl.StaticMDCBinder\&quot;.&quot;</span>);</span><br><span class="line">                Util.report(<span class="string">&quot;Defaulting to no-operation MDCAdapter implementation.&quot;</span>);</span><br><span class="line">                Util.report(<span class="string">&quot;See &quot;</span> + NO_STATIC_MDC_BINDER_URL + <span class="string">&quot; for further details.&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">throw</span> ncde;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// we should never get here</span></span><br><span class="line">            Util.report(<span class="string">&quot;MDC binding unsuccessful.&quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">put</span><span class="params">(String key, String val)</span> <span class="keyword">throws</span> IllegalArgumentException &#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;key parameter cannot be null&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (mdcAdapter == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;MDCAdapter cannot be null. See also &quot;</span> + NULL_MDCA_URL);</span><br><span class="line">        &#125;</span><br><span class="line">        mdcAdapter.put(key, val);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> MDCCloseable <span class="title function_">putCloseable</span><span class="params">(String key, String val)</span> <span class="keyword">throws</span> IllegalArgumentException &#123;</span><br><span class="line">        put(key, val);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MDCCloseable</span>(key);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">get</span><span class="params">(String key)</span> <span class="keyword">throws</span> IllegalArgumentException &#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;key parameter cannot be null&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (mdcAdapter == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;MDCAdapter cannot be null. See also &quot;</span> + NULL_MDCA_URL);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> mdcAdapter.get(key);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">remove</span><span class="params">(String key)</span> <span class="keyword">throws</span> IllegalArgumentException &#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;key parameter cannot be null&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (mdcAdapter == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;MDCAdapter cannot be null. See also &quot;</span> + NULL_MDCA_URL);</span><br><span class="line">        &#125;</span><br><span class="line">        mdcAdapter.remove(key);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (mdcAdapter == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;MDCAdapter cannot be null. See also &quot;</span> + NULL_MDCA_URL);</span><br><span class="line">        &#125;</span><br><span class="line">        mdcAdapter.clear();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title function_">getCopyOfContextMap</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (mdcAdapter == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;MDCAdapter cannot be null. See also &quot;</span> + NULL_MDCA_URL);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> mdcAdapter.getCopyOfContextMap();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">setContextMap</span><span class="params">(Map&lt;String, String&gt; contextMap)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (mdcAdapter == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;MDCAdapter cannot be null. See also &quot;</span> + NULL_MDCA_URL);</span><br><span class="line">        &#125;</span><br><span class="line">        mdcAdapter.setContextMap(contextMap);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> MDCAdapter <span class="title function_">getMDCAdapter</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> mdcAdapter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-2-Logback-的-MDCAdapter"><a href="#2-2-Logback-的-MDCAdapter" class="headerlink" title="2.2 Logback 的 MDCAdapter"></a>2.2 Logback 的 MDCAdapter</h4><blockquote>
<p><strong>当在 logback.xml 中 使用<code>SiftingAppender</code> 或者 在编码器中的模式配置了 <code>%X&#123;key&#125;</code>  ，在输出日志的时候，Logback 会从 MDC 中获取对应的 key 值，然后输出到日志</strong>。</p>
</blockquote>
<p>Logback 的 MDCAdapter 实现类是 LogbackMDCAdapter，实现 put、get、remove等方法。</p>
<p><strong>LogbackMDCAdapter  中最核心的就是 <code>copyOnThreadLocal</code>变量，其实就是一个 ThreadLocal 对象，用来储存<code>&lt;key，value&gt;</code>的值。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> ch.qos.logback.classic.util;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.slf4j.spi.MDCAdapter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogbackMDCAdapter</span> <span class="keyword">implements</span> <span class="title class_">MDCAdapter</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> ThreadLocal&lt;Map&lt;String, String&gt;&gt; copyOnThreadLocal = <span class="keyword">new</span> <span class="title class_">ThreadLocal</span>&lt;Map&lt;String, String&gt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">WRITE_OPERATION</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">MAP_COPY_OPERATION</span> <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// keeps track of the last operation performed</span></span><br><span class="line">    <span class="keyword">final</span> ThreadLocal&lt;Integer&gt; lastOperation = <span class="keyword">new</span> <span class="title class_">ThreadLocal</span>&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Integer <span class="title function_">getAndSetLastOperation</span><span class="params">(<span class="type">int</span> op)</span> &#123;</span><br><span class="line">        <span class="type">Integer</span> <span class="variable">lastOp</span> <span class="operator">=</span> lastOperation.get();</span><br><span class="line">        lastOperation.set(op);</span><br><span class="line">        <span class="keyword">return</span> lastOp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">wasLastOpReadOrNull</span><span class="params">(Integer lastOp)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> lastOp == <span class="literal">null</span> || lastOp.intValue() == MAP_COPY_OPERATION;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; <span class="title function_">duplicateAndInsertNewMap</span><span class="params">(Map&lt;String, String&gt; oldMap)</span> &#123;</span><br><span class="line">        Map&lt;String, String&gt; newMap = Collections.synchronizedMap(<span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, String&gt;());</span><br><span class="line">        <span class="keyword">if</span> (oldMap != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// we don&#x27;t want the parent thread modifying oldMap while we are</span></span><br><span class="line">            <span class="comment">// iterating over it</span></span><br><span class="line">            <span class="keyword">synchronized</span> (oldMap) &#123;</span><br><span class="line">                newMap.putAll(oldMap);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        copyOnThreadLocal.set(newMap);</span><br><span class="line">        <span class="keyword">return</span> newMap;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">put</span><span class="params">(String key, String val)</span> <span class="keyword">throws</span> IllegalArgumentException &#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;key cannot be null&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Map&lt;String, String&gt; oldMap = copyOnThreadLocal.get();</span><br><span class="line">        <span class="type">Integer</span> <span class="variable">lastOp</span> <span class="operator">=</span> getAndSetLastOperation(WRITE_OPERATION);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (wasLastOpReadOrNull(lastOp) || oldMap == <span class="literal">null</span>) &#123;</span><br><span class="line">            Map&lt;String, String&gt; newMap = duplicateAndInsertNewMap(oldMap);</span><br><span class="line">            newMap.put(key, val);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            oldMap.put(key, val);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">remove</span><span class="params">(String key)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        Map&lt;String, String&gt; oldMap = copyOnThreadLocal.get();</span><br><span class="line">        <span class="keyword">if</span> (oldMap == <span class="literal">null</span>)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">Integer</span> <span class="variable">lastOp</span> <span class="operator">=</span> getAndSetLastOperation(WRITE_OPERATION);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (wasLastOpReadOrNull(lastOp)) &#123;</span><br><span class="line">            Map&lt;String, String&gt; newMap = duplicateAndInsertNewMap(oldMap);</span><br><span class="line">            newMap.remove(key);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            oldMap.remove(key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span> &#123;</span><br><span class="line">        lastOperation.set(WRITE_OPERATION);</span><br><span class="line">        copyOnThreadLocal.remove();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">get</span><span class="params">(String key)</span> &#123;</span><br><span class="line">        <span class="keyword">final</span> Map&lt;String, String&gt; map = copyOnThreadLocal.get();</span><br><span class="line">        <span class="keyword">if</span> ((map != <span class="literal">null</span>) &amp;&amp; (key != <span class="literal">null</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> map.get(key);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Map&lt;String, String&gt; <span class="title function_">getPropertyMap</span><span class="params">()</span> &#123;</span><br><span class="line">        lastOperation.set(MAP_COPY_OPERATION);</span><br><span class="line">        <span class="keyword">return</span> copyOnThreadLocal.get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Set&lt;String&gt; <span class="title function_">getKeys</span><span class="params">()</span> &#123;</span><br><span class="line">        Map&lt;String, String&gt; map = getPropertyMap();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (map != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> map.keySet();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Map&lt;String, String&gt; <span class="title function_">getCopyOfContextMap</span><span class="params">()</span> &#123;</span><br><span class="line">        Map&lt;String, String&gt; hashMap = copyOnThreadLocal.get();</span><br><span class="line">        <span class="keyword">if</span> (hashMap == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, String&gt;(hashMap);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setContextMap</span><span class="params">(Map&lt;String, String&gt; contextMap)</span> &#123;</span><br><span class="line">        lastOperation.set(WRITE_OPERATION);</span><br><span class="line"></span><br><span class="line">        Map&lt;String, String&gt; newMap = Collections.synchronizedMap(<span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, String&gt;());</span><br><span class="line">        newMap.putAll(contextMap);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// the newMap replaces the old one for serialisation&#x27;s sake</span></span><br><span class="line">        copyOnThreadLocal.set(newMap);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-3-MDC-的使用方式"><a href="#2-3-MDC-的使用方式" class="headerlink" title="2.3 MDC 的使用方式"></a>2.3 MDC 的使用方式</h4><h5 id="2-3-1-添加-key"><a href="#2-3-1-添加-key" class="headerlink" title="2.3.1 添加 key"></a>2.3.1 添加 key</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MDC.put(“trace-id”, traceId); </span><br></pre></td></tr></table></figure>

<h5 id="2-3-2-移除-key"><a href="#2-3-2-移除-key" class="headerlink" title="2.3.2 移除 key"></a>2.3.2 移除 key</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MDC.remove(“trace-id”);</span><br></pre></td></tr></table></figure>

<h5 id="2-3-3-格式化输出-MDC-内容"><a href="#2-3-3-格式化输出-MDC-内容" class="headerlink" title="2.3.3 格式化输出 MDC 内容"></a>2.3.3 格式化输出 MDC 内容</h5><blockquote>
<p>以 logback 配置文件为例子</p>
</blockquote>
<p>在 logback 配置文件的 <code>encoder</code> 中，使用 <code>%X&#123;key&#125;</code> 取出 MDC 中 key 的值。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;console&quot;</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.ConsoleAppender&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; %X&#123;trace-id&#125; %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="3-线程池场景下传递-MDC-上下文"><a href="#3-线程池场景下传递-MDC-上下文" class="headerlink" title="3. 线程池场景下传递 MDC 上下文"></a>3. 线程池场景下传递 MDC 上下文</h3><blockquote>
<p>从上面的源码中可以看出，Logback 中 MDC 的实现方式其实是 ThreadLocal。而当创建一个新的线程的时候，新线程中会丢失 MDC 上下文。要实现一个完整的事件跟踪，就需要将 MDC 上下文传递到新线程。</p>
</blockquote>
<blockquote>
<p>那么存在以下问题：</p>
<ul>
<li>如何将父线程的 ThreadLocal  传递到子线程。</li>
<li>在线程池的情况下，如何解决线程复用时 ThreadLocal 也会被复用的问题。</li>
</ul>
</blockquote>
<p>将 ThreadLocal 上下文传递到子线程中的方法：</p>
<ul>
<li>（针对创建新线程场景，在变量层面）采用 JDK 自带的 ThreadLocal 的扩展类 InheritableThreadLocal。（无法传递 MDC、不适用于线程池）</li>
<li>（针对线程池，在变量层面）使用 Alibaba 的 <a href="https://github.com/alibaba/transmittable-thread-local">transmittable-thread-local</a>。</li>
<li>（针对线程池，在线程池层面）自定义线程池，在提交线程前，对线程进行处理，取出父线程的 ThreadLocal 并且传入子线程中。</li>
<li>（针对线程池，在线程池层面）使用 Spring 的 ThreadPoolTaskExecutor，定义线程装饰器，在执行线程前传递 ThreadLocal。</li>
</ul>
<p><strong>这里使用 Spring Boot 的 ThreadPoolTaskExecutor，自定义线程装饰器。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadPoolConfig</span> &#123;</span><br><span class="line">    <span class="comment">// 注入 SpringBoot 自动装配的 TaskExecutorBuilder，线程池参数使 用 Springboot 默认配置</span></span><br><span class="line">    <span class="comment">// 主要是在线程执行之前获取父线程 MDC 的拷贝副本, 并且在子线程执行前进行设置</span></span><br><span class="line">    <span class="comment">// 后续使用线程池都需要指定使用 MDCThreadPoolTask 这个名字的线程池 @Qualifier(&quot;MDCThreadPoolTask&quot;)</span></span><br><span class="line">    <span class="meta">@Bean(&quot;MDCThreadPoolTask&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> ThreadPoolTaskExecutor <span class="title function_">configThreadPool</span><span class="params">(TaskExecutorBuilder builder)</span>&#123;</span><br><span class="line">        builder = builder.taskDecorator(runnable -&gt; &#123;</span><br><span class="line">            <span class="comment">// 获取父线程 MDC 的拷贝副本</span></span><br><span class="line">            Map&lt;String, String&gt; contextMap = MDC.getCopyOfContextMap();</span><br><span class="line">            <span class="keyword">return</span> () -&gt; &#123;</span><br><span class="line">                <span class="keyword">try</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (contextMap != <span class="literal">null</span>)&#123;</span><br><span class="line">                        <span class="comment">// 设置子线程的 MDC</span></span><br><span class="line">                        MDC.setContextMap(contextMap);</span><br><span class="line">                    &#125;</span><br><span class="line">                    runnable.run();</span><br><span class="line">                &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="comment">// 由于使用的是线程池，因此在子线程完成业务操作之后，需要清空 MDC</span></span><br><span class="line">                    <span class="comment">// 否则后续线程池中复用的线程会取到上一次线程运行时存入的 MDC 值</span></span><br><span class="line">                    MDC.clear();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">return</span> builder.build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="4-自定义-AOP-注解"><a href="#4-自定义-AOP-注解" class="headerlink" title="4. 自定义 AOP 注解"></a>4. 自定义 AOP 注解</h3><blockquote>
<p>自定义AOP注解，在方法执行前后设置及清除 MDC。</p>
</blockquote>
<ul>
<li>定义 <code>MDCTrace</code> 注解，标记该注解的类或者方法调用都会执行 Advice 的增强方法。（可以在该注解上增加参数，用于表示如何生成请求的 uuid）</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ljh.logbacktest.aop.logtrace;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.ElementType;</span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.Retention;</span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.RetentionPolicy;</span><br><span class="line"><span class="keyword">import</span> java.lang.annotation.Target;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> MDCTrace &#123;</span><br><span class="line">    String <span class="title function_">mark</span><span class="params">()</span> <span class="keyword">default</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>定义 Aspect、Pointcut、Advice，在方法执行前根据方法入参以及<code>MDCTrace</code>注解的参数生成请求 uuid，并存入 MDC 。当方法返回后，清除 MDC 的内容。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ljh.logbacktest.aop.logtrace;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.JoinPoint;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.After;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Aspect;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Before;</span><br><span class="line"><span class="keyword">import</span> org.aspectj.lang.annotation.Pointcut;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.MDC;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Aspect</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MDCTraceAspect</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;logging.traceKey&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String KEY;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Pointcut(&quot;@annotation(mdcTrace)&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">mdcTracePointcut</span><span class="params">(MDCTrace mdcTrace)</span>&#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Before(value = &quot;mdcTracePointcut(mdcTrace)&quot;, argNames = &quot;joinPoint,mdcTrace&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">traceMdc</span><span class="params">(JoinPoint joinPoint, MDCTrace mdcTrace)</span>&#123;</span><br><span class="line">        Object[] args = joinPoint.getArgs();</span><br><span class="line">        <span class="type">String</span> <span class="variable">mark</span> <span class="operator">=</span> mdcTrace.mark();</span><br><span class="line">        <span class="comment">// 根据入参生成 uuid</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">uuid</span> <span class="operator">=</span> Arrays.deepToString(args) + mark;</span><br><span class="line">        MDC.put(KEY, uuid);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@After(value = &quot;mdcTracePointcut(mdcTrace)&quot;, argNames = &quot;mdcTrace&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clearMdc</span><span class="params">(MDCTrace mdcTrace)</span>&#123;</span><br><span class="line">        MDC.clear();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="5-自定义-Logback-Appender"><a href="#5-自定义-Logback-Appender" class="headerlink" title="5. 自定义 Logback Appender"></a>5. 自定义 Logback Appender</h3><blockquote>
<p>Logback 将写入日志事件的任务委托给 <a href="https://logback.qos.ch/manual/appenders.html">Appender 组件</a>。因此通过自定义 Appender，能够自己对日志进行处理、推送。</p>
</blockquote>
<p>所有的 Appender 都实现了 <code>Appender&lt;E&gt;</code> 接口。如果要实现 <code>Appender&lt;E&gt;</code> 接口，可以实现抽象类 <code>AppenderBase&lt;E&gt;</code> 或者 <code>UnsynchronizedAppenderBase&lt;E&gt;</code> 中，重写里面的 <code>append(E eventObject)</code> 方法。这两个抽象类都实现了所有 Appender 共享的基本功能，例如设置或者获取名称、激活状态、布局和过滤器的方法。</p>
<p>其中，<code>AppenderBase&lt;E&gt;</code> 是线程安全的，<code>UnsynchronizedAppenderBase&lt;E&gt;</code> 是线程不安全的。</p>
<h4 id="5-1-继承-UnsynchronizedAppenderBase"><a href="#5-1-继承-UnsynchronizedAppenderBase" class="headerlink" title="5.1 继承 UnsynchronizedAppenderBase"></a>5.1 继承 UnsynchronizedAppenderBase</h4><blockquote>
<p>判断 MDC 中是否存在 <code>tarceId </code>，如果存在，则推送日志；如果不存在，则不进行处理。</p>
</blockquote>
<blockquote>
<p>关于<code>UnsynchronizedAppenderBase</code>中的泛型<code>E</code>，在 logback-classic 模块中，<code>E</code>是类型<code>ILoggingEvent</code>，而在 logback-access 模块中是 <code>AccessEvent</code>。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.ljh.logbacktest.appender;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ch.qos.logback.classic.encoder.PatternLayoutEncoder;</span><br><span class="line"><span class="keyword">import</span> ch.qos.logback.classic.spi.ILoggingEvent;</span><br><span class="line"><span class="keyword">import</span> ch.qos.logback.core.UnsynchronizedAppenderBase;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyAppender</span> <span class="keyword">extends</span> <span class="title class_">UnsynchronizedAppenderBase</span>&lt;ILoggingEvent&gt; &#123;</span><br><span class="line">    <span class="comment">// keyName 通过配置文件注入</span></span><br><span class="line">    <span class="keyword">private</span> String keyName;</span><br><span class="line">    <span class="comment">// 编码器通过配置文件注入</span></span><br><span class="line">    <span class="keyword">private</span> PatternLayoutEncoder encoder;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">append</span><span class="params">(ILoggingEvent event)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> event.getMDCPropertyMap().get(keyName);</span><br><span class="line">        <span class="keyword">if</span> (value == <span class="literal">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 使用 encoder 编码事件为日志字符串</span></span><br><span class="line">        <span class="type">byte</span>[] byteArray = <span class="built_in">this</span>.encoder.encode(event);</span><br><span class="line">        <span class="type">String</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(byteArray);</span><br><span class="line">        pushLogInfo(value, msg);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">pushLogInfo</span><span class="params">(String value, String msg)</span>&#123;</span><br><span class="line">        <span class="comment">// 实现推送日志的具体逻辑</span></span><br><span class="line">        System.out.printf(<span class="string">&quot;MyAppender[%s]: %s&quot;</span>, value, msg);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setEncoder</span><span class="params">(PatternLayoutEncoder encoder)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.encoder = encoder;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setKeyName</span><span class="params">(String keyName)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.keyName = keyName;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="5-2-配置文件"><a href="#5-2-配置文件" class="headerlink" title="5.2 配置文件"></a>5.2 配置文件</h4><blockquote>
<p>因为现在都是使用的 SpringBoot 启动项目，所以直接使用命名为 <code>logback-spring.xml</code> 的配置文件就能够配置 logback 的属性，并且还能够引用 Spring 的一些特性。</p>
</blockquote>
<blockquote>
<p>下面两个配置文件中，配置了 SpringBoot 启动时，logback 的一些默认设置。</p>
<ul>
<li><p><code>org/springframework/boot/logging/logback/defaults.xml</code></p>
</li>
<li><p><code>org/springframework/boot/logging/logback/base.xml</code></p>
</li>
</ul>
</blockquote>
<h5 id="5-2-1-logback-spring-xml"><a href="#5-2-1-logback-spring-xml" class="headerlink" title="5.2.1 logback-spring.xml"></a>5.2.1 logback-spring.xml</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> ?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--引入springboot默认配置--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">include</span> <span class="attr">resource</span>=<span class="string">&quot;org/springframework/boot/logging/logback/defaults.xml&quot;</span>/&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--不引入控制台及日志文件的输出--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot;/&gt;--&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!--引入配置文件中logging.traceKey的值，后续能够通过$&#123;key&#125;引用--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">springProperty</span> <span class="attr">scope</span>=<span class="string">&quot;context&quot;</span> <span class="attr">name</span>=<span class="string">&quot;key&quot;</span> <span class="attr">source</span>=<span class="string">&quot;logging.traceKey&quot;</span>/&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;myAppender&quot;</span> <span class="attr">class</span>=<span class="string">&quot;com.ljh.logbacktest.appender.MyAppender&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">keyName</span>&gt;</span>$&#123;key&#125;<span class="tag">&lt;/<span class="name">keyName</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--使用SpringBoot配置中的控制台的输出格式（有颜色）且增加 MDC 中 key 的输出--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>[%X&#123;$&#123;key&#125;&#125;]$&#123;CONSOLE_LOG_PATTERN&#125;&#125;<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>$&#123;CONSOLE_LOG_CHARSET&#125;<span class="tag">&lt;/<span class="name">charset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--当profile为default环境的时候生效--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">springProfile</span> <span class="attr">name</span>=<span class="string">&quot;default&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;myAppender&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">springProfile</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h5 id="5-2-2-application-yml"><a href="#5-2-2-application-yml" class="headerlink" title="5.2.2 application.yml"></a>5.2.2 application.yml</h5><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">logging:</span></span><br><span class="line">  <span class="attr">traceKey:</span> <span class="string">key</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>一致性哈希的由来</title>
    <url>/2023/02/17/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%9A%84%E7%94%B1%E6%9D%A5/</url>
    <content><![CDATA[<h3 id="1-负载均衡"><a href="#1-负载均衡" class="headerlink" title="1. 负载均衡"></a>1. 负载均衡</h3><p>大多数网站背后不只有一台服务器提供服务，都由多台服务器构成集群来向外提供服务。分配客户端的请求到那一台服务器进行处理，就是负载均衡解决的问题。</p>
<img src="d3279ad754257977f98e702cb156e9cf.png" alt="img" style="zoom:67%;" />

<p>常见的负载均衡算法：</p>
<ul>
<li><strong>轮询法：</strong>将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。</li>
<li><strong>加权轮询法：</strong>给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载。</li>
<li><strong>随机法：</strong>通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。</li>
<li><strong>加权随机法：</strong>与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。</li>
<li><strong>最小连接数法：</strong>根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求。</li>
<li><strong>源地址哈希法：</strong>源地址哈希的思想是根据获取客户端的 IP 地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。</li>
</ul>
<h4 id="1-1-存在问题"><a href="#1-1-存在问题" class="headerlink" title="1.1 存在问题"></a>1.1 存在问题</h4><p><strong>在分布式系统场景中</strong>，每个节点储存的数据是不同的。因为想要提高系统的容量，需要对<strong>数据水平切分</strong>，将数据分布在不同的节点上储存。<strong>一个分布式 KV（key-value）缓存系统，某个 key 应该到哪个或者哪些节点上获取value，应该是确定的，并不是访问任意节点都能得到缓存结果。</strong></p>
<p>而通过上述的负载均衡算法，无法处理每个节点储存部分数据的情况。</p>
<h3 id="2-哈希算法"><a href="#2-哈希算法" class="headerlink" title="2. 哈希算法"></a>2. 哈希算法</h3><h4 id="2-1-原理"><a href="#2-1-原理" class="headerlink" title="2.1 原理"></a>2.1 原理</h4><p>哈希算法能够对关键字 key 进行哈希计算，每次计算都是相同的值，这样就能够将某个 key 映射到特定一个节点上了，满足分布式系统的负载均衡需求。</p>
<p>哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，可以基于以下公式对数据进行映射：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hash(key) % 3</span><br></pre></td></tr></table></figure>

<p>如果经过计算后得到的值为0，代表需要去第一个节点获取。</p>
<h4 id="2-2-存在问题"><a href="#2-2-存在问题" class="headerlink" title="2.2 存在问题"></a>2.2 存在问题</h4><p><strong>如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据</strong>，否则会出现查询不到数据的问题。</p>
<ul>
<li>举个例子，假设我们有一个由 A、B、C 三个节点组成分布式 K-V 缓存系统，基于计算公式 <code>hash(key) % 3</code> 将数据进行了映射，每个节点存储了不同的数据：</li>
</ul>
<img src="025ddcaabece1f4b5823dfb1fb7340ef.png" alt="img" style="zoom: 67%;" />

<ul>
<li>现在有 3 个查询 key 的请求，分别查询 key-01，key-02，key-03 的数据，这三个 key 分别经过 hash () 函数计算后的值为 hash ( key-01) &#x3D; 6、hash ( key-02) &#x3D; 7、hash (key-03) &#x3D; 8，然后再对这些值进行取模运算。</li>
</ul>
<img src="ed14c96417e08b4f916e0cd23d12b7bd.png" alt="img" style="zoom: 67%;" />

<ul>
<li>当 3 个节点不能满足业务需求了，这时我们增加了一个节点，节点的数量从 3 变化为 4，意味取模哈希函数中基数的变化，这样会导致<strong>大部分映射关系改变</strong>。</li>
</ul>
<img src="392c54cfb9ec47f5191008aa1d27d6b5.png" alt="img" style="zoom:67%;" />

<ul>
<li>要解决这个问题的办法，就需要我们进行<strong>迁移数据</strong>，比如节点的数量从 3 变化为 4 时，要基于新的计算公式 hash (key) % 4 ，重新对数据和节点做映射。假设总数据条数为 M，哈希算法在面对节点数量变化时，**最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O (M)**，这样数据的迁移成本太高了。</li>
</ul>
<h3 id="3-一致性哈希算法"><a href="#3-一致性哈希算法" class="headerlink" title="3. 一致性哈希算法"></a>3. 一致性哈希算法</h3><blockquote>
<p>在没有分布式的情况下，我们通过负载均衡算法来将请求分配到不同的服务器上。</p>
<p>但是在分布式场景下，需要对数据进行水平切分，因此需要根据 key 来定位数据在那台服务器上。</p>
<p>且在节点数量发生变化时，对系统的影响降到最低。</p>
<p>一致性哈希算法就是为了解决上述的问题。</p>
</blockquote>
<h4 id="3-1-原理"><a href="#3-1-原理" class="headerlink" title="3.1 原理"></a>3.1 原理</h4><p>一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而<strong>一致哈希算法是对 <code>2^32</code> 进行取模运算，是一个固定的值，将「存储节点」和「数据」都映射到一个首尾相连的哈希环上</strong>。</p>
<p>我们可以把一致哈希算法是对 <code>2^32</code> 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 <code>2^32</code> 个点组成的圆，这个圆环被称为<strong>哈希环</strong>，如下图：</p>
<img src="0ea3960fef48d4cbaeb4bec4345301e7.png" alt="img" style="zoom:50%;" />

<p>具体步骤：</p>
<ol>
<li>对<strong>储存节点</strong>进行哈希计算，映射到哈希环具体的位置上（可以根据节点的 IP 地址进行哈希）。</li>
<li>对<strong>数据</strong>进行储存或访问时，对数据的 key 进行哈希计算，映射到哈希环具体的位置上。<ul>
<li>现在储存节点和数据都映射到哈希环上，那么数据映射到哈希环后，顺时针方向最近的第一个节点就是储存该数据的节点。</li>
<li>比如下图中，三个节点根据 IP 地址对 <code>2^32</code> 取模后落到哈希环对应的位置上；<code>key-1</code> 对 <code>2^32</code> 取模后落到节点 A 前的位置，那么顺时针离 <code>key-1</code> 最近的节点就是 A，因此，节点 A 就负责储存 <code>key-1</code> 的数据。</li>
</ul>
</li>
</ol>
<img src="30c2c70721c12f9c140358fbdc5f2282.png" alt="img" style="zoom:50%;" />

<h4 id="3-2-存在问题"><a href="#3-2-存在问题" class="headerlink" title="3.2 存在问题"></a>3.2 存在问题</h4><h5 id="3-2-1-节点增加或减少的情况"><a href="#3-2-1-节点增加或减少的情况" class="headerlink" title="3.2.1 节点增加或减少的情况"></a>3.2.1 节点增加或减少的情况</h5><blockquote>
<p>在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。</p>
</blockquote>
<ul>
<li>当新增了节点 D，新的节点经过哈希计算后映射到下图中的位置，可以看到，<code>key-1</code>、<code>key-3</code>储存的节点都不受影响，只有<code>key-2</code>需要被迁移到节点 D。</li>
</ul>
<img src="f8909edef2f3949f8945bb99380baab3.png" alt="img" style="zoom:50%;" />

<ul>
<li>当删除节点 A 的情况下，只有<code>key-1</code> 被重新迁移到节点 B 上。</li>
</ul>
<img src="31485046f1303b57d8aaeaab103ea7ab.png" alt="img" style="zoom:50%;" />

<h5 id="3-2-2-节点分布不均匀"><a href="#3-2-2-节点分布不均匀" class="headerlink" title="3.2.2 节点分布不均匀"></a>3.2.2 节点分布不均匀</h5><blockquote>
<p>上述例子中的节点都是均匀分布在哈希环上。但是实际情况可能没有那么理想。</p>
</blockquote>
<ul>
<li>节点在哈希环上的分布不均匀时，如下图，这时超过半数的数据都寻址到节点 A，会给节点 A 带来大量的压力。此外，<strong>在容灾与扩容的时候，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应</strong>。如果节点 A 被移除或者宕机后，其上的数据都被迁移到相邻的节点 B 上，这样节点 B 的数据量和访问量都会暴增，一单超过节点 B 的处理能力，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。</li>
</ul>
<img src="d528bae6fcec2357ba2eb8f324ad9fd5.png" alt="img" style="zoom:50%;" />



<h4 id="3-3-解决方法"><a href="#3-3-解决方法" class="headerlink" title="3.3 解决方法"></a>3.3 解决方法</h4><p>为了解决哈希环上节点分布不均匀的情况，我们能够引入<strong>虚拟节点</strong>。</p>
<p>之前我们是将节点直接映射到哈希环上，那么分布的情况就要受节点实际情况影响。那么我们能不直接将实际节点映射到哈希环上，而是<strong>将虚拟节点均匀映射到哈希环上，再将实际节点映射到虚拟节点</strong>。</p>
<p>具体例子：</p>
<ul>
<li>设置 9 个虚拟节点，节点 ABC 分别按需轮流映射到这 9 个虚拟节点上。</li>
</ul>
<img src="dbb57b8d6071d011d05eeadd93269e13.png" alt="img" style="zoom:50%;" />

<p>总结：</p>
<ul>
<li>可以看到<strong>节点数量多了后，节点在哈希环上的分布就相对均匀了</strong>。这时候，如果有访问请求寻址到「A-01」这个虚拟节点，接着再通过「A-01」虚拟节点找到真实节点 A，这样请求就能访问到真实节点 A 了。</li>
<li>另外，虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。<strong>当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高</strong>。比如，当某个节点被移除时，对应该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了节点变化导致的压力。</li>
<li>而且，有了虚拟节点后，还可以为硬件配置更好的节点增加权重，比如对权重更高的节点增加更多的虚拟机节点即可。</li>
<li>因此，<strong>带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景</strong>。</li>
</ul>
<hr>
<p>参考资料：</p>
<p><a href="https://xiaolincoding.com/os/8_network_system/hash.html">什么是一致性哈希</a></p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>关于一些好看的写作规范</title>
    <url>/2022/11/02/%E5%85%B3%E4%BA%8E%E4%B8%80%E4%BA%9B%E5%A5%BD%E7%9C%8B%E7%9A%84%E5%86%99%E4%BD%9C%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>主要是统一一下自己的写作规范，尽可能好看一点</p>
<ul>
<li><p>尽可能使用markdown的标准语法，不要引入太多html或者是其他插件的语法</p>
</li>
<li><p>关于文章目录，所有最高层级的标题使用markdown的三级标题</p>
</li>
<li><p>关于不同标题层级之间的换行，在不同层级之间要空出一行，如果不空的话，文章看起来密密麻麻，父层级和第一个子层级之间可以不空出一行，但是子层级和子层级之间需要空出一行</p>
</li>
<li><p>句子中的英文，有的时候句子里面会写英文的单词，如果是：这是一个Test句子。中文与英文之间没有间隔，看起来就会很密，字一多起来，看起来头疼。所以在英文前后加上一个空格，如：这是一个 Test 句子（当然，页面渲染结果可以使用 hexo-pangu 这个插件来自动处理）。另外，这些英文尽可能首字母大小，看起来会舒服很多，但是也不一定全大写，自己看情况。</p>
</li>
<li><p>对于文本中的代码，不用说也知道，用&#96;&#96;&#96;引入代码块，再把代码黏贴进去，尽可能标注上代码类型，Java、Python 或 Shell 等。代码和文本不进行区分简直是反人类，这种博客看都不想看。</p>
</li>
<li><p>关于博客中最后的引用连接，最好写上标题名字，然后用超链接的方式，如<a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/18%20%20Kafka%E4%B8%AD%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF.md">Kafka中位移提交那些事儿</a>，如果连接失效了，就没办法了，所以自己最好在印象笔记里面存一份。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>日常踩坑</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>再战LVS DR模式</title>
    <url>/2023/07/18/%E5%86%8D%E6%88%98LVS-DR%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h3 id="1-工作原理"><a href="#1-工作原理" class="headerlink" title="1.工作原理"></a>1.工作原理</h3><blockquote>
<a href="/2022/08/18/LVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%AE%9E%E6%88%98/" title="LVS负载均衡实战">上一篇文章</a>中已经详细写了 NAT/TUN/DR 模式的工作原理了，这里不重复造轮子，只做简单叙述。
</blockquote>
<blockquote>
<p>在 DR 模式下，无论是 DS 服务器还是 RS 服务器都需要绑定上 VIP，需要知道 VIP 的地址。只不过 VIP 在 DS、RS 服务器上绑的网络接口不一样，但是只能由 DS 服务器响应 ARP 广播，RS 服务器不响应。</p>
</blockquote>
<h4 id="1-1-关于Director-Server-DS"><a href="#1-1-关于Director-Server-DS" class="headerlink" title="1.1 关于Director Server(DS)"></a>1.1 关于Director Server(DS)</h4><ul>
<li><p>LVS 在 DR 模式对数据包仅仅修改目的 MAC 地址，让其路由到 RS 服务器上，因此 DS 服务器需要跟 RS 服务器在同一个物理网络中。</p>
</li>
<li><p>DS 服务器在 DR 模式下不能再充当 RS 服务器的网关。</p>
</li>
<li><p>VIP 绑定在 DS 服务器的内网网卡上（如：eth0）。</p>
</li>
</ul>
<h4 id="1-2-关于Real-Server-RS"><a href="#1-2-关于Real-Server-RS" class="headerlink" title="1.2 关于Real Server(RS)"></a>1.2 关于Real Server(RS)</h4><p>RS 服务器也需要绑定 VIP，为了解决 ARP 广播响应的问题，需要按以下设置：</p>
<ul>
<li><p>使用回环虚接口 lo:0 承载 VIP 地址（回环接口没有 MAC 地址，不会接收 ARP 请求，也不会响应 ARP 请求）。</p>
</li>
<li><p>设置内核参数 arp_ignore&#x3D;1：系统只响应目的IP为该网络接口 IP 的 ARP 请求（默认情况下，所有网络接口会响应对任何本机 IP 地址的 ARP 查询请求）。</p>
</li>
<li><p>设置内核参数 arp_announce&#x3D;2：保证 RS 以源 IP 为 VIP 的情况下，发送出去数据包（避免通过 ARP 请求查询能到达客户端的网关 MAC 地址）。</p>
</li>
</ul>
<h3 id="2-环境信息"><a href="#2-环境信息" class="headerlink" title="2. 环境信息"></a>2. 环境信息</h3><ul>
<li>操作系统：Centos7.9</li>
<li>LVS 工作模式：DR</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th><strong>Director Server 01</strong></th>
<th><strong>Real Server 01</strong></th>
<th>Real Server 02</th>
</tr>
</thead>
<tbody><tr>
<td>IP</td>
<td>172.24.0.204（内网IP，eth0）<br />172.24.0.159（VIP，eth0）</td>
<td>172.24.0.246（内网IP，eth0）<br />172.24.0.159（VIP，lo）</td>
<td>172.24.0.251（内网IP，eth0）<br />172.24.0.159（VIP，lo）</td>
</tr>
<tr>
<td>端口</td>
<td>80</td>
<td>80</td>
<td>80</td>
</tr>
<tr>
<td>内核设置</td>
<td>无</td>
<td>net.ipv4.conf.lo.arp_ignore&#x3D;1<br />net.ipv4.conf.lo.arp_announce&#x3D;2<br />net.ipv4.conf.all.arp_ignore&#x3D;1<br />net.ipv4.conf.all.arp_announce&#x3D;2</td>
<td>net.ipv4.conf.lo.arp_ignore&#x3D;1<br />net.ipv4.conf.lo.arp_announce&#x3D;2<br />net.ipv4.conf.all.arp_ignore&#x3D;1<br />net.ipv4.conf.all.arp_announce&#x3D;2</td>
</tr>
</tbody></table>
<h3 id="3-集群部署"><a href="#3-集群部署" class="headerlink" title="3. 集群部署"></a>3. 集群部署</h3><h4 id="3-1-Real-Server设置"><a href="#3-1-Real-Server设置" class="headerlink" title="3.1 Real Server设置"></a>3.1 Real Server设置</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置内核参数</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;</span></span></span><br><span class="line">net.ipv4.conf.lo.arp_ignore=1</span><br><span class="line">net.ipv4.conf.lo.arp_announce=2</span><br><span class="line">net.ipv4.conf.all.arp_ignore=1</span><br><span class="line">net.ipv4.conf.all.arp_announce=2</span><br><span class="line">&quot; | sudo tee -a /etc/sysctl.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo sysctl -p</span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">绑定VIP至lo接口</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置文件中配置或者使用ip addr命令临时添加</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">echo</span> <span class="string">&quot;</span></span></span><br><span class="line">DEVICE=lo:0</span><br><span class="line">IPADDR=172.24.0.159</span><br><span class="line">NETMASK=255.255.255.255</span><br><span class="line">ONBOOT=yes&quot; | sudo tee /etc/sysconfig/network-scripts/ifcfg-lo:0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo systemctl restart network</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">或者临时添加</span></span></span><br><span class="line">sudo ip addr add 172.24.0.159/32 dev lo:0</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装Nginx</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装epel源</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y epel-release</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装nginx</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install nginx -y</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动nginx服务，默认80端口</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo servcie start nginx</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在RS1中执行</span></span><br><span class="line">echo &#x27;RS01&#x27; | sudo tee /usr/share/nginx/html/index.html</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在RS2中执行</span></span><br><span class="line">echo &#x27;RS02&#x27; | sudo tee /usr/share/nginx/html/index.html</span><br></pre></td></tr></table></figure>



<h4 id="3-2-Director-Server设置"><a href="#3-2-Director-Server设置" class="headerlink" title="3.2 Director Server设置"></a>3.2 Director Server设置</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装ipvsadm命令</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo yum install -y ipvsadm</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-g 表示使用DR模式</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo ipvsadm -A -t 172.24.0.159:80 -s -rr</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo ipvsadm -a -t 172.24.0.159:80 -r 172.24.0.246:80 -g</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo ipvsadm -a -t 172.24.0.159:80 -r 172.24.0.251:80 -g</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ipvsadm -Ln</span></span><br><span class="line">IP Virtual Server version 1.2.1 (size=4096)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">RemoteAddress:Port           Forward Weight ActiveConn InActConn</span></span><br><span class="line">TCP  172.24.0.159:80 rr</span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">172.24.0.246:80              Route   1      0          0</span>         </span><br><span class="line"><span class="meta prompt_">  -&gt; </span><span class="language-bash">172.24.0.251:80              Route   1      0          0</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">不能在DS上访问VIP，需要在内网其他机器访问</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 172.24.0.159:80</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 172.24.0.159:80</span></span><br><span class="line">RS01</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 172.24.0.159:80</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 172.24.0.159:80</span></span><br><span class="line">RS01</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 172.24.0.159:80</span></span><br><span class="line">RS02</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 172.24.0.159:80</span></span><br><span class="line">RS01</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl 172.24.0.159:80</span></span><br><span class="line">RS02</span><br></pre></td></tr></table></figure>



<h3 id="4-后记"><a href="#4-后记" class="headerlink" title="4. 后记"></a>4. 后记</h3><p>ipvs 只能通过 ipvsadm 进行管理，如果想要通过读取配置文件进行管理，可以结合 Keepalived 使用。</p>
<p>因为 LVS 的结构体系中，只有一个 DS 节点，所以如果想要做高可用，需要把 VIP 在多个 DS 节点中漂移，这也是 Keepalived 的功能。</p>
<p>以后会再写一篇文章介绍 Keepalived。</p>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title>基础知识回顾</title>
    <url>/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/</url>
    <content><![CDATA[<h2 id="JAVA基础知识"><a href="#JAVA基础知识" class="headerlink" title="JAVA基础知识"></a>JAVA基础知识</h2><h3 id="集合（未施工）"><a href="#集合（未施工）" class="headerlink" title="集合（未施工）"></a>集合（未施工）</h3><p>HashMap</p>
<p>ConcurrentHashMap</p>
<h3 id="JVM（未施工）"><a href="#JVM（未施工）" class="headerlink" title="JVM（未施工）"></a>JVM（未施工）</h3><h3 id="多线程（思维导图）"><a href="#多线程（思维导图）" class="headerlink" title="多线程（思维导图）"></a>多线程（思维导图）</h3><p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png" alt="image-20221020194941633"></p>
<p>线程状态</p>
<p>锁（栅栏、锁升级）</p>
<p>AQS（还是要看一下其思想是什么）</p>
<p>线程池</p>
<h3 id="Java网络IO"><a href="#Java网络IO" class="headerlink" title="Java网络IO"></a>Java网络IO</h3><h4 id="I-x2F-O"><a href="#I-x2F-O" class="headerlink" title="I&#x2F;O"></a>I&#x2F;O</h4><blockquote>
<p>Input&#x2F;Output的缩写，简单的理解为<strong>数据的输入输出</strong>，通常有网络IO、磁盘IO。而IO的类型又分为同步&#x2F;异步IO、阻塞&#x2F;非阻塞I&#x2F;O，组合成具体的IO模型。IO属于操作系统层面上的知识，Java只是在操作系统提供的系统调用上封装了操作接口。</p>
</blockquote>
<blockquote>
<p>所有的系统IO都分为两个阶段：等待就绪和操作。以网络IO举例来说，读函数，分为等待网卡可以读和真正的读；同理，写函数，分为等待网卡可以写和真正的写。</p>
<p>需要说明的是等待网卡就绪的阻塞是不使用CPU的，是在<strong>空等</strong>；而真正的读写操作的阻塞是在使用CPU的，真正的在<strong>干活</strong>，而且这个过程非常快，属于内存拷贝，带宽通常在1GB&#x2F;s级别以上，可以理解为基本不耗时。</p>
</blockquote>
<blockquote>
<p>操作系统层面上的IO模型包括</p>
<ul>
<li>同步阻塞IO</li>
<li>同步非阻塞IO</li>
<li>异步非阻塞IO</li>
<li>IO多路复用</li>
<li>信号驱动IO</li>
</ul>
</blockquote>
<p>我们通常在Java中说BIO、NIO、AIO都是在网络IO层面上的，因此处理<strong>大量网络连接、连接输入和输出数据的准备（因为数据的输入和输出需要经过网络，所以时延一定不会短）</strong>就是关键要处理的问题。</p>
<p>在Java中，JVM读写数据都需要经过操作系统内核</p>
<ul>
<li>发送数据：JVM首先要把数据发送给内核，然后内核把数据交给网卡，网卡将数据通过互联网发送至客户端。</li>
<li>接收数据：需要让内核到网卡中查看数据是否已经准备好，如果准备好，则将数据放入内核，内核将数据转交给JVM，JVM再把数据交给我们具体的应用程序；如果没有准备好，通常会被阻塞，也有通过回调方式检测就绪事件（epoll相关）。</li>
</ul>
<img src="JVM IO读写数据.png" alt="image-20221012105409202" style="zoom: 40%;" />

<img src="IO模型对比.png" alt="image-20221012144951976" style="zoom: 50%;" />



<h4 id="阻塞和非阻塞"><a href="#阻塞和非阻塞" class="headerlink" title="阻塞和非阻塞"></a>阻塞和非阻塞</h4><blockquote>
<p>阻塞和非阻塞的着重点在发起请求后，是否需要等待</p>
</blockquote>
<ul>
<li>阻塞：阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。</li>
<li>非阻塞：非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。</li>
</ul>
<h4 id="同步和异步"><a href="#同步和异步" class="headerlink" title="同步和异步"></a>同步和异步</h4><blockquote>
<p>同步和异步的着重点在两个任务之间是否需要等待</p>
</blockquote>
<ul>
<li>同步：两个同步任务相互依赖，并且一个任务必须依赖于另一任务的某种方式执行。比如在<code>A-&gt;B</code>事件模型中，需要先完成A才能执行B。换句话说，同步调用中，被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。举个例子，我要去买蛋糕和买菜，但是蛋糕还没做好，我需要等待蛋糕做好之后才能去买菜。</li>
<li>异步：两个异步的任务完全独立，一方的执行不需要等待另一方的执行。换句话说，异步调用中，调用后就返回，不需要等待结果返回，当结果返回的时候，通过回调函数或者其他方式拿着结果进行处理。举例来说，我要去买蛋糕和买菜，但是蛋糕还没做好，店主说留下地址蛋糕做好之后会送上门，那我立马就能去买菜了。</li>
</ul>
<h4 id="Linux中的select、poll、-epoll"><a href="#Linux中的select、poll、-epoll" class="headerlink" title="Linux中的select、poll、 epoll"></a>Linux中的select、poll、 epoll</h4><blockquote>
<p>select、poll、 epoll都是Linux内核提供给用户态的多路复用系统调用。进程可以通过一个系统调用函数从内核中获取多个事件。</p>
</blockquote>
<h5 id="select-x2F-poll"><a href="#select-x2F-poll" class="headerlink" title="select&#x2F;poll"></a>select&#x2F;poll</h5><p>select实现多路复用的方式是，将已连接的Socket都放到一个<strong>文件描述符集合</strong>，然后调用select函数将文件描述符集合<strong>拷贝</strong>到内核中，让内核来检查是否有网络事件产生，检测的方式很粗暴，就是通过<strong>遍历</strong>文件描述符集合的方式，当检查到有事件产生后，将此Socket标记伟可读或可写，接着再把整个文件描述符集合<strong>拷贝</strong>回用户态中，随后用户态还需要通过<strong>遍历</strong>的方法找到可读、可写或可建立连接的Socket，然后再对其处理。</p>
<p>所以，对于select这种方式，需要进行<strong>2次遍历文件描述符集合的操作</strong>，一次是在内核态中，一个是在用户态中，而且还会发生<strong>2次拷贝文件描述符集合的操作</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</p>
<p>select使用固定长度的BitsMap，表示文件描述符集合，而且BitsMap所支持的文件描述符的个数是有限的，在Linux系统中，由内核的FD_SETSIZE限制，默认最大值为<strong>1024</strong>。</p>
<p>poll不再用BitsMap来储存所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了select使用BitsMap存储文件描述符个数限制，当然还是会受到系统文件描述符的数量限制。</p>
<p>但是poll和select并没有太大的本质区别，都是使用线性结构储存进程关注的Socket集合，因此都需要遍历文件描述符集合来找到可读或可写的Socket，**时间复杂度为O(n)**，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。</p>
<h5 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h5><p>epoll在两个方面解决select&#x2F;poll的问题</p>
<p><strong>第一点</strong>，epoll在内核里使用<strong>红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的socket通过**epoll_ctl()**函数加入到内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是O(logn)，通过维护内核中的这颗红黑树，就不需要像select&#x2F;poll每次操作时都传入整个socket集合，只需要传入一个待检测的socket，减少了内核和用户态间大量的数据拷贝和内存分配。</p>
<p><strong>第二点</strong>，epoll使用<strong>事件驱动的机制</strong>，内核里<strong>维护了一个链表来记录就绪事件</strong>，当某个socket有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用**epoll_wait()**函数时，只会返回有事件发生的文件描述符，不需要像select&#x2F;poll一样遍历整个socket集合，大大提高了检测的效率。</p>
<img src="epoll.png" alt="epoll" style="zoom:70%;" />

<p>epoll的方式即使监听的Socket数量越多的时候，效率不会大幅度降低，能够同时监听Socket的数目也非常的多，上限就是系统定义的进程能够打开的最大文件描述符个数。因此epoll被称为解决C10K问题的利器。</p>
<p>epoll 支持两种事件触发模式，分别是<strong>边缘触发（edge-triggered，ET）</strong>和<strong>水平触发（level-triggered，LT）</strong>：</p>
<ul>
<li><strong>边缘触发（edge-triggered，ET）</strong>：当被监控的Socket描述符上有可读事件发生时，<strong>服务器端只会从epoll_wait中苏醒一次</strong>，即使进程没有调用read函数从内核读取数据，也依然只苏醒一次，因为我们程序要保证一次性将内核缓冲区的数据读完。</li>
<li><strong>水平触发（level-triggered，LT）</strong>：当被监控的Socket上有可读事件发生时，<strong>服务器端不断地从epoll_wait中苏醒，直到内核缓冲区数据被read函数读完才结束</strong>，目的时告诉我们有数据要读取（其实从这里就可以看出需要将数据从内核中拷贝到用户态）。</li>
</ul>
<p>如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据（需要等待接收到所有的数据），以免错失读写的机会。因此，我们会<strong>循环</strong>从文件描述符读写数据，那么如果文件描述符读写是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，<strong>边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用</strong>，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</p>
<p>一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。</p>
<p>select&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。</p>
<h4 id="同步阻塞（JAVA-BIO）"><a href="#同步阻塞（JAVA-BIO）" class="headerlink" title="同步阻塞（JAVA BIO）"></a>同步阻塞（JAVA BIO）</h4><blockquote>
<p>服务端实现模式为一个连接一个线程，所以当有大量连接的时候，线程数可能会超出JVM限制导致应用崩溃，当然可以使用线程池改善，限制线程池的最大线程数以限制最大连接数</p>
</blockquote>
<blockquote>
<p>在服务端视角，如果有N个客户端通讯，想要知道他们有没有发送数据过来，就需要告诉内核到网卡中查看，如果都没有数据过来，这N个线程就都被阻塞了</p>
</blockquote>
<h5 id="服务端Demo"><a href="#服务端Demo" class="headerlink" title="服务端Demo"></a>服务端Demo</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.net.ServerSocket;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BIOServer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="comment">// 可以通过替换为BIOServer::BIODemo、BIOServer::BIOThreadDemo、BIOServer::BIOThreadPoolDemo</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(BIOServer::BIODemo).start();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIODemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="comment">// serverSocket.accept()代表着去内核中取数据，如果没数据就会被阻塞</span></span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="comment">// 从socket中获取数据流</span></span><br><span class="line">                <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> socket.getInputStream();</span><br><span class="line">                <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                <span class="comment">// 读操作是同步阻塞的</span></span><br><span class="line">                inputStream.read(data);</span><br><span class="line">                <span class="comment">// 打印获取到的数据</span></span><br><span class="line">                System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                <span class="comment">// 将获取到的数据发送回客户端</span></span><br><span class="line">                <span class="type">OutputStream</span> <span class="variable">out</span> <span class="operator">=</span> socket.getOutputStream();</span><br><span class="line">                <span class="comment">// 写操作是同步阻塞的</span></span><br><span class="line">                out.write(data);</span><br><span class="line">                socket.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIOThreadDemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="keyword">final</span> <span class="type">Socket</span> <span class="variable">clientSocket</span> <span class="operator">=</span> socket;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span>&#123;</span><br><span class="line">                            <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> clientSocket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            inputStream.read(data);</span><br><span class="line"></span><br><span class="line">                            System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                            </span><br><span class="line">                            <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> clientSocket.getOutputStream();</span><br><span class="line">                            outputStream.write(data);</span><br><span class="line">                            outputStream.close();</span><br><span class="line">                        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;).start();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIOThreadPoolDemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ExecutorService</span> <span class="variable">executorService</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="keyword">final</span> <span class="type">Socket</span> <span class="variable">clientSocket</span> <span class="operator">=</span> socket;</span><br><span class="line">                executorService.submit(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span>&#123;</span><br><span class="line">                            <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> clientSocket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            inputStream.read(data);</span><br><span class="line"></span><br><span class="line">                            System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                            </span><br><span class="line">                            <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> clientSocket.getOutputStream();</span><br><span class="line">                            outputStream.write(data);</span><br><span class="line">                            outputStream.close();</span><br><span class="line">                        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="客户端Demo"><a href="#客户端Demo" class="headerlink" title="客户端Demo"></a>客户端Demo</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BIOClient</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Socket</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">8888</span>);</span><br><span class="line">        <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> socket.getInputStream();</span><br><span class="line">        <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> socket.getOutputStream();</span><br><span class="line">        <span class="type">DataInputStream</span> <span class="variable">dataInputStream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataInputStream</span>(inputStream);</span><br><span class="line">        <span class="type">DataOutputStream</span> <span class="variable">dataOutputStream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataOutputStream</span>(outputStream);</span><br><span class="line">        dataOutputStream.writeUTF(<span class="string">&quot;Hello world!&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">response</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">if</span>((response = dataInputStream.readUTF()) != <span class="literal">null</span>)&#123;</span><br><span class="line">            System.out.println(response);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        dataInputStream.close();</span><br><span class="line">        dataOutputStream.close();</span><br><span class="line">        socket.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="同步非阻塞（JAVA-NIO）"><a href="#同步非阻塞（JAVA-NIO）" class="headerlink" title="同步非阻塞（JAVA NIO）"></a>同步非阻塞（JAVA NIO）</h4><blockquote>
<p>JAVA NIO由IO多路复用实现，其中Socket主要的接收连接、读和写函数，在等待就绪阶段都是非阻塞的，真正的I&#x2F;O操作是同步阻塞的（消耗CPU但性能非常高）。</p>
</blockquote>
<p>JAVA NIO中有三个重要的概念，分别是缓冲区Buffer、通道Channel、选择器Selector：</p>
<ul>
<li><strong>缓冲区Buffer</strong>：包含一些要写入或者要读出的数据，在NIO库中，所有数据都是用缓冲区处理的。ByteBuffer、IntBuffer、CharBuffer、LongBuffer等都是其实现类。</li>
<li><strong>通道Channel</strong>：Channel是全双工的，可以通过它读取和写入数据。通道和流的不通之处就是通道是双向的，流是单向的（一个流必须是 InputStream 或者 OutputStream 的子类）。</li>
<li><strong>多路复用器Selector</strong>：多路复用器提供选择已经就绪的任务的能力，Selector 能够获取就绪的 Channel（<strong>Linux中select和poll是轮询来获取就绪的事件，但epoll实现是采用回调方式检测就绪事件，而不是轮询</strong>），如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 感知，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I&#x2F;O 操作。</li>
</ul>
<h5 id="服务端Demo-1"><a href="#服务端Demo-1" class="headerlink" title="服务端Demo"></a>服务端Demo</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SelectionKey;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.Selector;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.ServerSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NIOServer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//1、打开ServerSocketChannel,监听客户端的链接</span></span><br><span class="line">        <span class="type">ServerSocketChannel</span> <span class="variable">serverSocketChannel</span> <span class="operator">=</span> ServerSocketChannel.open();</span><br><span class="line">        <span class="comment">//2、绑定监听端口,设置backlog（默认50）:请求传入连接队列的最大长度</span></span><br><span class="line">        serverSocketChannel.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">        <span class="comment">//3、false,设置为非阻塞模式</span></span><br><span class="line">        serverSocketChannel.configureBlocking(<span class="literal">false</span>);</span><br><span class="line">        <span class="comment">//4、创建Selector, Selector是NIO的多路复用器, Selector能够获取注册在它上面就绪的通道Channel(Channel通道发生接收连接、读、写事件)</span></span><br><span class="line">        <span class="type">Selector</span> <span class="variable">selector</span> <span class="operator">=</span> Selector.open();</span><br><span class="line">        <span class="comment">//5、注册通道Channel到多路复用器Selector，并说明关注点SelectionKey.OP_ACCEPT，监听ACCEPT事件</span></span><br><span class="line">        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//6、不断轮询Selector中就绪的Channel</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)&#123;</span><br><span class="line">            <span class="comment">//7、阻塞等待，直到有就绪的Channel，能够设置超时时间</span></span><br><span class="line">            selector.select();</span><br><span class="line">            Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();</span><br><span class="line">            Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();</span><br><span class="line">            <span class="comment">//8、遍历就绪的channel</span></span><br><span class="line">            <span class="keyword">while</span> (iterator.hasNext())&#123;</span><br><span class="line">                <span class="type">SelectionKey</span> <span class="variable">key</span> <span class="operator">=</span> iterator.next();</span><br><span class="line">                <span class="comment">//9、判断Channel还是否有效</span></span><br><span class="line">                <span class="keyword">if</span> (!key.isValid())&#123;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span>(key.isAcceptable())&#123;</span><br><span class="line">                    <span class="comment">//10、Channel接收连接就绪</span></span><br><span class="line">                    <span class="comment">// 通过SelectionKey获取就绪的Channel</span></span><br><span class="line">                    <span class="type">ServerSocketChannel</span> <span class="variable">serverChannel</span> <span class="operator">=</span> (ServerSocketChannel) key.channel();</span><br><span class="line">                    <span class="comment">//11、Selector监听到有新的客户端连接，通过Channel完成TCP三次握手建立连接</span></span><br><span class="line">                    <span class="type">SocketChannel</span> <span class="variable">clientChannel</span> <span class="operator">=</span> serverChannel.accept();</span><br><span class="line">                    <span class="comment">//12、设置客户端SocketChannel为非阻塞模式</span></span><br><span class="line">                    <span class="comment">// 注意ServerSocketChannel用于服务器端接收新连接，SocketChannel用于服务器和客户端之间的连接</span></span><br><span class="line">                    clientChannel.configureBlocking(<span class="literal">false</span>);</span><br><span class="line">                    <span class="comment">//13、将客户端的SocketChannel注册到Selector中，并且监听读就绪事件</span></span><br><span class="line">                    clientChannel.register(selector, SelectionKey.OP_READ);</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isReadable())&#123;</span><br><span class="line">                    <span class="comment">//10、Channel读就绪</span></span><br><span class="line">                    <span class="comment">//11、创建缓冲区Buffer</span></span><br><span class="line">                    <span class="type">ByteBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> ByteBuffer.wrap(<span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>]);</span><br><span class="line">                    <span class="type">SocketChannel</span> <span class="variable">clientChannel</span> <span class="operator">=</span> (SocketChannel) key.channel();</span><br><span class="line">                    <span class="comment">//12、从Channel中读取数据到Buffer中</span></span><br><span class="line">                    <span class="type">int</span> <span class="variable">read</span> <span class="operator">=</span> clientChannel.read(buffer);</span><br><span class="line">                    <span class="keyword">if</span>(read == -<span class="number">1</span>)&#123;</span><br><span class="line">                        <span class="comment">// Buffer中无数据可读，关闭Channel，并且使SelectionKey失效</span></span><br><span class="line">                        key.cancel();</span><br><span class="line">                        clientChannel.close();</span><br><span class="line">                    &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 设置缓冲区的位置记录为数据的实际长度</span></span><br><span class="line">                        buffer.flip();</span><br><span class="line">                        System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(buffer.array(), StandardCharsets.UTF_8));</span><br><span class="line">                        <span class="comment">//13、通过Channel写出数据</span></span><br><span class="line">                        clientChannel.write(buffer);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                iterator.remove();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="客户端Demo-1"><a href="#客户端Demo-1" class="headerlink" title="客户端Demo"></a>客户端Demo</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NIOClient</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String[] messages = &#123;</span><br><span class="line">            <span class="string">&quot;message1 from client&quot;</span>,</span><br><span class="line">            <span class="string">&quot;message2 from client&quot;</span></span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>(<span class="type">SocketChannel</span> <span class="variable">socketChannel</span> <span class="operator">=</span> SocketChannel.open(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="number">8888</span>)))&#123;</span><br><span class="line">            <span class="keyword">for</span>(String message: messages)&#123;</span><br><span class="line">                <span class="type">ByteBuffer</span> <span class="variable">writeBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                writeBuffer.put(message.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">                writeBuffer.flip();</span><br><span class="line">                <span class="comment">// 这里写是阻塞的</span></span><br><span class="line">                socketChannel.write(writeBuffer);</span><br><span class="line"></span><br><span class="line">                <span class="type">ByteBuffer</span> <span class="variable">readBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                <span class="comment">// 这里读是阻塞的</span></span><br><span class="line">                socketChannel.read(readBuffer);</span><br><span class="line">                readBuffer.flip();</span><br><span class="line">                System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(readBuffer.array(), StandardCharsets.UTF_8));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h5 id="优化线程模型"><a href="#优化线程模型" class="headerlink" title="优化线程模型"></a>优化线程模型</h5><p>回忆BIO模型，之所以需要多线程，是因为在进行IO操作的时候，没办法知道硬件读写是否就绪，只能阻塞等待，造成大量的<strong>空等</strong>从而阻塞需要进行线程切换（<strong>浪费大量CPU资源在线程上下文切换</strong>）。而NIO通过将通道Channel注册到多路复用器Selector上，达到<strong>只有事件就绪才会执行真正的操作，减少空等的时间，提高CPU的利用率</strong>（CPU一直都在跑，没有等待），只有调用selector.select()时，没有就绪事件才会被阻塞，而这时没有事件就绪说明不需要处理，阻塞等待也是正常的。</p>
<p><strong>NIO将原来BIO的阻塞读写变成了单线程轮询事件（单Reactor单线程模型）</strong>，除了事件的轮询是阻塞的，剩余的IO操作都是纯CPU操作，没有必要开启多线程。并且由于节约线程，当连接数大的时候由线程切换带来的问题也随之解决，为海量连接提供可能。单线程处理I&#x2F;O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。<strong>但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I&#x2F;O，无疑对效率会有更大的提高。</strong></p>
<p>分析我们程序的主要功能，包括：</p>
<ul>
<li>网络IO处理，包括accept、read、write等</li>
<li>业务逻辑，通过网络获取到需要的数据之后需要对数据进行处理后返回，这里还会有其他的阻塞IO，如DB操作、RPC等</li>
</ul>
<p>根据功能的线程划分，能够将Reactor线程设计模式分为：</p>
<ul>
<li>单Reactor单线程模型</li>
<li>单Reactor多线程模型</li>
<li>主从Reactor多线程模型</li>
</ul>
<h5 id="Reactor设计模式"><a href="#Reactor设计模式" class="headerlink" title="Reactor设计模式"></a>Reactor设计模式</h5><blockquote>
<p>Reactor模型是可以处理一个或多个输入源，并通过Service Handler同步的将输入事件（Event）采用多路复用分发给相应的Request Handler（多个）处理的事件驱动模式</p>
</blockquote>
<blockquote>
<p>Reactor模型用于NIO，是一种思想，多线程的思想。其中定义了三个角色：</p>
<ul>
<li><strong>Reactor</strong>：负责监听和分配事件</li>
<li><strong>Acceptor</strong>：处理客户端到来的新连接，并分派请求到Handler链中</li>
<li><strong>Handler</strong>：执行非阻塞读写任务，完成数据读入，处理业务逻辑后，将结果写出</li>
</ul>
</blockquote>
<h6 id="单Reactor单线程模型"><a href="#单Reactor单线程模型" class="headerlink" title="单Reactor单线程模型"></a>单Reactor单线程模型</h6><blockquote>
<p>Reactor、Acceptor、Handler都在一个线程中</p>
<p>优点：模型简单，没有多线程、进程通信、竞争的问题</p>
<p>缺点：无法发挥多核CPU的性能，此外如果业务处理速度比较慢就会影响到程序的高并发性能，任何地方不可用都会导致整个通信模块的不可用</p>
<p>Redis就是这种模型，实际使用的是单线程+队列</p>
</blockquote>
<img src="单Reactor单线程.png" alt="image-20221013095437617" style="zoom:50%;" />

<h6 id="单Reactor多线程模型"><a href="#单Reactor多线程模型" class="headerlink" title="单Reactor多线程模型"></a>单Reactor多线程模型</h6><blockquote>
<p>Reactor主线程中主要负责网络IO相关的处理，包括连接的建立、数据读写，把具体的业务处理逻辑放到线程池中处理</p>
<p>优点：充分利用多核CPU的处理能力，业务阻塞不会影响通信模块</p>
<p>缺点：多线程数据共享和访问的问题，Reactor在单线程中承担所有事件的监听和相应，高并发场景下容易成为性能瓶颈</p>
</blockquote>
<img src="单Reactor多线程.png" alt="image-20221013100405912" style="zoom:53%;" />

<h6 id="主从Reactor多线程模型"><a href="#主从Reactor多线程模型" class="headerlink" title="主从Reactor多线程模型"></a>主从Reactor多线程模型</h6><blockquote>
<p>Reactor主线程中只负责连接的建立，Reactor子线程负责读写数据，在线程池完成业务处理</p>
<p><strong>对连接的处理和读写通常可以选择分开</strong>，这样对于海量连接的注册和读写就可以分发到不同的线程中进行处理，在单线程Reactor模型和单Reactor多线程模型中，虽然read()和write()都是效率比较高的非阻塞函数，但Reactor线程毕竟只占用一个CPU内核，如果面对更高的并发则无能为力。主从Reactor多线程模型就能够解决这个问题。</p>
<p>这种模型在许多项目中广泛使用，包括Nginx主从Reactor多进程模型，Memcached主从多线程，Netty主从多线程模型的支持。</p>
</blockquote>
<img src="主从Reactor多线程.png" alt="image-20221013100926483" style="zoom:52%;" />



<h4 id="异步非阻塞（JAVA-AIO）"><a href="#异步非阻塞（JAVA-AIO）" class="headerlink" title="异步非阻塞（JAVA AIO）"></a>异步非阻塞（JAVA AIO）</h4><blockquote>
<p>BIO和NIO对于内核来说，都是<strong>应用程序不询问我，我绝不会主动通知</strong>的方式</p>
</blockquote>
<blockquote>
<p>还记得IO操作分为两个阶段：等待就绪和实际操作。在NIO中，等待就绪阶段是不会被阻塞的，但是还是需要实际操作数据，将数据从内核态中拷贝到用户态。AIO解决的就是这个问题，当应用程序发起异步IO之后，内核会完成数据的就绪和将数据从内核态拷贝到用户态中，应用程序并不需要主动发起拷贝动作。</p>
</blockquote>
<blockquote>
<p>AIO采用<strong>订阅-通知</strong>的方式：应用程序向操作系统注册IO监听，然后继续做自己的事情。当操作系统发生IO事件，并且准备好数据后，再主动通知应用程序，触发相应的回调函数。<strong>如果发起异步读写请求，还需要传入数据缓冲区Buffer的地址（用于存放结果数据）等信息，这样内核才能自动帮我们把数据的读写工作完成。</strong></p>
</blockquote>
<blockquote>
<p>AIO也是需要操作系统支持，<strong>微软的windows系统提供了一种异步IO技术IOCP(I&#x2F;O Completion Port，I&#x2F;O完成端口)；Linux下由于没有这种异步IO技术，所以使用的是epoll对异步IO进行模拟</strong></p>
</blockquote>
<blockquote>
<p>NIO中有一个重要的概念多路复用器Selector，负责替应用查询中所有已注册的通道到操作系统中进行IO事件轮询、管理当前注册的通道集合，定位发生事件的通道等操操作；但是在Java AIO框架中，由于应用程序不是<strong>轮询</strong>方式，而是<strong>订阅-通知</strong>方式，所以不再需要Selector(选择器)了，改由channel通道直接到操作系统注册监听，让操作系统回调实际操作函数。</p>
</blockquote>
<img src="JAVA_AIO.png" alt="image-20221013142450630" style="zoom:50%;" />

<h5 id="服务器Demo"><a href="#服务器Demo" class="headerlink" title="服务器Demo"></a>服务器Demo</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.17.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.17.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousChannelGroup;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousServerSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.CompletionHandler;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.Log;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.LogFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.BasicConfigurator;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AIOServer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        BasicConfigurator.configure();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Object</span> <span class="variable">waitObject</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 对于使用的线程池技术，我一定要多说几句</span></span><br><span class="line"><span class="comment">         * 1、Executors是线程池生成工具，通过这个工具我们可以很轻松的生成“固定大小的线程池”、“调度池”、“可伸缩线程数量的池”。具体请看API Doc</span></span><br><span class="line"><span class="comment">         * 2、当然您也可以通过ThreadPoolExecutor直接生成池。</span></span><br><span class="line"><span class="comment">         * 3、这个线程池是用来得到操作系统的“IO事件通知”的，不是用来进行“得到IO数据后的业务处理的”。要进行后者的操作，您可以再使用一个池(最好不要混用)</span></span><br><span class="line"><span class="comment">         * 4、您也可以不使用线程池(不推荐)，如果决定不使用线程池，直接AsynchronousServerSocketChannel.open()就行了。</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">ExecutorService</span> <span class="variable">threadPool</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">20</span>);</span><br><span class="line">        <span class="type">AsynchronousChannelGroup</span> <span class="variable">group</span> <span class="operator">=</span> AsynchronousChannelGroup.withThreadPool(threadPool);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">AsynchronousServerSocketChannel</span> <span class="variable">serverSocket</span> <span class="operator">=</span> AsynchronousServerSocketChannel.open(group);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置要监听的端口“0.0.0.0”代表本机所有IP设备</span></span><br><span class="line">        serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">83</span>));</span><br><span class="line">        <span class="comment">//为AsynchronousServerSocketChannel注册监听，注意只是为AsynchronousServerSocketChannel通道注册监听</span></span><br><span class="line">        <span class="comment">//并不包括为 随后客户端和服务器 socketchannel通道注册的监听</span></span><br><span class="line">        serverSocket.accept(<span class="literal">null</span>, <span class="keyword">new</span> <span class="title class_">ServerSocketChannelHandle</span>(serverSocket));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//等待，以便观察现象(这个和要讲解的原理本身没有任何关系，只是为了保证守护线程不会退出)</span></span><br><span class="line">        <span class="keyword">synchronized</span>(waitObject) &#123;</span><br><span class="line">            waitObject.wait();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 这个处理器类，专门用来响应 ServerSocketChannel 的事件。</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ServerSocketChannelHandle</span> <span class="keyword">implements</span> <span class="title class_">CompletionHandler</span>&lt;AsynchronousSocketChannel, Void&gt; &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 日志</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Log</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LogFactory.getLog(ServerSocketChannelHandle.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> AsynchronousServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> serverSocketChannel</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ServerSocketChannelHandle</span><span class="params">(AsynchronousServerSocketChannel serverSocketChannel)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.serverSocketChannel = serverSocketChannel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注意，我们分别观察 this、socketChannel、attachment三个对象的id。</span></span><br><span class="line"><span class="comment">     * 来观察不同客户端连接到达时，这三个对象的变化，以说明ServerSocketChannelHandle的监听模式</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">completed</span><span class="params">(AsynchronousSocketChannel socketChannel, Void attachment)</span> &#123;</span><br><span class="line">        ServerSocketChannelHandle.LOGGER.info(<span class="string">&quot;completed(AsynchronousSocketChannel result, ByteBuffer attachment)&quot;</span>);</span><br><span class="line">        <span class="comment">//每次都要重新注册监听(一次注册，一次响应)，但是由于“文件状态标示符”是独享的，所以不需要担心有“漏掉的”事件</span></span><br><span class="line">        <span class="built_in">this</span>.serverSocketChannel.accept(attachment, <span class="built_in">this</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//为这个新的socketChannel注册“read”事件，以便操作系统在收到数据并准备好后，主动通知应用程序</span></span><br><span class="line">        <span class="comment">//在这里，由于我们要将这个客户端多次传输的数据累加起来一起处理，所以我们将一个stringbuffer对象作为一个“附件”依附在这个channel上</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="type">ByteBuffer</span> <span class="variable">readBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">50</span>);</span><br><span class="line">        socketChannel.read(readBuffer, <span class="keyword">new</span> <span class="title class_">StringBuffer</span>(), <span class="keyword">new</span> <span class="title class_">SocketChannelReadHandle</span>(socketChannel , readBuffer));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#failed(java.lang.Throwable, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">failed</span><span class="params">(Throwable exc, Void attachment)</span> &#123;</span><br><span class="line">        ServerSocketChannelHandle.LOGGER.info(<span class="string">&quot;failed(Throwable exc, ByteBuffer attachment)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 负责对每一个socketChannel的数据获取事件进行监听。&lt;p&gt;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 重要的说明: 一个socketchannel都会有一个独立工作的SocketChannelReadHandle对象(CompletionHandler接口的实现)，</span></span><br><span class="line"><span class="comment"> * 其中又都将独享一个“文件状态标示”对象FileDescriptor、</span></span><br><span class="line"><span class="comment"> * 一个独立的由程序员定义的Buffer缓存(这里我们使用的是ByteBuffer)、</span></span><br><span class="line"><span class="comment"> * 所以不用担心在服务器端会出现“窜对象”这种情况，因为JAVA AIO框架已经帮您组织好了。&lt;p&gt;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 但是最重要的，用于生成channel的对象: AsynchronousChannelProvider是单例模式，无论在哪组socketchannel，</span></span><br><span class="line"><span class="comment"> * 对是一个对象引用(但这没关系，因为您不会直接操作这个AsynchronousChannelProvider对象)。</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SocketChannelReadHandle</span> <span class="keyword">implements</span> <span class="title class_">CompletionHandler</span>&lt;Integer, StringBuffer&gt; &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 日志</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Log</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LogFactory.getLog(SocketChannelReadHandle.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> AsynchronousSocketChannel socketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 专门用于进行这个通道数据缓存操作的ByteBuffer&lt;br&gt;</span></span><br><span class="line"><span class="comment">     * 当然，您也可以作为CompletionHandler的attachment形式传入。&lt;br&gt;</span></span><br><span class="line"><span class="comment">     * 这是，在这段示例代码中，attachment被我们用来记录所有传送过来的Stringbuffer了。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> ByteBuffer byteBuffer;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SocketChannelReadHandle</span><span class="params">(AsynchronousSocketChannel socketChannel , ByteBuffer byteBuffer)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.socketChannel = socketChannel;</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer = byteBuffer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#completed(java.lang.Object, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">completed</span><span class="params">(Integer result, StringBuffer historyContext)</span> &#123;</span><br><span class="line">        <span class="comment">//如果条件成立，说明客户端主动终止了TCP套接字，这时服务端终止就可以了</span></span><br><span class="line">        <span class="keyword">if</span>(result == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="built_in">this</span>.socketChannel.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;completed(Integer result, Void attachment) : 然后我们来取出通道中准备好的值&quot;</span>);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 实际上，由于我们从Integer result知道了本次channel从操作系统获取数据总长度</span></span><br><span class="line"><span class="comment">         * 所以实际上，我们不需要切换成“读模式”的，但是为了保证编码的规范性，还是建议进行切换。</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 另外，无论是JAVA AIO框架还是JAVA NIO框架，都会出现“buffer的总容量”小于“当前从操作系统获取到的总数据量”，</span></span><br><span class="line"><span class="comment">         * 但区别是，JAVA AIO框架中，我们不需要专门考虑处理这样的情况，因为JAVA AIO框架已经帮我们做了处理(做成了多次通知)</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.flip();</span><br><span class="line">        <span class="type">byte</span>[] contexts = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.get(contexts, <span class="number">0</span>, result);</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.clear();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">nowContent</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(contexts , <span class="number">0</span> , result , <span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line">            historyContext.append(nowContent);</span><br><span class="line">            SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;================目前的传输结果: &quot;</span> + historyContext);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">            SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果条件成立，说明还没有接收到“结束标记”</span></span><br><span class="line">        <span class="keyword">if</span>(historyContext.indexOf(<span class="string">&quot;over&quot;</span>) == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//=========================================================================</span></span><br><span class="line">        <span class="comment">//          和上篇文章的代码相同，我们以“over”符号作为客户端完整信息的标记</span></span><br><span class="line">        <span class="comment">//=========================================================================</span></span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;=======收到完整信息，开始处理业务=========&quot;</span>);</span><br><span class="line">        historyContext = <span class="keyword">new</span> <span class="title class_">StringBuffer</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//还要继续监听(一次监听一次通知)</span></span><br><span class="line">        <span class="built_in">this</span>.socketChannel.read(<span class="built_in">this</span>.byteBuffer, historyContext, <span class="built_in">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#failed(java.lang.Throwable, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">failed</span><span class="params">(Throwable exc, StringBuffer historyContext)</span> &#123;</span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;=====发现客户端异常关闭，服务器将关闭TCP通道&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.socketChannel.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h5 id="Proactor设计模式"><a href="#Proactor设计模式" class="headerlink" title="Proactor设计模式"></a>Proactor设计模式</h5><blockquote>
<p>Reactor是用于非阻塞同步的设计模型，Proactor是用于异步IO的设计模型</p>
</blockquote>
<blockquote>
<p>Proactor整体上与Reactor一致，区别在于Proactor模式将所有IO操作都交给内核处理，工作线程仅仅负责业务逻辑。<strong>Proactor关注的不是就绪事件，而是完成事件，这是区分Reactor模式的关键点</strong>。</p>
<p>Proactor模型主要包括四个角色：</p>
<ul>
<li><strong>Procator Initiator</strong>：负责创建Handler和Procator，并将Procator和Handler（作为回调）都通过Asynchronous operation processor注册到内核</li>
<li><strong>Handler</strong>：执行业务流程的业务处理器</li>
<li><strong>Asynchronous operation processor</strong>：负责处理注册请求，并完成IO操作。完成IO操作后会通知Procator</li>
<li><strong>Procator</strong>：根据不同的事件类型回调不同的handler进行业务处理</li>
</ul>
</blockquote>
<img src="Proactor模型.png" alt="image-20221013172016259" style="zoom:60%;" />



<p>参考资料：</p>
<p><a href="https://tech.meituan.com/2016/11/04/nio.html">https://tech.meituan.com/2016/11/04/nio.html</a></p>
<p><a href="https://developer.aliyun.com/article/726698#slide-11">https://developer.aliyun.com/article/726698#slide-11</a></p>
<p><a href="https://blog.csdn.net/zdreamLife/article/details/124222337">https://blog.csdn.net/zdreamLife/article/details/124222337</a></p>
<p><a href="https://blog.csdn.net/u013256816/article/details/115388239">https://blog.csdn.net/u013256816/article/details/115388239</a></p>
<p><a href="https://pdai.tech/md/java/io/java-io-aio.html">https://pdai.tech/md/java/io/java-io-aio.html</a></p>
<p><a href="https://www.zhihu.com/question/26943938">https://www.zhihu.com/question/26943938</a></p>
<p><a href="https://www.cnblogs.com/chenssy/p/15526729.html">https://www.cnblogs.com/chenssy/p/15526729.html</a></p>
<p><a href="https://mp.weixin.qq.com/s/Qpa0qXxuIM8jrBqDaXmVNA">https://mp.weixin.qq.com/s/Qpa0qXxuIM8jrBqDaXmVNA</a></p>
<h2 id="计算机基础（部分施工）"><a href="#计算机基础（部分施工）" class="headerlink" title="计算机基础（部分施工）"></a>计算机基础（部分施工）</h2><h3 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h3><p>五元组确定一个连接：协议（TCP&#x2F;UDP）、源IP、源端口、目标IP、目标端口</p>
<p>发起HTTP请求的流程</p>
<p>ARP（地址解析协议）</p>
<p>DNS</p>
<p>PING，ICMP</p>
<p>TCP&#x2F;IP</p>
<p>TCP -三次握手四次挥手</p>
<p>CLOSED WAIT</p>
<p>TIME WAIT</p>
<p>UDP</p>
<h3 id="操作系统（部分施工）"><a href="#操作系统（部分施工）" class="headerlink" title="操作系统（部分施工）"></a>操作系统（部分施工）</h3><h4 id="上下文切换类型"><a href="#上下文切换类型" class="headerlink" title="上下文切换类型"></a>上下文切换类型</h4><ul>
<li>中断上下文切换：为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。在内核态执行不涉及进程的用户态，只包括内核态中断服务程序执行所必需的状态，包括CPU寄存器、程序计数器、内核堆栈、硬件中断参数等。</li>
<li>CPU上下文切换：CPU寄存器、程序计数器PC，所有函数调用都会触发CPU上下文切换，因为需要记住函数调用前的状态以及函数调用后的返回入口</li>
<li>线程上下文切换：线程私有数据、栈、寄存器等</li>
<li>进程上下文切换：虚拟内存、全局变量等</li>
</ul>
<h4 id="进程切换发生在什么时候？"><a href="#进程切换发生在什么时候？" class="headerlink" title="进程切换发生在什么时候？"></a>进程切换发生在什么时候？</h4><blockquote>
<p>进程切换一定发生在<strong>中断、异常、系统调用</strong>的处理过程中，因为<strong>中断、异常、系统调用</strong>进入内核态之后，系统进程管理模块就会根据进程的状态进行进程调度（进程调度实际上也是一个程序）</p>
</blockquote>
<ul>
<li>时间片中断、IO中断后更改优先级进程（导致被中断进程进入就绪态）</li>
<li>阻塞式系统调用、缺页中断（导致被中断进程进入等待态）</li>
<li>终止用系统调用、不能继续执行的异常（导致被中断进程进入终止态）</li>
</ul>
<blockquote>
<p>举例说明</p>
<ul>
<li>时钟中断：操作系统确定当前正在运行的进程的执行时间是否已经超过了最大允许时间段，如果超过了，进程必须切换到就绪态，调度另一个进程。（时钟频率，每隔一段时间就会发生一次时钟中断，时钟中断处理程序就会被自动调用，在其中判断进程时间片是否用完）</li>
<li>I&#x2F;O中断：操作系统确定是否发生了I&#x2F;O活动。如果I&#x2F;O活动是一个或多个进程正在等待的事件，操作系统把所有相应的阻塞态转换到就绪态，操作系统必须决定是让具有高优先级的就绪态进程抢占当前进程，还是继续执行当前处于运行态的进程。</li>
<li>缺页中断（内存页失效）：处理器访问一个虚拟内存地址，且此内存页不在内存中，操作系统必须从磁盘中调入该内存页至内存中。在发出调入内存页的I&#x2F;O请求之后，操作系统会执行一个进程切换，以高效利用CPU。而发生缺页的进程被置为阻塞态，当内存页调入完毕后，该进程被置为就绪态等待调度。</li>
<li>对于陷阱：操作系统确定错误或异常条件是否致命的。如果是，当前正在运行的进程被转换到退出态，并发生进程切换；如果不是，操作系统的动作取决于错误的种类和操作系统的设计，其行为可以是试图恢复或通知用户，操作系统可能会进行一次进程切换或者继续执行当前正在运行的进程。</li>
<li>操作系统的进程调度可能被来自正在执行的程序的系统调用激活。例如，一个用户进程正在运行，并且正在执行一条请求I&#x2F;O操作的指令，如打开文件，这个调用导致转移到作为操作系统代码一部分的一个例程上进行。通常，使用系统调用会导致操作系统把用户线程置为阻塞态。</li>
</ul>
</blockquote>
<p>进程是怎么样切换的</p>
<p>进程、线程、协程</p>
<p>页式、段式、段页式</p>
<p>虚拟内存（储存）</p>
<p>虚拟硬盘</p>
<p>CPU寻址、逻辑地址、物理地址</p>
<p>磁盘</p>
<h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h3 id="MyISAM和InnoDB的区别"><a href="#MyISAM和InnoDB的区别" class="headerlink" title="MyISAM和InnoDB的区别"></a>MyISAM和InnoDB的区别</h3><ul>
<li><p>MyISAM</p>
<ul>
<li>不支持事务、崩溃恢复</li>
<li>不支持行锁，只支持表锁</li>
<li>不支持外键</li>
<li>主键索引中叶子节点储存的不是数据记录，而是记录的内存地址，因此MyISAM的数据文件分为索引文件和数据文件</li>
</ul>
</li>
<li><p>InnoDB</p>
<ul>
<li>支持事务，崩溃恢复，有redo log</li>
<li>支持表锁、行级锁，通过MVCC和Next-key Lock在可重复读的隔离级别下解决幻读的问题</li>
<li>支持外键</li>
<li>InnoDB的主键索引是聚簇索引，所以数据文件只有一个</li>
</ul>
</li>
</ul>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><blockquote>
<p>以 InnoDB 的一个整数字段索引为例，N叉B+树的N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p>
</blockquote>
<h4 id="索引类型（分类角度）"><a href="#索引类型（分类角度）" class="headerlink" title="索引类型（分类角度）"></a>索引类型（分类角度）</h4><ul>
<li><p><strong>主键索引</strong>：一种<strong>特殊的唯一索引</strong>，一个表只能有一个主键，<strong>不允许有空值</strong>，主键索引的记录在物理存储上的方式跟数据库引擎的实现有关，MyISAM中主键索引B+树的叶子节点储存的是记录的物理地址（所以数据库的数据文件分为索引文件和数据文件），而InnoDB中主键索引B+树的叶子节点储存了记录的所有字段值。</p>
</li>
<li><p><strong>普通索引</strong>：就是普通的索引。</p>
</li>
<li><p><strong>唯一索引</strong>：字段唯一，能够<strong>允许NULL值</strong>，就是只要是NULL就认为是不一样的，在InnoDB中NULL值储存在B+树的最左边。</p>
</li>
<li><p><strong>前缀索引</strong>：指对字符类型字段的前几个字符或对二进制类型字段的前几个bytes建立的索引，而不是在整个字段上建索引。前缀索引可以建立在类型为char、varchar、binary、varbinary的列上，可以大大减少索引占用的存储空间，也能提升索引的查询效率。</p>
</li>
<li><p><strong>全文索引</strong>：与搜索引擎相关，都是需要分词，然后根据关键字中的词频和重要性进行排序。</p>
</li>
<li><p><strong>联合索引</strong>：由多个字段组合形成的索引。</p>
</li>
</ul>
<h4 id="聚簇索引与非聚簇索引（物理储存角度）"><a href="#聚簇索引与非聚簇索引（物理储存角度）" class="headerlink" title="聚簇索引与非聚簇索引（物理储存角度）"></a>聚簇索引与非聚簇索引（物理储存角度）</h4><ul>
<li><p><strong>聚簇索引</strong>：记录的物理储存顺序与列值（一般是主键的一列）的逻辑顺序相同，一个表中只有一个聚簇索引（因为聚簇索引的记录在物理储存上是有序的，所以当按照主键遍历的时候，相邻的主键都在同一块内存页中，能够减少缺页中断，提高查询效率）。</p>
</li>
<li><p><strong>非聚簇索引</strong>（二级索引、辅助索引）：与聚簇索引相反，如果记录的物理储存顺序与列值的逻辑顺序不一样，那么就是非聚簇索引，一个表中可以有多个非聚簇索引。</p>
</li>
</ul>
<h4 id="B-树索引和哈希索引（数据结构角度）"><a href="#B-树索引和哈希索引（数据结构角度）" class="headerlink" title="B+树索引和哈希索引（数据结构角度）"></a>B+树索引和哈希索引（数据结构角度）</h4><ul>
<li><p><strong>B+树索引</strong>：B+树是多叉平衡树，所以能够快速搜索到记录的位置，B+树的特点是非叶子节点不储存数据，叶子节点储存数据，最后所有叶子节点组成一条有序的双向链表，<strong>因为非叶子节点不储存数据，所以单个非叶子节点能够储存大量的索引数据，而由于这些索引数据是经常被访问的，所以能够常驻在内存中，减少缺页中断（或SWAP）带来的性能消耗</strong>。</p>
</li>
<li><p><strong>B树索引</strong>：B树叶子节点也储存数据，而且所有叶子节点不会组成有序链表。</p>
</li>
<li><p><strong>哈希索引</strong>：经过哈希函数能够快速找到记录的位置，不需要进行搜索（哈希冲突解决的办法）</p>
</li>
</ul>
<h4 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h4><blockquote>
<p>InnoDB引擎支持自适应哈希索引，是数据库自动优化，只能选择开启或者关闭。</p>
</blockquote>
<p>因为当使用辅助索引进行查找的时候，如果并不是覆盖索引，就需要<strong>回表</strong>到主键索引中找到记录的所有数据，如果这种查询的次数变多，那么InnoDB就会自动创建自适应哈希索引，<strong>提高在通过辅助索引查找到主键Id的时候，再回表的查询速度</strong>。（即通过辅助索引查找到主键Id，然后通过主键Id的哈希索引直接找到记录的位置）。</p>
<p>根据一些资料的统计，读取和写入速度可以提高2倍，辅助索引的连接操作性能可以提高5倍。</p>
<p><a href="https://juejin.cn/post/6844903888080863245">https://juejin.cn/post/6844903888080863245</a></p>
<h4 id="主键索引就是聚簇索引吗？"><a href="#主键索引就是聚簇索引吗？" class="headerlink" title="主键索引就是聚簇索引吗？"></a>主键索引就是聚簇索引吗？</h4><p><strong>不是</strong>！！！在InnoDB中主键的确是按聚簇索引的方式组织的，但是在MyISAM里面主键<strong>不是</strong>聚簇索引，sql server中还可以显示的指定聚簇索引。</p>
<p>InnoDB中如果没有定义主键，Innodb会选择非空的唯一索引代替。如果没有这样的索引，Innodb会隐式的定义一个主键来作为聚簇索引。</p>
<p><a href="https://www.cnblogs.com/lice-blog/p/11569443.html">https://www.cnblogs.com/lice-blog/p/11569443.html</a></p>
<h4 id="什么是联合索引、覆盖索引、索引最左匹配原则"><a href="#什么是联合索引、覆盖索引、索引最左匹配原则" class="headerlink" title="什么是联合索引、覆盖索引、索引最左匹配原则"></a>什么是联合索引、覆盖索引、索引最左匹配原则</h4><ul>
<li><p><strong>联合索引</strong>：由多个字段组合形成的索引</p>
</li>
<li><p><strong>覆盖索引</strong>：查询的字段会被索引覆盖到，就<strong>不需要回表</strong>根据主键Id查询其他字段，<strong>单个字段的索引</strong>和<strong>联合索引</strong>都能实现覆盖索引的功能。所以说覆盖索引并不是一种真正的索引，是查询的时候用到的索引覆盖到了所有需要查询的字段。</p>
</li>
<li><p><strong>索引最左匹配原则</strong>：对于一个联合索引（a, b, c, d），如果查询的时候指定了查询条件<code>a = 1 AND b = 2 AND c &gt; 4 AND d &lt; 5</code>，因为索引整体上是按<code>a,b,c,d</code>来排序的（即先按a排序，a相等的时候按b排序，以此类推），所以<strong>当a和b指定了确切的值的时候，记录在c上是有序的，但是在d上就不确认了</strong>。当联合索引遇到范围查询（&gt;，&lt;，between，like）最左匹配就不能进一步匹配了。（当然MySQL会优化查询的顺序比如，<code>d &lt; 5 AND b = 2 AND c &gt; 4 AND a = 1</code> 会优化为<code>a = 1 AND b = 2 AND c &gt; 4 AND d &lt; 5</code>）</p>
</li>
</ul>
<h4 id="说一下索引下推"><a href="#说一下索引下推" class="headerlink" title="说一下索引下推"></a>说一下索引下推</h4><blockquote>
<p>索引下推可以在索引遍历过程中（引擎层），对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p>
</blockquote>
<p>对于一个联合索引<strong>（name, age）</strong>和一个SQL语句</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from tuser where name like &#x27;张%&#x27; and age = 10 and ismale = 1;</span><br></pre></td></tr></table></figure>

<ul>
<li>如果没有索引下推，因为最左匹配原则，所以只会用到<code>name</code>的索引，所以在引擎层会找到所有<code>name like &#39;张%&#39;</code>的主键并返回给server层，然后逐个回表判断</li>
<li>如果有索引下推，即使有最左匹配原则，也会将索引能用到的<code>age = 10</code>放到引擎层进行判断，引擎层根据索引判断，只返回<code>name like &#39;张%&#39; and age = 10</code>的主键，这样过滤了不符合的部分数据，就能减少回表的次数</li>
</ul>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><h4 id="事务的四大特性（ACID）"><a href="#事务的四大特性（ACID）" class="headerlink" title="事务的四大特性（ACID）"></a>事务的四大特性（ACID）</h4><ol>
<li>原子性：一个事务是最小执行单位，事务中的动作要么都做，要么都不做</li>
<li>一致性：执行事务之后，数据保持一致，多个事务对同一个数据读取的结果是相同的</li>
<li>隔离性：并发访问数据库的时候，各个事务之间不会相互影响</li>
<li>持久性：一个事务被提交之后，对数据库的修改是持久的，即使数据库发生故障也不会有影响</li>
</ol>
<h4 id="可能出现的问题"><a href="#可能出现的问题" class="headerlink" title="可能出现的问题"></a>可能出现的问题</h4><ol>
<li><strong>脏读</strong>：事务A能够读到事务B还没提交的数据</li>
<li><strong>不可重复读</strong>：对于读取一行数据，一个事务中两次读到的数据不一样</li>
<li><strong>幻读</strong>：对于读取多行数据，一个事务中第二次读到的行数比第一次读到的行数要多</li>
<li><strong>丢失修改</strong>：ABA问题，事务A读取记录R为20，将R-1&#x3D;19后写入数据库，事务B也执行一样的操作，但是最后数据库中的记录是R&#x3D;19，事务A的操作被事务B覆盖（这种是程序逻辑本身的问题，所以需要对需要修改的数据加锁&#x2F;版本号&#x2F;旧值比较）</li>
</ol>
<h4 id="隔离等级"><a href="#隔离等级" class="headerlink" title="隔离等级"></a>隔离等级</h4><ol>
<li><p><strong>读未提交</strong>：一个事务还没提交，其变更就能被其他事务看到</p>
</li>
<li><p><strong>读已提交</strong>：一个事务提交之后，其变更才能被其他事务看到，能够解决脏读的问题</p>
</li>
<li><p><strong>可重复读</strong>：一个事务执行过程中，对同一字段的多次读取结果是一样的，除非数据是被自己事务本身修改，能够解决不可重复读的问题，但是幻读仍然有可能发生<strong>（InnoDB通过MVCC和Next-key Lock在可重复读的隔离级别下解决了幻读的问题）</strong></p>
</li>
<li><p><strong>串行化</strong>：所有事务都是串行执行的，完全服从ACID的隔离级别，能解决所有问题</p>
</li>
</ol>
<h3 id="锁-、间隙锁、Next-Key-Lock"><a href="#锁-、间隙锁、Next-Key-Lock" class="headerlink" title="锁 、间隙锁、Next-Key Lock"></a>锁 、间隙锁、Next-Key Lock</h3><ul>
<li><p><strong>全局锁</strong>：对整个数据库加锁（Flush tables with read lock），典型应用场景是做全库逻辑备份（如果使用InnoDB，则使用mysqldump备份数据库的时候，有MVCC的支持，就不用加全局锁了）</p>
</li>
<li><p><strong>表级锁</strong>：又分为<strong>表锁</strong>和<strong>元数据锁（metadata lock， MDL）</strong></p>
<ul>
<li>元数据锁：锁住表结构，在访问一个表的时候会被自动加上，事务中的MDL锁会在语句执行开始时申请，但是语句结束后并不会马上释放，而是等到整个事务提交后才会释放</li>
</ul>
</li>
<li><p><strong>行锁</strong>：锁住一行，在InnoDB的事务中，行锁是在语句执行的时候加上，但是要等到事务结束才会释放（<strong>两阶段锁协议</strong>）</p>
<ul>
<li>行锁可能出现死锁的一种情况，事务A执行了第一条语句，事务B执行了第一条语句，两个事务分别获得了不同的行锁</li>
<li>解决行锁死锁的方法， <strong>1. 等待超时（innodb_lock_wait_timeout）</strong>，<strong>2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务（innodb_deadlock_detect &#x3D; on）</strong></li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 事务A</span></span><br><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 事务B</span></span><br><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>间隙锁（Gap Lock）</strong>:锁住两个值之间的空隙，前开后开区间，如6个值，有7个空隙，包括（-∞，num）和（num, +∞）<ul>
<li><strong>跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作</strong></li>
<li>间隙锁死锁的例子<ul>
<li>session A 执行 select … for update 语句，由于 id&#x3D;9 这一行并不存在，因此会加上间隙锁 (5,10);</li>
<li>session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；</li>
<li>session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；</li>
<li>session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E9%97%B4%E9%9A%99%E9%94%81%E6%AD%BB%E9%94%81.png" alt="image-20220906104804761"></p>
<ul>
<li><strong>Next-key Lock</strong>：Inno加锁的<strong>基本单位</strong>，<strong>为的就是解决幻读</strong>，行锁<code>b</code>和间隙锁<code>(a, b)</code>加在一起，就是一个<strong>Next-key Lock</strong>，是前开后闭区间<code>(a, b]</code></li>
</ul>
<h3 id="多版本并发控制MVCC"><a href="#多版本并发控制MVCC" class="headerlink" title="多版本并发控制MVCC"></a>多版本并发控制MVCC</h3><blockquote>
<p>MVCC加上Next-key Lock就能够解决幻读的问题。单单MVCC只能解决可重复读，当前读的情况下，还是会出现幻读</p>
</blockquote>
<blockquote>
<p>在MVCC中，非锁定读（普通select）是不用加锁的，但是锁定读(select … for update &#x2F; select … lock in share mode &#x2F; update &#x2F; insert &#x2F; delete)的时候会用锁</p>
</blockquote>
<blockquote>
<p>InnoDB中，每条记录在更新的时候都会同时记录一条回滚操作，因此能得到上一个状态的值。（这个回滚日志<code>undolog</code>会在不需要的时候才删除，即当前所有事务中的最小版本号大于回滚日志的版本号）</p>
</blockquote>
<h4 id="标识ID"><a href="#标识ID" class="headerlink" title="标识ID"></a>标识ID</h4><ul>
<li><strong>每个事务</strong>都有一个唯一的<strong>事务ID（transaction id）</strong>，每个事务开始前向InnoDB的事务系统申请，严格递增</li>
<li><strong>每行数据</strong>都有多个版本<strong>row trx_id</strong>，每次事务更新数据的时候，都会生成一个新的数据版本，并把<strong>事务ID</strong>赋值给<strong>row trx_id</strong>，旧的数据版本能够通过回滚日志得到</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/MVCC.png" alt="image-20220905203039546"></p>
<h4 id="详细过程"><a href="#详细过程" class="headerlink" title="详细过程"></a>详细过程</h4><blockquote>
<p>核心是通过版本控制来获得一个一致性视图，但是当事务更新数据的时候，只能用当前读，如果当前记录的行锁被其他事务占用，就只能进入锁等待。</p>
</blockquote>
<ol>
<li><strong>当前事务开始时</strong>，构造一个<strong>数组</strong>用于保存当前事务启动瞬间<strong>活跃</strong>的<strong>所有事务ID</strong>（即启动了，但是还没有提交）</li>
<li>数组里面事务ID的<strong>最小值记为低水位</strong>，<strong>事务ID的最大值+1记为高水位</strong>，数组和高水位就组成了当前事务的一致性视图（read-view）</li>
<li>对于<strong>一个数据记录</strong>的<strong>row trx_id</strong>来说，有以下几种可能<ul>
<li><strong>row trx_id小于低水位</strong>，落在绿色部分，表示这个版本的数据是已经提交的，或者是当前事务自己生成的，所以数据<strong>可见</strong></li>
<li><strong>row trx_id大于高水位</strong>，落在红色部分，表示这个版本的数据是由未来的事务生成的，<strong>不可见</strong></li>
<li>如果落在黄色部分：<ul>
<li><strong>row trx_id在数组中</strong>，表示这个版本是由未提交的事务生成的，<strong>不可见</strong></li>
<li><strong>row trx_id不在数组中</strong>，表示这个版本的数据是由已提交的事务生成的，<strong>可见</strong>（因为低水位和高水位表示的只是一个区间，这个区间中有已经提交的事务和未提交的事务，数组中的是未提交的事务，而当前的事务ID大于高水位，<strong>row trx_id</strong>落在这个区间内已提交的事务，哪当然是可见的）</li>
</ul>
</li>
</ul>
</li>
<li><strong>当前读</strong>：<strong>更新数据都是先读后写的</strong>，而这个读，只能<strong>读已经提交完成的最新版本</strong></li>
<li>如果是更新&#x2F;删除&#x2F;插入这些锁定读的事务呢？<strong>两阶段锁协议</strong>，需要等到获得锁的事务结束了，释放锁，才能继续<strong>当前读</strong>，继续后面的操作</li>
</ol>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/MVCC%E6%B0%B4%E4%BD%8D.png" alt="image-20220905225008836"></p>
<h4 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h4><p>MVCC也会出现ABA问题，因为只有在锁定读的时候才会加锁，所以可能会出现ABA问题，一个简单的例子，事务A读取了记录R数值为1，之后事务B也读取这个记录R数值为1，之后事务AB都想要将记录R+1后更新，那么最后结果就会变成2，但是期望是3。ABA问题是编程问题，所以可以使用select … lock for update来锁住想要更新的表，这样只有获取到锁的事务才能进行操作。或者加一个旧值&#x2F;版本号进行判断，只有当旧值&#x2F;版本号一样的时候才更新（但是修改失败需要有重试机制）。</p>
<h3 id="binlog、redolog"><a href="#binlog、redolog" class="headerlink" title="binlog、redolog"></a>binlog、redolog</h3><h4 id="binlog（归档日志）"><a href="#binlog（归档日志）" class="headerlink" title="binlog（归档日志）"></a>binlog（归档日志）</h4><blockquote>
<p>binlog的主要作用是用于备份，以及主从同步</p>
</blockquote>
<blockquote>
<p>binlog的写是追加写，所以不会覆盖以前的数据</p>
</blockquote>
<p>三种数据格式：</p>
<ul>
<li>statement – 记录执行的SQL语句，简洁，但是主库与从库执行同一条语句的结果可能不一样，如NOW()</li>
<li>row – 记录真实数据的变化，可靠，主从库执行结果一样，但是占空间</li>
<li>mixed – 前两种的混合，MySQL自己判断如果会引起主备不一致的时候，就用row格式，否则用statement</li>
</ul>
<h4 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a>redo log（重做日志）</h4><blockquote>
<p>redolog主要的作用是用于崩溃恢复，固定大小，循环写，可以比如可以配置一组4个文件，每个文件大小1GB，从头开始写，写到末尾又回到开头循环写。</p>
</blockquote>
<ul>
<li><p><strong>write pos</strong>：表示当前写记录的位置，一边写一边后移</p>
</li>
<li><p><strong>check point</strong>：check point之前的数据都是已经落盘（flush到磁盘）上的，write pos大于check point，write pos 与check point之间的数据表示在内存页上，但是还没落盘的数据</p>
</li>
</ul>
<h4 id="缓冲结构"><a href="#缓冲结构" class="headerlink" title="缓冲结构"></a>缓冲结构</h4><blockquote>
<p>崩溃分为数据库崩溃和操作系统崩溃，数据库崩溃只会影响MySQL中的缓存（丢失这一部分，已经调用write写入到操作系统缓存中的则是正常的），操作系统崩溃则是影响数据的落盘（无法恢复）</p>
</blockquote>
<ul>
<li><p><strong>buffer pool</strong>：MySQL中用于缓存页的地方，有脏页以及干净页，脏页落盘需要flush，干净页不用</p>
</li>
<li><p><strong>change buffer</strong>：buffer pool内的一部分，<strong>主要用于记录页面数据的变化</strong>，如果一个<strong>数据页已经在内存</strong>中，则可以直接修改这个内存数据页然后变成脏页；但是如果一个<strong>数据页不在内存中，在磁盘中</strong>，则可以将更新操作写到change buffer中，这样能够避免将数据页从磁盘中读取到内存中，<strong>减少磁盘的随机读IO，适用于多写少读</strong>，当要读取这个数据页的数据时，再将从磁盘中读取的数据执行change buffer中的操作就能得到最新的数据。</p>
</li>
<li><p><strong>redolog buffer</strong>：可以认为也是buffer pool中的一部分，事务执行过程中更新数据的日志都得先保存起来，但是又不能在还没commit的时候写入到redo log文件中，所以先用redolog buffer来存redo日志。</p>
</li>
<li><p><strong>操作系统的缓存 os cache</strong>：调用操作系统的write函数并不会将数据直接写入磁盘，而是先写入系统的缓冲池中，系统自己判断何时将数据flush进磁盘，<strong>数据库崩溃不会影响到这部分的数据，操作系统崩溃才会影响</strong>。</p>
</li>
</ul>
<h4 id="二阶段提交"><a href="#二阶段提交" class="headerlink" title="二阶段提交"></a>二阶段提交</h4><p>redo log是InnoDB引擎特有，用于提供崩溃恢复的功能，而二阶段提交涉及到<code>binlog(归档日志)</code>还有<code>redolog(重做日志)</code>，即server层与引擎层之间的交互。</p>
<p><strong>两阶段提交的作用</strong>：保证MySQL数据库中的记录与磁盘中的记录一致</p>
<p><strong>方法流程</strong>：</p>
<ul>
<li>执行器调用引擎的API接口(未写<code>binlog</code>)，写入一行数据</li>
<li>InnoDB引擎把数据保存在内存中，同时记录<code>redolog</code>，此时<code>redolog </code>进入<code>prepare状态</code>，然后告诉执行器，执行完成可以随时提交</li>
<li>执行器收到通知后记录<code>binlog</code>，然后调用InnoDB引擎接口说已经写完<code>binlog</code></li>
<li>InnoDB写<code>redolog</code>为<code>commit状态</code></li>
<li>更新完成</li>
</ul>
<p><strong>为什么要这样子？</strong></p>
<ul>
<li>假设<strong>先写redolog并设为commit状态，然后写binlog</strong>，那么写完<code>redolog</code>之后，机器挂了，<code>binlog</code>日志没有被写入。机器重启后，会通过<code>redolog</code>恢复数据，但是<code>binlog</code>没有记录这一条数据，那么后续机器根据<code>binlog</code><strong>备份</strong>或者<strong>主从同步</strong>的时候，就会丢失这一条数据。</li>
<li>假设<strong>先写binlog，然后写redolog</strong>，那么当<code>binlog</code>写完的时候，机器异常重启了，但是由于没有这条<code>redolog</code>，所以机器无法恢复这一条记录，但是<code>binlog</code>里面多出这一条数据，哪备份或者主从同步的时候也会出现同样的问题。</li>
<li><strong>二阶段提交如何保证一致性？</strong>假设极端的状态是<code>redolog</code>已经处于<strong>prepare状态</strong>，<code>binlog</code>也已经写完了，这个时候发生异常重启，就要依赖MySQL的处理机制<ul>
<li>判断<code>redolog</code>是否完整(<strong>commit状态</strong>)，如果是完整的，就能立即提交</li>
<li>如果<code>redolog</code>只是<code>prepare</code>状态，但<strong>不是commit状态</strong>，这个时候就判断<code>binlog</code>是否完整，如果完整就提交<code>redolog</code>，不完整就回滚事务</li>
</ul>
</li>
</ul>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485097&idx=1&sn=84c89da477b1338bdf3e9fcd65514ac1&chksm=cea24962f9d5c074d8d3ff1ab04ee8f0d6486e3d015cfd783503685986485c11738ccb542ba7&token=79317275&lang=zh_CN%23rd">一条SQL语句在MySQL中如何执行的 (qq.com)</a></p>
<h3 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h3><h4 id="详细流程"><a href="#详细流程" class="headerlink" title="详细流程"></a>详细流程</h4><ol>
<li>在备库B上通过<strong>change master</strong>命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量</li>
<li>在备库B上执行<strong>start slave</strong>命令，这个时候备库会启动两个线程，一个是<strong>io_thread</strong>，另一个是<strong>sql_thread</strong>。<strong>io_thread负责与主库A建立连接，获取binlog</strong></li>
<li>主库A校验完备库B传来的参数之后，按照请求的位置读取binlog通过<strong>dump_thread</strong>线程发给备库B</li>
<li>备库B拿到binlog之后，写到本地文件，称为<strong>中转日志（relay log）</strong></li>
<li>备库B中的<strong>sql_thread读取中转日志，解析日志理的命令，并执行</strong></li>
</ol>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B.png" alt="image-20220906144751652"></p>
<h4 id="循环复制问题"><a href="#循环复制问题" class="headerlink" title="循环复制问题"></a>循环复制问题</h4><blockquote>
<p>一般来说都是双Master结构，即节点A和节点B之间互为主从关系</p>
</blockquote>
<blockquote>
<p>但是这样会产生一个问题，就是节点A更新了一条语句，并将binlog发给节点B，节点B更新之后又将binlog发给节点A执行</p>
</blockquote>
<p><strong>解决方法</strong></p>
<p>设置server id</p>
<ol>
<li>规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系</li>
<li>一个备库收到binlog并且在重放过程中，要生成与原binlog的server id相同的新binlog</li>
<li>备库收到主库发过来的binlog记录，先判断server id是不是跟自己的一样，一样表示这个日志是自己生成的，则直接丢弃；不一样表示不是自己生成的，重做这个日志</li>
</ol>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2.png" alt="image-20220906145810695"></p>
<h3 id="inner-join、left-join、right-join、full-join"><a href="#inner-join、left-join、right-join、full-join" class="headerlink" title="inner join、left join、right join、full join"></a>inner join、left join、right join、full join</h3><ul>
<li><p><strong>inner join</strong>：等同于平时使用<code>，</code>连接两个表，内连接，交集</p>
</li>
<li><p><strong>left join</strong>：返回左表的全部数据</p>
</li>
<li><p><strong>right join</strong>：返回右表的全部数据</p>
</li>
<li><p><strong>full join</strong>：返回左右两个表的所有数据，并集</p>
</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/join.png" alt="image-20220906162852592"></p>
<h4 id="on和where的区别"><a href="#on和where的区别" class="headerlink" title="on和where的区别"></a>on和where的区别</h4><ul>
<li><p><strong>on</strong>：在生成临时表时使用的条件，不管on中的条件，都会返回left join &#x2F; right join &#x2F; full join时，左边&#x2F;右边&#x2F;两边表中的记录</p>
</li>
<li><p><strong>where</strong>：临时表生成好后，对临时表进行过滤，所有条件不为真的记录都被过滤掉</p>
</li>
</ul>
<p><a href="https://www.runoob.com/w3cnote/sql-different-on-and-where.html">https://www.runoob.com/w3cnote/sql-different-on-and-where.html</a></p>
<h3 id="小表驱动大表"><a href="#小表驱动大表" class="headerlink" title="小表驱动大表"></a>小表驱动大表</h3><blockquote>
<p>select * from t1 straight_join t2 on (t1.a &#x3D; t2.a); 能够让MySQL使用固定的连接方式执行查询，t1是驱动表、t2是被驱动表</p>
</blockquote>
<blockquote>
<p>小表是指两个表按照各自的条件过滤之后，参与join的各个字段的<strong>总数据量</strong>小的表</p>
</blockquote>
<p>驱动与被驱动：按照驱动表t1的数据到被驱动表t2中逐条查找数据，驱动表是外层循环，被驱动表是内层循环</p>
<p>Index Nested-Loop Join：能够用上被驱动表的索引</p>
<p>Simple Nested-Loop Join：不能用索引的情况下，就是两层循环</p>
<p>Block Nested-Loop Join：先将驱动表数据放入join buffer中，再根据被驱动表与join buffer中的数据对比</p>
<h3 id="数据库优化（未施工）"><a href="#数据库优化（未施工）" class="headerlink" title="数据库优化（未施工）"></a>数据库优化（未施工）</h3><h2 id="Spring（未施工）"><a href="#Spring（未施工）" class="headerlink" title="Spring（未施工）"></a>Spring（未施工）</h2><h3 id="DI-IOC-AOP"><a href="#DI-IOC-AOP" class="headerlink" title="DI IOC AOP"></a>DI IOC AOP</h3><h3 id="Bean的生命周期"><a href="#Bean的生命周期" class="headerlink" title="Bean的生命周期"></a>Bean的生命周期</h3><h3 id="Spring-MVC的工作流程"><a href="#Spring-MVC的工作流程" class="headerlink" title="Spring MVC的工作流程"></a>Spring MVC的工作流程</h3><h3 id="Spring-MVC的常用注解"><a href="#Spring-MVC的常用注解" class="headerlink" title="Spring MVC的常用注解"></a>Spring MVC的常用注解</h3><h2 id="k8s（待收拾）"><a href="#k8s（待收拾）" class="headerlink" title="k8s（待收拾）"></a>k8s（待收拾）</h2><h3 id="k8s的操作命令"><a href="#k8s的操作命令" class="headerlink" title="k8s的操作命令"></a>k8s的操作命令</h3><p>kubectl 动作 资源 -其他参数</p>
<ul>
<li>动作包括<ul>
<li>create</li>
<li>apply</li>
<li>get</li>
<li>describe</li>
<li>exec</li>
<li>logs</li>
<li>delete</li>
<li>explain</li>
</ul>
</li>
<li>资源包括<ul>
<li>Deployment</li>
<li>StatefullSet</li>
<li>ConfigMap</li>
<li>Secret</li>
<li>HPA</li>
<li>RC、RS</li>
<li>pods</li>
<li>nodes</li>
<li>namespace</li>
</ul>
</li>
</ul>
<h3 id="k8s的组件"><a href="#k8s的组件" class="headerlink" title="k8s的组件"></a>k8s的组件</h3><img src="k8s组件.png" alt="image-20220908094016645" style="zoom:50%;" />

<ul>
<li>Kubectl：客户端与k8s集群交互的命令行工具</li>
<li>API  server：作为k8s系统的入口，其封装了核心对象的增删改查操作，以及提供RESTful API接口给外部客户端或者k8s内部组件调用。维护的RSET对象会被持久化储存到etcd分布式数据库中</li>
<li>Scheduler：负责集群的资源调度，为新建立的pod选择节点node进行部署。组件抽离，可以方便替换成其他调度器</li>
<li>Controller Manager：负责维护集群的状态，比如故障检测、自动扩展、滚动更新等</li>
<li>Kubelet：负责维护容器的生命周期，同时也负责Volume（CSI）和网络（CNI）的管理</li>
<li>Container runtime：负责镜像管理以及pod和容器的真正运行（CRI）</li>
<li>Kube-proxy：负责为Service提供cluster内部的服务发现和负载均衡</li>
<li>CoreDNS：负责为整个集群提供DNS服务</li>
<li>Ingress Controller：为k8s中的服务提供外网入口</li>
<li>Prometheus：为整个集群提供资源监控能力</li>
<li>Dashboard</li>
<li>Federation</li>
</ul>
<h3 id="控制器类型"><a href="#控制器类型" class="headerlink" title="控制器类型"></a>控制器类型</h3><ul>
<li>HPA：根据CPU使用率和内存使用率进行自动扩缩容<ul>
<li>Deployment：一般用于负责管理RC和RS，提供滚动更新&#x2F;回滚能力<ul>
<li>Replication Controller 和 Replication Set：RS用于替代RC，主要作用是维护应用的副本数量，并且RS支持集合式的selector</li>
</ul>
</li>
</ul>
</li>
<li>StatefullSet：解决有状态服务的问题，Pod重新调度之后还是有：稳定的持久化存储、稳定的网络标志（基于Headless Service没有Cluster IP的Service来实现）、有序部署、有序收缩</li>
<li>DaemonSet：保证每个节点Node上都运行一个Pod的副本</li>
<li>Job，CronJob：Job负责仅执行一次的任务，Cron Job则是基于Crontable的定时任务</li>
</ul>
<h3 id="K8S网络"><a href="#K8S网络" class="headerlink" title="K8S网络"></a>K8S网络</h3><p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/k8s%E7%BD%91%E7%BB%9C.png" alt="image-20220908101831528"></p>
<h3 id="资源类型"><a href="#资源类型" class="headerlink" title="资源类型"></a>资源类型</h3><blockquote>
<p>资源清单–k8s中用于定义资源的yaml文件</p>
</blockquote>
<ul>
<li>NameSpace级别<ul>
<li>工作负载型资源：Pod、RC、RS、Deployment…..</li>
<li>服务发现及负载均衡型资源：Service、Ingress…</li>
<li>配置与储存型资源：PV、PVC…</li>
<li>特殊类型的储存卷：ConfigMap，Secret….</li>
</ul>
</li>
<li>集群级别<ul>
<li>NameSpace、Node、ClusterRole、ClusterRoleBinding</li>
</ul>
</li>
<li>元数据型资源<ul>
<li>HPA、PodTemplate、LimitRange</li>
</ul>
</li>
</ul>
<h3 id="Pod的生命周期"><a href="#Pod的生命周期" class="headerlink" title="Pod的生命周期"></a>Pod的生命周期</h3><blockquote>
<p>一个Pod里面至少有两个容器，一个是pause容器，负责维护pod内部的网络和共享储存卷，使得pod内部的容器能够使用localhost互相访问，以及使用相同的共享储存卷，其他的容器就是应用启动的容器了</p>
</blockquote>
<ul>
<li>Init容器：用于做初始化的容器，执行的顺序是按照定义时候的顺序，Init容器启动失败k8s会不断地重试，除非将restartPolicy设为Never（Pod重启，Init容器也会重新执行）</li>
<li>探针<ul>
<li>就绪探针</li>
<li>存活探针</li>
</ul>
</li>
<li>Pod hook钩子：在容器中进程启动前或者容器中进程终止运行之前运行，包含在容器的生命周期之中<ul>
<li>exec：执行一段命令</li>
<li>HTTP：发送Http请求</li>
</ul>
</li>
</ul>
<h3 id="Service的网络流向"><a href="#Service的网络流向" class="headerlink" title="Service的网络流向"></a>Service的网络流向</h3><p>apiserver发出一个请求（IP，PORT）随机到一个节点Node上，那么节点Node怎么知道是要访问哪个pod地址呢？</p>
<p>首先会经过节点上的kube-proxy，然后kube-proxy到内核中去查找ip映射表，这个时候就要用上ipvs或者是iptables了，查找到之后再将流量负载均衡定向到对应的pod中</p>
<h3 id="ipvs对比iptables"><a href="#ipvs对比iptables" class="headerlink" title="ipvs对比iptables"></a>ipvs对比iptables</h3><blockquote>
<p>都是基于netfilter</p>
</blockquote>
<ul>
<li>iptables使用列表来记录所有的规则，并且匹配方式是全部扫描匹配，所以当集群规模大的时候，性能问题就会突出</li>
<li>ipvs使用hash表，hash随机访问的特性在集群规模大的时候，也不会影响性能</li>
</ul>
<h3 id="Headless-Service"><a href="#Headless-Service" class="headerlink" title="Headless Service"></a>Headless Service</h3><p>有时候不需要或者不想要负载均衡，以及单独的Service IP，可以将Cluster IP设置为None来创建Headless Service，StatefullSet的网络也是依靠Headless Service来实现稳定访问的</p>
<p>Statefulset中创建的无头服务会为集群内部的每个成员提供一个唯一的DNS域名来作为每个成员的网络标识，集群内部成员之间使用域名通信（<code>pod名称+序号.Service名称</code>），如服务名称是<code>服务名.命名空间.svc.cluster.local</code>，那么一个创建的Pod使用的域名是<code>pod名称-序号.服务名.命名空间.svc.cluster.local</code>，如果StatefulSet中的一个Pod挂掉，那么新创建的Pod会被赋予跟原来Pod一样的名字，通过这个名字来匹配原来的储存和网络，因此实现了状态的保存。</p>
<blockquote>
<p>访问一个普通的<code>Service</code>, kube-proxy会将请求重定向到后端的某个<code>Pod</code>, 多次请求虽然发送到的后端可能不同, 但是前端是无感知的, 因为Service本身有固定IP.</p>
<p>但是访问一个<code>headless service</code>, 其实是随机且直接访问到后端<code>Pod</code>, 比如多次<code>ping redis-service</code>, 你会发现解析出来的地址是不同的, 而这些地址都是Pod的地址.</p>
</blockquote>
<h3 id="亲和性，反亲和性，污点，污点容忍"><a href="#亲和性，反亲和性，污点，污点容忍" class="headerlink" title="亲和性，反亲和性，污点，污点容忍"></a>亲和性，反亲和性，污点，污点容忍</h3><h4 id="亲和性（pod的策略）"><a href="#亲和性（pod的策略）" class="headerlink" title="亲和性（pod的策略）"></a>亲和性（pod的策略）</h4><ul>
<li>节点亲和性<ul>
<li>软策略</li>
<li>硬策略</li>
</ul>
</li>
<li>Pod亲和性<ul>
<li>硬策略</li>
<li>软策略</li>
</ul>
</li>
</ul>
<h3 id="污点（node的策略）"><a href="#污点（node的策略）" class="headerlink" title="污点（node的策略）"></a>污点（node的策略）</h3><p>节点选项：</p>
<ul>
<li>NoSchedule：表示k8s将不会将pod调度到具有该污点的Node上</li>
<li>PreferNoSchedule：表示k8s将尽量避免将pod调度到具有该污点的Node上</li>
<li>NoExecute：表示k8s将不会将pod调度到具有该污点的Node上，同时会将Node上已经存在的pod驱逐出去</li>
</ul>
<p>pod的污点容忍：pod可以容忍node中污点的存在，并被调度到存在污点的node上</p>
<h3 id="Prometheus-operator"><a href="#Prometheus-operator" class="headerlink" title="Prometheus-operator"></a>Prometheus-operator</h3><h2 id="Redis（未施工）"><a href="#Redis（未施工）" class="headerlink" title="Redis（未施工）"></a>Redis（未施工）</h2><p>Redis 数据类型</p>
<ul>
<li>string</li>
<li>list</li>
<li>hash</li>
<li>set</li>
<li>zset</li>
<li>hyperloglog</li>
<li>GEO</li>
<li>bitmap</li>
<li>stream</li>
</ul>
<p>Redis 数据结构</p>
<ul>
<li>SDS</li>
<li>链表</li>
<li>压缩列表-缺陷是啥</li>
<li>哈希表-rehash过程，渐进式哈希（两个哈希表），哈希冲突解决方法</li>
<li>整数集合–升级过程</li>
<li>跳表-查询过程，层数设计，插入方式</li>
<li>quicklist–链表+压缩列表</li>
<li>listpack</li>
</ul>
<p>持久化</p>
<ul>
<li>RDB - 生成RDB流程</li>
<li>AOF - 生成AOD流程，以及AOF重写，AOF写回策略</li>
</ul>
<p>过期删除和内存淘汰策略</p>
<ul>
<li>过期删除的删除策略是什么？</li>
<li>内存淘汰策略<ul>
<li>不淘汰 - 抛出异常</li>
<li>淘汰<ul>
<li>在设置了过期时间的键中删除（随机，LFU，LRU，TTL）</li>
<li>在所有键中删除（随机，LRU，LFU）</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>高可用</p>
<ul>
<li>主从复制流程</li>
<li>哨兵模式</li>
</ul>
<p>缓存</p>
<ul>
<li>缓存雪崩</li>
<li>缓存击穿</li>
<li>缓存穿透</li>
</ul>
<p><a href="https://xiaolincoding.com/redis/base/redis_interview.html#%E8%AE%A4%E8%AF%86-redis">https://xiaolincoding.com/redis/base/redis_interview.html#%E8%AE%A4%E8%AF%86-redis</a></p>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><blockquote>
<p>主要是分清Broker、主题Topic、分区Partition、副本Replica之间的概念</p>
</blockquote>
<h4 id="服务器层面"><a href="#服务器层面" class="headerlink" title="服务器层面"></a>服务器层面</h4><ul>
<li><strong>Broker</strong>：一个独立的Kafka服务被称为Broker，可以理解为Kafka集群中的一个节点。</li>
<li><strong>集群控制器（Controller）</strong>：每一个集群都会选举出一个Broker作为集群控制器Controller（第一个成功在zookeeper中创建<code>/kafka/controller</code>节点的Broker会被指定为集群控制器），主要负责集群管理工作，包括：<ul>
<li>创建删除主题、增加分区并选择副本的Leader</li>
<li>集群Broker管理（Broker新增、退出、故障）</li>
<li>分区副本Preferred Leader选举</li>
<li>消费者组分区重分配</li>
<li>数据服务 – 向其他Broker提供集群的元数据信息</li>
</ul>
</li>
</ul>
<h4 id="主题层面"><a href="#主题层面" class="headerlink" title="主题层面"></a>主题层面</h4><ul>
<li><strong>主题（Topic）：</strong>主题-订阅的模式，生产者将消息发送至相应的Topic中，消费者则从感兴趣的Topic中取出消息消费。Topic是一个逻辑概念。</li>
<li><strong>分区（Partition）</strong>：一个Topic被分成多个分区Partition，一个Partition从属于一个Broker，是最基本的<strong>储存单元</strong>，储存着一个Topic中的部分数据。每个Partition都有自己独立的log文件，每条记录都以追加的形式写入。</li>
<li><strong>副本（Replica）</strong>：为了保证Kafka的高可用，一个分区通常拥有多个副本。其中一个为<strong>Leader replica</strong>，其他为<strong>Follower replica</strong>，所有的事件都直接发送给<strong>Leader replica</strong>，<strong>Follower replica</strong>通过主从同步来保持与<strong>Leader replica</strong>数据一致。</li>
<li><strong>偏移量（Offset）</strong>：Partition中的每条记录都会被分配一个唯一的序号，称为偏移量Offset。</li>
<li><strong>消息（Message）</strong>：Kafka的基本数据单元。</li>
<li><strong>批次（Batch）</strong>：为了减少网络了开销，提高IO效率，多个消息会被放入同一批次之后再发送给Kafka。</li>
</ul>
<h4 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h4><blockquote>
<p>Kafka中多处涉及选举机制，容易混淆</p>
</blockquote>
<ul>
<li>Broker Controller组件Leader的选举 – 主要是监控Kafka集群状态</li>
<li>分区多副本机制选举Leader – 副本的Leader负责与生产者消费者的所有通信，Follower只是作为可靠性备份（主从机制）</li>
<li>消费者选举Leader – 消费者的Leader选举主要是负责消费者组内各个消费者消费分区的分配</li>
</ul>
<h3 id="生产者客户端工作原理"><a href="#生产者客户端工作原理" class="headerlink" title="生产者客户端工作原理"></a>生产者客户端工作原理</h3><img src="kafka消费者工作流程.png" alt="kafka消费者工作流程" style="zoom:80%;" />

<blockquote>
<p>整个生产者客户端主要由两个线程协调运行，分别是程序主线程和发送线程。</p>
<ul>
<li>程序主线程：主要负责消息的产生，然后通过拦截器、序列化器和分区器处理之后缓存到消息收集器RecordAccumulator中（多个消息打包之后变成ProducerBatch）</li>
<li>发送线程：主要负责从消息收集器中获取消息并将其发送至Kafka集群中</li>
</ul>
</blockquote>
<ol>
<li>首先，客户端生成消息，交给拦截器，拦截器可以对数据进行预处理，比如消息的格式化显示等。</li>
<li>随后，消息交给序列化器，对其中的key和value进行序列化</li>
<li>分区器使得生产者能够根据一定的规则，将特定的消息发送至特定的分区中</li>
<li>之后消息会到消息收集器中，根据设定的batch.size或者linger.ms触发消息发送之后，才会将收集器中的消息发送给kafka集群<ol>
<li><strong>batch.size</strong>：数据累积到batch.size大小之后，sender才会发送数据，默认16k</li>
<li><strong>linger.ms</strong>：如果数据没有达到batch.size，sender等待linger.ms设置的时间之后就会发送数据，默认值是0，表示没有延迟，一有消息到达就将消息发送出去（会导致网络IO频繁）</li>
</ol>
</li>
<li>在发送线程中，InFlightRequests缓存这已经发出去，但是还没有收到响应的请求（Map&lt;NodeId, Deque&gt;，即Kafka节点Id和发出去的请求队列）。主要是限制最多缓存的请求数，通过<code>max.in.flight.requests.per.connection</code>参数设置，默认为5，即每个连接维护一个长度为5的滑动窗口，最多只能缓存5个未响应的请求间隔（有点像TCP的滑动窗口，就算中间已经收到了响应，但是头和尾未响应，也是算头和尾之间的间距），如果超过该数据之后就不能向这个连接中发送更多的请求了</li>
<li>Kafka集群的应答acks：<ol>
<li>设置为0：生产者发送的数据，不需要等待Kafka集群数据落盘立即应答</li>
<li>设置为1：生产者发送的数据，Leader分区收到数据落盘后应答</li>
<li>设置为-1（all）：生产者发送的数据，<strong>Leader和ISR队列</strong>里面的所有节点数据落盘之后再由Leader应答</li>
</ol>
</li>
</ol>
<h4 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h4><blockquote>
<p>如果自定义了分区器的话，当然是用自定义的方法，这里说的是默认情况下</p>
</blockquote>
<p>使用默认分区器的情况下：</p>
<ol>
<li>如果指定了消息的发往的分区，则使用这个分区</li>
<li>如果没有指定分区，但是指定了消息的key，则根据key的hash值映射到特定的分区（如果主题的分区数不变，key跟分区的映射关系就能保持一致）</li>
<li>如果没有指定分区或者是消息的key，会采用粘性分区器，消息会被随机发送到指定主题的其中一个可用分区，并尽可能一直使用该分区，直到发送至该分区的消息收集器中能够达到batch.size之后，才会切换发送至别的分区（随机至另外一个分区）</li>
</ol>
<h4 id="数据可靠性保证"><a href="#数据可靠性保证" class="headerlink" title="数据可靠性保证"></a>数据可靠性保证</h4><p>acks设置为不同值下可能出现的情况</p>
<ul>
<li><strong>0：</strong>生产者发送至Kafka集群中的数据，不需要等待落盘，立即应答<strong>（应答之后Leader挂了，数据存在丢失的问题）</strong></li>
<li><strong>1：</strong>Leader分区收到数据并落盘之后应答<strong>（应答之后Leader挂了，其他Follower都还没有同步到数据，也存在数据丢失的问题）</strong></li>
<li><strong>-1（all）：</strong>Leader和ISR队列里面的所有节点数据落盘之后再由Leader应答<strong>（可能因为某个Follower网络或者挂掉的原因迟迟未能同步，会导致ACK响应阻塞，Kafka使用ISR队列来解决这个问题）（如果分区副本设置为1个，或者ISR中应答的最小副本数量min.insync.replicas为1，则跟ack&#x3D;1效果差不多，还是有数据丢失的问题）</strong><ul>
<li><strong>ISR（in-sync replicas）队列：</strong>和Leader保持同步的所有Follower+Leader的集合（Leader：0，ISR：0、1、2），如果Follower长时间未向Leader发送通信请求或者同步数据，则会被Leader踢出ISR队列，由replica.lag.time.max.ms参数设置，默认30s。</li>
<li><strong>OSR（out-sync replicas）队列：</strong>与Leader不同步的Follower集合</li>
</ul>
</li>
</ul>
<p><strong>数据完全可靠的条件</strong> &#x3D; <strong>ACK级别为-1</strong> + <strong>分区副本数大于等于2</strong> + <strong>ISR里应答的最小副本数量大于等于2</strong></p>
<h4 id="数据重复问题"><a href="#数据重复问题" class="headerlink" title="数据重复问题"></a>数据重复问题</h4><blockquote>
<p>acks设置为-1的时候，生产者可能发送了数据过来，Leader正在跟Follower同步数据，还未响应，但是此时，部分Follower已经同步了数据，Leader却挂了，Kafka集群会重新挑选出新的Leader分区，生产者会重新发送数据，如果这个新选出来的Leader已经同步了旧Leader的数据，那么就会出现数据重复的问题。</p>
</blockquote>
<h5 id="数据传递的语义"><a href="#数据传递的语义" class="headerlink" title="数据传递的语义"></a>数据传递的语义</h5><ul>
<li><strong>至少一次（At Least Once）：</strong> ACK级别为-1 + 分区副本数大于等于2 + ISR里应答的最小副本数量大于等于2，<strong>保证生产者发送的数据Kafka集群会落盘，保证数据不会丢失，但可能重复</strong></li>
<li><strong>最多一次（At Most Once）：</strong> ACK &#x3D; 0，<strong>保证生产者发送的数据最多只发送一次到Kafka集群，保证数据不重复，但是可能会丢失</strong></li>
<li><strong>精确一次（Exactly Once）：</strong> <strong>数据即不能重复，也不能丢失</strong><ul>
<li><strong>幂等性（单会话单分区精确一次）：</strong>生产者无论向Broker发送多少次重复数据，Broker都只会持久化一条，保证不会重复，结合至少一次就能达到精确一次。</li>
<li><strong>事务：</strong>通过事务保证精确一次，实现多个Topic、多个Partition原子性的写入（见下文）</li>
</ul>
</li>
</ul>
<h5 id="生产者幂等性"><a href="#生产者幂等性" class="headerlink" title="生产者幂等性"></a>生产者幂等性</h5><blockquote>
<p>Kafka的幂等性是单会话单分区幂等</p>
</blockquote>
<p>通过**&lt;PID，partition，SeqNumber&gt;**区分每一条数据。（单分区的原因看区分规则就知道，不同分区当成不同的消息）</p>
<ul>
<li><p><strong>PID（Producer ID）</strong>：对用户完全透明，是Producer每次连接上Kafka集群之后，都会向Broker申请一个全局唯一的PID，用来标识本次会话，<strong>如果Producer重启会导致PID的变化，所以Broker就会当成是一个新的生产者（单次会话的原因）</strong>。</p>
</li>
<li><p><strong>partition</strong>：消息需要发往的分区号</p>
</li>
<li><p><strong>SeqNumber</strong>：从0开始单调递增的，Broker端缓存了SeqNumber，对于每条接收的消息，只有SeqNumber比Broker缓存中的大1才接受，否则丢弃（实现幂等）。</p>
</li>
</ul>
<h3 id="消费者客户端工作原理"><a href="#消费者客户端工作原理" class="headerlink" title="消费者客户端工作原理"></a>消费者客户端工作原理</h3><blockquote>
<p>消息的两种<strong>消费方式</strong>：</p>
<ul>
<li><strong>pull（拉）模式：</strong>消费者主动从  mq 服务器中拉取数据（Kafka采用的方式）</li>
<li><strong>push（推）模式：</strong>mq服务器主动将数据推送至消费者（很难保证消费者的消费速度能跟得上mq服务器的推送速度）</li>
</ul>
</blockquote>
<blockquote>
<p>常见的有两种<strong>消费模型</strong>：</p>
<ul>
<li><strong>队列模型（queuing）：</strong>一组消费者从服务读取消息，一条消息只有其中的一个消费者来处理。</li>
<li><strong>发布-订阅模型（publish-subscribe）：</strong>消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。</li>
</ul>
</blockquote>
<blockquote>
<p>Kafka 提供两种<strong>订阅方式</strong>：</p>
<ul>
<li><strong>subscribe：</strong>订阅主题，能够通过正则表达式订阅多个主题，<strong>具有消费者组再平衡的功能</strong>。</li>
<li><strong>assign：</strong>能够直接订阅特定主题的特定分区，<strong>不具备消费者再平衡的功能</strong>。</li>
</ul>
</blockquote>
<p>Kafka 为这两种模型提供单一的消费者抽象模型：<strong>消费者组（Comsumer group）</strong>。</p>
<p>消费者用一个消费者组名（GroupId）标记自己，一个发布在 Topic 上的消息被分发给此消费者组中的一个成员（<strong>每个Topic的 Partition 只能由消费者组中的一个成员消费，但是一个消费者成员能够消费多个 Partition中的消息，是多对一关系</strong>）。</p>
<ul>
<li>假如<strong>所有的消费者都在一个组中，那么这就变成了队列模型</strong></li>
<li>假如<strong>所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型</strong></li>
</ul>
<p>一个消费者组中的消费者成员订阅同一个 Topic，每个消费者成员接收 Topic 的一部分分区的消息，从而实现对消费者的横向扩展，对消息进行分流。<strong>但是不要让消费者组中消费者成员的数量多于 Topic的 Partition 的数量，因为多余的消费者成员会空闲出来。</strong></p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E5%88%86%E5%8C%BA%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB.png" alt="img"></p>
<h4 id="分区的分配策略"><a href="#分区的分配策略" class="headerlink" title="分区的分配策略"></a>分区的分配策略</h4><blockquote>
<p>分区分配策略的主要作用是决定每个消费者组成员消费订阅 Topic 中的哪个分区。</p>
</blockquote>
<blockquote>
<p>Kafka 可以同时使用多个分区分配策略，由<code>partition.assignment.strategy</code>参数设定，默认是 Range + CooperativeSticky。</p>
<p>消费者也可以自定分区策略，通过继承<code>PartitionAssignor</code>接口或者<code>AbstractPartitionAssignor</code>抽象类来实现。</p>
</blockquote>
<p>消费者组分区的分配策略主要有：</p>
<ul>
<li><strong>RangeAssignor（范围）</strong></li>
<li><strong>RoundRobinAssignor（轮询）</strong></li>
<li><strong>StickyAssignor（粘性）</strong></li>
<li><strong>CooperativeStickyAssignor（合作者粘性）</strong>：与StickyAssignor类似</li>
</ul>
<h5 id="RangeAssignor"><a href="#RangeAssignor" class="headerlink" title="RangeAssignor"></a>RangeAssignor</h5><blockquote>
<p>对<strong>每个 Topic 进行独立的分区分配</strong>。对于每一个 Topic，首先对分区按照分区 ID 进行排序，然后对订阅该 Topic 的消费者组成员进行排序，之后尽量均衡地将分区分配给消费者。</p>
<p>首先要决定每个消费者消费分区的个数，Topic 分区数对消费者个数取余便是每个消费者至少要处理的分区个数，但是会有剩余的分区，剩余的分区则平均分配给排序靠前的消费者。然后从0号分区开始按每个消费者的消费分区个数按顺序分配。</p>
<p>缺点：随着消费者订阅 Topic 数量的增加，会导致不平衡问题，排序靠前的消费者会被分配更多的分区（因为上面的分配策略是针对单个 Topic 的）。</p>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5Range.png" alt="img"></p>
<h5 id="RoundRobinAssignor"><a href="#RoundRobinAssignor" class="headerlink" title="RoundRobinAssignor"></a>RoundRobinAssignor</h5><blockquote>
<p>将<strong>消费者组内订阅所有 Topic 的分区</strong>及所有消费者进行排序后尽量均衡的分配。如果消费者组内，消费者订阅 Topic 列表是相同的（每个消费者成员都订阅了相同的 Topic），那么分配结果是尽量均衡的（针对所有 Topic，消费者成员之间分配到的分区数的差值不会超过 1）。如果订阅的 Topic 列表是不同的，那么分配结果是不保证“尽量均衡”的，因为某些消费者成员不参与部分 Topic 的分配。</p>
<p>分配策略是：将所有 Topic 的 Partition  和所有消费者成员都列出来，分别按照 <code>hashcode</code> 进行排序，最后通过轮询算法分配 Partition给消费者成员。</p>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5RoundRobin.png" alt="img"></p>
<blockquote>
<p>对于订阅组内消费者订阅 Topic 不一致的情况：假设有三个消费者分别为C0、C1、C2，有3个 Topic T0、T1、T2，分别拥有1、2、3个分区，并且C0订阅T0，C1订阅T0和T1，C2订阅T0、T1、T0，那么RoundRobinAssignor的分配结果如下图所示，<strong>没有订阅对应 Topic 的消费者不参与分配，但是排序轮询还是按正常一样</strong>。</p>
<p>可以看到已经尽量保证均衡了，但是 C2 承担了 4 个分区，而 C1 其实是订阅了 T1 的，如果把 T1P1 交给 C1 负责会更加均衡。</p>
</blockquote>
<img src="Kafka分区分配策略RoundRobin缺点.png" alt="img" style="zoom:50%;" />

<h5 id="StickyAssignor"><a href="#StickyAssignor" class="headerlink" title="StickyAssignor"></a>StickyAssignor</h5><blockquote>
<p>无论是RangeAssignor，还是RoundRobinAssignor，当前的分区分配算法都没有考虑上一次的分配结果。StickyAssignor解决的就是这个问题。</p>
</blockquote>
<blockquote>
<p>StickyAssignor的主要目标：</p>
<ul>
<li>分区的分配尽量均衡</li>
<li>每一次重分配的结果尽量与上一次分配结果保持一致</li>
</ul>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5StickyAssignor.png" alt="img"></p>
<blockquote>
<p>上面的例子中，C1 下线后，Sticky 模式原来分配给 C0、C2 的分区都没有发生变动，并且最终 C0、C1达到均衡的目的；而RoundRobin 模式中原本分配给 C0 的 T1P1，以及原本分配给 C2 的 T1P0 都发生了变动。</p>
</blockquote>
<blockquote>
<p>下面是另外一个例子</p>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5StickyAssignor2.png" alt="img"></p>
<h4 id="消费者组再平衡"><a href="#消费者组再平衡" class="headerlink" title="消费者组再平衡"></a>消费者组再平衡</h4><blockquote>
<p><strong>再平衡是指 Kafka 消费者组成员或者订阅 Topic 发生变化时的一种分区重分配机制，再平衡期间消费者会停下手头的事情</strong>，一般有三种情况会触发再平衡：</p>
<ul>
<li><strong>消费者组成员数量发生变化：</strong>消费者组中新增或者删除某个成员，导致需要重新调整分区分配</li>
<li><strong>订阅主题 Topic 数量发生变化：</strong>消费者订阅的 Topic 发生变化，比如订阅的 Topic 采用的是正则表达式的形式 <code>test-*</code>，如果新建了一个 Topic 名为 <code>test-hello</code>，那么该 Topic 也是需要分配给消费者的，此时就会触发再平衡</li>
<li><strong>订阅主题 Topic 的分区数发生变化：</strong>订阅主题 Topic  增加或减少了分区数量，也会触发再平衡</li>
</ul>
</blockquote>
<blockquote>
<p>再平衡主要涉及到Kafka Broker中的<strong>Group Coordinator</strong>以及内部 Topic <strong>__consumer_offsets（更正式的名字是 Offset Topic）</strong>。</p>
</blockquote>
<h5 id="Group-Coordinator"><a href="#Group-Coordinator" class="headerlink" title="Group Coordinator"></a>Group Coordinator</h5><blockquote>
<p>Group Coordinator 主要用于消费者 offset 管理、消费者组成员与 Topic Partition的分配和 Consumer Rebalance。</p>
<p>在 Broker 启动时，每个 Broker 都会启动一个 Group Coordinator ，但只有<code>__consumer_offsets</code> 的 Partition 的 Leader 才会直接与消费者进行交互，也就是该消费者组的 Group Coordinator，其他的分区副本的 Group Coordinator只是作备份，一旦 Leader 所在 Broker 挂掉之后及时进行替代。</p>
</blockquote>
<h5 id="消费者组状态机"><a href="#消费者组状态机" class="headerlink" title="消费者组状态机"></a>消费者组状态机</h5><blockquote>
<p>Kafka 设计了一套消费者组状态机，来帮 Group Coordinator 完成整个再平衡流程。状态机中为消费者组定义了 5 种状态：Empty、Dead、PreparingRebalance、CompletingRebalance 和 Stable。</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">状态</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Empty</td>
<td>消费者组内没有任何成员，但消费者组可能存在已提交的 offset 数据，而且这些 offset 数据尚未过期</td>
</tr>
<tr>
<td align="center">Dead</td>
<td>同样是消费者组内没有任何成员，但消费者组的元数据信息已经在 Group Coordinator 端被移除。Group Coordinator 组件保存着当前向它注册过的所有消费者组信息，所谓的元数据信息就类似于这个注册信息</td>
</tr>
<tr>
<td align="center">PreparingRebalance</td>
<td>消费者组准备开启再平衡，此时所有成员都要重新请求加入消费者组</td>
</tr>
<tr>
<td align="center">CompletingRebalance</td>
<td>消费者组下所有成员已经加入，各个成员正在等待分配方案。该状态在老一点的版本种被称为 AwaitingSync，它和 CompletingRebalance是等价的</td>
</tr>
<tr>
<td align="center">Stable</td>
<td>消费者组的稳定状态。该状态表明再平衡已经完成，组内各成员能够正常消费数据了</td>
</tr>
</tbody></table>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1%E7%8A%B6%E6%80%81%E6%9C%BA.png" alt="img"></p>
<p> 一个消费者组最开始是 Empty 状态，当再平衡开启后，它会被置于 PreparingRebalance 状态等待成员加入，之后变更到  CompletingRebalance 状态等待分区分配方案，最后流转到 Stable 状态完成再平衡。</p>
<p>当有新成员加入或者已有成员退出消费者组的时候，消费者组的状态从 Stable 直接跳到 PreparingRebalance 状态，此时，所有现存成员就必须重新申请加入消费者组。当所有成员都退出组后，消费者组状态变更为 Empty。<strong>Kafka定期自动删除过期位移的条件就是，消费者组要处于 Empty 状态。</strong>因此，如果你的消费者组停掉了很长的时间（超过 7 天），那么 Kafka 很可能就把该组的 offset 数据删除了。我相信，你在 Kafka 的日志种一定经常看到下面这个输出：<code>Removed ✘✘✘ expired offsets in ✘✘✘ milliseconds.</code>。这就是 Kafka 在尝试定期删除过期 offset。</p>
<h5 id="再平衡全流程"><a href="#再平衡全流程" class="headerlink" title="再平衡全流程"></a>再平衡全流程</h5><h6 id="第一步-FIND-COORDINATOR"><a href="#第一步-FIND-COORDINATOR" class="headerlink" title="第一步 FIND_COORDINATOR"></a>第一步 FIND_COORDINATOR</h6><p>消费者启动的时候会发送 FindCoordinatorRequest 请求。</p>
<p><strong>目的：</strong></p>
<ul>
<li>确定负责该消费者组的 Group Coordinator 所在的 Broker（每个 Broker 中都会有 Group Coordinator，但是一个消费者组由一个 Group Coordinator 协调工作）</li>
<li>创建与该 Broker相互通信的网络连接</li>
</ul>
<p><strong>过程：</strong></p>
<ul>
<li>如果消费者已经保存了消费者组对应的 Group Coordinator 节点的信息，并且与它之间的网络连接是正常的，那么可以进入下一阶段；否则向 Kafka 集群中**负载最小的 Broker **发送 FindCoordinatorRequest 请求寻找 Group Coordinator。</li>
<li>**Group Coordinator的选择方式是：BrokerId &#x3D;  PartitionLeader( Hash( GroupId ) % __consumer_offsets的分区数 )<strong>，即将 GroupId 取哈希之后对 <code>__consumer_offsets</code> 的分区数取余，然后</strong>这个余数就作为以后 消费者 offset 要写入的<code>__consumer_offsets</code> 的分区，这个分区 Partition Leader 所在的 Broker 中的 Group Coordinator 就负责这个消费者组的工作协调（非常绕，多看几遍）（其实就是消费者 offset 需要写入 __consumer_offsets分区的Leader所在 Broker中）。</li>
</ul>
<h6 id="第二步-JOIN-GROUP"><a href="#第二步-JOIN-GROUP" class="headerlink" title="第二步 JOIN_GROUP"></a>第二步 JOIN_GROUP</h6><p>当消费者组成员加入组时，会向 Group Coordinator 发送 JoinGroup 请求，该请求中包含成员订阅的主题。</p>
<p><strong>目的：</strong></p>
<ul>
<li>选举消费者 Leader</li>
<li>由消费者 Leader 制定具体的分区分配方案</li>
</ul>
<p><strong>过程：</strong></p>
<ul>
<li>第一个发送 JoinGroup 请求到 Group Coordinator 的成员自动成为消费者 Leader，根据 Group Coordinator 响应中的消费者组成员订阅信息制定分区分配方案。</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1JoinGroup%E8%AF%B7%E6%B1%82.png" alt="img"></p>
<h6 id="第三步-SYNC-GROUP"><a href="#第三步-SYNC-GROUP" class="headerlink" title="第三步 SYNC_GROUP"></a>第三步 SYNC_GROUP</h6><p>消费者 Leader 将制定好的分区分配方案发送在 SyncGroup 请求中发送给 Group Coordinator。其他消费者成员也会向  Group Coordinator 发送 SyncGroup 请求，只不过请求体中没有实际的内容。然后 Group Coordinator 以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区。当所有成员都成功接收到分配方案之后，消费者组就进入到了 Stable 状态，开始正常消费工作（也会经过反序列化器、拦截器）。</p>
<p><strong>目的：</strong></p>
<ul>
<li>通过  Group Coordinator 同步消费者 Leader 制定好的分区分配方案</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1SyncGroup%E8%AF%B7%E6%B1%82.png" alt="img"></p>
<h6 id="Heartbeat-线程"><a href="#Heartbeat-线程" class="headerlink" title="Heartbeat 线程"></a>Heartbeat 线程</h6><p>心跳线程是一个独立的线程，通过向 Group Coordinator 发送心跳来维持自己与消费者组的从属关系，以及对分区的所有权关系。</p>
<p>当消费者组有新成员加入时，也是<strong>通过心跳请求的响应来通知组内现有成员开启新一轮的再平衡</strong>。</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%96%B0%E6%88%90%E5%91%98%E5%85%A5%E7%BB%84.png" alt="img"></p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%88%90%E5%91%98%E7%A6%BB%E7%BB%84.png" alt="img"></p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%88%90%E5%91%98%E5%B4%A9%E6%BA%83%E7%A6%BB%E7%BB%84.png" alt="img"></p>
<blockquote>
<p>正常情况下，每个组内成员都会定期汇报位移给协调者。当重平衡开启时，协调者会给予成员一段缓冲时间，要求每个成员必须在这段时间内快速地上报自己的位移信息，然后再开启正常的 JoinGroup&#x2F;SyncGroup 请求发送。</p>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E7%BB%84%E6%88%90%E5%91%98%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB.png" alt="img"></p>
<p><a href="https://blog.csdn.net/jy02268879/article/details/112273332">https://blog.csdn.net/jy02268879/article/details/112273332</a></p>
<p><a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/25%20%20%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%87%8D%E5%B9%B3%E8%A1%A1%E5%85%A8%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90.md">https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/25%20%20%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%87%8D%E5%B9%B3%E8%A1%A1%E5%85%A8%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90.md</a></p>
<h4 id="内部Offset-Topic"><a href="#内部Offset-Topic" class="headerlink" title="内部Offset Topic"></a>内部Offset Topic</h4><blockquote>
<p>在 Kafka 0.9 版本之前，消费者的 offset 是保存在 zookeeper 中的，但是 <strong>zookeeper 不适合用于高频写操作的场景</strong>，这会影响 Kafka 的消息吞吐量，所以 Kafka 需要一个能够提供<strong>高持久性、支持高频写操作</strong>的地方保存 offset。明显 Kafka 的Topic 设计天然就满足了这两个条件，因此 Kafka 使用内部主题保存 offset 的这件事，是自然而然的。</p>
</blockquote>
<blockquote>
<p>Offset Topic 的 offset管理机制其实也很简单，就是<strong>将 Consumer 的消费的 offset 数据作为一条普通的 Kafka 消息， 提交到 __consumer_offsets 中</strong>。默认情况下，__consumer_offsets 主题的<strong>分区数是 50，副本数是 3。</strong></p>
</blockquote>
<p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题，Offset Topic 主题的 Key 和 Value 组成如下：</p>
<ul>
<li><strong>Key：</strong> 应该保存 3 部分的内容 <strong>&lt;GroupId, 主题名, 分区号&gt;</strong></li>
<li><strong>Value：</strong> 应该保存的数据有 **&lt;offset, 时间戳， 元数据&gt;**，元数据是为了帮助 Kafka 执行各种各样的后续操作，比如删除过期位移消息等。</li>
</ul>
<p>具体消费者消费的 offset 储存到 <code>__consumer_offsets</code> 的哪个分区上，是根据<code>abs(GroupId.hashCode()) % NumPartitions</code>来计算（其中，NumPartitions 是 <code>__consumer_offsets的分区数</code>）</p>
<h5 id="提交偏移量"><a href="#提交偏移量" class="headerlink" title="提交偏移量"></a>提交偏移量</h5><p>如果消费者消费到了 offset，则提交的偏移量位置是 offset + 1，指向下一跳消息的位置。</p>
<p>提交的偏移量是 poll() 最后一次拉取的偏移量。当然手动提交的时候，也能够指定偏移量位置。</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%81%8F%E7%A7%BB%E9%87%8F%E6%8F%90%E4%BA%A4%E6%96%B9%E6%B3%95.jpeg" alt="img"></p>
<h6 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h6><p>开启时，消费者使用 poll() 方法从 Kafka 中拉取消息数据，同时消费者会有一个后台线程定时向 Kafka 提交消费者的 offset，自动提交涉及两个参数：</p>
<ul>
<li><strong>enable.auto.commit：</strong>设为 true，表示开启自动提交（默认）</li>
<li><strong>auto.commit.interval.ms：</strong>自动提交时间间隔，默认是 5 秒</li>
</ul>
<p><strong>自动提交丢数据场景</strong>：消费者A，第一次 poll 了100条数据，刚好第一次提交偏移量也是 100+1（ 5 秒提交一次），但是拉取的这 100 条才处理了前 50 条，A 就挂了，相当于51 - 100 的数据已经提交了偏移量，但还没处理。因此发生了消费再平衡，由 B 来接着消费这个分区，B 从 101 开始消费，51-101 的数据就丢失了。</p>
<p><strong>自动提交重复消费场景：</strong>消费者A，第一次 poll 了 100 条数据，刚好第一次提交偏移量也是 100+1（ 5 秒提交一次），在后面的 3 秒中，消费者 A 又 poll 了 2 次数据，每次 100 条，相当于此时消费者 A 已经消费到了偏移量 300 了，此时才过 3 秒，还没有到下一次触发自动提交的时间。此时，消费者 A 挂了，发生了消费再平衡，由 B 来接着消费这个分区，那 B 就是从 101 偏移量开始消费，那么101-300都被重复消费了。</p>
<h6 id="手动提交"><a href="#手动提交" class="headerlink" title="手动提交"></a>手动提交</h6><p>使用手动提交的时候，需要将 <strong>enable.auto.commit</strong> 设置为 false。</p>
<p>**同步提交commitSync()**：调用 commitSync() 时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果。</p>
<p>**异步提交commitAsync()**：调用 commitAsync() 之后，它会立即返回，不会阻塞。commitAsync 的问题在于，出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经 “过期” 或不是最新值了（重试之前，已经有另外一次提交）。</p>
<p><a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/18%20%20Kafka%E4%B8%AD%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF.md">Kafka中位移提交那些事儿</a></p>
<h3 id="Broker工作原理"><a href="#Broker工作原理" class="headerlink" title="Broker工作原理"></a>Broker工作原理</h3><blockquote>
<p>Kafka在2.8版本之前的集群信息管理依赖于Zookeeper，在2.8版本之后引入了Raft协议，去除了Zookeeper的依赖，但是还是提供多Zookeeper的版本（因为Raft协议的版本暂时还不成熟），下面主要以Zookeeper的版本介绍</p>
</blockquote>
<h4 id="Zookeeper中储存的信息"><a href="#Zookeeper中储存的信息" class="headerlink" title="Zookeeper中储存的信息"></a>Zookeeper中储存的信息</h4><p>Zookeeper中主要储存以下信息</p>
<ul>
<li><strong>&#x2F;brokers&#x2F;ids</strong>： 记录有哪些在线的Broker</li>
<li><strong>&#x2F;brokers&#x2F;topics&#x2F;主题名&#x2F;partitions&#x2F;分区号&#x2F;state</strong>： 记录分区副本中谁是Leader，谁是Follower，记录有哪些分区的副本是在线的（ISR队列）</li>
<li><strong>&#x2F;controller</strong>： 负责Broker Controller组件Leader的选举，谁能先注册到这个节点，谁就是Leader</li>
</ul>
<h4 id="Broker中的Controller组件"><a href="#Broker中的Controller组件" class="headerlink" title="Broker中的Controller组件"></a>Broker中的Controller组件</h4><blockquote>
<p>Controller组件是Kafka的核心组件，主要作用是在Zookeeper的帮助下管理和协调整个Kafka集群。Kafka集群中的任意一个Broker都会有一个Controller组件，但是在运行的过程中只有一个Controller能够称为集群的Leader Controller，管理和协调集群的运行，其他的Controller作为高可用的后备，Leader Controller挂了就顶上。</p>
</blockquote>
<p>Controller组件主要负责：</p>
<ul>
<li>创建删除主题、增加分区并选择副本的Leader</li>
<li>集群Broker管理（Broker新增、退出、故障）</li>
<li>分区副本Preferred Leader选举</li>
<li>消费者组分区重分配</li>
<li>数据服务 – 向其他Broker提供集群的元数据信息</li>
</ul>
<h5 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h5><p>![image-20221027232023434](Broker Controller工作流程.png)</p>
<ol>
<li>当Broker启动的时候，会向Zookeeper中的<code>/brokers/ids/</code>写入自己的Broker ID</li>
<li>随后Controller会尝试向Zookeeper中创建<code>/controller</code>节点，第一个成功创建<code>/controller</code>节点的Controller会写入自己的Broker ID成为Leader Controller，并向<code>/controller_epoch</code>节点写入自己的任期Epoch（任期是单调递增的），然后拉取Zookeeper中相应节点中的信息进行集群的初始化。</li>
<li>其他尝试创建<code>/controller</code>节点的Controller会向<code>/controller</code>节点注册监听，当Leader挂了，就尝试顶上。</li>
<li>Leader Controller会监听<code>/brokers/ids/</code>中子节点的变化，以监控Broker的上下线。</li>
<li>Leader Controller开始负责集群信息的管理，并且维护<code>/brokers/topics/</code>节点中的信息。</li>
<li>当Leader Controller挂了之后，其他Controller会尝试创建<code>/controller</code>节点成为新的Leader Controller并将任期Epoch + 1，从Zookeeper中拉取信息初始化集群上下文，其他Broker收到小于当前Leader Controller任期Epoch的事件都会丢弃，以隔离僵尸Leader的影响。</li>
</ol>
<h5 id="Controller内部结构"><a href="#Controller内部结构" class="headerlink" title="Controller内部结构"></a>Controller内部结构</h5><blockquote>
<p>在 Kafka 0.11 版本之前，控制器的设计是相当繁琐的，代码更是有些混乱，这就导致社区中很多控制器方面的 Bug 都无法修复。<strong>控制器是多线程的设计，会在内部创建很多个线程。</strong>比如，控制器需要为每个 Broker 都创建一个对应的 Socket 连接，然后再创建一个专属的线程，用于向这些 Broker 发送特定请求。如果集群中的 Broker 数量很多，那么控制器端需要创建的线程就会很多。另外，控制器连接 ZooKeeper 的会话，也会创建单独的线程来处理 Watch 机制的通知回调。除了以上这些线程，控制器还会为主题删除创建额外的 I&#x2F;O 线程。</p>
<p>比起多线程的设计，更糟糕的是，这些线程还会访问共享的控制器缓存数据。我们都知道，多线程访问共享可变数据是维持线程安全最大的难题。为了保护数据安全性，控制器不得不在代码中大量使用ReentrantLock同步机制，这就进一步拖慢了整个控制器的处理速度。</p>
<p><strong>鉴于这些原因，社区于 0.11 版本重构了控制器的底层设计，最大的改进就是，把多线程的方案改成了单线程加事件队列的方案。</strong></p>
<p>从这张图中，我们可以看到，社区引入了一个事件处理线程，统一处理各种控制器事件，然后控制器将原来执行的操作全部建模成一个个独立的事件，发送到专属的事件队列中，供此线程消费。这就是所谓的单线程 + 队列的实现方式。 值得注意的是，这里的单线程不代表之前提到的所有线程都被“干掉”了，控制器只是把缓存状态变更方面的工作委托给了这个线程而已。</p>
<p>这个方案的最大好处在于，控制器缓存中保存的状态只被一个线程处理，因此不再需要重量级的线程同步机制来维护线程安全，Kafka 不用再担心多线程并发访问的问题，非常利于社区定位和诊断控制器的各种问题。事实上，自 0.11 版本重构控制器代码后，社区关于控制器方面的 Bug 明显少多了，这也说明了这种方案是有效的。</p>
<p>针对控制器的第二个改进就是，将之前同步操Zookeeper 全部改为异步操作。ZooKeeper 本身的 API 提供了同步写和异步写两种方式。之前控制器操作 ZooKeeper 使用的是同步的 API，性能很差，集中表现为，当有大量主题分区发生变更时，ZooKeeper 容易成为系统的瓶颈。新版本 Kafka 修改了这部分设计，完全摒弃了之前的同步 API 调用，转而采用异步 API 写入 ZooKeeper，性能有了很大的提升。根据社区的测试，改成异步之后，ZooKeeper 写入提升了 10 倍！</p>
</blockquote>
<p>![img](Broker Controller结构.jpg)</p>
<h4 id="数据的储存"><a href="#数据的储存" class="headerlink" title="数据的储存"></a>数据的储存</h4><blockquote>
<p>Kafka的存储最终实现方案是<strong>基于顺序追加写日志  + 稀疏哈希索引</strong></p>
</blockquote>
<p>一般通过以下手段来提高数据的读写性能：</p>
<ul>
<li><strong>提高读速度：</strong>利用索引，来提高查询速度，但是有了索引，大量写操作都会维护索引，那么会降低写入效率。常见的如关系型数据库MySQL</li>
<li><strong>提高写操作：</strong>这种一般是采用日志储存，通过顺序追加写的方式来提高写入速度，因为没有索引，无法快速查询，只能顺序遍历</li>
</ul>
<p>Kafka主要用来处理海量数据流，这个场景的特点主要包括：</p>
<ul>
<li><strong>写操作：</strong>写并发要求非常高，基本得达到百万级TPS。顺序追加写日志即可，<strong>无需考虑更新操作（无需考虑更新操作是跟数据库最大的区别）</strong></li>
<li><strong>读操作：</strong>相对写操作来说，比较简单，只要能按照一定规则高效查询即可（Offset或者时间戳）</li>
</ul>
<blockquote>
<p>这个时候就显示了数据结构的重要性了，因为使用的场景不一样。Kafka无需考虑数据的更新操作，只要能快速写数据，快速读数据就可以了。那么，提高写速度的就只有通过顺序追加写的方式（这是由硬件底层决定的），需要考虑的就是怎么提高读速度。这种数据有序的情况下，最好方式就是哈希索引，在内存中维护一个映射关系，每次根据消息Offset查询消息的时候，从哈希表中得到文件偏移量。再去读文件就能快速定位。但是，哈希表是要常驻在内存的，对于Kafka来说不太现实。可以在写消息的时候，将Offset设计成一个有序的字段与消息一起记录，将消息文件按照一定大小分割成块，用一个表索引每个消息文件块中第一条消息记录的Offset和磁盘位置（分片和索引），就能够通过索引快速定位消息所在文件块的位置，再顺序遍历找到消息的位置。（为什么不用B+树索引呢？因为Kafka是要删除过期数据的，用B+树索引在删除的时候就需要大量的维护，而现在这种方式只要把块文件一删，块索引一删就完事了，而且<strong>对于生产者和消费者来说，后续都是追加写或者是顺序读</strong>）</p>
</blockquote>
<img src="Kafka稀疏索引.png" style="zoom: 67%;" />

<img src="Kafka储存机制.png" style="zoom:67%;" />

<blockquote>
<p>根据 Offset 查找消息过程：</p>
<ol>
<li>根据目标 Offset 定位到 Segment 文件</li>
<li>根据<code>.index</code>文件找到小于等于目标值 Offset 的最大 Offset 对应的索引项</li>
<li>根据索引项索引 Position 定位到<code>.log</code>文件中的指定位置</li>
<li>向下遍历找到目标Record</li>
</ol>
</blockquote>
<p>Kafka 是基于「主题 + 分区 + 副本 + 分段 + 索引」的结构，每一个分区副本Replica都对应一个Log，一个Log又分为多个日志分段Segment：</p>
<ul>
<li>Kafka 中消息是以主题 Topic 为基本单位进行归类的，这里的 Topic 是逻辑上的概念，实际上在磁盘存储是根据分区 Partition 存储的, 即每个 Topic 被分成多个 Partition，分区 Partition 的数量可以在主题 Topic 创建的时候进行指定。</li>
<li>Partition 分区主要是为了解决 Kafka 存储的水平扩展问题而设计的，如果一个 Topic 的所有消息都只存储到一个 Kafka Broker 上的话， 对于 Kafka 每秒写入几百万消息的高并发系统来说，这个 Broker 肯定会出现瓶颈， 故障时候不好进行恢复，所以 Kafka 将 Topic 的消息划分成多个 Partition，然后均衡的分布到整个 Kafka Broker 集群中。</li>
<li>Partition 分区内每条消息都会被分配一个唯一的消息 id，即我们通常所说的 偏移量 Offset，因此 Kafka 只能保证每个分区内部有序性，并不能保证全局有序性。</li>
<li>然后每个 Partition 分区又被划分成了多个 LogSegment，这是为了防止 Log 日志过大，Kafka 又引入了日志分段（LogSegment）的概念，将 Log 切分为多个 LogSegement，相当于一个巨型文件被平均分割为一些相对较小的文件，这样也便于消息的查找、维护和清理。这样在做历史数据清理的时候，直接删除旧的 LogSegement 文件就可以了。</li>
<li>Log 日志在物理上只是以文件夹的形式存储，文件夹的命名规则是<code>topic名称-分区号</code>，而每个 LogSegement 对应磁盘上的4个文件：<code>.index</code>索引文件（**.index文件中保存的是相对 Offset，相对于 Segment 中的第一条消息，能够保证 Offset 的值所占用的空间不会过大<strong>）、<code>.log</code>消息数据文件、<code>.snapshot</code>快照文件、<code>.timeindex</code>时间索引文件，</strong>这些文件以当前Segment的第一条消息的Offset命名**。</li>
</ul>
<h4 id="PageCache和零拷贝"><a href="#PageCache和零拷贝" class="headerlink" title="PageCache和零拷贝"></a>PageCache和零拷贝</h4><blockquote>
<p>在 Kafka 中，大量使用了 <strong>PageCache（ Java 中使用 mmap 实现，将进程的一段虚拟地址空间映射到文件的内存地址中，避免用户态和内核态之间的数据拷贝过程</strong>），这也是 Kafka 能实现高吞吐的重要因素之一。</p>
<p>PageCache 的作用是当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据页是否在 PageCache 中，如果命中则直接返回数据，从而避免了对磁盘IO操作；如果没有命中，操作系统则会向磁盘发起读取请求并将读取的数据页存入 PageCache 中，之后再将数据返回给进程。</p>
<p>同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检查数据页是否存在缓存中，如果不存在，则 PageCache 中添加相应的数据页，最后将数据写入对应的磁盘块中。被修改过的数据页会变成脏页，操作系统会在合适的时间把脏页中断数据写入磁盘（当PageCache 被读取或者失效的时候），以保持数据的一致性。</p>
</blockquote>
<p>为什么 Kafka 不自己管理缓存，而用 PageCache 呢，主要是因为：</p>
<ul>
<li>JVM 中一切皆对象，数据的对象储存会带来所谓 Object overhead 浪费空间</li>
<li>如果由 JVM 来管理缓存，会受到 GC 的影响，并且过大的堆也会拖累 GC 的效率，降低吞吐量</li>
<li>一旦程序崩溃，自己管理的缓存数据会全部丢失（用 PageCache 的话，PageCache 中的数据会随着内核中的 Flusher 线程的调度以及对 sync()&#x2F;fsync() 的调用写回到磁盘，就算进程崩溃，也不用担心数据丢失）</li>
</ul>
<p>Kafka还使用了<strong>零拷贝（Zero-Copy）</strong>来提高系统性能，其实对于消费者来说，读取的是原原本本的数据，不需要Kafka进行加工，所以数据其实不需要经过用户态（Kafka进程），而<strong>在内核态的时候，直接就把读取到的数据发送给消费者，这样就能够避免数据从内核态传输到用户态，再传输给用户的时候又从用户态拷贝到内核态再发送到网卡中发送给消费者</strong>。</p>
<p>Linux 2.4+ 内核通过<code>sendfile</code>系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件-网络发送由一个<code>sendfile</code>调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E9%9B%B6%E6%8B%B7%E8%B4%9D.png"></p>
<h4 id="日志清理机制"><a href="#日志清理机制" class="headerlink" title="日志清理机制"></a>日志清理机制</h4><blockquote>
<p>Kafka无论消息是否被消费，Kafka都会保留所有消息，随着写入数据不断增加，磁盘占用空间越来越大，为了控制占用空间就需要对消息进行清理。日志的清理比较简单，因为Log被分为多个日志分段Segment，最先创建的Segment一定是历史日志，只要根据一定的策略删除这个Segment即可。</p>
</blockquote>
<p>Kafka中由日志管理器（LogManager）周期性检测和清理日志分段文件，提供以下两种日志清理策略，</p>
<ul>
<li><strong>日志删除（Log Retention）：</strong>按照指定策略删除日志分段LogSegment<ul>
<li><strong>基于时间策略：</strong>能够设定日志分段文件保留多久<strong>（参数优先级毫秒log.retention.ms &gt; 分钟log.retention.minutes &gt; 小时log.retention.hours ）</strong>，但是并不是日志记录超过了设定的时间就立即删除，而是根据日志分段LogSegment中消息最大的时间戳来算，LogSegment中最大时间戳超过了设定的时间，这个LogSegment才会被删除（很好理解，<strong>因为一个LogSegment中有很多消息，但不是所有消息都是超过了设定的时间，只有所有消息都超过了设定的时间，才将这个LogSegment删除</strong>）。</li>
<li><strong>基于日志大小策略：</strong>能够检查整个分区副本日志大小是否超过设定的阈值，如果超过了，从日志文件中的第一个日志段开始寻找可以删除的日志分段集合（同理，如果有一个日志分段在被删和不被删之间反复横跳，也是不会被删的）。</li>
<li><strong>基于日志起始偏移量：</strong>判断依据是某日志分段 Segment 的下一个日志分段 Segment 的起始偏移量 baseOffset 是否小于等于 logStartOffset，若是，则可以删除此日志分段。</li>
</ul>
</li>
<li><strong>日志压缩（Log Compaction）：</strong>日志压缩对于相同 Key 不同 Value 的时候，只根据 Key 保留最后一个版本（即保留最新的Value）。</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9.png"></p>
<p><a href="http://dockone.io/article/2434664">http://dockone.io/article/2434664</a></p>
<p><a href="https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html">https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html</a></p>
<p><a href="https://blog.csdn.net/qq_34412985/article/details/120380212">https://blog.csdn.net/qq_34412985/article/details/120380212</a></p>
<h3 id="分区副本机制"><a href="#分区副本机制" class="headerlink" title="分区副本机制"></a>分区副本机制</h3><p>所谓的副本机制（Replication），也可以称之为备份机制，通常是指分布式系统在多台网络互联的机上保存有相同的数据拷贝。</p>
<p>Kafka 是有主题 Topic 概念的，而每个主题又进一步划分成若干个分区 Partition。副本 Replication 的概念实际上是在分区层级下定义的，每个分区配置有若干个副本。</p>
<p><strong>所谓副本（Replica），本质就是一个只能追加写消息的提交日志</strong>。根据 Kafka 副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些<strong>副本分散保存在不同的 Broker 上</strong>，从而能够对抗部分 Broker 宕机带来的数据不可用。</p>
<p><strong>Kafka 中分区的副本是基于领导者（Leader-based）的副本机制，生产者和消费者的所有请求由 Leader Replica 处理，Follower Replica 只负责异步地从 Leader Replica 中拉取数据同步，不对外提供服务。</strong></p>
<img src="Kafka Broker中的副本.png" alt="img" style="zoom: 33%;" />

<img src="Kafka副本角色.png" alt="img" style="zoom:33%;" />

<p>Leader Replica会成为 Kafka 集群的性能瓶颈，但是这种副本机制的好处是：</p>
<ul>
<li><strong>方便实现“Read-your-writes”：</strong>生产者写入后，消费者马上就能够获取到</li>
<li><strong>方便实现单调读（Monotonic Reads）</strong>：消费者多次消费消息时，不会存在从不同副本读取到不同数据的情况（因为都是从 Leader Replica中读）</li>
</ul>
<h4 id="In-sync-Replicas（ISR）"><a href="#In-sync-Replicas（ISR）" class="headerlink" title="In-sync Replicas（ISR）"></a>In-sync Replicas（ISR）</h4><p>ISR 中的副本都是与 Leader 同步的副本，相反，不在 ISR 中的追随者副本就被认为是与 Leader 不同步的。</p>
<p>ISR 是一个动态调整的集合，能否存在于 ISR 集合中的标准是<strong>Broker 端参数 replica.lag.time.max.ms 参数值，设定了 Follower 副本能够落后 Leader 副本的最长时间间隔</strong>，默认值是 10 秒，只要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 副本与 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息；否则，Follower 副本会被移动到 OSR 集合中。</p>
<h5 id="最少同步副本"><a href="#最少同步副本" class="headerlink" title="最少同步副本"></a>最少同步副本</h5><p><code>min.insync.replicas</code>参数能够再 Broker 或者主题级别进行配置，代表 ISR 列表中至少要有几个可用副本。当 ISR 列表中可用副本数量小于该值时，就认为整个分区处于不可用状态，此时客户端再向分区写入数据时就会抛出异常<code>NotEnoughReplicasExceptoin</code>。</p>
<h4 id="Out-sync-Replicas（OSR）"><a href="#Out-sync-Replicas（OSR）" class="headerlink" title="Out-sync Replicas（OSR）"></a>Out-sync Replicas（OSR）</h4><p>Kafka 把所有不在 ISR 中存活的副本都称为非同步副本（Out-sync Replicas）。</p>
<p>通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。<strong>Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举</strong>。</p>
<p>开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。</p>
<h4 id="元数据请求机制"><a href="#元数据请求机制" class="headerlink" title="元数据请求机制"></a>元数据请求机制</h4><p>在所有副本中，只有领导副本才能进行消息的读写处理。由于不同分区的领导副本可能在不同的 Broker 上，如果某个 Broker 收到了一个分区请求，但是该分区的领导副本并不在该 Broker 上，那么它就会向客户端返回一个 <code>Not a Leader for Partition</code> 的错误响应。为了解决这个问题，Kafka 提供了元数据请求机制。</p>
<p>首先<strong>集群中的每个 Broker 都会缓存所有主题的分区副本信息，客户端会定期发送发送元数据请求，然后将获取的元数据进行缓存</strong>。定时刷新元数据的时间间隔可以通过为客户端配置 <code>metadata.max.age.ms</code> 来进行指定。有了元数据信息后，客户端就知道了领导副本所在的 Broker，之后直接将读写请求发送给对应的 Broker 即可。</p>
<p>如果在定时请求的时间间隔内发生的分区副本的选举，则意味着原来缓存的信息可能已经过时了，此时还有可能会收到 <code>Not a Leader for Partition</code> 的错误响应，这种情况下客户端会再次求发出元数据请求，然后刷新本地缓存，之后再去正确的 Broker 上执行对应的操作。</p>
<p>![img](Kafka 元数据请求机制.jpg)</p>
<h4 id="Leader-Replica-选举"><a href="#Leader-Replica-选举" class="headerlink" title="Leader Replica 选举"></a>Leader Replica 选举</h4><blockquote>
<p>AR（All Replica）就是所有副本，ISR 与 OSR 的并集，存的是 Broker ID</p>
</blockquote>
<p>副本 Leader 选举是由 Controller Leader 来处理的。只有在 ISR 集合中的副本才有资格参选，随后选取 AR 中排序靠前的作为 Leader Replica。</p>
<h5 id="优先副本"><a href="#优先副本" class="headerlink" title="优先副本"></a>优先副本</h5><p>优先副本即 AR 集合列表中的第 1 个副本，比如 AR [1, 2, 0]，那么分区优先副本即为 1。引入优先副本的概念是为了 所以分区的 Leader Replica 在所有 Broker 中均匀分布，避免消费者或者生产者的请求集中在某几个 Broker 中。</p>
<p>如果优先副本被选举为 Leader Replica，则该Leader 称为 <strong>Prefect Leader</strong>。</p>
<h5 id="Leader-Replica-自动平衡"><a href="#Leader-Replica-自动平衡" class="headerlink" title="Leader Replica 自动平衡"></a>Leader Replica 自动平衡</h5><p>正常情况下，Kafka 本身会把 Leader Replica 均匀地分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些 Broker 宕机，Leader Replica重新选举之后会导致所有 Topic 中的 Leader Replica 过于集中在其他部分几台 Broker 上，造成集群负载不均衡。所以 Kafka 提供了 Leader Replica 自动平衡的机制。</p>
<p>当 Broker 中 中存在的 Leader Replica 不是优先副本的时候，不平衡数就会加 1，当不平衡比率达到设定阈值的时候就会触发自动平衡。</p>
<p>其中，Broker 中有三个参数：</p>
<ul>
<li><strong>auto.leader.rebalance.enable：</strong>默认为 True，自动 Leader Replica 平衡，生产环境中，Leader Replica 重选举的代价比较大，可能会带来性能影响，建议设置为 False 关闭。</li>
<li><strong>leader.imbalance.per.broker.percentage：</strong>默认是 10%，每个 Broker 允许的不平衡的比例。如果每个 Broker 都超过了这个值，控制器会触发 Leader Replica的平衡。</li>
<li><strong>leader.imbalance.check.interval.seconds：</strong>默认值 300 秒，检查 Leader Replica 负载是否平衡的间隔时间。</li>
</ul>
<h4 id="副本数据同步"><a href="#副本数据同步" class="headerlink" title="副本数据同步"></a>副本数据同步</h4><blockquote>
<p>为了保证数据一致性，只有被所有同步副本（ISR中所有副本）都保存了的数据才能被客户端读取到，即高水位。在这里不讨论 Kafka 事务，因为事务还依靠 LSO（Log Stable Offset）来判断事务型消费者的可见性</p>
<p><strong>高水位和日志末端位移是副本的两个重要属性，每个副本都会有。但是 Leader 副本的高水位就是分区的高水位。</strong></p>
</blockquote>
<ul>
<li><strong>高水位 HW（High Watermark）：</strong>生产者已提交消息位移 offset + 1，高水位用于定义消息的可见性，用来标识分区下的哪些消息是可以被消费者消费的，同时帮助 Kafka 完成副本的同步。</li>
<li><strong>日志末端位移 LEO（Log End Offset）：</strong>副本下一条消息写入的位移值。</li>
</ul>
<p>![img](Kafka HW 和 LEO.png)</p>
<h5 id="高水位更新机制"><a href="#高水位更新机制" class="headerlink" title="高水位更新机制"></a>高水位更新机制</h5><blockquote>
<p>每个副本对象都保存一组 HW 值和 LEO 值。而 Leader 副本所在 Broker 除了保存自己 LEO 值，还会保存所有 Follower 副本的 LEO 值（为了帮助 Leader 副本确定自己的高水位，即分区高水位）。</p>
</blockquote>
<p>注意区分保存 HW 值和 LEO 值的位置，参考下图，分别有：</p>
<ul>
<li>Broker 0 上 Leader 副本 LEO 值</li>
<li>Broker 0 上 Leader 副本储存所有 Follower 的 LEO 值</li>
<li>Broker 1 上 Follower 副本 LEO 值</li>
<li>Broker 0 上 Leader 副本 HW 值</li>
<li>Broker 1 上 Follower 副本 HW 值</li>
</ul>
<p>![img](Kafka HW 和 LEO 储存位置.png)</p>
<table>
<thead>
<tr>
<th align="center">更新对象</th>
<th>更新时机</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Broker 0 上 Leader 副本 LEO</td>
<td>Leader 副本接收到生产者发送的消息，写入到本地磁盘后，会更新其 LEO 值。</td>
</tr>
<tr>
<td align="center">Broker 0 上 远程副本 LEO</td>
<td>Follower 副本从 Leader 副本拉取消息时，会告诉 Leader 副本从哪个位移处开始拉取。Leader 副本会使用这个位移值来更新远程副本的 LEO。</td>
</tr>
<tr>
<td align="center">Broker 1 上 Follower 副本 LEO</td>
<td>Follower 副本从 Leader 副本拉取消息，写入到本地磁盘后，会更新其 LEO值。</td>
</tr>
<tr>
<td align="center">Broker 0 上 Leader 副本 HW</td>
<td>主要有两个更新时机：1. Leader 副本更新 LEO 后；2. 更新完远程副本 LEO 后。具体更新方法是：取 Leader 副本和所有 Leader 同步的远程副本 LEO 中的<strong>最小值</strong>。</td>
</tr>
<tr>
<td align="center">Broker 1 上 Follower 副本 HW</td>
<td>Follower 副本成功更新完 LEO 之后，会比较其 LEO 值与 Leader 副本发来的高水位值，并用两者的<strong>较小值</strong>去更新它自己的高水位。</td>
</tr>
</tbody></table>
<p>关于上述的与 Leader 副本保持同步，有两个判断条件：</p>
<ul>
<li>该远程 Follower 副本在 ISR 中。</li>
<li>该远程 Follower 副本 LEO 值落后于 Leader 副本 LEO 值的时间，不超过 Broker 端参数 replica.lag.time.max.ms 的值。</li>
</ul>
<p>乍一看，这两个条件好像是一回事，因为目前某个副本能否进入 ISR 就是靠第 2 个条件判断的。但有些时候，会发生这样的情况：即 Follower 副本已经“追上”了 Leader 的进度，却不在 ISR 中，比如某个刚刚重启回来的副本。如果 Kafka 只判断第 2 个条件的话，就可能出现某些副本具备了“进入 ISR”的资格，但却尚未进入到 ISR 中的情况。此时，分区高水位值就可能超过 ISR 中副本 LEO，而高水位 &gt; LEO 的情形是不被允许的。</p>
<h5 id="副本同步机制"><a href="#副本同步机制" class="headerlink" title="副本同步机制"></a>副本同步机制</h5><p>首先是初始状态。下面这张图中的 remote LEO 就是刚才的远程副本的 LEO 值。在初始状态时，所有值都是 0。</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B1.png" alt="img"></p>
<p>当生产者给主题分区发送一条消息后，状态变更为：</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B2.png" alt="img"></p>
<p>此时，Leader 副本成功将消息写入了本地磁盘，故 LEO 值被更新为 1。</p>
<p>Follower 再次尝试从 Leader 拉取消息。和之前不同的是，这次有消息可以拉取了，因此状态进一步变更为：</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B3.png" alt="img"></p>
<p>这时，Follower 副本也成功地更新 LEO 为 1。此时，Leader 和 Follower 副本的 LEO 都是 1，但各自的高水位依然是 0，还没有被更新。<strong>它们需要在下一轮的拉取中被更新</strong>，如下图所示：</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B4.png" alt="img"></p>
<p>在新一轮的拉取请求中，由于位移值是 0 的消息已经拉取成功，因此 Follower 副本这次请求拉取的是位移值 &#x3D;1 的消息。Leader 副本接收到此请求后，更新远程副本 LEO 为 1，然后更新 Leader 高水位为 1。做完这些之后，它会将当前已更新过的高水位值 1 发送给 Follower 副本。Follower 副本接收到以后，也将自己的高水位值更新成 1。至此，一次完整的消息同步周期就结束了。事实上，Kafka 就是利用这样的机制，实现了 Leader 和 Follower 副本之间的同步。</p>
<h5 id="Leader-Epoch"><a href="#Leader-Epoch" class="headerlink" title="Leader Epoch"></a>Leader Epoch</h5><blockquote>
<p>上面的例子举了两个副本的例子，如果扩展到多个副本，可能会存在问题。首先 Leader 副本高水位更新和 Follower 副本高水位更新在时间上是岔开的。Follower 副本高水位的更新是拉取数据时 Leader 返回当时的高水位，而 Leader 的高水位由所有远程副本 LEO中的最小值决定的。这种错配会导致“数据丢失”或者“数据不一致”的问题。</p>
</blockquote>
<blockquote>
<p>引入了 Leader Epoch之后，故障后恢复不再根据 HW 进行截断，而是根据 Epoch 和 Leader 的 LEO。</p>
</blockquote>
<blockquote>
<p>具体的问题示例，查看后面链接中的例子</p>
</blockquote>
<p>Leader Epoch 解决的就是上述的问题，由两部分数据组成：</p>
<ul>
<li><strong>Epoch：</strong>一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li>
<li><strong>起始位移（Start Offset）：</strong>Leader 副本在其 Epoch 值上写入的首条消息的位移。</li>
</ul>
<p>举例来说，某个 Partition 有两个 Leader Epoch，分别为 (0, 0) 和 (1, 100) 。这意味该 Partion 历经一次 Leader 副本变更，版本号为 0 的 Leader 从 Offset&#x3D;0 处开始写入消息，共写入了 100 条。而版本号为 1 的 Leader 则从 Offset&#x3D;100 处开始写入消息。</p>
<p>每个副本的 Leader Epoch 信息既缓存在内存中，也会定期写入消息目录下的 leaderer-epoch-checkpoint 文件中。当一个 Follower 副本从故障中恢复重新加入 ISR 中，它将：</p>
<ol>
<li>向 Leader 发送 LeaderEpochRequest，请求中包含了 Follower 的 Epoch 信息；</li>
<li><strong>Leader 将返回该 Follower 所在 Epoch 的 Last Offset；</strong></li>
<li>如果 Leader 与 Follower 处于同一 Epoch，那么 Last Offset 显然等于 Leader LEO；</li>
<li>如果 Follower 的 Epoch 落后于Leader，则Last Offset等于Follower Epoch + 1所对应的 Start Offset。这可能有点难以理解，我们还是以 (0, 0) 和 (1, 100) 为例进行说明：Offset&#x3D;100 的消息既是 Epoch&#x3D;1 的 Start Offset，也是 Epoch&#x3D;0 的 Last Offset；</li>
<li><strong>Follower 接收响应后根据返回的 Last Offset 截断数据；</strong></li>
<li>在数据同步期间，只要 Follower 发现 Leader 返回的 Epoch 信息与自身不一致，便会随之更新 Leader Epoch 并写入磁盘。</li>
</ol>
<p><a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/23%20%20Kafka%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3.md">Kafka副本机制详解</a></p>
<p><a href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/27%20%20%E5%85%B3%E4%BA%8E%E9%AB%98%E6%B0%B4%E4%BD%8D%E5%92%8CLeader%20Epoch%E7%9A%84%E8%AE%A8%E8%AE%BA.md">关于高水位和Leader Epoch的讨论</a></p>
<p><a href="https://www.cnblogs.com/koktlzz/p/14580109.html">Kafka：副本同步机制（HW&amp;Leader Epoch）</a></p>
<h3 id="Kafka事务原理"><a href="#Kafka事务原理" class="headerlink" title="Kafka事务原理"></a>Kafka事务原理</h3><blockquote>
<p>需要注意的几个点</p>
<ul>
<li>Kafka的事务机制，<strong>涉及到 Transactional producer 和 Transactional consumer</strong>, 两者配合使用，才能实现Producer端到Consumer端有且仅有一次的语义（end-to-end EOS）（而且Consumer端的下游业务也必须支持事务）</li>
<li>当然Kafka的Producer和Consumer是解耦的，也可以使用非Transactional的Consumer来消费Transactional的Producer生产的消息，但是此时就丢失了从生产者端到消费者端事务的支持</li>
<li><strong>通过事务机制，Kafka可以实现对多个Topic的多个Partition的原子性写入</strong>，即处于同一个事务内的所有消息，不管最终需要落地到哪个Topic的哪个Partition，最终结果都是要么全部写成功，要么全部写失败</li>
<li>Kafka的事务机制，在底层依赖于幂等性生产者，需要开启幂等性功能</li>
</ul>
</blockquote>
<p>为了支持事务机制，Kafka引入了两个新的组件：<strong>事务协调器Transaction Coordinator和Transaction log</strong></p>
<ul>
<li>事务协调器Transaction Coordinator是运行在Kafka Broker上的一个<strong>功能模块</strong>，不要和主题Topic的功能混淆</li>
<li><strong>Transaction log由一个主题<code>__transaction_state</code>实现，该主题存在多个分区，每个分区都有副本，所以就有Leader分区。</strong></li>
<li>由于Transaction Coordinator是Kafka Broker内部的一个模块，而Transaction log是Kafka中的一个内部Topic，所以Kafka能够通过内部的<strong>副本复制协议和Leader选举机制（Replication Protocol and Leader Election Processes）</strong>，来确保Transaction coordinator的可用性和事务状态Transaction state的持久性。</li>
<li>Transaction log内部主题Topic中储存的只是事务的最新状态和其相关元数据的信息，Kafka Producer生产的原始消息，仍然只是储存在Kafka Producer指定的Topic中。储存的事务状态Transaction state有：<code>Ongoing</code>、<code>Prepare commit</code>、<code>Completed</code>。</li>
</ul>
<h4 id="完整事务流程"><a href="#完整事务流程" class="headerlink" title="完整事务流程"></a>完整事务流程</h4><blockquote>
<p>事务包含两种信息：事务状态和原始消息</p>
<ul>
<li><p>事务状态记录在内部主题__transaction_state中</p>
</li>
<li><p>原始消息还是储存在用户主题中</p>
</li>
</ul>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/KafkaTransaction.png" alt="img"></p>
<h4 id="生产者事务"><a href="#生产者事务" class="headerlink" title="生产者事务"></a>生产者事务</h4><blockquote>
<p>步骤标号参考&lt;完整事务流程&gt;图中的顺序标号</p>
</blockquote>
<blockquote>
<p>生产者端需要设置全局唯一Transaction ID，并且开启幂等性</p>
</blockquote>
<h5 id="寻找Transaction-Coordinator"><a href="#寻找Transaction-Coordinator" class="headerlink" title="寻找Transaction Coordinator"></a>寻找Transaction Coordinator</h5><p>Producer向任意一个Broker发送<strong>FindCoordinator请求</strong>，找到<strong>Transaction Coordinator</strong>所在的位置。</p>
<p>Broker根据生产者发送过来的<strong>Transaction ID取Hash值</strong>，并根据Hash值<strong>对__transaction_state主题的分区数</strong>取余，即<code>Hash(TID) % Partition num</code>，**__transaction_state主题余数分区副本的Leader所在Broker中的Transaction Coordinator**就负责该生产者的事务记录。</p>
<h5 id="获取PID"><a href="#获取PID" class="headerlink" title="获取PID"></a>获取PID</h5><blockquote>
<p>对于生产者来说，事务中需要保存两个参数，一个是PID，一个是Producer的Epoch</p>
</blockquote>
<p>Producer向Transaction Coordinator发送<strong>InitPidRequest请求</strong>以获取PID，该行为是同步阻塞的，会等待Kafka处理完异常的事务再返回。如果Transaction Coordinator是第一次收到包含该Transaction ID的InitPidRequest请求，它会<strong>将&lt;Transaction ID, PID&gt;存入到Transaction Log中，从而保证对应的关系被持久化</strong>，即使Producer或者Broker宕机也能根据TID返回一样的PID。此外，<strong>每个PID还维护着一个Epoch，Epoch也会返回给Producer</strong>。</p>
<p>每次Producer发送InitPidRequest请求时（就是建立Session的时候，只会执行一次），<strong>Transaction Coordinator会递增该PID对应的Epoch</strong>，并完成以下操作</p>
<ul>
<li>具有相同PID，但Epoch小于最新Epoch的其他僵尸Producer新开启的事务都会被拒绝（屏蔽僵尸Producer对事务的影响）</li>
<li>Commit或者Abort之前Producer未完成的事务</li>
</ul>
<h5 id="开启事务"><a href="#开启事务" class="headerlink" title="开启事务"></a>开启事务</h5><p>Kafka从0.11.0.0版本开始，提供<code>beginTransaction()</code>方法用于开启一个事务。<strong>调用该方法后，Producer本地会记录已经开启了事务，但<code>Transaction Coordinator</code>只有在Producer发送第一条消息后才认为事务已经开启。</strong></p>
<h5 id="事务发送"><a href="#事务发送" class="headerlink" title="事务发送"></a>事务发送</h5><p>在这一个阶段包含整个事务数据处理过程，并且包含多种请求（以下按请求顺序）：</p>
<ol>
<li><strong>AddPartitionsToTxnRequest</strong>：一个Producer可能会给多个**&lt;Topic, Partition&gt;<strong>发送数据，在此之前，它需要先向Transaction Coordinator发送<code>AddPartitionsToTxnRequest</code>请求。Transaction Coordinator会将该</strong>&lt;Transaction, Topic, Partition&gt;<strong>存于Transaction Log内，并将其状态置为BEGIN（还会有事务超时时间的设置），如流程图4.1所示。有了该信息后，我们才可以在后续步骤中为每个</strong>&lt;Topic, Partition&gt;**设置COMMIT或者ABORT标记（如流程图5.2所示）。</li>
<li><strong>ProduceRequest</strong>：就是生产者实际需要发送的消息，除了Topic、Partition、Key、Value的数据，该请求还包含了<strong>PID、Epoch、SeqNumber</strong>。（流程图4.2所示）</li>
<li><strong>AddOffsetsToTxnRequest</strong>：<code>sendOffsetsToTransaction</code>方法能够将<strong>多组消息的发送和消费放入同一批处理内</strong>，该方法会先判断当前事务中是否传入了相同的Group ID，如果是，则到下一个请求，不会发出<strong>AddOffsetsToTxnRequest</strong>请求；否则，生产者会向Transaction Coordinator发送<strong>AddOffsetsToTxnRequest</strong>请求，事务协调器会将**事务中所有的&lt;Topic, Partition&gt;**存于Transaction Log中，并将其状态记为BEGIN，流程图4.3所示。</li>
<li><strong>TxnOffsetCommitRequest</strong>：Producer发送<strong>TxnOffsetCommitRequest</strong>请求给<strong>Consumer Coordinator</strong>，从而将本事务中包含的<strong>读操作相关</strong>的各个&lt;Topic， Partition&gt;的Offset持久化到内部的**__consumer_offsets主题<strong>中，如流程图4.4所示。</strong>Consumer Coordinator**会通过PID和对应的epoch来验证是否允许该Producer的请求。<ul>
<li>写入**__consumer_offsets**的Offset信息在当前事务Commit前对外是不可见的。也即在当前事务被Commit前，可认为该Offset尚未Commit，也即对应的消息尚未被完成处理。</li>
<li><strong>Consumer Coordinator</strong>并不会立即更新缓存中相应**&lt;Topic, Partition&gt;**的Offset，因为此时这些更新操作尚未被COMMIT或ABORT。</li>
</ul>
</li>
</ol>
<h5 id="Commit或Abort事务"><a href="#Commit或Abort事务" class="headerlink" title="Commit或Abort事务"></a>Commit或Abort事务</h5><blockquote>
<p> 数据写入完成之后，需要对事务进行Commit或者是Abort</p>
</blockquote>
<blockquote>
<p>Commit事务能够使得Producer写入的数据对下游Consumer可见；Abort事务能够使得Producer产生的数据对READ_COMMITTED等级的下游Consumer不可见</p>
</blockquote>
<p>Producer会发送<strong>EndTxnRequest</strong>请求，随后Transaction Coordinator会执行以下操作：</p>
<ul>
<li>向Transaction Log中写入<strong>PREPARE_COMMIT或者PREPARE_ABORT</strong>，流程图中5.1所示</li>
<li>事务协调器发出<strong>WriteTxnMarkerRequest</strong>请求至事务涉及到的各个分区的Leader，<strong>将COMMIT或ABORT信息以Transaction Marker的形式写入至用户数据日志以及Offset Log（__consumer_offsets）中</strong>，流程图5.2所示</li>
<li>待所有<strong>WriteTxnMarkerRequest</strong>请求响应后，事务协调器将<strong>COMPLETE_COMMIT或COMPLETE_ABORT信息</strong>写入Transaction Log中，表明该事务结束，流程图5.3所示（这个时候Transaction Log中关于该事务的消息都可以被移除，因为事务日志是以主题的方式储存的，所以也是会被定期删除）（<strong>COMPLETE_COMMIT或COMPLETE_ABORT信息的写入不需要等到所有副本的ACK，因为如果消息丢失，可以根据事务协议重发</strong>）</li>
</ul>
<h4 id="消费者事务"><a href="#消费者事务" class="headerlink" title="消费者事务"></a>消费者事务</h4><p>Kafka 消费者消费消息时可以指定具体的读隔离级别，当指定使用 read_committed 隔离级别时，在内部会使用存储在目标 topic-partition 中的 事务控制消息，来过滤掉没有提交的消息，包括回滚的消息和尚未提交的消息。</p>
<p>需要注意的是，过滤消息时，Kafka consumer 不需要跟 transactional coordinator 进行 rpc 交互，因为 topic 中存储的消息，包括正常的数据消息和控制消息，包含了足够的元数据信息来支持消息过滤。Kafka 消费者消费消息时也可以指定使用 read_uncommitted 隔离级别，此时目标 topic-partition 中的所有消息都会被返回，不会进行过滤。</p>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="Zookeeper简介"><a href="#Zookeeper简介" class="headerlink" title="Zookeeper简介"></a>Zookeeper简介</h3><h4 id="Zookeeper的作用"><a href="#Zookeeper的作用" class="headerlink" title="Zookeeper的作用"></a>Zookeeper的作用</h4><blockquote>
<p>目的是解决协作任务，如果是在单台机器上的多线程任务，能够使用操作系统提供的原语对资源进行访问，但是如果是跨多台机器分布式协作任务，就不能使用操作系统提供的原语了，因此需要一个中间件来解决分布式任务之间对资源的访问协调</p>
</blockquote>
<blockquote>
<p>本质是一个分布式文件系统，以及有事件通知机制，不适合用作海量数据的储存，一个znode解决能够储存的数据大小默认是1M</p>
</blockquote>
<p>Zookeeper基于分布式计算的核心概念而设计，主要目的是给开发人员提供一套容易理解和开发的接口，从而简化分布式系统构建的任务。Zookeeper是从文件系统API得到启发，提供一组简单的API，是的开发人员可以实现通用的协作任务，包括选举主节点、管理组内成员关系、管理元数据等。</p>
<ul>
<li>顺序一致性：从同一客户端发起的事务请求，最终会严格地按照顺序被应用到Zookeeper中</li>
<li>原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，集群中的所有机器都成功应用了某一个事务，要么都没有应用</li>
<li>单一视图：无论客户端连到哪一个Zookeeper服务器上，其看到的服务端数据模型都是一致的</li>
<li>可靠性：一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来</li>
<li>最终一致性：Zookeeper仅仅能保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态</li>
</ul>
<h4 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h4><blockquote>
<p>CAP理论：没有系统能够同时满足一致性、可用性、分区容错性这三种属性，只能尽量保证两种。Zookeeper 保证的是 CP。</p>
</blockquote>
<ul>
<li>一致性（Consistency）：等同于所有节点访问同一份最新的数据副本</li>
<li>可用性（Available）：每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据</li>
<li>分区容错性（Partition tolerance）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择</li>
</ul>
<h4 id="常用场景"><a href="#常用场景" class="headerlink" title="常用场景"></a>常用场景</h4><ul>
<li>主从模式</li>
<li>分布式锁</li>
<li>统一命名服务</li>
<li>统一配置管理</li>
<li>服务器节点动态上下线</li>
<li>软负载均衡</li>
</ul>
<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><p>ls、get、set、stat、create、delete、deleteall、help</p>
<p>ls、get都可以通过加<code>-w</code>参数监听节点的状态</p>
<h4 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h4><table>
<thead>
<tr>
<th></th>
<th>持久节点</th>
<th>临时节点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>无序节点</strong></td>
<td>持久无序节点</td>
<td>临时无序节点</td>
</tr>
<tr>
<td><strong>有序节点</strong></td>
<td>持久有序节点</td>
<td>临时有序节点</td>
</tr>
</tbody></table>
<ul>
<li>持久节点：创建了之后就一直存在，除非使用delete删除</li>
<li>临时节点：当创建该节点的客户端连接断开&#x2F;会话超时时，这个节点就会被删除（临时节点不允许有子节点）</li>
<li>有序节点：有序znode节点会被分配唯一个单调递增的整数序号，并附加到路径名上面，如创建的路径名<code>/tasks/task-</code>，分配序号是2，则最后创建出来的节点为<code>/tasks/task-2</code></li>
</ul>
<blockquote>
<p>znode中储存的数据主要包括存储数据、访问权限、子节点引用、节点状态信息</p>
<ul>
<li>data：znode存储的业务数据信息</li>
<li>ACL：记录客户端对znode节点的访问权限，如IP、Digest等</li>
<li>child：当前节点的子节点引用</li>
<li>stat：包含znode节点的状态信息，比如事务Id、版本号、时间戳等等</li>
</ul>
</blockquote>
<h4 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h4><blockquote>
<p>写数据会先写入Leader节点，然后通知Follower节点进行变更</p>
</blockquote>
<blockquote>
<p>读数据既能够从Leader节点中读，也能从Follower节点中读</p>
</blockquote>
<p><strong>角色</strong>：</p>
<ul>
<li>Leader节点：集群内唯一，事务请求的唯一调度和处理者，保证集群事务处理的顺序性</li>
<li>Follower节点：主要处理客户端的非事务请求，转发事务请求给Leader节点，参与事务请求Proposal的投票，参与Leader选举投票</li>
<li>Observer节点：3.3.0版本开始引入的服务器角色，会处理客户端的非事务请求，并转发事务请求给Leader节点，但是不参与任何形式的投票</li>
</ul>
<p><strong>节点工作状态</strong>：</p>
<ul>
<li>LOOKING：正在寻找Leader，处于该状态时，会认为当前集群中没有Leader，因此需要进入Leader的选举状态</li>
<li>FOLLOWING：跟随者状态，表明当前节点角色是Follower</li>
<li>LEADING：领导者状态，表明当前节点角色是Leader</li>
<li>OBSERVING：观察者状态，表明当前服务器角色是Oberver</li>
</ul>
<h3 id="Watcher监听机制"><a href="#Watcher监听机制" class="headerlink" title="Watcher监听机制"></a>Watcher监听机制</h3><blockquote>
<p>Zookeeper允许客户端对某个znode注册一个Watcher监听，当服务端的一些指定事件触发了Watcher，服务端就会发送一个事件通知该客户端znode节点的变化，客户端根据znode节点的变化类型作出处理</p>
</blockquote>
<h4 id="Watcher类型（待施工）"><a href="#Watcher类型（待施工）" class="headerlink" title="Watcher类型（待施工）"></a>Watcher类型（待施工）</h4><p>- </p>
<h3 id="Zookeeper原子广播协议ZAB"><a href="#Zookeeper原子广播协议ZAB" class="headerlink" title="Zookeeper原子广播协议ZAB"></a>Zookeeper原子广播协议ZAB</h3><blockquote>
<p>包括两种模式，消息广播和崩溃恢复</p>
</blockquote>
<img src="ZXID.png" alt="image-20220907164835614" style="zoom:50%;" />

<p>需要了解的两个ID</p>
<ul>
<li><strong>Server Id</strong> –  服务器Id，即配置文件中的myid，每个节点上的值都要设为不同</li>
<li><strong>ZXID</strong> – 事务ID，由一个64位的数字组成<ul>
<li>高32位是Leader的任期epoch，每次选举Leader，epoch都会自增加一</li>
<li>低32位是事务计数器，单调递增，每产生一个事务，计数器加一</li>
</ul>
</li>
</ul>
<h4 id="消息广播：Zookeeper如何保证事务的顺序一致性？"><a href="#消息广播：Zookeeper如何保证事务的顺序一致性？" class="headerlink" title="消息广播：Zookeeper如何保证事务的顺序一致性？"></a>消息广播：Zookeeper如何保证事务的顺序一致性？</h4><p><strong>Zookeeper的保证的最终一致性也叫顺序一致性</strong>，即每个节点的数据都是严格按照事务的发起顺序生效的。</p>
<blockquote>
<p>由ZXID的产生规则可以看出，在同一个Leader的任期内，ZXID是连续的，<strong>每个服务器节点都会保存着自己最新生效的ZXID</strong>，节点可以通过最新提案的ZXID与自身最新的ZXID是否相差<code>1</code>，来保证事务是严格按照顺序生效的</p>
</blockquote>
<p>Zookeeper集群的写入是由Leader节点协调的，<strong>类似于InnoDB引擎的二阶段提交</strong>，Leader会将提案广播给所有Follower，<strong>当收到半数以上的ACK时</strong>，就能够将提案生效(commit)并广播给所有Follower节点。</p>
<h5 id="详细过程-1"><a href="#详细过程-1" class="headerlink" title="详细过程"></a>详细过程</h5><ul>
<li>客户端发起一个事务，如果连接的是Follower，就会将事务转交给Leader处理</li>
<li>Leader收到请求后会生成一个ZXID，并将事务存到磁盘日志文件，此外，<strong>Leader会使用一个ConcurrentHashMap记录所有未提交的提案，key为ZXID，value是提案的信息</strong>，并将提案的ZXID与内容放到Map中，作为待提交的提案，并广播给Follower进行处理（Leader会为每个Follower都分配一个单独的FIFO队列，提案会被放到这个FIFO队列中）</li>
<li>Follower收到提案之后会把它写到磁盘日志文件中，完全写入后，发送ACK响应给Leader</li>
<li>Leader收到Follower的ACK信息后，根据ACK中的ZXID从Map中获取到对应的提案，并对ACK计数，提案提交判断流程是</li>
</ul>
<ol>
<li>首先判断该事务ZXID之前还有没有未提交的事务（map中是否有存在<code>ZXID - 1</code>的key），有，则暂时不能提交</li>
<li>随后判断提案是否收到半数以上ACK，如果达到半数，则可以提交，将磁盘中日志文件的提案加载到znode内存数据结构中，将该提案转移到一个<code>ConcurrentLinkedQueue toBeApplied</code>中，里面记录着能提交的提案，并将该ZXID从当前map中清除，根据queue逐个向Followers广播提交当前提案</li>
</ol>
<ul>
<li>Follower收到commit消息后，将磁盘中日志文件数据加载到znode内存数据结构中，数据即能生效</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E6%81%AF%E5%B9%BF%E6%92%AD1.png" alt="image-20220907203724192"></p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E6%81%AF%E5%B9%BF%E6%92%AD2.png" alt="image-20220907203759457"></p>
<p><a href="https://www.jianshu.com/p/cfeb2f97af8a">https://www.jianshu.com/p/cfeb2f97af8a</a></p>
<p><a href="https://time.geekbang.org/column/article/239261">https://time.geekbang.org/column/article/239261</a></p>
<p><a href="https://juejin.cn/post/6844903464414232584#heading-12">https://juejin.cn/post/6844903464414232584#heading-12</a></p>
<h4 id="崩溃恢复"><a href="#崩溃恢复" class="headerlink" title="崩溃恢复"></a>崩溃恢复</h4><blockquote>
<p>因为消息广播中的两阶段提交并不能解决Leader故障，因此需要崩溃恢复</p>
</blockquote>
<blockquote>
<p>Zookeeper正常工作时，Zab协议会一直处于广播模式，直到<strong>Leader故障</strong>或<strong>失去了指定数量的Follower</strong>，就会进入崩溃恢复模式</p>
</blockquote>
<p>崩溃恢复必须要保证两点：</p>
<ul>
<li>已经被Leader发送出去的提案，最终会被所有服务器都提交</li>
<li>只在Leader中出现的提案，都要丢弃</li>
</ul>
<h5 id="详细过程-2"><a href="#详细过程-2" class="headerlink" title="详细过程"></a>详细过程</h5><ul>
<li>每台Follow节点都会发起投票，每个节点都会先投自己一票，并同步给其他Follower节点。</li>
<li>节点收到其他节点的投票信息后，进行选票筛选，不是同一个投票轮次的投票信息会被丢弃，随后根据（ZXID，Server Id）投票，<strong>这里的ZXID是本地磁盘日志文件中的</strong>，ZXID最大值获选，如果ZXID相同，则Server Id更大者胜出，更新自己的投票信息，并开始新一轮的投票，直到相同票数信息超过半数</li>
<li>新Leader被选出，将epoch + 1，事务计数器置0，开始一个新的纪元<ul>
<li>Follower连接到新的Leader上，会对比自己的ZXID与Leader的ZXID，所有没见过的提案都会被排队并提交</li>
<li>当<code>旧的Leader</code>重新连接到<code>新的Leader</code>的时候，它已经变成了Follower，然后会对比ZXID，多出来的提案会被丢弃清除</li>
</ul>
</li>
</ul>
<p><a href="https://www.cnblogs.com/sunddenly/p/4138580.html">https://www.cnblogs.com/sunddenly/p/4138580.html</a></p>
<p><a href="https://www.51cto.com/article/704705.html">https://www.51cto.com/article/704705.html</a></p>
<h3 id="分布式锁的实现"><a href="#分布式锁的实现" class="headerlink" title="分布式锁的实现"></a>分布式锁的实现</h3><blockquote>
<p>羊群效应是指，一个节点挂掉，所有节点都去监听，然后做出反应，这样会给服务器带来巨大的压力</p>
</blockquote>
<blockquote>
<p>如果一个客户端的ZooKeeper会话过期，那么它所创建的短暂znode将会被删除，已持有的锁会被释放，或是放弃了申请锁的位置。使用锁的应用程序应当意识到它已经不再持有锁，应当清理它的状态，然后通过创建并尝试申请一个新的锁对象来重新启动。注意，这个过程是由应用程序控制的，而不是锁，因为锁是不能预知应用程序需要如何清理自己的状态。</p>
</blockquote>
<h4 id="非公平锁"><a href="#非公平锁" class="headerlink" title="非公平锁"></a>非公平锁</h4><blockquote>
<p>依赖临时节点客户端连接断开会自动删除的特性</p>
</blockquote>
<blockquote>
<p>存在的问题：羊群效应</p>
</blockquote>
<ol>
<li>客户端以同一个资源名称路径创建一个临时节点，如<code>/path/resourceA</code></li>
<li>客户端观察节点是否创建成功<ol>
<li>如果创建成功，则表明自己已经取得了资源的使用权</li>
<li>如果节点已经存在，则表明资源已经被其他客户端占用，则在该节点上设置监听器</li>
<li>如果其他异常失败，则进行节点创建重试，或者其他处理</li>
</ol>
</li>
<li>客户端使用完资源以后，主动删除节点，或者由于网络异常，连接断开，临时节点被删除</li>
<li>其他客户端监听到临时节点被删除的事件，开始重复步骤1</li>
</ol>
<h4 id="公平锁"><a href="#公平锁" class="headerlink" title="公平锁"></a>公平锁</h4><blockquote>
<p>依赖临时节点客户端连接断开会自动删除的特性</p>
</blockquote>
<blockquote>
<p>依赖顺序节点会自动产生单调递增的整数序号的特性</p>
</blockquote>
<blockquote>
<p>如果想要实现可公平重入锁，可以在获取到资源使用权的时候，在节点数据中写一个状态值，每次获取锁状态值就加一，释放锁就减一，为0的时候删除节点</p>
</blockquote>
<ol>
<li>客户端在同一个目录下创建一个临时顺序节点，如<code>/resourceA/A-000001</code></li>
<li>客户端获取资源目录下的所有节点，观察序号最小的节点是不是自己创建的序号<ol>
<li>如果是，则表示自己已经取得了资源的使用权</li>
<li>如果不是，则表示资源已经被其他客户端占用，在自己的前一个节点（序号比自己小的节点中，序号最大的节点）设置监听器</li>
<li>如果其他异常失败，则重试，或者其他处理</li>
</ol>
</li>
<li>客户端使用完资源以后，主动删除节点，或者由于网络异常，连接断开，临时节点被删除</li>
<li>在被删除节点上设置了监听器的客户端监听到删除事件，开始重复步骤2</li>
</ol>
<h3 id="Leader选举机制"><a href="#Leader选举机制" class="headerlink" title="Leader选举机制"></a>Leader选举机制</h3><p>跟崩溃恢复差不多</p>
<h3 id="Chroot特性"><a href="#Chroot特性" class="headerlink" title="Chroot特性"></a>Chroot特性</h3><blockquote>
<p>3.2.0版本后添加的特性，Chroot特性允许每个客户端为自己设置一个命名空间。如果一个客户端设置了Chroot，那么对Zookeeper集群的任何操作，都会被限制在自己的命名空间下。Chroot能够将客户端对应上Zookeeper的一颗子树，因此在多个应用公用一个Zookeeper集群的时候，有利于应用间的相互隔离。</p>
</blockquote>
<h3 id="ACL-访问控制"><a href="#ACL-访问控制" class="headerlink" title="ACL 访问控制"></a>ACL 访问控制</h3>]]></content>
  </entry>
  <entry>
    <title>文件名大小写引起的血案</title>
    <url>/2023/01/28/%E6%96%87%E4%BB%B6%E5%90%8D%E5%A4%A7%E5%B0%8F%E5%86%99%E5%BC%95%E8%B5%B7%E7%9A%84%E8%A1%80%E6%A1%88/</url>
    <content><![CDATA[<h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h2><p>之前写博客的时候，觉得 tags 标签英文字母都是小写的，不太好看，于是乎将其编辑了一遍，修改为首字母大写。但是，随之而来的就是页面访问出现了问题。</p>
<p>一开始时 Debug 的方向，想着是不是有的文件没有生成成功，或者是标签的设置是不是有问题。不过查看目录结构以后发现什么毛病都没有。</p>
<p>于是乎看浏览器的访问路径。因为 Hexo 生成的网页都是静态页面，所以浏览器的访问路径应该是跟目录的路径差不多。然后突然发现，虽然修改了 tags 标签，但是文件系统中的文件夹名没有变化，即没有重新生成。才想起来 Windows 文件名对大小写不敏感这回事。</p>
<p>这时觉得满心欢喜，本地访问没有问题了。然后 Git 一提交，GitHub Pages 上访问倒是不行了。是不是没提交成功？重新提交了好几遍都不行，Github 上确实也有提交的记录，只是文件夹的名字还是小写的。明显是 Git 默认对文件名大小写不敏感的问题。</p>
<p>这件事联想起了最新有个项目的 Git 代码，不知道为什么多了一个重名的分支，只有大小写不一样，导致联调的时候一堆问题，估摸着不知道是谁对文件名改动了。</p>
<h2 id="2-Windows-大小写敏感设置"><a href="#2-Windows-大小写敏感设置" class="headerlink" title="2. Windows 大小写敏感设置"></a>2. Windows 大小写敏感设置</h2><blockquote>
<p>C 盘中系统相关的目录最好不要修改，因为某些 Windows 应用程序可能不会使用大小写敏感来引用文件，此时如果修改了，应用程序将无法正常运行。</p>
</blockquote>
<p>默认情况下，Linux 是对文件名大小写敏感的，但是 Windows 是对文件名大小写不敏感的（可以通过新建文件进行测试），即：</p>
<ul>
<li>区分大小写：FOO.txt ≠ foo.txt ≠ Foo.txt</li>
<li>不区分大小写：FOO.txt &#x3D; foo.txt &#x3D; Foo.txt</li>
</ul>
<p>Windows 文件系统支持使用属性标志按目录设置区分大小写。 虽然标准行为是不区分大小写，但可以分配属性标志来使目录区分大小写，以便它能够识别可能仅大小写不同的 Linux 文件和文件夹。</p>
<p>在将驱动器装载到适用于 Linux 的 Windows 子系统 (WSL) 文件系统时，尤其如此。 在 WSL 文件系统中工作时，运行的是 Linux，因此默认情况下，文件和目录被视为区分大小写。</p>
<h3 id="2-1-敏感设置需求"><a href="#2-1-敏感设置需求" class="headerlink" title="2.1 敏感设置需求"></a>2.1 敏感设置需求</h3><ol>
<li><strong>自 Windows 10 内部版本 17107 开始，支持按目录区分大小写。 在 Windows 10 内部版本 17692 中，支持更新目录区分大小写</strong>，包括从 WSL 内检查和修改目录的区分大小写标志。 使用名为 <code>system.wsl_case_sensitive</code> 的扩展属性公开区分大小写。 对于不区分大小写的目录，此属性的值为 0；对于区分大小写的目录，此属性的值为 1。</li>
<li><strong>只能在 NTFS 格式的文件系统中的目录上设置区分大小写属性</strong>。默认情况下，WSL (Linux) 文件系统中的目录区分大小写（不能使用 fsutil.exe 工具设置为不区分大小写）。</li>
<li>以管理员的身份运行 DOS 或者 PowerShell。</li>
</ol>
<h3 id="2-2-检查是否大小写敏感"><a href="#2-2-检查是否大小写敏感" class="headerlink" title="2.2 检查是否大小写敏感"></a>2.2 检查是否大小写敏感</h3><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将 &lt;path&gt; 替换为文件路径</span></span><br><span class="line">&gt; fsutil.exe file queryCaseSensitiveInfo &lt;path&gt;</span><br></pre></td></tr></table></figure>

<p>例子：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">&gt; fsutil.exe file queryCaseSensitiveInfo ./</span><br><span class="line">已启用目录 D:\blog\ 的区分大小写属性。</span><br></pre></td></tr></table></figure>

<h3 id="2-3-设置目录大小写敏感"><a href="#2-3-设置目录大小写敏感" class="headerlink" title="2.3 设置目录大小写敏感"></a>2.3 设置目录大小写敏感</h3><blockquote>
<p>创建新目录的时候，新目录将会继承父目录的大小写敏感设置。</p>
</blockquote>
<p>修改目录大小写敏感设置需要以管理员的身份运行，并且还需要对目录具有 “写入属性”、“创建文件”、“创建文件夹” 和 “删除子文件夹和文件” 权限。</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启用大小写敏感</span></span><br><span class="line"><span class="comment"># 将 &lt;path&gt; 替换为文件路径</span></span><br><span class="line">&gt; fsutil.exe file setCaseSensitiveInfo &lt;path&gt; enable</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停用大小写敏感</span></span><br><span class="line">&gt; fsutil.exe file setCaseSensitiveInfo &lt;path&gt; disable</span><br></pre></td></tr></table></figure>



<h2 id="3-Git-大小写敏感设置"><a href="#3-Git-大小写敏感设置" class="headerlink" title="3. Git 大小写敏感设置"></a>3. Git 大小写敏感设置</h2><p>Git 默认不区分文件名大小写。</p>
<p>当你创建一个 <code>readme.md</code>文件之后，提交到线上代码仓库，然后在本地修改文件名为 <code>Readme.md</code>，再提交，会发现代码没有变化。</p>
<p>但是，可以通过 Git 配置文件中的 <code>core.ignorecase</code> 属性来配置是否大小写敏感（不敏感：true，敏感：false）。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">当前 Git 仓库</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置大小写敏感</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config core.ignorecase <span class="literal">false</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置大小写不敏感</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git config core.ignorecase <span class="literal">true</span></span></span><br></pre></td></tr></table></figure>

<p>设置之后，如果需要修改已经提交到代码仓库的文件，需要先删除文件之后，再添加后提交。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从 Git 中移除 readme.md 文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">rm</span> readme.md</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重新添加文件</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git add Readme.md</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提交</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git commit -m <span class="string">&#x27;Readme.md&#x27;</span></span></span><br></pre></td></tr></table></figure>



<hr>
<p>相关链接：</p>
<p><a href="https://learn.microsoft.com/zh-cn/windows/wsl/case-sensitivity">Windows区分大小写</a></p>
<p><a href="https://git-scm.com/docs/git-config/#Documentation/git-config.txt-coreignoreCase">Git core.ignoreCase配置</a></p>
]]></content>
      <categories>
        <category>日常踩坑</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次WSDL使用</title>
    <url>/2022/11/01/%E8%AE%B0%E4%B8%80%E6%AC%A1WSDL%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h3 id="1-起因"><a href="#1-起因" class="headerlink" title="1. 起因"></a>1. 起因</h3><p>突然要求对接公司集团的一个接口，给了一个 <code>http://192.168.1.1:7001/services/NotifyService?wsdl</code> 这种地址过来，然后还给了个说明文档，介绍用 XML 的格式发送报文。</p>
<p>一开始觉得跟 restful 接口差不多，就没多大留意。然后按照说明文档构建了 XML 格式的报文，跟下面的例子差不多。觉得没啥问题了，用 Postman 一测试，哎，怎么返回失败呢？首先是网络，检查了一下是通的。哪说明是调用接口的方式出了问题。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ReqRoot</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ReqTime</span>&gt;</span>2022-10-27 10:03:02<span class="tag">&lt;/<span class="name">ReqTime</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">BillNo</span>&gt;</span></span><br><span class="line">            000000</span><br><span class="line">        <span class="tag">&lt;/<span class="name">BillNo</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">Content</span>&gt;</span>消息成功发送<span class="tag">&lt;/<span class="name">Content</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">SendUser</span>&gt;</span>user<span class="tag">&lt;/<span class="name">SendUser</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">Address</span>&gt;</span>mobile<span class="tag">&lt;/<span class="name">Address</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ReqRoot</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="2-经过"><a href="#2-经过" class="headerlink" title="2. 经过"></a>2. 经过</h3><p>既然调用失败，那就百度一下为什么调用失败。看到给的链接后面有个 <code>wsdl</code> 的东西，感觉不太对劲，于是乎搜索了一下 <code>wsdl</code>。问了一下同事，说这是历史久远的接口。</p>
<h4 id="2-1-什么是WSDL？"><a href="#2-1-什么是WSDL？" class="headerlink" title="2.1 什么是WSDL？"></a>2.1 什么是WSDL？</h4><blockquote>
<p>WSDL 是一种使用 XML 编写的文档。这种文档可描述某个 Web service。它可规定服务的位置，以及此服务提供的操作（或方法）。</p>
</blockquote>
<blockquote>
<p>在 2001 年 3 月，WSDL 1.1 被 IBM、微软作为一个 W3C 记录（W3C note）提交到有关 XML 协议的 W3C XML 活动，用于描述网络服务。（W3C 记录仅供讨论。一项 W3C 记录的发布并不代表它已被 W3C 或 W3C 团队亦或任何 W3C 成员认可。）</p>
</blockquote>
<ul>
<li>WSDL（Web Services Description Language）指网络服务描述语言</li>
<li>WSDL 使用 XML 编写</li>
<li>WSDL 是一种 XML 文档</li>
<li>WSDL 用于描述网络服务</li>
<li>WSDL 也可用于定位网络服务</li>
<li>WSDL 还不是 W3C 标准</li>
</ul>
<h4 id="2-2-怎么使用"><a href="#2-2-怎么使用" class="headerlink" title="2.2 怎么使用"></a>2.2 怎么使用</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">可以用下面的这个链接进行测试，这是一个中国电视节目预告 Web 服务</span><br><span class="line">http://www.webxml.com.cn/webservices/ChinaTVprogramWebService.asmx?wsdl</span><br></pre></td></tr></table></figure>

<p>我主要关注的是怎么用这个接口，起码能保证业务上的功能正常再去关注这是什么东西。于是乎开始搜索怎么才能让接口调用成功。</p>
<p>突然发现这个接口是能够直接在浏览器上面打开的，不过其实打开了，也看不出什么东西，因为是一堆的 XML 文本。大概知道的就是这个文本里面定义了有哪些接口，还有接口的调用方式。</p>
<p><img src="/2022/11/01/%E8%AE%B0%E4%B8%80%E6%AC%A1WSDL%E4%BD%BF%E7%94%A8/wsdl%E7%BD%91%E9%A1%B5.png" alt="image-20221124152448072"></p>
<p>然后在网上找啊找，都没怎么找到比较好的方式去调用，但是起码别人是能调通的。观察发现怎么有一个应用叫 SoapUI 能够生成请求的报文体呢（截图截全一点对大家都好）。于是乎自己下载了一个下来看一下。</p>
<p><img src="/2022/11/01/%E8%AE%B0%E4%B8%80%E6%AC%A1WSDL%E4%BD%BF%E7%94%A8/soapui.png" alt="image-20221124153100317"></p>
<p>界面上就是上面的样子，填入 wsdl 的链接就能够比较直观的看到有哪些能够调用的方法，在对应的方法里面创建请求还会帮你填充好一些 SOAP 协议相关的东西（之前就是缺少了这一部分）。如果把请求部分填充完整，是能够使用 SoapUI 请求成功。</p>
<h4 id="2-3-使用-Postman-调用"><a href="#2-3-使用-Postman-调用" class="headerlink" title="2.3 使用 Postman 调用"></a>2.3 使用 Postman 调用</h4><p>既然能够使用 SoapUI 请求成功，那么就要尝试一下怎样才能使用 Postman 请求成功了。简单分为以下三步：</p>
<ul>
<li>将请求的 Content-Type 设置为 text&#x2F;xml</li>
<li>请求头部加上SOAPAction，值可以置为空</li>
<li>将 SoapUI 中接口自动生成的部分填入到请求体的 Body 中，然后填充必要的内容。（接口中给定的文档是 XML 文本，因此需要使用<code>&lt;![CDATA[your_data]]&gt;</code>的格式，your_data替换为接口文档中的格式）（CDATA 代表字符数据，其中的数据可以包含 XML 标记，但是还是会被当做字符串）</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">soapenv:Envelope</span> <span class="attr">xmlns:soapenv</span>=<span class="string">&quot;http://schemas.xmlsoap.org/soap/envelope/&quot;</span> <span class="attr">xmlns:dom</span>=<span class="string">&quot;http://domain.webservice.itsm.ffcs.com&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">soapenv:Header</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">soapenv:Body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dom:sendMsgNew</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dom:request</span>&gt;</span></span><br><span class="line">                &lt;![CDATA[</span><br><span class="line">                &lt;ReqRoot&gt;</span><br><span class="line">                    &lt;Body&gt;</span><br><span class="line">                        &lt;ReqTime&gt;2022-10-27 10:03:02&lt;/ReqTime&gt;</span><br><span class="line">                        &lt;BillNo&gt;</span><br><span class="line">                            000000</span><br><span class="line">                        &lt;/BillNo&gt;</span><br><span class="line">                        &lt;Content&gt;消息成功发送&lt;/Content&gt;</span><br><span class="line">                        &lt;SendUser&gt;user&lt;/SendUser&gt;</span><br><span class="line">                        &lt;Address&gt;mobile&lt;/Address&gt;</span><br><span class="line">                    &lt;/Body&gt;</span><br><span class="line">                &lt;/ReqRoot&gt;</span><br><span class="line">               ]]&gt;</span><br><span class="line">            <span class="tag">&lt;/<span class="name">dom:request</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dom:sendMsgNew</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">soapenv:Body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">soapenv:Envelope</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h3><p>其实就是 WSDL 与 Soap 的相关知识，但是其实现在很少用，等什么时候有空了再详细看看吧。</p>
]]></content>
      <categories>
        <category>日常踩坑</category>
      </categories>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title>网络抓包工具使用</title>
    <url>/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="1-网络抓包原理"><a href="#1-网络抓包原理" class="headerlink" title="1. 网络抓包原理"></a>1. 网络抓包原理</h2><blockquote>
<p>抓包实际上是分析网络协议的一种过程，只要网络数据流经过我们的节点，就能够对数据流进行抓包。</p>
</blockquote>
<h3 id="1-1-网卡或代理抓包"><a href="#1-1-网卡或代理抓包" class="headerlink" title="1.1 网卡或代理抓包"></a>1.1 网卡或代理抓包</h3><p>目前的抓包软件总体上可以分成两类：</p>
<ul>
<li>一种是设置代理抓取 http 包，比如Charles、mitmproxy这些软件。</li>
<li>另一种是直接抓取经过本机网络的所有协议包，其中最出名的就是 wireshark 以及 Linux 自带的抓包软件命令 tcpdump。</li>
</ul>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/15202375411791.jpg" alt="img"></p>
<h3 id="1-2-http-与-https"><a href="#1-2-http-与-https" class="headerlink" title="1.2 http 与 https"></a>1.2 http 与 https</h3><p>http 与 https 最大的区别是 http 的数据包是不加密的， https 的数据包是加密的。因此对于 wireshark 这种在数据链路层进行抓包的工具，所获取到的 https 数据包是加密的，因此无法分析包的内容。而 Charles 等只要安装 Charles 的证书，就能够解密 https 数据包的内容。</p>
<h2 id="2-tcpdump-使用"><a href="#2-tcpdump-使用" class="headerlink" title="2. tcpdump 使用"></a>2. tcpdump 使用</h2><blockquote>
<p>tcpdump可以把抓取到的数据包导出为 wireshark 格式的文件。</p>
</blockquote>
<blockquote>
<p>不重复造轮子，详情请看<a href="https://www.cnblogs.com/wongbingming/p/13212306.html">tcpdump使用指南</a>，或者参考 man 文档。</p>
</blockquote>
<h3 id="2-1-命令格式"><a href="#2-1-命令格式" class="headerlink" title="2.1 命令格式"></a>2.1 命令格式</h3><p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/20200628111325.png" alt="img"></p>
<ul>
<li><p><strong>option 可选参数</strong>：常用的有<code>-i 指定网卡名字</code>、<code>-w 保存抓包数据到文件</code>、<code>-r 从文件中读取抓包数据</code>、<code>-v\-vv\-vvv 输出更详细的内容</code>、<code>-n\-nn\-N 不解析域名\端口</code>。</p>
</li>
<li><p><strong>proto 类过滤器</strong>：根据协议进行过滤，可识别的关键词有： <code>tcp、udp、icmp、ip、ip6、arp、rarp、ether、wlan、fddi、tr、decnet</code>。</p>
</li>
<li><p><strong>direction 类过滤器</strong>：根据数据流向进行过滤，可识别的关键字有：<code>src、dst</code>，同时你可以使用逻辑运算符进行组合，比如 <code>src or dst</code>。</p>
</li>
<li><p><strong>type 类过滤器</strong>：可识别的关键词有：<code>host、net、port、portrange</code>，这些词后边需要再接参数。</p>
</li>
</ul>
<h3 id="2-2-输出内容格式"><a href="#2-2-输出内容格式" class="headerlink" title="2.2 输出内容格式"></a>2.2 输出内容格式</h3><blockquote>
<p>加入不同的可选参数，可能会使得输出的内容格式会有区别，但是能够触类旁通。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo tcpdump -nn src host 172.25.122.140</span></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">11:21:04.200134 IP 172.25.122.140.40236 &gt; 14.215.177.39.443: Flags [S], seq 3457030617, win 64240, options [mss 1460,sackOK,TS val 148049843 ecr 0,nop,wscale 7], length 0</span><br><span class="line">11:21:04.206621 IP 172.25.122.140.40236 &gt; 14.215.177.39.443: Flags [.], ack 3549651488, win 502, length 0</span><br><span class="line">11:21:04.212251 IP 172.25.122.140.40236 &gt; 14.215.177.39.443: Flags [P.], seq 0:517, ack 1, win 502, length 517</span><br></pre></td></tr></table></figure>

<p>以最后一条数据为例：</p>
<ol>
<li><strong>第一列，时分秒毫秒</strong> ：11:21:04.212251</li>
<li><strong>第二列，网络协议</strong> ：IP</li>
<li><strong>第三列，发送方 IP + 端口</strong>：IP - 172.25.122.140 | 端口 - 40236</li>
<li><strong>第四列，数据流向 &gt;</strong> ：从 172.25.122.140.40236 流向 14.215.177.39.443</li>
<li><strong>第五列，接收方 IP + 端口</strong>：IP - 14.215.177.39 | 端口 - 443</li>
<li><strong>第六列，冒号</strong><code>：</code></li>
<li><strong>第七列， 数据包内容</strong>：包括 Flags 标识符，seq 号，ack 号，win 窗口，数据长度 length</li>
</ol>
<p><strong>Flags 标识符</strong>：</p>
<ul>
<li><code>[S]</code> : SYN（开始连接）</li>
<li><code>[P]</code> : PSH（推送数据）</li>
<li><code>[F]</code> : FIN （结束连接）</li>
<li><code>[R]</code> : RST（重置连接）</li>
<li><code>[.]</code> : 没有 Flag （意思是除上面四种类型外的其他情况，有可能是 ACK 也有可能是 URG）</li>
</ul>
<h2 id="3-Wireshark-使用"><a href="#3-Wireshark-使用" class="headerlink" title="3. Wireshark 使用"></a>3. Wireshark 使用</h2><blockquote>
<p>Wireshark 使用中最难的，其实就是过滤器的使用，如何从海量请求数据包过滤出自己需要分析的内容。</p>
</blockquote>
<blockquote>
<p>Wireshark 包括两种过滤器：</p>
<ul>
<li><p>捕获过滤器：抓包的过滤规则，只抓取特定条件的数据包</p>
</li>
<li><p>显示过滤器：对抓取到的数据再次过滤，只显示符合特定规则数据包</p>
</li>
</ul>
</blockquote>
<h3 id="3-1-抓包示例"><a href="#3-1-抓包示例" class="headerlink" title="3.1 抓包示例"></a>3.1 抓包示例</h3><blockquote>
<p>使用 Wireshark 抓取 ping <a href="http://www.baidu.com/">www.baidu.com</a> 的数据包</p>
</blockquote>
<ol>
<li>打开 Wireshark 主界面。</li>
</ol>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104161119826.png" alt="image-20230104161119826"></p>
<ol start="2">
<li>选择菜单栏上<code>捕获-&gt;选项-&gt;选择网卡-&gt;开始</code>，或者直接在主界面中选择需要抓包的网卡就能够开始抓包（网卡通常只会处理发送给它自身地址的流量，如果想要捕获所有经过网卡的流量就需要开启混杂模式）。</li>
</ol>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104162023100.png" alt="image-20230104162023100"></p>
<ol start="3">
<li>启动之后，Wireshark 就处于抓包状态了。</li>
</ol>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104162352660.png" alt="image-20230104162352660"></p>
<ol start="4">
<li>在 cmd 窗口执行<code>ping www.baidu.com</code>命令。</li>
</ol>
<img src="image-20230104162742232.png" alt="image-20230104162742232" style="zoom:60%;" />

<ol start="5">
<li>操作完成之后，就能在 Wireshark 中看到抓取的数据包了。为了避免其他不相关的数据包影响分析，可以在过滤栏设置显示过滤条件。<code>ip.addr == 14.215.177.39 and icmp</code>表示只显示源主机 IP 或者目标主机 IP 为 <code>14.215.177.39</code> 且 ICMP 协议的数据包。</li>
</ol>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104163323961.png" alt="image-20230104163323961"></p>
<h3 id="3-2-界面介绍"><a href="#3-2-界面介绍" class="headerlink" title="3.2 界面介绍"></a>3.2 界面介绍</h3><p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104164142717.png" alt="image-20230104164142717"></p>
<h4 id="3-2-1-捕获过滤器"><a href="#3-2-1-捕获过滤器" class="headerlink" title="3.2.1 捕获过滤器"></a>3.2.1 捕获过滤器</h4><h5 id="3-2-1-1-界面设置"><a href="#3-2-1-1-界面设置" class="headerlink" title="3.2.1.1 界面设置"></a>3.2.1.1 界面设置</h5><p>能够在<code>捕获-&gt;捕获过滤器</code>中进行设置，只抓取符合规则的数据包，能够在开始抓包前进行设置。</p>
<img src="image-20230104170403368.png" alt="image-20230104170403368"  />

<img src="image-20230104170503369.png" alt="image-20230104170503369"  />

<h5 id="3-2-1-2-捕获过滤器规则"><a href="#3-2-1-2-捕获过滤器规则" class="headerlink" title="3.2.1.2 捕获过滤器规则"></a>3.2.1.2 捕获过滤器规则</h5><blockquote>
<p>捕获过滤器规则设置规则跟 tcpdump 是一样的，只介绍简单的过滤规则，详情请翻阅<a href="https://www.wireshark.org/docs/wsug_html_chunked/ChCapCaptureFilterSection.html">官方文档</a></p>
</blockquote>
<p>捕获过滤器的设置主要包括：网络类型 Type(host、net、port)、方向 Dir(src、dst)、协议类型 Proto(ether、ip、tcp、udp、http、icmp、ftp等)、逻辑运算符(&amp;&amp;、||、! 或者 and、or、not)。</p>
<p>以下显示一些使用示例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">host 172.18.5.4     # 只捕捉源地址或者目的地址为172.18.5.4的流量</span><br><span class="line">net 192.168.0.0/24  # 捕捉192.168.0.0/24网段中的流量</span><br><span class="line">src net 192.168.0.0/24 # 捕捉源地址IP在网段192.168.0.0/24中的流量</span><br><span class="line">not broadcast and not multicast # 仅捕捉单播流量，不捕捉广播和多播的流量</span><br></pre></td></tr></table></figure>



<h4 id="3-2-2-显示过滤器"><a href="#3-2-2-显示过滤器" class="headerlink" title="3.2.2 显示过滤器"></a>3.2.2 显示过滤器</h4><h5 id="3-2-2-1-界面设置"><a href="#3-2-2-1-界面设置" class="headerlink" title="3.2.2.1 界面设置"></a>3.2.2.1 界面设置</h5><p>对抓取到的数据再次过滤，只显示符合特定规则数据包。显示过滤器能够在<code>分析-&gt;显示过滤器</code>中进行设置。</p>
<p>在主界面中右键选择<code>作为过滤器应用</code>有惊喜，可以将界面中的一些数据作为过滤规则。</p>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104170955371.png" alt="image-20230104170955371"></p>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104173929469.png" alt="image-20230104173929469"></p>
<h5 id="3-2-2-2-显示过滤器规则"><a href="#3-2-2-2-显示过滤器规则" class="headerlink" title="3.2.2.2 显示过滤器规则"></a>3.2.2.2 显示过滤器规则</h5><blockquote>
<p>详细设置规则请参阅<a href="https://www.wireshark.org/docs/wsug_html_chunked/ChWorkBuildDisplayFilterSection.html">官方文档</a></p>
</blockquote>
<p>设置规则基本上是<code>key 运算符 value</code>的格式，运算符可以取<code>==、!=、===、!==、&gt;、&lt;、&gt;=、&lt;=、~</code>。</p>
<p>使用示例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tcp # 只显示tcp协议的数据包列表</span><br><span class="line">http # 只显示http协议的数据包列表</span><br><span class="line">ip.src == 192.168.1.104 # 显示源地址为192.168.1.104的数据包列表</span><br><span class="line">ip.dst == 192.168.1.104 # 显示目标地址为192.168.1.104的数据包列表</span><br><span class="line">ip.addr == 192.168.1.104 # 显示源IP地址或目标IP地址为192.168.1.104的数据包列表</span><br><span class="line">tcp.port == 80 # 显示源主机或者目的主机端口为80的数据包列表</span><br><span class="line">tcp.srcport == 80 # 只显示TCP协议的源主机端口为80的数据包列表</span><br><span class="line">tcp.dstport == 80 # 只显示TCP协议的目的主机端口为80的数据包列表</span><br><span class="line">http.request.method == &quot;GET&quot; # 只显示HTTP GET方法的</span><br></pre></td></tr></table></figure>

<h4 id="3-2-3-数据包列表区"><a href="#3-2-3-数据包列表区" class="headerlink" title="3.2.3 数据包列表区"></a>3.2.3 数据包列表区</h4><p>显示捕获到的数据包，每一行代表一个数据包，每个数据包包含编号、时间戳、源地址、目的地址、协议、长度以及数据包信息。不同的协议数据包使用了不同的颜色显示进行区分，可以在<code>视图-&gt;着色规则</code>中查看详细的设定。</p>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104175334347.png" alt="image-20230104175334347"></p>
<img src="image-20230104165647707.png" alt="image-20230104165647707" style="zoom:50%;" />

<h4 id="3-2-4-详细数据区"><a href="#3-2-4-详细数据区" class="headerlink" title="3.2.4 详细数据区"></a>3.2.4 详细数据区</h4><p>数据包详细信息面板是最重要的，包含了数据包的所有详细信息内容，从物理层到应用层的数据，用来查看协议中的每一个字段信息。</p>
<p><strong>参照 OSI 七层模型， 每一行代表着每一层中的数据，根据不同层次的不同协议，显示可能会有所不同。</strong></p>
<ul>
<li>Frame：物理层的数据帧状况，即全部数据。</li>
<li>Ethernet II：数据链路层以太网帧头部信息。</li>
<li>Internet Protocol Version 4：IPv4 包的头部信息。</li>
<li>Transmission Control Protocol：TCP 协议的头部信息。</li>
<li>Hypertext Transfer Protocol：HTTP数据包的所有信息。</li>
</ul>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104180450263.png" alt="image-20230104180450263"></p>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230105105346183.png" alt="image-20230105105346183"></p>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230105155339201.png" alt="image-20230105155339201"></p>
<h4 id="3-2-5-数据包字节区"><a href="#3-2-5-数据包字节区" class="headerlink" title="3.2.5 数据包字节区"></a>3.2.5 数据包字节区</h4><p>显示原始接收到的数据包字节，通过点击数据包详情区对应的字段，会在数据包字节区显示所对应的数据。</p>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230104181425789.png" alt="image-20230104181425789"></p>
<h3 id="3-3-抓包-TCP-三次握手"><a href="#3-3-抓包-TCP-三次握手" class="headerlink" title="3.3 抓包 TCP 三次握手"></a>3.3 抓包 TCP 三次握手</h3><h4 id="3-3-1-TCP-三次握手过程"><a href="#3-3-1-TCP-三次握手过程" class="headerlink" title="3.3.1 TCP 三次握手过程"></a>3.3.1 TCP 三次握手过程</h4><blockquote>
<p>要分析抓到数据包，首先需要了解其原理</p>
</blockquote>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230105165221418.png" alt="image-20230105165221418"></p>
<ol>
<li>TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了LISTEN（监听）状态；</li>
<li>TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位 SYN&#x3D;1，同时选择一个初始序列号 seq&#x3D;x ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。<strong>TCP规定，SYN报文段（SYN&#x3D;1的报文段）不能携带数据，但需要消耗掉一个序号</strong>；</li>
<li>TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK&#x3D;1，SYN&#x3D;1，确认号是ack&#x3D;x+1，同时也要为自己初始化一个序列号 seq&#x3D;y，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。<strong>这个报文也不能携带数据，但是同样要消耗一个序号</strong>；</li>
<li>TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK&#x3D;1，ack&#x3D;y+1，自己的序列号seq&#x3D;x+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。<strong>TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号</strong>；</li>
<li>当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了；</li>
</ol>
<h4 id="3-3-2-抓取-TCP-数据包"><a href="#3-3-2-抓取-TCP-数据包" class="headerlink" title="3.3.2 抓取 TCP 数据包"></a>3.3.2 抓取 TCP 数据包</h4><ol>
<li>在 cmd 使用 <code>ping jandan.net</code>获取域名 IP；</li>
</ol>
<img src="image-20230105114055220.png" alt="image-20230105114055220" style="zoom:50%;" />

<ol start="2">
<li>启动 Wireshark 开始抓包；</li>
<li>设置显示过滤器<code>ip.addr == 59.37.142.220 </code>；</li>
</ol>
<img src="image-20230105114302324.png" alt="image-20230105114302324" style="zoom:50%;" />

<ol start="4">
<li>浏览器中访问 <code>http://jandan.net/</code>；</li>
</ol>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230105142256229.png" alt="image-20230105142256229"></p>
<p>从图中可以看到，这次访问 TCP 握手的三个过程。注意的是因为我这不是第一次访问网站，所以会有关闭之前连接的请求。然后访问的时候发起了两个 TCP 请求，可以通过端口号的不同进行区分，我们关注的是本地 54418 端口到服务器 80 端口的 TCP 请求。</p>
<h4 id="3-3-3-第一次握手数据包"><a href="#3-3-3-第一次握手数据包" class="headerlink" title="3.3.3 第一次握手数据包"></a>3.3.3 第一次握手数据包</h4><p>WireShark 中显示了两个<code>Sequence Number</code>一个为<code>0</code>，一个为<code>605892471</code>，是因为 WireShark 为了更加容易观察进行的处理，一个是相对 Seq，一个是实际请求的 Seq，如果分别点击会发现数据包字节区是对应的同一块区域。</p>
<ul>
<li>SYN 标志位置为 1，表示向服务器请求建立连接；</li>
<li>Seq 序列号为 605892471，相对位置为 0，表示当前客户端当前还没有发送数据；</li>
</ul>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230105144046541.png" alt="image-20230105144046541"></p>
<h4 id="3-3-4-第二次握手数据包"><a href="#3-3-4-第二次握手数据包" class="headerlink" title="3.3.4 第二次握手数据包"></a>3.3.4 第二次握手数据包</h4><p>第二次握手数据包是服务器返回给客户端的，可以看到是从 59.37.142.220 的 80 端口到本机IP 的 54418 端口。跟 Seq 序列号一样，Acknowledgement number 也有相对与实际的区别。</p>
<ul>
<li>服务器响应新生成了 Seq 序列号：483437807，相对位置为 0， 表示当前服务器还没有发送数据；</li>
<li>ack 设置为请求的 Seq 序列号 + 1，即为 605892472，表示响应的是第一次握手的数据包；</li>
<li>ACK 和 SYN 标志位都置为 1，表示服务器同意建立连接并返回响应；</li>
</ul>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230105145332078.png" alt="image-20230105145332078"></p>
<h4 id="3-3-5-第三次握手数据包"><a href="#3-3-5-第三次握手数据包" class="headerlink" title="3.3.5 第三次握手数据包"></a>3.3.5 第三次握手数据包</h4><p>第三次握手就比较简单了，建立完成之后就能开始数据交互：</p>
<ul>
<li>Seq 序列号为服务器响应 ack 的值，相对位置为 1，表示已经发送一个数据；</li>
<li>ack 为服务器响应 Seq 序列号的值 + 1，表示当前客户端成功接收到的数据位数，虽然服务端没有发送任何有效数据，确认号还是被加 1，因为包含 SYN 或 FIN 标志位（并不会对有效数据的计数产生影响，因为含有SYN或FIN标志位的包并不携带有效数据)；</li>
<li>ACK 标志位置 1，表示已经接收到第二次握手数据包；</li>
</ul>
<p><img src="/2023/01/03/%E7%BD%91%E7%BB%9C%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/image-20230105150139918.png" alt="image-20230105150139918"></p>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
  </entry>
</search>
