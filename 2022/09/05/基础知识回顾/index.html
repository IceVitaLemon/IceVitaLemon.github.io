<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="JAVA基础知识集合（未施工）HashMap">
<meta property="og:type" content="article">
<meta property="og:title" content="基础知识回顾">
<meta property="og:url" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/index.html">
<meta property="og:site_name" content="IceVitalemon&#39;s Blog">
<meta property="og:description" content="JAVA基础知识集合（未施工）HashMap">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/JVM%20IO%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/IO%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/epoll.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E5%8D%95Reactor%E5%8D%95%E7%BA%BF%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/JAVA_AIO.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Proactor%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E9%97%B4%E9%9A%99%E9%94%81%E6%AD%BB%E9%94%81.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/MVCC.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/MVCC%E6%B0%B4%E4%BD%8D.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/join.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/k8s%E7%BB%84%E4%BB%B6.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/k8s%E7%BD%91%E7%BB%9C.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/kafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E5%88%86%E5%8C%BA%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5Range.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5RoundRobin.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5RoundRobin%E7%BC%BA%E7%82%B9.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5StickyAssignor.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5StickyAssignor2.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1%E7%8A%B6%E6%80%81%E6%9C%BA.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1JoinGroup%E8%AF%B7%E6%B1%82.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1SyncGroup%E8%AF%B7%E6%B1%82.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%96%B0%E6%88%90%E5%91%98%E5%85%A5%E7%BB%84.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%88%90%E5%91%98%E7%A6%BB%E7%BB%84.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%88%90%E5%91%98%E5%B4%A9%E6%BA%83%E7%A6%BB%E7%BB%84.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E7%BB%84%E6%88%90%E5%91%98%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%81%8F%E7%A7%BB%E9%87%8F%E6%8F%90%E4%BA%A4%E6%96%B9%E6%B3%95.jpeg">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E7%A8%80%E7%96%8F%E7%B4%A2%E5%BC%95.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%82%A8%E5%AD%98%E6%9C%BA%E5%88%B6.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E9%9B%B6%E6%8B%B7%E8%B4%9D.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%20Broker%E4%B8%AD%E7%9A%84%E5%89%AF%E6%9C%AC.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E8%A7%92%E8%89%B2.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B1.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B2.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B3.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B4.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/KafkaTransaction.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/ZXID.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E6%81%AF%E5%B9%BF%E6%92%AD1.png">
<meta property="og:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E6%81%AF%E5%B9%BF%E6%92%AD2.png">
<meta property="article:published_time" content="2022-09-05T02:07:20.000Z">
<meta property="article:modified_time" content="2022-12-05T03:13:43.834Z">
<meta property="article:author" content="Junhao Lin">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png">


<link rel="canonical" href="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/","path":"2022/09/05/基础知识回顾/","title":"基础知识回顾"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>基础知识回顾 | IceVitalemon's Blog</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">IceVitalemon's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#JAVA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="nav-text">JAVA基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E5%90%88%EF%BC%88%E6%9C%AA%E6%96%BD%E5%B7%A5%EF%BC%89"><span class="nav-text">集合（未施工）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#JVM%EF%BC%88%E6%9C%AA%E6%96%BD%E5%B7%A5%EF%BC%89"><span class="nav-text">JVM（未施工）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%88%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE%EF%BC%89"><span class="nav-text">多线程（思维导图）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Java%E7%BD%91%E7%BB%9CIO"><span class="nav-text">Java网络IO</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#I-x2F-O"><span class="nav-text">I&#x2F;O</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%98%BB%E5%A1%9E%E5%92%8C%E9%9D%9E%E9%98%BB%E5%A1%9E"><span class="nav-text">阻塞和非阻塞</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E5%92%8C%E5%BC%82%E6%AD%A5"><span class="nav-text">同步和异步</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Linux%E4%B8%AD%E7%9A%84select%E3%80%81poll%E3%80%81-epoll"><span class="nav-text">Linux中的select、poll、 epoll</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#select-x2F-poll"><span class="nav-text">select&#x2F;poll</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#epoll"><span class="nav-text">epoll</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E9%98%BB%E5%A1%9E%EF%BC%88JAVA-BIO%EF%BC%89"><span class="nav-text">同步阻塞（JAVA BIO）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E7%AB%AFDemo"><span class="nav-text">服务端Demo</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AFDemo"><span class="nav-text">客户端Demo</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E9%9D%9E%E9%98%BB%E5%A1%9E%EF%BC%88JAVA-NIO%EF%BC%89"><span class="nav-text">同步非阻塞（JAVA NIO）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E7%AB%AFDemo-1"><span class="nav-text">服务端Demo</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AFDemo-1"><span class="nav-text">客户端Demo</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-text">优化线程模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Reactor%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F"><span class="nav-text">Reactor设计模式</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%8D%95Reactor%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-text">单Reactor单线程模型</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-text">单Reactor多线程模型</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="nav-text">主从Reactor多线程模型</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E9%9D%9E%E9%98%BB%E5%A1%9E%EF%BC%88JAVA-AIO%EF%BC%89"><span class="nav-text">异步非阻塞（JAVA AIO）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8Demo"><span class="nav-text">服务器Demo</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Proactor%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F"><span class="nav-text">Proactor设计模式</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%EF%BC%88%E9%83%A8%E5%88%86%E6%96%BD%E5%B7%A5%EF%BC%89"><span class="nav-text">计算机基础（部分施工）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C"><span class="nav-text">计算机网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%88%E9%83%A8%E5%88%86%E6%96%BD%E5%B7%A5%EF%BC%89"><span class="nav-text">操作系统（部分施工）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E7%B1%BB%E5%9E%8B"><span class="nav-text">上下文切换类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E5%8F%91%E7%94%9F%E5%9C%A8%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%EF%BC%9F"><span class="nav-text">进程切换发生在什么时候？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MySQL"><span class="nav-text">MySQL</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MyISAM%E5%92%8CInnoDB%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-text">MyISAM和InnoDB的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B4%A2%E5%BC%95"><span class="nav-text">索引</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%EF%BC%88%E5%88%86%E7%B1%BB%E8%A7%92%E5%BA%A6%EF%BC%89"><span class="nav-text">索引类型（分类角度）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E4%B8%8E%E9%9D%9E%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%EF%BC%88%E7%89%A9%E7%90%86%E5%82%A8%E5%AD%98%E8%A7%92%E5%BA%A6%EF%BC%89"><span class="nav-text">聚簇索引与非聚簇索引（物理储存角度）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#B-%E6%A0%91%E7%B4%A2%E5%BC%95%E5%92%8C%E5%93%88%E5%B8%8C%E7%B4%A2%E5%BC%95%EF%BC%88%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%A7%92%E5%BA%A6%EF%BC%89"><span class="nav-text">B+树索引和哈希索引（数据结构角度）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E9%80%82%E5%BA%94%E5%93%88%E5%B8%8C%E7%B4%A2%E5%BC%95"><span class="nav-text">自适应哈希索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95%E5%B0%B1%E6%98%AF%E8%81%9A%E7%B0%87%E7%B4%A2%E5%BC%95%E5%90%97%EF%BC%9F"><span class="nav-text">主键索引就是聚簇索引吗？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E3%80%81%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95%E3%80%81%E7%B4%A2%E5%BC%95%E6%9C%80%E5%B7%A6%E5%8C%B9%E9%85%8D%E5%8E%9F%E5%88%99"><span class="nav-text">什么是联合索引、覆盖索引、索引最左匹配原则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%B4%E4%B8%80%E4%B8%8B%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8"><span class="nav-text">说一下索引下推</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8B%E5%8A%A1"><span class="nav-text">事务</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%9B%9B%E5%A4%A7%E7%89%B9%E6%80%A7%EF%BC%88ACID%EF%BC%89"><span class="nav-text">事务的四大特性（ACID）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-text">可能出现的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9A%94%E7%A6%BB%E7%AD%89%E7%BA%A7"><span class="nav-text">隔离等级</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%94%81-%E3%80%81%E9%97%B4%E9%9A%99%E9%94%81%E3%80%81Next-Key-Lock"><span class="nav-text">锁 、间隙锁、Next-Key Lock</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6MVCC"><span class="nav-text">多版本并发控制MVCC</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%87%E8%AF%86ID"><span class="nav-text">标识ID</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%A6%E7%BB%86%E8%BF%87%E7%A8%8B"><span class="nav-text">详细过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ABA%E9%97%AE%E9%A2%98"><span class="nav-text">ABA问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#binlog%E3%80%81redolog"><span class="nav-text">binlog、redolog</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#binlog%EF%BC%88%E5%BD%92%E6%A1%A3%E6%97%A5%E5%BF%97%EF%BC%89"><span class="nav-text">binlog（归档日志）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#redo-log%EF%BC%88%E9%87%8D%E5%81%9A%E6%97%A5%E5%BF%97%EF%BC%89"><span class="nav-text">redo log（重做日志）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%93%E5%86%B2%E7%BB%93%E6%9E%84"><span class="nav-text">缓冲结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4"><span class="nav-text">二阶段提交</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F"><span class="nav-text">主从模式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B"><span class="nav-text">详细流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E5%A4%8D%E5%88%B6%E9%97%AE%E9%A2%98"><span class="nav-text">循环复制问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#inner-join%E3%80%81left-join%E3%80%81right-join%E3%80%81full-join"><span class="nav-text">inner join、left join、right join、full join</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#on%E5%92%8Cwhere%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-text">on和where的区别</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E8%A1%A8%E9%A9%B1%E5%8A%A8%E5%A4%A7%E8%A1%A8"><span class="nav-text">小表驱动大表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%EF%BC%88%E6%9C%AA%E6%96%BD%E5%B7%A5%EF%BC%89"><span class="nav-text">数据库优化（未施工）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spring%EF%BC%88%E6%9C%AA%E6%96%BD%E5%B7%A5%EF%BC%89"><span class="nav-text">Spring（未施工）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DI-IOC-AOP"><span class="nav-text">DI IOC AOP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F"><span class="nav-text">Bean的生命周期</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spring-MVC%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-text">Spring MVC的工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spring-MVC%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3"><span class="nav-text">Spring MVC的常用注解</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k8s%EF%BC%88%E5%BE%85%E6%94%B6%E6%8B%BE%EF%BC%89"><span class="nav-text">k8s（待收拾）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#k8s%E7%9A%84%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4"><span class="nav-text">k8s的操作命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#k8s%E7%9A%84%E7%BB%84%E4%BB%B6"><span class="nav-text">k8s的组件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A7%E5%88%B6%E5%99%A8%E7%B1%BB%E5%9E%8B"><span class="nav-text">控制器类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K8S%E7%BD%91%E7%BB%9C"><span class="nav-text">K8S网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B"><span class="nav-text">资源类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pod%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F"><span class="nav-text">Pod的生命周期</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Service%E7%9A%84%E7%BD%91%E7%BB%9C%E6%B5%81%E5%90%91"><span class="nav-text">Service的网络流向</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ipvs%E5%AF%B9%E6%AF%94iptables"><span class="nav-text">ipvs对比iptables</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Headless-Service"><span class="nav-text">Headless Service</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%B2%E5%92%8C%E6%80%A7%EF%BC%8C%E5%8F%8D%E4%BA%B2%E5%92%8C%E6%80%A7%EF%BC%8C%E6%B1%A1%E7%82%B9%EF%BC%8C%E6%B1%A1%E7%82%B9%E5%AE%B9%E5%BF%8D"><span class="nav-text">亲和性，反亲和性，污点，污点容忍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%B2%E5%92%8C%E6%80%A7%EF%BC%88pod%E7%9A%84%E7%AD%96%E7%95%A5%EF%BC%89"><span class="nav-text">亲和性（pod的策略）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B1%A1%E7%82%B9%EF%BC%88node%E7%9A%84%E7%AD%96%E7%95%A5%EF%BC%89"><span class="nav-text">污点（node的策略）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prometheus-operator"><span class="nav-text">Prometheus-operator</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis%EF%BC%88%E6%9C%AA%E6%96%BD%E5%B7%A5%EF%BC%89"><span class="nav-text">Redis（未施工）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka"><span class="nav-text">Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B1%82%E9%9D%A2"><span class="nav-text">服务器层面</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E9%A2%98%E5%B1%82%E9%9D%A2"><span class="nav-text">主题层面</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader%E9%80%89%E4%B8%BE"><span class="nav-text">Leader选举</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">生产者客户端工作原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="nav-text">分区策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81"><span class="nav-text">数据可靠性保证</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98"><span class="nav-text">数据重复问题</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%BC%A0%E9%80%92%E7%9A%84%E8%AF%AD%E4%B9%89"><span class="nav-text">数据传递的语义</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%B9%82%E7%AD%89%E6%80%A7"><span class="nav-text">生产者幂等性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">消费者客户端工作原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E7%9A%84%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="nav-text">分区的分配策略</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#RangeAssignor"><span class="nav-text">RangeAssignor</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RoundRobinAssignor"><span class="nav-text">RoundRobinAssignor</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#StickyAssignor"><span class="nav-text">StickyAssignor</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="nav-text">消费者组再平衡</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Group-Coordinator"><span class="nav-text">Group Coordinator</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%8A%B6%E6%80%81%E6%9C%BA"><span class="nav-text">消费者组状态机</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%8D%E5%B9%B3%E8%A1%A1%E5%85%A8%E6%B5%81%E7%A8%8B"><span class="nav-text">再平衡全流程</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5-FIND-COORDINATOR"><span class="nav-text">第一步 FIND_COORDINATOR</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5-JOIN-GROUP"><span class="nav-text">第二步 JOIN_GROUP</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5-SYNC-GROUP"><span class="nav-text">第三步 SYNC_GROUP</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Heartbeat-%E7%BA%BF%E7%A8%8B"><span class="nav-text">Heartbeat 线程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%86%85%E9%83%A8Offset-Topic"><span class="nav-text">内部Offset Topic</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8F%90%E4%BA%A4%E5%81%8F%E7%A7%BB%E9%87%8F"><span class="nav-text">提交偏移量</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4"><span class="nav-text">自动提交</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4"><span class="nav-text">手动提交</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Broker%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-text">Broker工作原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Zookeeper%E4%B8%AD%E5%82%A8%E5%AD%98%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="nav-text">Zookeeper中储存的信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Broker%E4%B8%AD%E7%9A%84Controller%E7%BB%84%E4%BB%B6"><span class="nav-text">Broker中的Controller组件</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-text">工作流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Controller%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84"><span class="nav-text">Controller内部结构</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E5%82%A8%E5%AD%98"><span class="nav-text">数据的储存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PageCache%E5%92%8C%E9%9B%B6%E6%8B%B7%E8%B4%9D"><span class="nav-text">PageCache和零拷贝</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86%E6%9C%BA%E5%88%B6"><span class="nav-text">日志清理机制</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="nav-text">分区副本机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#In-sync-Replicas%EF%BC%88ISR%EF%BC%89"><span class="nav-text">In-sync Replicas（ISR）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%80%E5%B0%91%E5%90%8C%E6%AD%A5%E5%89%AF%E6%9C%AC"><span class="nav-text">最少同步副本</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Out-sync-Replicas%EF%BC%88OSR%EF%BC%89"><span class="nav-text">Out-sync Replicas（OSR）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE%E8%AF%B7%E6%B1%82%E6%9C%BA%E5%88%B6"><span class="nav-text">元数据请求机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader-Replica-%E9%80%89%E4%B8%BE"><span class="nav-text">Leader Replica 选举</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BC%98%E5%85%88%E5%89%AF%E6%9C%AC"><span class="nav-text">优先副本</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Leader-Replica-%E8%87%AA%E5%8A%A8%E5%B9%B3%E8%A1%A1"><span class="nav-text">Leader Replica 自动平衡</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5"><span class="nav-text">副本数据同步</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%AB%98%E6%B0%B4%E4%BD%8D%E6%9B%B4%E6%96%B0%E6%9C%BA%E5%88%B6"><span class="nav-text">高水位更新机制</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6"><span class="nav-text">副本同步机制</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Leader-Epoch"><span class="nav-text">Leader Epoch</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86"><span class="nav-text">Kafka事务原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E4%BA%8B%E5%8A%A1%E6%B5%81%E7%A8%8B"><span class="nav-text">完整事务流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="nav-text">生产者事务</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AF%BB%E6%89%BETransaction-Coordinator"><span class="nav-text">寻找Transaction Coordinator</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96PID"><span class="nav-text">获取PID</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BC%80%E5%90%AF%E4%BA%8B%E5%8A%A1"><span class="nav-text">开启事务</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BA%8B%E5%8A%A1%E5%8F%91%E9%80%81"><span class="nav-text">事务发送</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Commit%E6%88%96Abort%E4%BA%8B%E5%8A%A1"><span class="nav-text">Commit或Abort事务</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="nav-text">消费者事务</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Zookeeper"><span class="nav-text">Zookeeper</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Zookeeper%E7%AE%80%E4%BB%8B"><span class="nav-text">Zookeeper简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Zookeeper%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-text">Zookeeper的作用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CAP%E7%90%86%E8%AE%BA"><span class="nav-text">CAP理论</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-text">常用场景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="nav-text">常用命令</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B"><span class="nav-text">节点类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E8%A7%92%E8%89%B2"><span class="nav-text">集群角色</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Watcher%E7%9B%91%E5%90%AC%E6%9C%BA%E5%88%B6"><span class="nav-text">Watcher监听机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Watcher%E7%B1%BB%E5%9E%8B%EF%BC%88%E5%BE%85%E6%96%BD%E5%B7%A5%EF%BC%89"><span class="nav-text">Watcher类型（待施工）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Zookeeper%E5%8E%9F%E5%AD%90%E5%B9%BF%E6%92%AD%E5%8D%8F%E8%AE%AEZAB"><span class="nav-text">Zookeeper原子广播协议ZAB</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E5%B9%BF%E6%92%AD%EF%BC%9AZookeeper%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%A1%BA%E5%BA%8F%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F"><span class="nav-text">消息广播：Zookeeper如何保证事务的顺序一致性？</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%A6%E7%BB%86%E8%BF%87%E7%A8%8B-1"><span class="nav-text">详细过程</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B4%A9%E6%BA%83%E6%81%A2%E5%A4%8D"><span class="nav-text">崩溃恢复</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%A6%E7%BB%86%E8%BF%87%E7%A8%8B-2"><span class="nav-text">详细过程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">分布式锁的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9D%9E%E5%85%AC%E5%B9%B3%E9%94%81"><span class="nav-text">非公平锁</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%AC%E5%B9%B3%E9%94%81"><span class="nav-text">公平锁</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Leader%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6"><span class="nav-text">Leader选举机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chroot%E7%89%B9%E6%80%A7"><span class="nav-text">Chroot特性</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <a href="/">
      <img class="site-author-image" itemprop="image" alt="Junhao Lin"
        src="/images/avatar.gif">
    </a>
  <p class="site-author-name" itemprop="name">Junhao Lin</p>
  <div class="site-description" itemprop="description">朝花夕拾</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/IceVitaLemon" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;IceVitaLemon" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:junhaol0902@outlook.com" title="E-Mail → mailto:junhaol0902@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Junhao Lin">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="IceVitalemon's Blog">
      <meta itemprop="description" content="朝花夕拾">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="基础知识回顾 | IceVitalemon's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基础知识回顾
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-09-05 10:07:20" itemprop="dateCreated datePublished" datetime="2022-09-05T10:07:20+08:00">2022-09-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-12-05 11:13:43" itemprop="dateModified" datetime="2022-12-05T11:13:43+08:00">2022-12-05</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>35k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2:06</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="JAVA基础知识"><a href="#JAVA基础知识" class="headerlink" title="JAVA基础知识"></a>JAVA基础知识</h2><h3 id="集合（未施工）"><a href="#集合（未施工）" class="headerlink" title="集合（未施工）"></a>集合（未施工）</h3><p>HashMap</p>
<p>ConcurrentHashMap</p>
<h3 id="JVM（未施工）"><a href="#JVM（未施工）" class="headerlink" title="JVM（未施工）"></a>JVM（未施工）</h3><h3 id="多线程（思维导图）"><a href="#多线程（思维导图）" class="headerlink" title="多线程（思维导图）"></a>多线程（思维导图）</h3><p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png" alt="image-20221020194941633"></p>
<p>线程状态</p>
<p>锁（栅栏、锁升级）</p>
<p>AQS（还是要看一下其思想是什么）</p>
<p>线程池</p>
<h3 id="Java网络IO"><a href="#Java网络IO" class="headerlink" title="Java网络IO"></a>Java网络IO</h3><h4 id="I-x2F-O"><a href="#I-x2F-O" class="headerlink" title="I&#x2F;O"></a>I&#x2F;O</h4><blockquote>
<p>Input&#x2F;Output的缩写，简单的理解为<strong>数据的输入输出</strong>，通常有网络IO、磁盘IO。而IO的类型又分为同步&#x2F;异步IO、阻塞&#x2F;非阻塞I&#x2F;O，组合成具体的IO模型。IO属于操作系统层面上的知识，Java只是在操作系统提供的系统调用上封装了操作接口。</p>
</blockquote>
<blockquote>
<p>所有的系统IO都分为两个阶段：等待就绪和操作。以网络IO举例来说，读函数，分为等待网卡可以读和真正的读；同理，写函数，分为等待网卡可以写和真正的写。</p>
<p>需要说明的是等待网卡就绪的阻塞是不使用CPU的，是在<strong>空等</strong>；而真正的读写操作的阻塞是在使用CPU的，真正的在<strong>干活</strong>，而且这个过程非常快，属于内存拷贝，带宽通常在1GB&#x2F;s级别以上，可以理解为基本不耗时。</p>
</blockquote>
<blockquote>
<p>操作系统层面上的IO模型包括</p>
<ul>
<li>同步阻塞IO</li>
<li>同步非阻塞IO</li>
<li>异步非阻塞IO</li>
<li>IO多路复用</li>
<li>信号驱动IO</li>
</ul>
</blockquote>
<p>我们通常在Java中说BIO、NIO、AIO都是在网络IO层面上的，因此处理<strong>大量网络连接、连接输入和输出数据的准备（因为数据的输入和输出需要经过网络，所以时延一定不会短）</strong>就是关键要处理的问题。</p>
<p>在Java中，JVM读写数据都需要经过操作系统内核</p>
<ul>
<li>发送数据：JVM首先要把数据发送给内核，然后内核把数据交给网卡，网卡将数据通过互联网发送至客户端。</li>
<li>接收数据：需要让内核到网卡中查看数据是否已经准备好，如果准备好，则将数据放入内核，内核将数据转交给JVM，JVM再把数据交给我们具体的应用程序；如果没有准备好，通常会被阻塞，也有通过回调方式检测就绪事件（epoll相关）。</li>
</ul>
<img src="JVM IO读写数据.png" alt="image-20221012105409202" style="zoom: 40%;" />

<img src="IO模型对比.png" alt="image-20221012144951976" style="zoom: 50%;" />



<h4 id="阻塞和非阻塞"><a href="#阻塞和非阻塞" class="headerlink" title="阻塞和非阻塞"></a>阻塞和非阻塞</h4><blockquote>
<p>阻塞和非阻塞的着重点在发起请求后，是否需要等待</p>
</blockquote>
<ul>
<li>阻塞：阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。</li>
<li>非阻塞：非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情。</li>
</ul>
<h4 id="同步和异步"><a href="#同步和异步" class="headerlink" title="同步和异步"></a>同步和异步</h4><blockquote>
<p>同步和异步的着重点在两个任务之间是否需要等待</p>
</blockquote>
<ul>
<li>同步：两个同步任务相互依赖，并且一个任务必须依赖于另一任务的某种方式执行。比如在<code>A-&gt;B</code>事件模型中，需要先完成A才能执行B。换句话说，同步调用中，被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。举个例子，我要去买蛋糕和买菜，但是蛋糕还没做好，我需要等待蛋糕做好之后才能去买菜。</li>
<li>异步：两个异步的任务完全独立，一方的执行不需要等待另一方的执行。换句话说，异步调用中，调用后就返回，不需要等待结果返回，当结果返回的时候，通过回调函数或者其他方式拿着结果进行处理。举例来说，我要去买蛋糕和买菜，但是蛋糕还没做好，店主说留下地址蛋糕做好之后会送上门，那我立马就能去买菜了。</li>
</ul>
<h4 id="Linux中的select、poll、-epoll"><a href="#Linux中的select、poll、-epoll" class="headerlink" title="Linux中的select、poll、 epoll"></a>Linux中的select、poll、 epoll</h4><blockquote>
<p>select、poll、 epoll都是Linux内核提供给用户态的多路复用系统调用。进程可以通过一个系统调用函数从内核中获取多个事件。</p>
</blockquote>
<h5 id="select-x2F-poll"><a href="#select-x2F-poll" class="headerlink" title="select&#x2F;poll"></a>select&#x2F;poll</h5><p>select实现多路复用的方式是，将已连接的Socket都放到一个<strong>文件描述符集合</strong>，然后调用select函数将文件描述符集合<strong>拷贝</strong>到内核中，让内核来检查是否有网络事件产生，检测的方式很粗暴，就是通过<strong>遍历</strong>文件描述符集合的方式，当检查到有事件产生后，将此Socket标记伟可读或可写，接着再把整个文件描述符集合<strong>拷贝</strong>回用户态中，随后用户态还需要通过<strong>遍历</strong>的方法找到可读、可写或可建立连接的Socket，然后再对其处理。</p>
<p>所以，对于select这种方式，需要进行<strong>2次遍历文件描述符集合的操作</strong>，一次是在内核态中，一个是在用户态中，而且还会发生<strong>2次拷贝文件描述符集合的操作</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</p>
<p>select使用固定长度的BitsMap，表示文件描述符集合，而且BitsMap所支持的文件描述符的个数是有限的，在Linux系统中，由内核的FD_SETSIZE限制，默认最大值为<strong>1024</strong>。</p>
<p>poll不再用BitsMap来储存所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了select使用BitsMap存储文件描述符个数限制，当然还是会受到系统文件描述符的数量限制。</p>
<p>但是poll和select并没有太大的本质区别，都是使用线性结构储存进程关注的Socket集合，因此都需要遍历文件描述符集合来找到可读或可写的Socket，**时间复杂度为O(n)**，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。</p>
<h5 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h5><p>epoll在两个方面解决select&#x2F;poll的问题</p>
<p><strong>第一点</strong>，epoll在内核里使用<strong>红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的socket通过**epoll_ctl()**函数加入到内核中的红黑树里，红黑树是个高效的数据结构，增删查一般时间复杂度是O(logn)，通过维护内核中的这颗红黑树，就不需要像select&#x2F;poll每次操作时都传入整个socket集合，只需要传入一个待检测的socket，减少了内核和用户态间大量的数据拷贝和内存分配。</p>
<p><strong>第二点</strong>，epoll使用<strong>事件驱动的机制</strong>，内核里<strong>维护了一个链表来记录就绪事件</strong>，当某个socket有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用**epoll_wait()**函数时，只会返回有事件发生的文件描述符，不需要像select&#x2F;poll一样遍历整个socket集合，大大提高了检测的效率。</p>
<img src="epoll.png" alt="epoll" style="zoom:70%;" />

<p>epoll的方式即使监听的Socket数量越多的时候，效率不会大幅度降低，能够同时监听Socket的数目也非常的多，上限就是系统定义的进程能够打开的最大文件描述符个数。因此epoll被称为解决C10K问题的利器。</p>
<p>epoll 支持两种事件触发模式，分别是<strong>边缘触发（edge-triggered，ET）</strong>和<strong>水平触发（level-triggered，LT）</strong>：</p>
<ul>
<li><strong>边缘触发（edge-triggered，ET）</strong>：当被监控的Socket描述符上有可读事件发生时，<strong>服务器端只会从epoll_wait中苏醒一次</strong>，即使进程没有调用read函数从内核读取数据，也依然只苏醒一次，因为我们程序要保证一次性将内核缓冲区的数据读完。</li>
<li><strong>水平触发（level-triggered，LT）</strong>：当被监控的Socket上有可读事件发生时，<strong>服务器端不断地从epoll_wait中苏醒，直到内核缓冲区数据被read函数读完才结束</strong>，目的时告诉我们有数据要读取（其实从这里就可以看出需要将数据从内核中拷贝到用户态）。</li>
</ul>
<p>如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据（需要等待接收到所有的数据），以免错失读写的机会。因此，我们会<strong>循环</strong>从文件描述符读写数据，那么如果文件描述符读写是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，<strong>边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用</strong>，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</p>
<p>一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。</p>
<p>select&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。</p>
<h4 id="同步阻塞（JAVA-BIO）"><a href="#同步阻塞（JAVA-BIO）" class="headerlink" title="同步阻塞（JAVA BIO）"></a>同步阻塞（JAVA BIO）</h4><blockquote>
<p>服务端实现模式为一个连接一个线程，所以当有大量连接的时候，线程数可能会超出JVM限制导致应用崩溃，当然可以使用线程池改善，限制线程池的最大线程数以限制最大连接数</p>
</blockquote>
<blockquote>
<p>在服务端视角，如果有N个客户端通讯，想要知道他们有没有发送数据过来，就需要告诉内核到网卡中查看，如果都没有数据过来，这N个线程就都被阻塞了</p>
</blockquote>
<h5 id="服务端Demo"><a href="#服务端Demo" class="headerlink" title="服务端Demo"></a>服务端Demo</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.net.ServerSocket;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BIOServer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="comment">// 可以通过替换为BIOServer::BIODemo、BIOServer::BIOThreadDemo、BIOServer::BIOThreadPoolDemo</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(BIOServer::BIODemo).start();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIODemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="comment">// serverSocket.accept()代表着去内核中取数据，如果没数据就会被阻塞</span></span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="comment">// 从socket中获取数据流</span></span><br><span class="line">                <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> socket.getInputStream();</span><br><span class="line">                <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                <span class="comment">// 读操作是同步阻塞的</span></span><br><span class="line">                inputStream.read(data);</span><br><span class="line">                <span class="comment">// 打印获取到的数据</span></span><br><span class="line">                System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                <span class="comment">// 将获取到的数据发送回客户端</span></span><br><span class="line">                <span class="type">OutputStream</span> <span class="variable">out</span> <span class="operator">=</span> socket.getOutputStream();</span><br><span class="line">                <span class="comment">// 写操作是同步阻塞的</span></span><br><span class="line">                out.write(data);</span><br><span class="line">                socket.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIOThreadDemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="keyword">final</span> <span class="type">Socket</span> <span class="variable">clientSocket</span> <span class="operator">=</span> socket;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span>&#123;</span><br><span class="line">                            <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> clientSocket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            inputStream.read(data);</span><br><span class="line"></span><br><span class="line">                            System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                            </span><br><span class="line">                            <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> clientSocket.getOutputStream();</span><br><span class="line">                            outputStream.write(data);</span><br><span class="line">                            outputStream.close();</span><br><span class="line">                        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;).start();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">BIOThreadPoolDemo</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">ExecutorService</span> <span class="variable">executorService</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">            <span class="type">ServerSocket</span> <span class="variable">serverSocket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ServerSocket</span>();</span><br><span class="line">            serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">            Socket socket;</span><br><span class="line">            <span class="keyword">while</span> ((socket = serverSocket.accept()) != <span class="literal">null</span>)&#123;</span><br><span class="line">                <span class="keyword">final</span> <span class="type">Socket</span> <span class="variable">clientSocket</span> <span class="operator">=</span> socket;</span><br><span class="line">                executorService.submit(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span>&#123;</span><br><span class="line">                            <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> clientSocket.getInputStream();</span><br><span class="line">                            <span class="type">byte</span>[] data = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">                            inputStream.read(data);</span><br><span class="line"></span><br><span class="line">                            System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(data, StandardCharsets.UTF_8));</span><br><span class="line">                            </span><br><span class="line">                            <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> clientSocket.getOutputStream();</span><br><span class="line">                            outputStream.write(data);</span><br><span class="line">                            outputStream.close();</span><br><span class="line">                        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="客户端Demo"><a href="#客户端Demo" class="headerlink" title="客户端Demo"></a>客户端Demo</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BIOClient</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Socket</span>(<span class="string">&quot;localhost&quot;</span>, <span class="number">8888</span>);</span><br><span class="line">        <span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> socket.getInputStream();</span><br><span class="line">        <span class="type">OutputStream</span> <span class="variable">outputStream</span> <span class="operator">=</span> socket.getOutputStream();</span><br><span class="line">        <span class="type">DataInputStream</span> <span class="variable">dataInputStream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataInputStream</span>(inputStream);</span><br><span class="line">        <span class="type">DataOutputStream</span> <span class="variable">dataOutputStream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataOutputStream</span>(outputStream);</span><br><span class="line">        dataOutputStream.writeUTF(<span class="string">&quot;Hello world!&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">response</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">if</span>((response = dataInputStream.readUTF()) != <span class="literal">null</span>)&#123;</span><br><span class="line">            System.out.println(response);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        dataInputStream.close();</span><br><span class="line">        dataOutputStream.close();</span><br><span class="line">        socket.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="同步非阻塞（JAVA-NIO）"><a href="#同步非阻塞（JAVA-NIO）" class="headerlink" title="同步非阻塞（JAVA NIO）"></a>同步非阻塞（JAVA NIO）</h4><blockquote>
<p>JAVA NIO由IO多路复用实现，其中Socket主要的接收连接、读和写函数，在等待就绪阶段都是非阻塞的，真正的I&#x2F;O操作是同步阻塞的（消耗CPU但性能非常高）。</p>
</blockquote>
<p>JAVA NIO中有三个重要的概念，分别是缓冲区Buffer、通道Channel、选择器Selector：</p>
<ul>
<li><strong>缓冲区Buffer</strong>：包含一些要写入或者要读出的数据，在NIO库中，所有数据都是用缓冲区处理的。ByteBuffer、IntBuffer、CharBuffer、LongBuffer等都是其实现类。</li>
<li><strong>通道Channel</strong>：Channel是全双工的，可以通过它读取和写入数据。通道和流的不通之处就是通道是双向的，流是单向的（一个流必须是 InputStream 或者 OutputStream 的子类）。</li>
<li><strong>多路复用器Selector</strong>：多路复用器提供选择已经就绪的任务的能力，Selector 能够获取就绪的 Channel（<strong>Linux中select和poll是轮询来获取就绪的事件，但epoll实现是采用回调方式检测就绪事件，而不是轮询</strong>），如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 感知，然后通过 SelectionKey 可以获取就绪 Channel 的集合，进行后续的 I&#x2F;O 操作。</li>
</ul>
<h5 id="服务端Demo-1"><a href="#服务端Demo-1" class="headerlink" title="服务端Demo"></a>服务端Demo</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SelectionKey;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.Selector;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.ServerSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NIOServer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//1、打开ServerSocketChannel,监听客户端的链接</span></span><br><span class="line">        <span class="type">ServerSocketChannel</span> <span class="variable">serverSocketChannel</span> <span class="operator">=</span> ServerSocketChannel.open();</span><br><span class="line">        <span class="comment">//2、绑定监听端口,设置backlog（默认50）:请求传入连接队列的最大长度</span></span><br><span class="line">        serverSocketChannel.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">8888</span>), <span class="number">50</span>);</span><br><span class="line">        <span class="comment">//3、false,设置为非阻塞模式</span></span><br><span class="line">        serverSocketChannel.configureBlocking(<span class="literal">false</span>);</span><br><span class="line">        <span class="comment">//4、创建Selector, Selector是NIO的多路复用器, Selector能够获取注册在它上面就绪的通道Channel(Channel通道发生接收连接、读、写事件)</span></span><br><span class="line">        <span class="type">Selector</span> <span class="variable">selector</span> <span class="operator">=</span> Selector.open();</span><br><span class="line">        <span class="comment">//5、注册通道Channel到多路复用器Selector，并说明关注点SelectionKey.OP_ACCEPT，监听ACCEPT事件</span></span><br><span class="line">        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//6、不断轮询Selector中就绪的Channel</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)&#123;</span><br><span class="line">            <span class="comment">//7、阻塞等待，直到有就绪的Channel，能够设置超时时间</span></span><br><span class="line">            selector.select();</span><br><span class="line">            Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();</span><br><span class="line">            Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();</span><br><span class="line">            <span class="comment">//8、遍历就绪的channel</span></span><br><span class="line">            <span class="keyword">while</span> (iterator.hasNext())&#123;</span><br><span class="line">                <span class="type">SelectionKey</span> <span class="variable">key</span> <span class="operator">=</span> iterator.next();</span><br><span class="line">                <span class="comment">//9、判断Channel还是否有效</span></span><br><span class="line">                <span class="keyword">if</span> (!key.isValid())&#123;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span>(key.isAcceptable())&#123;</span><br><span class="line">                    <span class="comment">//10、Channel接收连接就绪</span></span><br><span class="line">                    <span class="comment">// 通过SelectionKey获取就绪的Channel</span></span><br><span class="line">                    <span class="type">ServerSocketChannel</span> <span class="variable">serverChannel</span> <span class="operator">=</span> (ServerSocketChannel) key.channel();</span><br><span class="line">                    <span class="comment">//11、Selector监听到有新的客户端连接，通过Channel完成TCP三次握手建立连接</span></span><br><span class="line">                    <span class="type">SocketChannel</span> <span class="variable">clientChannel</span> <span class="operator">=</span> serverChannel.accept();</span><br><span class="line">                    <span class="comment">//12、设置客户端SocketChannel为非阻塞模式</span></span><br><span class="line">                    <span class="comment">// 注意ServerSocketChannel用于服务器端接收新连接，SocketChannel用于服务器和客户端之间的连接</span></span><br><span class="line">                    clientChannel.configureBlocking(<span class="literal">false</span>);</span><br><span class="line">                    <span class="comment">//13、将客户端的SocketChannel注册到Selector中，并且监听读就绪事件</span></span><br><span class="line">                    clientChannel.register(selector, SelectionKey.OP_READ);</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isReadable())&#123;</span><br><span class="line">                    <span class="comment">//10、Channel读就绪</span></span><br><span class="line">                    <span class="comment">//11、创建缓冲区Buffer</span></span><br><span class="line">                    <span class="type">ByteBuffer</span> <span class="variable">buffer</span> <span class="operator">=</span> ByteBuffer.wrap(<span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>]);</span><br><span class="line">                    <span class="type">SocketChannel</span> <span class="variable">clientChannel</span> <span class="operator">=</span> (SocketChannel) key.channel();</span><br><span class="line">                    <span class="comment">//12、从Channel中读取数据到Buffer中</span></span><br><span class="line">                    <span class="type">int</span> <span class="variable">read</span> <span class="operator">=</span> clientChannel.read(buffer);</span><br><span class="line">                    <span class="keyword">if</span>(read == -<span class="number">1</span>)&#123;</span><br><span class="line">                        <span class="comment">// Buffer中无数据可读，关闭Channel，并且使SelectionKey失效</span></span><br><span class="line">                        key.cancel();</span><br><span class="line">                        clientChannel.close();</span><br><span class="line">                    &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 设置缓冲区的位置记录为数据的实际长度</span></span><br><span class="line">                        buffer.flip();</span><br><span class="line">                        System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(buffer.array(), StandardCharsets.UTF_8));</span><br><span class="line">                        <span class="comment">//13、通过Channel写出数据</span></span><br><span class="line">                        clientChannel.write(buffer);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                iterator.remove();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="客户端Demo-1"><a href="#客户端Demo-1" class="headerlink" title="客户端Demo"></a>客户端Demo</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.SocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NIOClient</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String[] messages = &#123;</span><br><span class="line">            <span class="string">&quot;message1 from client&quot;</span>,</span><br><span class="line">            <span class="string">&quot;message2 from client&quot;</span></span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="keyword">try</span>(<span class="type">SocketChannel</span> <span class="variable">socketChannel</span> <span class="operator">=</span> SocketChannel.open(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="number">8888</span>)))&#123;</span><br><span class="line">            <span class="keyword">for</span>(String message: messages)&#123;</span><br><span class="line">                <span class="type">ByteBuffer</span> <span class="variable">writeBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                writeBuffer.put(message.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">                writeBuffer.flip();</span><br><span class="line">                <span class="comment">// 这里写是阻塞的</span></span><br><span class="line">                socketChannel.write(writeBuffer);</span><br><span class="line"></span><br><span class="line">                <span class="type">ByteBuffer</span> <span class="variable">readBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                <span class="comment">// 这里读是阻塞的</span></span><br><span class="line">                socketChannel.read(readBuffer);</span><br><span class="line">                readBuffer.flip();</span><br><span class="line">                System.out.println(<span class="keyword">new</span> <span class="title class_">String</span>(readBuffer.array(), StandardCharsets.UTF_8));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (IOException e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h5 id="优化线程模型"><a href="#优化线程模型" class="headerlink" title="优化线程模型"></a>优化线程模型</h5><p>回忆BIO模型，之所以需要多线程，是因为在进行IO操作的时候，没办法知道硬件读写是否就绪，只能阻塞等待，造成大量的<strong>空等</strong>从而阻塞需要进行线程切换（<strong>浪费大量CPU资源在线程上下文切换</strong>）。而NIO通过将通道Channel注册到多路复用器Selector上，达到<strong>只有事件就绪才会执行真正的操作，减少空等的时间，提高CPU的利用率</strong>（CPU一直都在跑，没有等待），只有调用selector.select()时，没有就绪事件才会被阻塞，而这时没有事件就绪说明不需要处理，阻塞等待也是正常的。</p>
<p><strong>NIO将原来BIO的阻塞读写变成了单线程轮询事件（单Reactor单线程模型）</strong>，除了事件的轮询是阻塞的，剩余的IO操作都是纯CPU操作，没有必要开启多线程。并且由于节约线程，当连接数大的时候由线程切换带来的问题也随之解决，为海量连接提供可能。单线程处理I&#x2F;O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。<strong>但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I&#x2F;O，无疑对效率会有更大的提高。</strong></p>
<p>分析我们程序的主要功能，包括：</p>
<ul>
<li>网络IO处理，包括accept、read、write等</li>
<li>业务逻辑，通过网络获取到需要的数据之后需要对数据进行处理后返回，这里还会有其他的阻塞IO，如DB操作、RPC等</li>
</ul>
<p>根据功能的线程划分，能够将Reactor线程设计模式分为：</p>
<ul>
<li>单Reactor单线程模型</li>
<li>单Reactor多线程模型</li>
<li>主从Reactor多线程模型</li>
</ul>
<h5 id="Reactor设计模式"><a href="#Reactor设计模式" class="headerlink" title="Reactor设计模式"></a>Reactor设计模式</h5><blockquote>
<p>Reactor模型是可以处理一个或多个输入源，并通过Service Handler同步的将输入事件（Event）采用多路复用分发给相应的Request Handler（多个）处理的事件驱动模式</p>
</blockquote>
<blockquote>
<p>Reactor模型用于NIO，是一种思想，多线程的思想。其中定义了三个角色：</p>
<ul>
<li><strong>Reactor</strong>：负责监听和分配事件</li>
<li><strong>Acceptor</strong>：处理客户端到来的新连接，并分派请求到Handler链中</li>
<li><strong>Handler</strong>：执行非阻塞读写任务，完成数据读入，处理业务逻辑后，将结果写出</li>
</ul>
</blockquote>
<h6 id="单Reactor单线程模型"><a href="#单Reactor单线程模型" class="headerlink" title="单Reactor单线程模型"></a>单Reactor单线程模型</h6><blockquote>
<p>Reactor、Acceptor、Handler都在一个线程中</p>
<p>优点：模型简单，没有多线程、进程通信、竞争的问题</p>
<p>缺点：无法发挥多核CPU的性能，此外如果业务处理速度比较慢就会影响到程序的高并发性能，任何地方不可用都会导致整个通信模块的不可用</p>
<p>Redis就是这种模型，实际使用的是单线程+队列</p>
</blockquote>
<img src="单Reactor单线程.png" alt="image-20221013095437617" style="zoom:50%;" />

<h6 id="单Reactor多线程模型"><a href="#单Reactor多线程模型" class="headerlink" title="单Reactor多线程模型"></a>单Reactor多线程模型</h6><blockquote>
<p>Reactor主线程中主要负责网络IO相关的处理，包括连接的建立、数据读写，把具体的业务处理逻辑放到线程池中处理</p>
<p>优点：充分利用多核CPU的处理能力，业务阻塞不会影响通信模块</p>
<p>缺点：多线程数据共享和访问的问题，Reactor在单线程中承担所有事件的监听和相应，高并发场景下容易成为性能瓶颈</p>
</blockquote>
<img src="单Reactor多线程.png" alt="image-20221013100405912" style="zoom:53%;" />

<h6 id="主从Reactor多线程模型"><a href="#主从Reactor多线程模型" class="headerlink" title="主从Reactor多线程模型"></a>主从Reactor多线程模型</h6><blockquote>
<p>Reactor主线程中只负责连接的建立，Reactor子线程负责读写数据，在线程池完成业务处理</p>
<p><strong>对连接的处理和读写通常可以选择分开</strong>，这样对于海量连接的注册和读写就可以分发到不同的线程中进行处理，在单线程Reactor模型和单Reactor多线程模型中，虽然read()和write()都是效率比较高的非阻塞函数，但Reactor线程毕竟只占用一个CPU内核，如果面对更高的并发则无能为力。主从Reactor多线程模型就能够解决这个问题。</p>
<p>这种模型在许多项目中广泛使用，包括Nginx主从Reactor多进程模型，Memcached主从多线程，Netty主从多线程模型的支持。</p>
</blockquote>
<img src="主从Reactor多线程.png" alt="image-20221013100926483" style="zoom:52%;" />



<h4 id="异步非阻塞（JAVA-AIO）"><a href="#异步非阻塞（JAVA-AIO）" class="headerlink" title="异步非阻塞（JAVA AIO）"></a>异步非阻塞（JAVA AIO）</h4><blockquote>
<p>BIO和NIO对于内核来说，都是<strong>应用程序不询问我，我绝不会主动通知</strong>的方式</p>
</blockquote>
<blockquote>
<p>还记得IO操作分为两个阶段：等待就绪和实际操作。在NIO中，等待就绪阶段是不会被阻塞的，但是还是需要实际操作数据，将数据从内核态中拷贝到用户态。AIO解决的就是这个问题，当应用程序发起异步IO之后，内核会完成数据的就绪和将数据从内核态拷贝到用户态中，应用程序并不需要主动发起拷贝动作。</p>
</blockquote>
<blockquote>
<p>AIO采用<strong>订阅-通知</strong>的方式：应用程序向操作系统注册IO监听，然后继续做自己的事情。当操作系统发生IO事件，并且准备好数据后，再主动通知应用程序，触发相应的回调函数。<strong>如果发起异步读写请求，还需要传入数据缓冲区Buffer的地址（用于存放结果数据）等信息，这样内核才能自动帮我们把数据的读写工作完成。</strong></p>
</blockquote>
<blockquote>
<p>AIO也是需要操作系统支持，<strong>微软的windows系统提供了一种异步IO技术IOCP(I&#x2F;O Completion Port，I&#x2F;O完成端口)；Linux下由于没有这种异步IO技术，所以使用的是epoll对异步IO进行模拟</strong></p>
</blockquote>
<blockquote>
<p>NIO中有一个重要的概念多路复用器Selector，负责替应用查询中所有已注册的通道到操作系统中进行IO事件轮询、管理当前注册的通道集合，定位发生事件的通道等操操作；但是在Java AIO框架中，由于应用程序不是<strong>轮询</strong>方式，而是<strong>订阅-通知</strong>方式，所以不再需要Selector(选择器)了，改由channel通道直接到操作系统注册监听，让操作系统回调实际操作函数。</p>
</blockquote>
<img src="JAVA_AIO.png" alt="image-20221013142450630" style="zoom:50%;" />

<h5 id="服务器Demo"><a href="#服务器Demo" class="headerlink" title="服务器Demo"></a>服务器Demo</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.17.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.17.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.25<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousChannelGroup;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousServerSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.AsynchronousSocketChannel;</span><br><span class="line"><span class="keyword">import</span> java.nio.channels.CompletionHandler;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.Log;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.LogFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.BasicConfigurator;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AIOServer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        BasicConfigurator.configure();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Object</span> <span class="variable">waitObject</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 对于使用的线程池技术，我一定要多说几句</span></span><br><span class="line"><span class="comment">         * 1、Executors是线程池生成工具，通过这个工具我们可以很轻松的生成“固定大小的线程池”、“调度池”、“可伸缩线程数量的池”。具体请看API Doc</span></span><br><span class="line"><span class="comment">         * 2、当然您也可以通过ThreadPoolExecutor直接生成池。</span></span><br><span class="line"><span class="comment">         * 3、这个线程池是用来得到操作系统的“IO事件通知”的，不是用来进行“得到IO数据后的业务处理的”。要进行后者的操作，您可以再使用一个池(最好不要混用)</span></span><br><span class="line"><span class="comment">         * 4、您也可以不使用线程池(不推荐)，如果决定不使用线程池，直接AsynchronousServerSocketChannel.open()就行了。</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">ExecutorService</span> <span class="variable">threadPool</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">20</span>);</span><br><span class="line">        <span class="type">AsynchronousChannelGroup</span> <span class="variable">group</span> <span class="operator">=</span> AsynchronousChannelGroup.withThreadPool(threadPool);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">AsynchronousServerSocketChannel</span> <span class="variable">serverSocket</span> <span class="operator">=</span> AsynchronousServerSocketChannel.open(group);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置要监听的端口“0.0.0.0”代表本机所有IP设备</span></span><br><span class="line">        serverSocket.bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="string">&quot;0.0.0.0&quot;</span>, <span class="number">83</span>));</span><br><span class="line">        <span class="comment">//为AsynchronousServerSocketChannel注册监听，注意只是为AsynchronousServerSocketChannel通道注册监听</span></span><br><span class="line">        <span class="comment">//并不包括为 随后客户端和服务器 socketchannel通道注册的监听</span></span><br><span class="line">        serverSocket.accept(<span class="literal">null</span>, <span class="keyword">new</span> <span class="title class_">ServerSocketChannelHandle</span>(serverSocket));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//等待，以便观察现象(这个和要讲解的原理本身没有任何关系，只是为了保证守护线程不会退出)</span></span><br><span class="line">        <span class="keyword">synchronized</span>(waitObject) &#123;</span><br><span class="line">            waitObject.wait();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 这个处理器类，专门用来响应 ServerSocketChannel 的事件。</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ServerSocketChannelHandle</span> <span class="keyword">implements</span> <span class="title class_">CompletionHandler</span>&lt;AsynchronousSocketChannel, Void&gt; &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 日志</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Log</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LogFactory.getLog(ServerSocketChannelHandle.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> AsynchronousServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> serverSocketChannel</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ServerSocketChannelHandle</span><span class="params">(AsynchronousServerSocketChannel serverSocketChannel)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.serverSocketChannel = serverSocketChannel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注意，我们分别观察 this、socketChannel、attachment三个对象的id。</span></span><br><span class="line"><span class="comment">     * 来观察不同客户端连接到达时，这三个对象的变化，以说明ServerSocketChannelHandle的监听模式</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">completed</span><span class="params">(AsynchronousSocketChannel socketChannel, Void attachment)</span> &#123;</span><br><span class="line">        ServerSocketChannelHandle.LOGGER.info(<span class="string">&quot;completed(AsynchronousSocketChannel result, ByteBuffer attachment)&quot;</span>);</span><br><span class="line">        <span class="comment">//每次都要重新注册监听(一次注册，一次响应)，但是由于“文件状态标示符”是独享的，所以不需要担心有“漏掉的”事件</span></span><br><span class="line">        <span class="built_in">this</span>.serverSocketChannel.accept(attachment, <span class="built_in">this</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//为这个新的socketChannel注册“read”事件，以便操作系统在收到数据并准备好后，主动通知应用程序</span></span><br><span class="line">        <span class="comment">//在这里，由于我们要将这个客户端多次传输的数据累加起来一起处理，所以我们将一个stringbuffer对象作为一个“附件”依附在这个channel上</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="type">ByteBuffer</span> <span class="variable">readBuffer</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">50</span>);</span><br><span class="line">        socketChannel.read(readBuffer, <span class="keyword">new</span> <span class="title class_">StringBuffer</span>(), <span class="keyword">new</span> <span class="title class_">SocketChannelReadHandle</span>(socketChannel , readBuffer));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#failed(java.lang.Throwable, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">failed</span><span class="params">(Throwable exc, Void attachment)</span> &#123;</span><br><span class="line">        ServerSocketChannelHandle.LOGGER.info(<span class="string">&quot;failed(Throwable exc, ByteBuffer attachment)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 负责对每一个socketChannel的数据获取事件进行监听。&lt;p&gt;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 重要的说明: 一个socketchannel都会有一个独立工作的SocketChannelReadHandle对象(CompletionHandler接口的实现)，</span></span><br><span class="line"><span class="comment"> * 其中又都将独享一个“文件状态标示”对象FileDescriptor、</span></span><br><span class="line"><span class="comment"> * 一个独立的由程序员定义的Buffer缓存(这里我们使用的是ByteBuffer)、</span></span><br><span class="line"><span class="comment"> * 所以不用担心在服务器端会出现“窜对象”这种情况，因为JAVA AIO框架已经帮您组织好了。&lt;p&gt;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 但是最重要的，用于生成channel的对象: AsynchronousChannelProvider是单例模式，无论在哪组socketchannel，</span></span><br><span class="line"><span class="comment"> * 对是一个对象引用(但这没关系，因为您不会直接操作这个AsynchronousChannelProvider对象)。</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> yinwenjie</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SocketChannelReadHandle</span> <span class="keyword">implements</span> <span class="title class_">CompletionHandler</span>&lt;Integer, StringBuffer&gt; &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 日志</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Log</span> <span class="variable">LOGGER</span> <span class="operator">=</span> LogFactory.getLog(SocketChannelReadHandle.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> AsynchronousSocketChannel socketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 专门用于进行这个通道数据缓存操作的ByteBuffer&lt;br&gt;</span></span><br><span class="line"><span class="comment">     * 当然，您也可以作为CompletionHandler的attachment形式传入。&lt;br&gt;</span></span><br><span class="line"><span class="comment">     * 这是，在这段示例代码中，attachment被我们用来记录所有传送过来的Stringbuffer了。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> ByteBuffer byteBuffer;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SocketChannelReadHandle</span><span class="params">(AsynchronousSocketChannel socketChannel , ByteBuffer byteBuffer)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.socketChannel = socketChannel;</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer = byteBuffer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#completed(java.lang.Object, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">completed</span><span class="params">(Integer result, StringBuffer historyContext)</span> &#123;</span><br><span class="line">        <span class="comment">//如果条件成立，说明客户端主动终止了TCP套接字，这时服务端终止就可以了</span></span><br><span class="line">        <span class="keyword">if</span>(result == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="built_in">this</span>.socketChannel.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;completed(Integer result, Void attachment) : 然后我们来取出通道中准备好的值&quot;</span>);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * 实际上，由于我们从Integer result知道了本次channel从操作系统获取数据总长度</span></span><br><span class="line"><span class="comment">         * 所以实际上，我们不需要切换成“读模式”的，但是为了保证编码的规范性，还是建议进行切换。</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 另外，无论是JAVA AIO框架还是JAVA NIO框架，都会出现“buffer的总容量”小于“当前从操作系统获取到的总数据量”，</span></span><br><span class="line"><span class="comment">         * 但区别是，JAVA AIO框架中，我们不需要专门考虑处理这样的情况，因为JAVA AIO框架已经帮我们做了处理(做成了多次通知)</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.flip();</span><br><span class="line">        <span class="type">byte</span>[] contexts = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.get(contexts, <span class="number">0</span>, result);</span><br><span class="line">        <span class="built_in">this</span>.byteBuffer.clear();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">nowContent</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(contexts , <span class="number">0</span> , result , <span class="string">&quot;UTF-8&quot;</span>);</span><br><span class="line">            historyContext.append(nowContent);</span><br><span class="line">            SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;================目前的传输结果: &quot;</span> + historyContext);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">            SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果条件成立，说明还没有接收到“结束标记”</span></span><br><span class="line">        <span class="keyword">if</span>(historyContext.indexOf(<span class="string">&quot;over&quot;</span>) == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//=========================================================================</span></span><br><span class="line">        <span class="comment">//          和上篇文章的代码相同，我们以“over”符号作为客户端完整信息的标记</span></span><br><span class="line">        <span class="comment">//=========================================================================</span></span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;=======收到完整信息，开始处理业务=========&quot;</span>);</span><br><span class="line">        historyContext = <span class="keyword">new</span> <span class="title class_">StringBuffer</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//还要继续监听(一次监听一次通知)</span></span><br><span class="line">        <span class="built_in">this</span>.socketChannel.read(<span class="built_in">this</span>.byteBuffer, historyContext, <span class="built_in">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* (non-Javadoc)</span></span><br><span class="line"><span class="comment">     * @see java.nio.channels.CompletionHandler#failed(java.lang.Throwable, java.lang.Object)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">failed</span><span class="params">(Throwable exc, StringBuffer historyContext)</span> &#123;</span><br><span class="line">        SocketChannelReadHandle.LOGGER.info(<span class="string">&quot;=====发现客户端异常关闭，服务器将关闭TCP通道&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.socketChannel.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            SocketChannelReadHandle.LOGGER.error(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h5 id="Proactor设计模式"><a href="#Proactor设计模式" class="headerlink" title="Proactor设计模式"></a>Proactor设计模式</h5><blockquote>
<p>Reactor是用于非阻塞同步的设计模型，Proactor是用于异步IO的设计模型</p>
</blockquote>
<blockquote>
<p>Proactor整体上与Reactor一致，区别在于Proactor模式将所有IO操作都交给内核处理，工作线程仅仅负责业务逻辑。<strong>Proactor关注的不是就绪事件，而是完成事件，这是区分Reactor模式的关键点</strong>。</p>
<p>Proactor模型主要包括四个角色：</p>
<ul>
<li><strong>Procator Initiator</strong>：负责创建Handler和Procator，并将Procator和Handler（作为回调）都通过Asynchronous operation processor注册到内核</li>
<li><strong>Handler</strong>：执行业务流程的业务处理器</li>
<li><strong>Asynchronous operation processor</strong>：负责处理注册请求，并完成IO操作。完成IO操作后会通知Procator</li>
<li><strong>Procator</strong>：根据不同的事件类型回调不同的handler进行业务处理</li>
</ul>
</blockquote>
<img src="Proactor模型.png" alt="image-20221013172016259" style="zoom:60%;" />



<p>参考资料：</p>
<p><a target="_blank" rel="noopener" href="https://tech.meituan.com/2016/11/04/nio.html">https://tech.meituan.com/2016/11/04/nio.html</a></p>
<p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/726698#slide-11">https://developer.aliyun.com/article/726698#slide-11</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zdreamLife/article/details/124222337">https://blog.csdn.net/zdreamLife/article/details/124222337</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013256816/article/details/115388239">https://blog.csdn.net/u013256816/article/details/115388239</a></p>
<p><a target="_blank" rel="noopener" href="https://pdai.tech/md/java/io/java-io-aio.html">https://pdai.tech/md/java/io/java-io-aio.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/26943938">https://www.zhihu.com/question/26943938</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/chenssy/p/15526729.html">https://www.cnblogs.com/chenssy/p/15526729.html</a></p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Qpa0qXxuIM8jrBqDaXmVNA">https://mp.weixin.qq.com/s/Qpa0qXxuIM8jrBqDaXmVNA</a></p>
<h2 id="计算机基础（部分施工）"><a href="#计算机基础（部分施工）" class="headerlink" title="计算机基础（部分施工）"></a>计算机基础（部分施工）</h2><h3 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h3><p>五元组确定一个连接：协议（TCP&#x2F;UDP）、源IP、源端口、目标IP、目标端口</p>
<p>发起HTTP请求的流程</p>
<p>ARP（地址解析协议）</p>
<p>DNS</p>
<p>PING，ICMP</p>
<p>TCP&#x2F;IP</p>
<p>TCP -三次握手四次挥手</p>
<p>CLOSED WAIT</p>
<p>TIME WAIT</p>
<p>UDP</p>
<h3 id="操作系统（部分施工）"><a href="#操作系统（部分施工）" class="headerlink" title="操作系统（部分施工）"></a>操作系统（部分施工）</h3><h4 id="上下文切换类型"><a href="#上下文切换类型" class="headerlink" title="上下文切换类型"></a>上下文切换类型</h4><ul>
<li>中断上下文切换：为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。在内核态执行不涉及进程的用户态，只包括内核态中断服务程序执行所必需的状态，包括CPU寄存器、程序计数器、内核堆栈、硬件中断参数等。</li>
<li>CPU上下文切换：CPU寄存器、程序计数器PC，所有函数调用都会触发CPU上下文切换，因为需要记住函数调用前的状态以及函数调用后的返回入口</li>
<li>线程上下文切换：线程私有数据、栈、寄存器等</li>
<li>进程上下文切换：虚拟内存、全局变量等</li>
</ul>
<h4 id="进程切换发生在什么时候？"><a href="#进程切换发生在什么时候？" class="headerlink" title="进程切换发生在什么时候？"></a>进程切换发生在什么时候？</h4><blockquote>
<p>进程切换一定发生在<strong>中断、异常、系统调用</strong>的处理过程中，因为<strong>中断、异常、系统调用</strong>进入内核态之后，系统进程管理模块就会根据进程的状态进行进程调度（进程调度实际上也是一个程序）</p>
</blockquote>
<ul>
<li>时间片中断、IO中断后更改优先级进程（导致被中断进程进入就绪态）</li>
<li>阻塞式系统调用、缺页中断（导致被中断进程进入等待态）</li>
<li>终止用系统调用、不能继续执行的异常（导致被中断进程进入终止态）</li>
</ul>
<blockquote>
<p>举例说明</p>
<ul>
<li>时钟中断：操作系统确定当前正在运行的进程的执行时间是否已经超过了最大允许时间段，如果超过了，进程必须切换到就绪态，调度另一个进程。（时钟频率，每隔一段时间就会发生一次时钟中断，时钟中断处理程序就会被自动调用，在其中判断进程时间片是否用完）</li>
<li>I&#x2F;O中断：操作系统确定是否发生了I&#x2F;O活动。如果I&#x2F;O活动是一个或多个进程正在等待的事件，操作系统把所有相应的阻塞态转换到就绪态，操作系统必须决定是让具有高优先级的就绪态进程抢占当前进程，还是继续执行当前处于运行态的进程。</li>
<li>缺页中断（内存页失效）：处理器访问一个虚拟内存地址，且此内存页不在内存中，操作系统必须从磁盘中调入该内存页至内存中。在发出调入内存页的I&#x2F;O请求之后，操作系统会执行一个进程切换，以高效利用CPU。而发生缺页的进程被置为阻塞态，当内存页调入完毕后，该进程被置为就绪态等待调度。</li>
<li>对于陷阱：操作系统确定错误或异常条件是否致命的。如果是，当前正在运行的进程被转换到退出态，并发生进程切换；如果不是，操作系统的动作取决于错误的种类和操作系统的设计，其行为可以是试图恢复或通知用户，操作系统可能会进行一次进程切换或者继续执行当前正在运行的进程。</li>
<li>操作系统的进程调度可能被来自正在执行的程序的系统调用激活。例如，一个用户进程正在运行，并且正在执行一条请求I&#x2F;O操作的指令，如打开文件，这个调用导致转移到作为操作系统代码一部分的一个例程上进行。通常，使用系统调用会导致操作系统把用户线程置为阻塞态。</li>
</ul>
</blockquote>
<p>进程是怎么样切换的</p>
<p>进程、线程、协程</p>
<p>页式、段式、段页式</p>
<p>虚拟内存（储存）</p>
<p>虚拟硬盘</p>
<p>CPU寻址、逻辑地址、物理地址</p>
<p>磁盘</p>
<h2 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h2><h3 id="MyISAM和InnoDB的区别"><a href="#MyISAM和InnoDB的区别" class="headerlink" title="MyISAM和InnoDB的区别"></a>MyISAM和InnoDB的区别</h3><ul>
<li><p>MyISAM</p>
<ul>
<li>不支持事务、崩溃恢复</li>
<li>不支持行锁，只支持表锁</li>
<li>不支持外键</li>
<li>主键索引中叶子节点储存的不是数据记录，而是记录的内存地址，因此MyISAM的数据文件分为索引文件和数据文件</li>
</ul>
</li>
<li><p>InnoDB</p>
<ul>
<li>支持事务，崩溃恢复，有redo log</li>
<li>支持表锁、行级锁，通过MVCC和Next-key Lock在可重复读的隔离级别下解决幻读的问题</li>
<li>支持外键</li>
<li>InnoDB的主键索引是聚簇索引，所以数据文件只有一个</li>
</ul>
</li>
</ul>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><blockquote>
<p>以 InnoDB 的一个整数字段索引为例，N叉B+树的N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p>
</blockquote>
<h4 id="索引类型（分类角度）"><a href="#索引类型（分类角度）" class="headerlink" title="索引类型（分类角度）"></a>索引类型（分类角度）</h4><ul>
<li><p><strong>主键索引</strong>：一种<strong>特殊的唯一索引</strong>，一个表只能有一个主键，<strong>不允许有空值</strong>，主键索引的记录在物理存储上的方式跟数据库引擎的实现有关，MyISAM中主键索引B+树的叶子节点储存的是记录的物理地址（所以数据库的数据文件分为索引文件和数据文件），而InnoDB中主键索引B+树的叶子节点储存了记录的所有字段值。</p>
</li>
<li><p><strong>普通索引</strong>：就是普通的索引。</p>
</li>
<li><p><strong>唯一索引</strong>：字段唯一，能够<strong>允许NULL值</strong>，就是只要是NULL就认为是不一样的，在InnoDB中NULL值储存在B+树的最左边。</p>
</li>
<li><p><strong>前缀索引</strong>：指对字符类型字段的前几个字符或对二进制类型字段的前几个bytes建立的索引，而不是在整个字段上建索引。前缀索引可以建立在类型为char、varchar、binary、varbinary的列上，可以大大减少索引占用的存储空间，也能提升索引的查询效率。</p>
</li>
<li><p><strong>全文索引</strong>：与搜索引擎相关，都是需要分词，然后根据关键字中的词频和重要性进行排序。</p>
</li>
<li><p><strong>联合索引</strong>：由多个字段组合形成的索引。</p>
</li>
</ul>
<h4 id="聚簇索引与非聚簇索引（物理储存角度）"><a href="#聚簇索引与非聚簇索引（物理储存角度）" class="headerlink" title="聚簇索引与非聚簇索引（物理储存角度）"></a>聚簇索引与非聚簇索引（物理储存角度）</h4><ul>
<li><p><strong>聚簇索引</strong>：记录的物理储存顺序与列值（一般是主键的一列）的逻辑顺序相同，一个表中只有一个聚簇索引（因为聚簇索引的记录在物理储存上是有序的，所以当按照主键遍历的时候，相邻的主键都在同一块内存页中，能够减少缺页中断，提高查询效率）。</p>
</li>
<li><p><strong>非聚簇索引</strong>（二级索引、辅助索引）：与聚簇索引相反，如果记录的物理储存顺序与列值的逻辑顺序不一样，那么就是非聚簇索引，一个表中可以有多个非聚簇索引。</p>
</li>
</ul>
<h4 id="B-树索引和哈希索引（数据结构角度）"><a href="#B-树索引和哈希索引（数据结构角度）" class="headerlink" title="B+树索引和哈希索引（数据结构角度）"></a>B+树索引和哈希索引（数据结构角度）</h4><ul>
<li><p><strong>B+树索引</strong>：B+树是多叉平衡树，所以能够快速搜索到记录的位置，B+树的特点是非叶子节点不储存数据，叶子节点储存数据，最后所有叶子节点组成一条有序的双向链表，<strong>因为非叶子节点不储存数据，所以单个非叶子节点能够储存大量的索引数据，而由于这些索引数据是经常被访问的，所以能够常驻在内存中，减少缺页中断（或SWAP）带来的性能消耗</strong>。</p>
</li>
<li><p><strong>B树索引</strong>：B树叶子节点也储存数据，而且所有叶子节点不会组成有序链表。</p>
</li>
<li><p><strong>哈希索引</strong>：经过哈希函数能够快速找到记录的位置，不需要进行搜索（哈希冲突解决的办法）</p>
</li>
</ul>
<h4 id="自适应哈希索引"><a href="#自适应哈希索引" class="headerlink" title="自适应哈希索引"></a>自适应哈希索引</h4><blockquote>
<p>InnoDB引擎支持自适应哈希索引，是数据库自动优化，只能选择开启或者关闭。</p>
</blockquote>
<p>因为当使用辅助索引进行查找的时候，如果并不是覆盖索引，就需要<strong>回表</strong>到主键索引中找到记录的所有数据，如果这种查询的次数变多，那么InnoDB就会自动创建自适应哈希索引，<strong>提高在通过辅助索引查找到主键Id的时候，再回表的查询速度</strong>。（即通过辅助索引查找到主键Id，然后通过主键Id的哈希索引直接找到记录的位置）。</p>
<p>根据一些资料的统计，读取和写入速度可以提高2倍，辅助索引的连接操作性能可以提高5倍。</p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903888080863245">https://juejin.cn/post/6844903888080863245</a></p>
<h4 id="主键索引就是聚簇索引吗？"><a href="#主键索引就是聚簇索引吗？" class="headerlink" title="主键索引就是聚簇索引吗？"></a>主键索引就是聚簇索引吗？</h4><p><strong>不是</strong>！！！在InnoDB中主键的确是按聚簇索引的方式组织的，但是在MyISAM里面主键<strong>不是</strong>聚簇索引，sql server中还可以显示的指定聚簇索引。</p>
<p>InnoDB中如果没有定义主键，Innodb会选择非空的唯一索引代替。如果没有这样的索引，Innodb会隐式的定义一个主键来作为聚簇索引。</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/lice-blog/p/11569443.html">https://www.cnblogs.com/lice-blog/p/11569443.html</a></p>
<h4 id="什么是联合索引、覆盖索引、索引最左匹配原则"><a href="#什么是联合索引、覆盖索引、索引最左匹配原则" class="headerlink" title="什么是联合索引、覆盖索引、索引最左匹配原则"></a>什么是联合索引、覆盖索引、索引最左匹配原则</h4><ul>
<li><p><strong>联合索引</strong>：由多个字段组合形成的索引</p>
</li>
<li><p><strong>覆盖索引</strong>：查询的字段会被索引覆盖到，就<strong>不需要回表</strong>根据主键Id查询其他字段，<strong>单个字段的索引</strong>和<strong>联合索引</strong>都能实现覆盖索引的功能。所以说覆盖索引并不是一种真正的索引，是查询的时候用到的索引覆盖到了所有需要查询的字段。</p>
</li>
<li><p><strong>索引最左匹配原则</strong>：对于一个联合索引（a, b, c, d），如果查询的时候指定了查询条件<code>a = 1 AND b = 2 AND c &gt; 4 AND d &lt; 5</code>，因为索引整体上是按<code>a,b,c,d</code>来排序的（即先按a排序，a相等的时候按b排序，以此类推），所以<strong>当a和b指定了确切的值的时候，记录在c上是有序的，但是在d上就不确认了</strong>。当联合索引遇到范围查询（&gt;，&lt;，between，like）最左匹配就不能进一步匹配了。（当然MySQL会优化查询的顺序比如，<code>d &lt; 5 AND b = 2 AND c &gt; 4 AND a = 1</code> 会优化为<code>a = 1 AND b = 2 AND c &gt; 4 AND d &lt; 5</code>）</p>
</li>
</ul>
<h4 id="说一下索引下推"><a href="#说一下索引下推" class="headerlink" title="说一下索引下推"></a>说一下索引下推</h4><blockquote>
<p>索引下推可以在索引遍历过程中（引擎层），对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p>
</blockquote>
<p>对于一个联合索引<strong>（name, age）</strong>和一个SQL语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from tuser where name like &#x27;张%&#x27; and age = 10 and ismale = 1;</span><br></pre></td></tr></table></figure>

<ul>
<li>如果没有索引下推，因为最左匹配原则，所以只会用到<code>name</code>的索引，所以在引擎层会找到所有<code>name like &#39;张%&#39;</code>的主键并返回给server层，然后逐个回表判断</li>
<li>如果有索引下推，即使有最左匹配原则，也会将索引能用到的<code>age = 10</code>放到引擎层进行判断，引擎层根据索引判断，只返回<code>name like &#39;张%&#39; and age = 10</code>的主键，这样过滤了不符合的部分数据，就能减少回表的次数</li>
</ul>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><h4 id="事务的四大特性（ACID）"><a href="#事务的四大特性（ACID）" class="headerlink" title="事务的四大特性（ACID）"></a>事务的四大特性（ACID）</h4><ol>
<li>原子性：一个事务是最小执行单位，事务中的动作要么都做，要么都不做</li>
<li>一致性：执行事务之后，数据保持一致，多个事务对同一个数据读取的结果是相同的</li>
<li>隔离性：并发访问数据库的时候，各个事务之间不会相互影响</li>
<li>持久性：一个事务被提交之后，对数据库的修改是持久的，即使数据库发生故障也不会有影响</li>
</ol>
<h4 id="可能出现的问题"><a href="#可能出现的问题" class="headerlink" title="可能出现的问题"></a>可能出现的问题</h4><ol>
<li><strong>脏读</strong>：事务A能够读到事务B还没提交的数据</li>
<li><strong>不可重复读</strong>：对于读取一行数据，一个事务中两次读到的数据不一样</li>
<li><strong>幻读</strong>：对于读取多行数据，一个事务中第二次读到的行数比第一次读到的行数要多</li>
<li><strong>丢失修改</strong>：ABA问题，事务A读取记录R为20，将R-1&#x3D;19后写入数据库，事务B也执行一样的操作，但是最后数据库中的记录是R&#x3D;19，事务A的操作被事务B覆盖（这种是程序逻辑本身的问题，所以需要对需要修改的数据加锁&#x2F;版本号&#x2F;旧值比较）</li>
</ol>
<h4 id="隔离等级"><a href="#隔离等级" class="headerlink" title="隔离等级"></a>隔离等级</h4><ol>
<li><p><strong>读未提交</strong>：一个事务还没提交，其变更就能被其他事务看到</p>
</li>
<li><p><strong>读已提交</strong>：一个事务提交之后，其变更才能被其他事务看到，能够解决脏读的问题</p>
</li>
<li><p><strong>可重复读</strong>：一个事务执行过程中，对同一字段的多次读取结果是一样的，除非数据是被自己事务本身修改，能够解决不可重复读的问题，但是幻读仍然有可能发生<strong>（InnoDB通过MVCC和Next-key Lock在可重复读的隔离级别下解决了幻读的问题）</strong></p>
</li>
<li><p><strong>串行化</strong>：所有事务都是串行执行的，完全服从ACID的隔离级别，能解决所有问题</p>
</li>
</ol>
<h3 id="锁-、间隙锁、Next-Key-Lock"><a href="#锁-、间隙锁、Next-Key-Lock" class="headerlink" title="锁 、间隙锁、Next-Key Lock"></a>锁 、间隙锁、Next-Key Lock</h3><ul>
<li><p><strong>全局锁</strong>：对整个数据库加锁（Flush tables with read lock），典型应用场景是做全库逻辑备份（如果使用InnoDB，则使用mysqldump备份数据库的时候，有MVCC的支持，就不用加全局锁了）</p>
</li>
<li><p><strong>表级锁</strong>：又分为<strong>表锁</strong>和<strong>元数据锁（metadata lock， MDL）</strong></p>
<ul>
<li>元数据锁：锁住表结构，在访问一个表的时候会被自动加上，事务中的MDL锁会在语句执行开始时申请，但是语句结束后并不会马上释放，而是等到整个事务提交后才会释放</li>
</ul>
</li>
<li><p><strong>行锁</strong>：锁住一行，在InnoDB的事务中，行锁是在语句执行的时候加上，但是要等到事务结束才会释放（<strong>两阶段锁协议</strong>）</p>
<ul>
<li>行锁可能出现死锁的一种情况，事务A执行了第一条语句，事务B执行了第一条语句，两个事务分别获得了不同的行锁</li>
<li>解决行锁死锁的方法， <strong>1. 等待超时（innodb_lock_wait_timeout）</strong>，<strong>2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务（innodb_deadlock_detect &#x3D; on）</strong></li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 事务A</span></span><br><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 事务B</span></span><br><span class="line"><span class="keyword">start</span> transaction;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line"><span class="keyword">update</span> t <span class="keyword">set</span> k <span class="operator">=</span> k <span class="operator">+</span> <span class="number">1</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>间隙锁（Gap Lock）</strong>:锁住两个值之间的空隙，前开后开区间，如6个值，有7个空隙，包括（-∞，num）和（num, +∞）<ul>
<li><strong>跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作</strong></li>
<li>间隙锁死锁的例子<ul>
<li>session A 执行 select … for update 语句，由于 id&#x3D;9 这一行并不存在，因此会加上间隙锁 (5,10);</li>
<li>session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；</li>
<li>session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；</li>
<li>session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E9%97%B4%E9%9A%99%E9%94%81%E6%AD%BB%E9%94%81.png" alt="image-20220906104804761"></p>
<ul>
<li><strong>Next-key Lock</strong>：Inno加锁的<strong>基本单位</strong>，<strong>为的就是解决幻读</strong>，行锁<code>b</code>和间隙锁<code>(a, b)</code>加在一起，就是一个<strong>Next-key Lock</strong>，是前开后闭区间<code>(a, b]</code></li>
</ul>
<h3 id="多版本并发控制MVCC"><a href="#多版本并发控制MVCC" class="headerlink" title="多版本并发控制MVCC"></a>多版本并发控制MVCC</h3><blockquote>
<p>MVCC加上Next-key Lock就能够解决幻读的问题。单单MVCC只能解决可重复读，当前读的情况下，还是会出现幻读</p>
</blockquote>
<blockquote>
<p>在MVCC中，非锁定读（普通select）是不用加锁的，但是锁定读(select … for update &#x2F; select … lock in share mode &#x2F; update &#x2F; insert &#x2F; delete)的时候会用锁</p>
</blockquote>
<blockquote>
<p>InnoDB中，每条记录在更新的时候都会同时记录一条回滚操作，因此能得到上一个状态的值。（这个回滚日志<code>undolog</code>会在不需要的时候才删除，即当前所有事务中的最小版本号大于回滚日志的版本号）</p>
</blockquote>
<h4 id="标识ID"><a href="#标识ID" class="headerlink" title="标识ID"></a>标识ID</h4><ul>
<li><strong>每个事务</strong>都有一个唯一的<strong>事务ID（transaction id）</strong>，每个事务开始前向InnoDB的事务系统申请，严格递增</li>
<li><strong>每行数据</strong>都有多个版本<strong>row trx_id</strong>，每次事务更新数据的时候，都会生成一个新的数据版本，并把<strong>事务ID</strong>赋值给<strong>row trx_id</strong>，旧的数据版本能够通过回滚日志得到</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/MVCC.png" alt="image-20220905203039546"></p>
<h4 id="详细过程"><a href="#详细过程" class="headerlink" title="详细过程"></a>详细过程</h4><blockquote>
<p>核心是通过版本控制来获得一个一致性视图，但是当事务更新数据的时候，只能用当前读，如果当前记录的行锁被其他事务占用，就只能进入锁等待。</p>
</blockquote>
<ol>
<li><strong>当前事务开始时</strong>，构造一个<strong>数组</strong>用于保存当前事务启动瞬间<strong>活跃</strong>的<strong>所有事务ID</strong>（即启动了，但是还没有提交）</li>
<li>数组里面事务ID的<strong>最小值记为低水位</strong>，<strong>事务ID的最大值+1记为高水位</strong>，数组和高水位就组成了当前事务的一致性视图（read-view）</li>
<li>对于<strong>一个数据记录</strong>的<strong>row trx_id</strong>来说，有以下几种可能<ul>
<li><strong>row trx_id小于低水位</strong>，落在绿色部分，表示这个版本的数据是已经提交的，或者是当前事务自己生成的，所以数据<strong>可见</strong></li>
<li><strong>row trx_id大于高水位</strong>，落在红色部分，表示这个版本的数据是由未来的事务生成的，<strong>不可见</strong></li>
<li>如果落在黄色部分：<ul>
<li><strong>row trx_id在数组中</strong>，表示这个版本是由未提交的事务生成的，<strong>不可见</strong></li>
<li><strong>row trx_id不在数组中</strong>，表示这个版本的数据是由已提交的事务生成的，<strong>可见</strong>（因为低水位和高水位表示的只是一个区间，这个区间中有已经提交的事务和未提交的事务，数组中的是未提交的事务，而当前的事务ID大于高水位，<strong>row trx_id</strong>落在这个区间内已提交的事务，哪当然是可见的）</li>
</ul>
</li>
</ul>
</li>
<li><strong>当前读</strong>：<strong>更新数据都是先读后写的</strong>，而这个读，只能<strong>读已经提交完成的最新版本</strong></li>
<li>如果是更新&#x2F;删除&#x2F;插入这些锁定读的事务呢？<strong>两阶段锁协议</strong>，需要等到获得锁的事务结束了，释放锁，才能继续<strong>当前读</strong>，继续后面的操作</li>
</ol>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/MVCC%E6%B0%B4%E4%BD%8D.png" alt="image-20220905225008836"></p>
<h4 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h4><p>MVCC也会出现ABA问题，因为只有在锁定读的时候才会加锁，所以可能会出现ABA问题，一个简单的例子，事务A读取了记录R数值为1，之后事务B也读取这个记录R数值为1，之后事务AB都想要将记录R+1后更新，那么最后结果就会变成2，但是期望是3。ABA问题是编程问题，所以可以使用select … lock for update来锁住想要更新的表，这样只有获取到锁的事务才能进行操作。或者加一个旧值&#x2F;版本号进行判断，只有当旧值&#x2F;版本号一样的时候才更新（但是修改失败需要有重试机制）。</p>
<h3 id="binlog、redolog"><a href="#binlog、redolog" class="headerlink" title="binlog、redolog"></a>binlog、redolog</h3><h4 id="binlog（归档日志）"><a href="#binlog（归档日志）" class="headerlink" title="binlog（归档日志）"></a>binlog（归档日志）</h4><blockquote>
<p>binlog的主要作用是用于备份，以及主从同步</p>
</blockquote>
<blockquote>
<p>binlog的写是追加写，所以不会覆盖以前的数据</p>
</blockquote>
<p>三种数据格式：</p>
<ul>
<li>statement – 记录执行的SQL语句，简洁，但是主库与从库执行同一条语句的结果可能不一样，如NOW()</li>
<li>row – 记录真实数据的变化，可靠，主从库执行结果一样，但是占空间</li>
<li>mixed – 前两种的混合，MySQL自己判断如果会引起主备不一致的时候，就用row格式，否则用statement</li>
</ul>
<h4 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a>redo log（重做日志）</h4><blockquote>
<p>redolog主要的作用是用于崩溃恢复，固定大小，循环写，可以比如可以配置一组4个文件，每个文件大小1GB，从头开始写，写到末尾又回到开头循环写。</p>
</blockquote>
<ul>
<li><p><strong>write pos</strong>：表示当前写记录的位置，一边写一边后移</p>
</li>
<li><p><strong>check point</strong>：check point之前的数据都是已经落盘（flush到磁盘）上的，write pos大于check point，write pos 与check point之间的数据表示在内存页上，但是还没落盘的数据</p>
</li>
</ul>
<h4 id="缓冲结构"><a href="#缓冲结构" class="headerlink" title="缓冲结构"></a>缓冲结构</h4><blockquote>
<p>崩溃分为数据库崩溃和操作系统崩溃，数据库崩溃只会影响MySQL中的缓存（丢失这一部分，已经调用write写入到操作系统缓存中的则是正常的），操作系统崩溃则是影响数据的落盘（无法恢复）</p>
</blockquote>
<ul>
<li><p><strong>buffer pool</strong>：MySQL中用于缓存页的地方，有脏页以及干净页，脏页落盘需要flush，干净页不用</p>
</li>
<li><p><strong>change buffer</strong>：buffer pool内的一部分，<strong>主要用于记录页面数据的变化</strong>，如果一个<strong>数据页已经在内存</strong>中，则可以直接修改这个内存数据页然后变成脏页；但是如果一个<strong>数据页不在内存中，在磁盘中</strong>，则可以将更新操作写到change buffer中，这样能够避免将数据页从磁盘中读取到内存中，<strong>减少磁盘的随机读IO，适用于多写少读</strong>，当要读取这个数据页的数据时，再将从磁盘中读取的数据执行change buffer中的操作就能得到最新的数据。</p>
</li>
<li><p><strong>redolog buffer</strong>：可以认为也是buffer pool中的一部分，事务执行过程中更新数据的日志都得先保存起来，但是又不能在还没commit的时候写入到redo log文件中，所以先用redolog buffer来存redo日志。</p>
</li>
<li><p><strong>操作系统的缓存 os cache</strong>：调用操作系统的write函数并不会将数据直接写入磁盘，而是先写入系统的缓冲池中，系统自己判断何时将数据flush进磁盘，<strong>数据库崩溃不会影响到这部分的数据，操作系统崩溃才会影响</strong>。</p>
</li>
</ul>
<h4 id="二阶段提交"><a href="#二阶段提交" class="headerlink" title="二阶段提交"></a>二阶段提交</h4><p>redo log是InnoDB引擎特有，用于提供崩溃恢复的功能，而二阶段提交涉及到<code>binlog(归档日志)</code>还有<code>redolog(重做日志)</code>，即server层与引擎层之间的交互。</p>
<p><strong>两阶段提交的作用</strong>：保证MySQL数据库中的记录与磁盘中的记录一致</p>
<p><strong>方法流程</strong>：</p>
<ul>
<li>执行器调用引擎的API接口(未写<code>binlog</code>)，写入一行数据</li>
<li>InnoDB引擎把数据保存在内存中，同时记录<code>redolog</code>，此时<code>redolog </code>进入<code>prepare状态</code>，然后告诉执行器，执行完成可以随时提交</li>
<li>执行器收到通知后记录<code>binlog</code>，然后调用InnoDB引擎接口说已经写完<code>binlog</code></li>
<li>InnoDB写<code>redolog</code>为<code>commit状态</code></li>
<li>更新完成</li>
</ul>
<p><strong>为什么要这样子？</strong></p>
<ul>
<li>假设<strong>先写redolog并设为commit状态，然后写binlog</strong>，那么写完<code>redolog</code>之后，机器挂了，<code>binlog</code>日志没有被写入。机器重启后，会通过<code>redolog</code>恢复数据，但是<code>binlog</code>没有记录这一条数据，那么后续机器根据<code>binlog</code><strong>备份</strong>或者<strong>主从同步</strong>的时候，就会丢失这一条数据。</li>
<li>假设<strong>先写binlog，然后写redolog</strong>，那么当<code>binlog</code>写完的时候，机器异常重启了，但是由于没有这条<code>redolog</code>，所以机器无法恢复这一条记录，但是<code>binlog</code>里面多出这一条数据，哪备份或者主从同步的时候也会出现同样的问题。</li>
<li><strong>二阶段提交如何保证一致性？</strong>假设极端的状态是<code>redolog</code>已经处于<strong>prepare状态</strong>，<code>binlog</code>也已经写完了，这个时候发生异常重启，就要依赖MySQL的处理机制<ul>
<li>判断<code>redolog</code>是否完整(<strong>commit状态</strong>)，如果是完整的，就能立即提交</li>
<li>如果<code>redolog</code>只是<code>prepare</code>状态，但<strong>不是commit状态</strong>，这个时候就判断<code>binlog</code>是否完整，如果完整就提交<code>redolog</code>，不完整就回滚事务</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485097&idx=1&sn=84c89da477b1338bdf3e9fcd65514ac1&chksm=cea24962f9d5c074d8d3ff1ab04ee8f0d6486e3d015cfd783503685986485c11738ccb542ba7&token=79317275&lang=zh_CN%23rd">一条SQL语句在MySQL中如何执行的 (qq.com)</a></p>
<h3 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h3><h4 id="详细流程"><a href="#详细流程" class="headerlink" title="详细流程"></a>详细流程</h4><ol>
<li>在备库B上通过<strong>change master</strong>命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量</li>
<li>在备库B上执行<strong>start slave</strong>命令，这个时候备库会启动两个线程，一个是<strong>io_thread</strong>，另一个是<strong>sql_thread</strong>。<strong>io_thread负责与主库A建立连接，获取binlog</strong></li>
<li>主库A校验完备库B传来的参数之后，按照请求的位置读取binlog通过<strong>dump_thread</strong>线程发给备库B</li>
<li>备库B拿到binlog之后，写到本地文件，称为<strong>中转日志（relay log）</strong></li>
<li>备库B中的<strong>sql_thread读取中转日志，解析日志理的命令，并执行</strong></li>
</ol>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B.png" alt="image-20220906144751652"></p>
<h4 id="循环复制问题"><a href="#循环复制问题" class="headerlink" title="循环复制问题"></a>循环复制问题</h4><blockquote>
<p>一般来说都是双Master结构，即节点A和节点B之间互为主从关系</p>
</blockquote>
<blockquote>
<p>但是这样会产生一个问题，就是节点A更新了一条语句，并将binlog发给节点B，节点B更新之后又将binlog发给节点A执行</p>
</blockquote>
<p><strong>解决方法</strong></p>
<p>设置server id</p>
<ol>
<li>规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系</li>
<li>一个备库收到binlog并且在重放过程中，要生成与原binlog的server id相同的新binlog</li>
<li>备库收到主库发过来的binlog记录，先判断server id是不是跟自己的一样，一样表示这个日志是自己生成的，则直接丢弃；不一样表示不是自己生成的，重做这个日志</li>
</ol>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2.png" alt="image-20220906145810695"></p>
<h3 id="inner-join、left-join、right-join、full-join"><a href="#inner-join、left-join、right-join、full-join" class="headerlink" title="inner join、left join、right join、full join"></a>inner join、left join、right join、full join</h3><ul>
<li><p><strong>inner join</strong>：等同于平时使用<code>，</code>连接两个表，内连接，交集</p>
</li>
<li><p><strong>left join</strong>：返回左表的全部数据</p>
</li>
<li><p><strong>right join</strong>：返回右表的全部数据</p>
</li>
<li><p><strong>full join</strong>：返回左右两个表的所有数据，并集</p>
</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/join.png" alt="image-20220906162852592"></p>
<h4 id="on和where的区别"><a href="#on和where的区别" class="headerlink" title="on和where的区别"></a>on和where的区别</h4><ul>
<li><p><strong>on</strong>：在生成临时表时使用的条件，不管on中的条件，都会返回left join &#x2F; right join &#x2F; full join时，左边&#x2F;右边&#x2F;两边表中的记录</p>
</li>
<li><p><strong>where</strong>：临时表生成好后，对临时表进行过滤，所有条件不为真的记录都被过滤掉</p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.runoob.com/w3cnote/sql-different-on-and-where.html">https://www.runoob.com/w3cnote/sql-different-on-and-where.html</a></p>
<h3 id="小表驱动大表"><a href="#小表驱动大表" class="headerlink" title="小表驱动大表"></a>小表驱动大表</h3><blockquote>
<p>select * from t1 straight_join t2 on (t1.a &#x3D; t2.a); 能够让MySQL使用固定的连接方式执行查询，t1是驱动表、t2是被驱动表</p>
</blockquote>
<blockquote>
<p>小表是指两个表按照各自的条件过滤之后，参与join的各个字段的<strong>总数据量</strong>小的表</p>
</blockquote>
<p>驱动与被驱动：按照驱动表t1的数据到被驱动表t2中逐条查找数据，驱动表是外层循环，被驱动表是内层循环</p>
<p>Index Nested-Loop Join：能够用上被驱动表的索引</p>
<p>Simple Nested-Loop Join：不能用索引的情况下，就是两层循环</p>
<p>Block Nested-Loop Join：先将驱动表数据放入join buffer中，再根据被驱动表与join buffer中的数据对比</p>
<h3 id="数据库优化（未施工）"><a href="#数据库优化（未施工）" class="headerlink" title="数据库优化（未施工）"></a>数据库优化（未施工）</h3><h2 id="Spring（未施工）"><a href="#Spring（未施工）" class="headerlink" title="Spring（未施工）"></a>Spring（未施工）</h2><h3 id="DI-IOC-AOP"><a href="#DI-IOC-AOP" class="headerlink" title="DI IOC AOP"></a>DI IOC AOP</h3><h3 id="Bean的生命周期"><a href="#Bean的生命周期" class="headerlink" title="Bean的生命周期"></a>Bean的生命周期</h3><h3 id="Spring-MVC的工作流程"><a href="#Spring-MVC的工作流程" class="headerlink" title="Spring MVC的工作流程"></a>Spring MVC的工作流程</h3><h3 id="Spring-MVC的常用注解"><a href="#Spring-MVC的常用注解" class="headerlink" title="Spring MVC的常用注解"></a>Spring MVC的常用注解</h3><h2 id="k8s（待收拾）"><a href="#k8s（待收拾）" class="headerlink" title="k8s（待收拾）"></a>k8s（待收拾）</h2><h3 id="k8s的操作命令"><a href="#k8s的操作命令" class="headerlink" title="k8s的操作命令"></a>k8s的操作命令</h3><p>kubectl 动作 资源 -其他参数</p>
<ul>
<li>动作包括<ul>
<li>create</li>
<li>apply</li>
<li>get</li>
<li>describe</li>
<li>exec</li>
<li>logs</li>
<li>delete</li>
<li>explain</li>
</ul>
</li>
<li>资源包括<ul>
<li>Deployment</li>
<li>StatefullSet</li>
<li>ConfigMap</li>
<li>Secret</li>
<li>HPA</li>
<li>RC、RS</li>
<li>pods</li>
<li>nodes</li>
<li>namespace</li>
</ul>
</li>
</ul>
<h3 id="k8s的组件"><a href="#k8s的组件" class="headerlink" title="k8s的组件"></a>k8s的组件</h3><img src="k8s组件.png" alt="image-20220908094016645" style="zoom:50%;" />

<ul>
<li>Kubectl：客户端与k8s集群交互的命令行工具</li>
<li>API  server：作为k8s系统的入口，其封装了核心对象的增删改查操作，以及提供RESTful API接口给外部客户端或者k8s内部组件调用。维护的RSET对象会被持久化储存到etcd分布式数据库中</li>
<li>Scheduler：负责集群的资源调度，为新建立的pod选择节点node进行部署。组件抽离，可以方便替换成其他调度器</li>
<li>Controller Manager：负责维护集群的状态，比如故障检测、自动扩展、滚动更新等</li>
<li>Kubelet：负责维护容器的生命周期，同时也负责Volume（CSI）和网络（CNI）的管理</li>
<li>Container runtime：负责镜像管理以及pod和容器的真正运行（CRI）</li>
<li>Kube-proxy：负责为Service提供cluster内部的服务发现和负载均衡</li>
<li>CoreDNS：负责为整个集群提供DNS服务</li>
<li>Ingress Controller：为k8s中的服务提供外网入口</li>
<li>Prometheus：为整个集群提供资源监控能力</li>
<li>Dashboard</li>
<li>Federation</li>
</ul>
<h3 id="控制器类型"><a href="#控制器类型" class="headerlink" title="控制器类型"></a>控制器类型</h3><ul>
<li>HPA：根据CPU使用率和内存使用率进行自动扩缩容<ul>
<li>Deployment：一般用于负责管理RC和RS，提供滚动更新&#x2F;回滚能力<ul>
<li>Replication Controller 和 Replication Set：RS用于替代RC，主要作用是维护应用的副本数量，并且RS支持集合式的selector</li>
</ul>
</li>
</ul>
</li>
<li>StatefullSet：解决有状态服务的问题，Pod重新调度之后还是有：稳定的持久化存储、稳定的网络标志（基于Headless Service没有Cluster IP的Service来实现）、有序部署、有序收缩</li>
<li>DaemonSet：保证每个节点Node上都运行一个Pod的副本</li>
<li>Job，CronJob：Job负责仅执行一次的任务，Cron Job则是基于Crontable的定时任务</li>
</ul>
<h3 id="K8S网络"><a href="#K8S网络" class="headerlink" title="K8S网络"></a>K8S网络</h3><p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/k8s%E7%BD%91%E7%BB%9C.png" alt="image-20220908101831528"></p>
<h3 id="资源类型"><a href="#资源类型" class="headerlink" title="资源类型"></a>资源类型</h3><blockquote>
<p>资源清单–k8s中用于定义资源的yaml文件</p>
</blockquote>
<ul>
<li>NameSpace级别<ul>
<li>工作负载型资源：Pod、RC、RS、Deployment…..</li>
<li>服务发现及负载均衡型资源：Service、Ingress…</li>
<li>配置与储存型资源：PV、PVC…</li>
<li>特殊类型的储存卷：ConfigMap，Secret….</li>
</ul>
</li>
<li>集群级别<ul>
<li>NameSpace、Node、ClusterRole、ClusterRoleBinding</li>
</ul>
</li>
<li>元数据型资源<ul>
<li>HPA、PodTemplate、LimitRange</li>
</ul>
</li>
</ul>
<h3 id="Pod的生命周期"><a href="#Pod的生命周期" class="headerlink" title="Pod的生命周期"></a>Pod的生命周期</h3><blockquote>
<p>一个Pod里面至少有两个容器，一个是pause容器，负责维护pod内部的网络和共享储存卷，使得pod内部的容器能够使用localhost互相访问，以及使用相同的共享储存卷，其他的容器就是应用启动的容器了</p>
</blockquote>
<ul>
<li>Init容器：用于做初始化的容器，执行的顺序是按照定义时候的顺序，Init容器启动失败k8s会不断地重试，除非将restartPolicy设为Never（Pod重启，Init容器也会重新执行）</li>
<li>探针<ul>
<li>就绪探针</li>
<li>存活探针</li>
</ul>
</li>
<li>Pod hook钩子：在容器中进程启动前或者容器中进程终止运行之前运行，包含在容器的生命周期之中<ul>
<li>exec：执行一段命令</li>
<li>HTTP：发送Http请求</li>
</ul>
</li>
</ul>
<h3 id="Service的网络流向"><a href="#Service的网络流向" class="headerlink" title="Service的网络流向"></a>Service的网络流向</h3><p>apiserver发出一个请求（IP，PORT）随机到一个节点Node上，那么节点Node怎么知道是要访问哪个pod地址呢？</p>
<p>首先会经过节点上的kube-proxy，然后kube-proxy到内核中去查找ip映射表，这个时候就要用上ipvs或者是iptables了，查找到之后再将流量负载均衡定向到对应的pod中</p>
<h3 id="ipvs对比iptables"><a href="#ipvs对比iptables" class="headerlink" title="ipvs对比iptables"></a>ipvs对比iptables</h3><blockquote>
<p>都是基于netfilter</p>
</blockquote>
<ul>
<li>iptables使用列表来记录所有的规则，并且匹配方式是全部扫描匹配，所以当集群规模大的时候，性能问题就会突出</li>
<li>ipvs使用hash表，hash随机访问的特性在集群规模大的时候，也不会影响性能</li>
</ul>
<h3 id="Headless-Service"><a href="#Headless-Service" class="headerlink" title="Headless Service"></a>Headless Service</h3><p>有时候不需要或者不想要负载均衡，以及单独的Service IP，可以将Cluster IP设置为None来创建Headless Service，StatefullSet的网络也是依靠Headless Service来实现稳定访问的</p>
<p>Statefulset中创建的无头服务会为集群内部的每个成员提供一个唯一的DNS域名来作为每个成员的网络标识，集群内部成员之间使用域名通信（<code>pod名称+序号.Service名称</code>），如服务名称是<code>服务名.命名空间.svc.cluster.local</code>，那么一个创建的Pod使用的域名是<code>pod名称-序号.服务名.命名空间.svc.cluster.local</code>，如果StatefulSet中的一个Pod挂掉，那么新创建的Pod会被赋予跟原来Pod一样的名字，通过这个名字来匹配原来的储存和网络，因此实现了状态的保存。</p>
<blockquote>
<p>访问一个普通的<code>Service</code>, kube-proxy会将请求重定向到后端的某个<code>Pod</code>, 多次请求虽然发送到的后端可能不同, 但是前端是无感知的, 因为Service本身有固定IP.</p>
<p>但是访问一个<code>headless service</code>, 其实是随机且直接访问到后端<code>Pod</code>, 比如多次<code>ping redis-service</code>, 你会发现解析出来的地址是不同的, 而这些地址都是Pod的地址.</p>
</blockquote>
<h3 id="亲和性，反亲和性，污点，污点容忍"><a href="#亲和性，反亲和性，污点，污点容忍" class="headerlink" title="亲和性，反亲和性，污点，污点容忍"></a>亲和性，反亲和性，污点，污点容忍</h3><h4 id="亲和性（pod的策略）"><a href="#亲和性（pod的策略）" class="headerlink" title="亲和性（pod的策略）"></a>亲和性（pod的策略）</h4><ul>
<li>节点亲和性<ul>
<li>软策略</li>
<li>硬策略</li>
</ul>
</li>
<li>Pod亲和性<ul>
<li>硬策略</li>
<li>软策略</li>
</ul>
</li>
</ul>
<h3 id="污点（node的策略）"><a href="#污点（node的策略）" class="headerlink" title="污点（node的策略）"></a>污点（node的策略）</h3><p>节点选项：</p>
<ul>
<li>NoSchedule：表示k8s将不会将pod调度到具有该污点的Node上</li>
<li>PreferNoSchedule：表示k8s将尽量避免将pod调度到具有该污点的Node上</li>
<li>NoExecute：表示k8s将不会将pod调度到具有该污点的Node上，同时会将Node上已经存在的pod驱逐出去</li>
</ul>
<p>pod的污点容忍：pod可以容忍node中污点的存在，并被调度到存在污点的node上</p>
<h3 id="Prometheus-operator"><a href="#Prometheus-operator" class="headerlink" title="Prometheus-operator"></a>Prometheus-operator</h3><h2 id="Redis（未施工）"><a href="#Redis（未施工）" class="headerlink" title="Redis（未施工）"></a>Redis（未施工）</h2><p>Redis 数据类型</p>
<ul>
<li>string</li>
<li>list</li>
<li>hash</li>
<li>set</li>
<li>zset</li>
<li>hyperloglog</li>
<li>GEO</li>
<li>bitmap</li>
<li>stream</li>
</ul>
<p>Redis 数据结构</p>
<ul>
<li>SDS</li>
<li>链表</li>
<li>压缩列表-缺陷是啥</li>
<li>哈希表-rehash过程，渐进式哈希（两个哈希表），哈希冲突解决方法</li>
<li>整数集合–升级过程</li>
<li>跳表-查询过程，层数设计，插入方式</li>
<li>quicklist–链表+压缩列表</li>
<li>listpack</li>
</ul>
<p>持久化</p>
<ul>
<li>RDB - 生成RDB流程</li>
<li>AOF - 生成AOD流程，以及AOF重写，AOF写回策略</li>
</ul>
<p>过期删除和内存淘汰策略</p>
<ul>
<li>过期删除的删除策略是什么？</li>
<li>内存淘汰策略<ul>
<li>不淘汰 - 抛出异常</li>
<li>淘汰<ul>
<li>在设置了过期时间的键中删除（随机，LFU，LRU，TTL）</li>
<li>在所有键中删除（随机，LRU，LFU）</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>高可用</p>
<ul>
<li>主从复制流程</li>
<li>哨兵模式</li>
</ul>
<p>缓存</p>
<ul>
<li>缓存雪崩</li>
<li>缓存击穿</li>
<li>缓存穿透</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/redis/base/redis_interview.html#%E8%AE%A4%E8%AF%86-redis">https://xiaolincoding.com/redis/base/redis_interview.html#%E8%AE%A4%E8%AF%86-redis</a></p>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><blockquote>
<p>主要是分清Broker、主题Topic、分区Partition、副本Replica之间的概念</p>
</blockquote>
<h4 id="服务器层面"><a href="#服务器层面" class="headerlink" title="服务器层面"></a>服务器层面</h4><ul>
<li><strong>Broker</strong>：一个独立的Kafka服务被称为Broker，可以理解为Kafka集群中的一个节点。</li>
<li><strong>集群控制器（Controller）</strong>：每一个集群都会选举出一个Broker作为集群控制器Controller（第一个成功在zookeeper中创建<code>/kafka/controller</code>节点的Broker会被指定为集群控制器），主要负责集群管理工作，包括：<ul>
<li>创建删除主题、增加分区并选择副本的Leader</li>
<li>集群Broker管理（Broker新增、退出、故障）</li>
<li>分区副本Preferred Leader选举</li>
<li>消费者组分区重分配</li>
<li>数据服务 – 向其他Broker提供集群的元数据信息</li>
</ul>
</li>
</ul>
<h4 id="主题层面"><a href="#主题层面" class="headerlink" title="主题层面"></a>主题层面</h4><ul>
<li><strong>主题（Topic）：</strong>主题-订阅的模式，生产者将消息发送至相应的Topic中，消费者则从感兴趣的Topic中取出消息消费。Topic是一个逻辑概念。</li>
<li><strong>分区（Partition）</strong>：一个Topic被分成多个分区Partition，一个Partition从属于一个Broker，是最基本的<strong>储存单元</strong>，储存着一个Topic中的部分数据。每个Partition都有自己独立的log文件，每条记录都以追加的形式写入。</li>
<li><strong>副本（Replica）</strong>：为了保证Kafka的高可用，一个分区通常拥有多个副本。其中一个为<strong>Leader replica</strong>，其他为<strong>Follower replica</strong>，所有的事件都直接发送给<strong>Leader replica</strong>，<strong>Follower replica</strong>通过主从同步来保持与<strong>Leader replica</strong>数据一致。</li>
<li><strong>偏移量（Offset）</strong>：Partition中的每条记录都会被分配一个唯一的序号，称为偏移量Offset。</li>
<li><strong>消息（Message）</strong>：Kafka的基本数据单元。</li>
<li><strong>批次（Batch）</strong>：为了减少网络了开销，提高IO效率，多个消息会被放入同一批次之后再发送给Kafka。</li>
</ul>
<h4 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h4><blockquote>
<p>Kafka中多处涉及选举机制，容易混淆</p>
</blockquote>
<ul>
<li>Broker Controller组件Leader的选举 – 主要是监控Kafka集群状态</li>
<li>分区多副本机制选举Leader – 副本的Leader负责与生产者消费者的所有通信，Follower只是作为可靠性备份（主从机制）</li>
<li>消费者选举Leader – 消费者的Leader选举主要是负责消费者组内各个消费者消费分区的分配</li>
</ul>
<h3 id="生产者客户端工作原理"><a href="#生产者客户端工作原理" class="headerlink" title="生产者客户端工作原理"></a>生产者客户端工作原理</h3><img src="kafka消费者工作流程.png" alt="kafka消费者工作流程" style="zoom:80%;" />

<blockquote>
<p>整个生产者客户端主要由两个线程协调运行，分别是程序主线程和发送线程。</p>
<ul>
<li>程序主线程：主要负责消息的产生，然后通过拦截器、序列化器和分区器处理之后缓存到消息收集器RecordAccumulator中（多个消息打包之后变成ProducerBatch）</li>
<li>发送线程：主要负责从消息收集器中获取消息并将其发送至Kafka集群中</li>
</ul>
</blockquote>
<ol>
<li>首先，客户端生成消息，交给拦截器，拦截器可以对数据进行预处理，比如消息的格式化显示等。</li>
<li>随后，消息交给序列化器，对其中的key和value进行序列化</li>
<li>分区器使得生产者能够根据一定的规则，将特定的消息发送至特定的分区中</li>
<li>之后消息会到消息收集器中，根据设定的batch.size或者linger.ms触发消息发送之后，才会将收集器中的消息发送给kafka集群<ol>
<li><strong>batch.size</strong>：数据累积到batch.size大小之后，sender才会发送数据，默认16k</li>
<li><strong>linger.ms</strong>：如果数据没有达到batch.size，sender等待linger.ms设置的时间之后就会发送数据，默认值是0，表示没有延迟，一有消息到达就将消息发送出去（会导致网络IO频繁）</li>
</ol>
</li>
<li>在发送线程中，InFlightRequests缓存这已经发出去，但是还没有收到响应的请求（Map&lt;NodeId, Deque&gt;，即Kafka节点Id和发出去的请求队列）。主要是限制最多缓存的请求数，通过<code>max.in.flight.requests.per.connection</code>参数设置，默认为5，即每个连接维护一个长度为5的滑动窗口，最多只能缓存5个未响应的请求间隔（有点像TCP的滑动窗口，就算中间已经收到了响应，但是头和尾未响应，也是算头和尾之间的间距），如果超过该数据之后就不能向这个连接中发送更多的请求了</li>
<li>Kafka集群的应答acks：<ol>
<li>设置为0：生产者发送的数据，不需要等待Kafka集群数据落盘立即应答</li>
<li>设置为1：生产者发送的数据，Leader分区收到数据落盘后应答</li>
<li>设置为-1（all）：生产者发送的数据，<strong>Leader和ISR队列</strong>里面的所有节点数据落盘之后再由Leader应答</li>
</ol>
</li>
</ol>
<h4 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h4><blockquote>
<p>如果自定义了分区器的话，当然是用自定义的方法，这里说的是默认情况下</p>
</blockquote>
<p>使用默认分区器的情况下：</p>
<ol>
<li>如果指定了消息的发往的分区，则使用这个分区</li>
<li>如果没有指定分区，但是指定了消息的key，则根据key的hash值映射到特定的分区（如果主题的分区数不变，key跟分区的映射关系就能保持一致）</li>
<li>如果没有指定分区或者是消息的key，会采用粘性分区器，消息会被随机发送到指定主题的其中一个可用分区，并尽可能一直使用该分区，直到发送至该分区的消息收集器中能够达到batch.size之后，才会切换发送至别的分区（随机至另外一个分区）</li>
</ol>
<h4 id="数据可靠性保证"><a href="#数据可靠性保证" class="headerlink" title="数据可靠性保证"></a>数据可靠性保证</h4><p>acks设置为不同值下可能出现的情况</p>
<ul>
<li><strong>0：</strong>生产者发送至Kafka集群中的数据，不需要等待落盘，立即应答<strong>（应答之后Leader挂了，数据存在丢失的问题）</strong></li>
<li><strong>1：</strong>Leader分区收到数据并落盘之后应答<strong>（应答之后Leader挂了，其他Follower都还没有同步到数据，也存在数据丢失的问题）</strong></li>
<li><strong>-1（all）：</strong>Leader和ISR队列里面的所有节点数据落盘之后再由Leader应答<strong>（可能因为某个Follower网络或者挂掉的原因迟迟未能同步，会导致ACK响应阻塞，Kafka使用ISR队列来解决这个问题）（如果分区副本设置为1个，或者ISR中应答的最小副本数量min.insync.replicas为1，则跟ack&#x3D;1效果差不多，还是有数据丢失的问题）</strong><ul>
<li><strong>ISR（in-sync replicas）队列：</strong>和Leader保持同步的所有Follower+Leader的集合（Leader：0，ISR：0、1、2），如果Follower长时间未向Leader发送通信请求或者同步数据，则会被Leader踢出ISR队列，由replica.lag.time.max.ms参数设置，默认30s。</li>
<li><strong>OSR（out-sync replicas）队列：</strong>与Leader不同步的Follower集合</li>
</ul>
</li>
</ul>
<p><strong>数据完全可靠的条件</strong> &#x3D; <strong>ACK级别为-1</strong> + <strong>分区副本数大于等于2</strong> + <strong>ISR里应答的最小副本数量大于等于2</strong></p>
<h4 id="数据重复问题"><a href="#数据重复问题" class="headerlink" title="数据重复问题"></a>数据重复问题</h4><blockquote>
<p>acks设置为-1的时候，生产者可能发送了数据过来，Leader正在跟Follower同步数据，还未响应，但是此时，部分Follower已经同步了数据，Leader却挂了，Kafka集群会重新挑选出新的Leader分区，生产者会重新发送数据，如果这个新选出来的Leader已经同步了旧Leader的数据，那么就会出现数据重复的问题。</p>
</blockquote>
<h5 id="数据传递的语义"><a href="#数据传递的语义" class="headerlink" title="数据传递的语义"></a>数据传递的语义</h5><ul>
<li><strong>至少一次（At Least Once）：</strong> ACK级别为-1 + 分区副本数大于等于2 + ISR里应答的最小副本数量大于等于2，<strong>保证生产者发送的数据Kafka集群会落盘，保证数据不会丢失，但可能重复</strong></li>
<li><strong>最多一次（At Most Once）：</strong> ACK &#x3D; 0，<strong>保证生产者发送的数据最多只发送一次到Kafka集群，保证数据不重复，但是可能会丢失</strong></li>
<li><strong>精确一次（Exactly Once）：</strong> <strong>数据即不能重复，也不能丢失</strong><ul>
<li><strong>幂等性（单会话单分区精确一次）：</strong>生产者无论向Broker发送多少次重复数据，Broker都只会持久化一条，保证不会重复，结合至少一次就能达到精确一次。</li>
<li><strong>事务：</strong>通过事务保证精确一次，实现多个Topic、多个Partition原子性的写入（见下文）</li>
</ul>
</li>
</ul>
<h5 id="生产者幂等性"><a href="#生产者幂等性" class="headerlink" title="生产者幂等性"></a>生产者幂等性</h5><blockquote>
<p>Kafka的幂等性是单会话单分区幂等</p>
</blockquote>
<p>通过**&lt;PID，partition，SeqNumber&gt;**区分每一条数据。（单分区的原因看区分规则就知道，不同分区当成不同的消息）</p>
<ul>
<li><p><strong>PID（Producer ID）</strong>：对用户完全透明，是Producer每次连接上Kafka集群之后，都会向Broker申请一个全局唯一的PID，用来标识本次会话，<strong>如果Producer重启会导致PID的变化，所以Broker就会当成是一个新的生产者（单次会话的原因）</strong>。</p>
</li>
<li><p><strong>partition</strong>：消息需要发往的分区号</p>
</li>
<li><p><strong>SeqNumber</strong>：从0开始单调递增的，Broker端缓存了SeqNumber，对于每条接收的消息，只有SeqNumber比Broker缓存中的大1才接受，否则丢弃（实现幂等）。</p>
</li>
</ul>
<h3 id="消费者客户端工作原理"><a href="#消费者客户端工作原理" class="headerlink" title="消费者客户端工作原理"></a>消费者客户端工作原理</h3><blockquote>
<p>消息的两种<strong>消费方式</strong>：</p>
<ul>
<li><strong>pull（拉）模式：</strong>消费者主动从  mq 服务器中拉取数据（Kafka采用的方式）</li>
<li><strong>push（推）模式：</strong>mq服务器主动将数据推送至消费者（很难保证消费者的消费速度能跟得上mq服务器的推送速度）</li>
</ul>
</blockquote>
<blockquote>
<p>常见的有两种<strong>消费模型</strong>：</p>
<ul>
<li><strong>队列模型（queuing）：</strong>一组消费者从服务读取消息，一条消息只有其中的一个消费者来处理。</li>
<li><strong>发布-订阅模型（publish-subscribe）：</strong>消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。</li>
</ul>
</blockquote>
<blockquote>
<p>Kafka 提供两种<strong>订阅方式</strong>：</p>
<ul>
<li><strong>subscribe：</strong>订阅主题，能够通过正则表达式订阅多个主题，<strong>具有消费者组再平衡的功能</strong>。</li>
<li><strong>assign：</strong>能够直接订阅特定主题的特定分区，<strong>不具备消费者再平衡的功能</strong>。</li>
</ul>
</blockquote>
<p>Kafka 为这两种模型提供单一的消费者抽象模型：<strong>消费者组（Comsumer group）</strong>。</p>
<p>消费者用一个消费者组名（GroupId）标记自己，一个发布在 Topic 上的消息被分发给此消费者组中的一个成员（<strong>每个Topic的 Partition 只能由消费者组中的一个成员消费，但是一个消费者成员能够消费多个 Partition中的消息，是多对一关系</strong>）。</p>
<ul>
<li>假如<strong>所有的消费者都在一个组中，那么这就变成了队列模型</strong></li>
<li>假如<strong>所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型</strong></li>
</ul>
<p>一个消费者组中的消费者成员订阅同一个 Topic，每个消费者成员接收 Topic 的一部分分区的消息，从而实现对消费者的横向扩展，对消息进行分流。<strong>但是不要让消费者组中消费者成员的数量多于 Topic的 Partition 的数量，因为多余的消费者成员会空闲出来。</strong></p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E5%88%86%E5%8C%BA%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB.png" alt="img"></p>
<h4 id="分区的分配策略"><a href="#分区的分配策略" class="headerlink" title="分区的分配策略"></a>分区的分配策略</h4><blockquote>
<p>分区分配策略的主要作用是决定每个消费者组成员消费订阅 Topic 中的哪个分区。</p>
</blockquote>
<blockquote>
<p>Kafka 可以同时使用多个分区分配策略，由<code>partition.assignment.strategy</code>参数设定，默认是 Range + CooperativeSticky。</p>
<p>消费者也可以自定分区策略，通过继承<code>PartitionAssignor</code>接口或者<code>AbstractPartitionAssignor</code>抽象类来实现。</p>
</blockquote>
<p>消费者组分区的分配策略主要有：</p>
<ul>
<li><strong>RangeAssignor（范围）</strong></li>
<li><strong>RoundRobinAssignor（轮询）</strong></li>
<li><strong>StickyAssignor（粘性）</strong></li>
<li><strong>CooperativeStickyAssignor（合作者粘性）</strong>：与StickyAssignor类似</li>
</ul>
<h5 id="RangeAssignor"><a href="#RangeAssignor" class="headerlink" title="RangeAssignor"></a>RangeAssignor</h5><blockquote>
<p>对<strong>每个 Topic 进行独立的分区分配</strong>。对于每一个 Topic，首先对分区按照分区 ID 进行排序，然后对订阅该 Topic 的消费者组成员进行排序，之后尽量均衡地将分区分配给消费者。</p>
<p>首先要决定每个消费者消费分区的个数，Topic 分区数对消费者个数取余便是每个消费者至少要处理的分区个数，但是会有剩余的分区，剩余的分区则平均分配给排序靠前的消费者。然后从0号分区开始按每个消费者的消费分区个数按顺序分配。</p>
<p>缺点：随着消费者订阅 Topic 数量的增加，会导致不平衡问题，排序靠前的消费者会被分配更多的分区（因为上面的分配策略是针对单个 Topic 的）。</p>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5Range.png" alt="img"></p>
<h5 id="RoundRobinAssignor"><a href="#RoundRobinAssignor" class="headerlink" title="RoundRobinAssignor"></a>RoundRobinAssignor</h5><blockquote>
<p>将<strong>消费者组内订阅所有 Topic 的分区</strong>及所有消费者进行排序后尽量均衡的分配。如果消费者组内，消费者订阅 Topic 列表是相同的（每个消费者成员都订阅了相同的 Topic），那么分配结果是尽量均衡的（针对所有 Topic，消费者成员之间分配到的分区数的差值不会超过 1）。如果订阅的 Topic 列表是不同的，那么分配结果是不保证“尽量均衡”的，因为某些消费者成员不参与部分 Topic 的分配。</p>
<p>分配策略是：将所有 Topic 的 Partition  和所有消费者成员都列出来，分别按照 <code>hashcode</code> 进行排序，最后通过轮询算法分配 Partition给消费者成员。</p>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5RoundRobin.png" alt="img"></p>
<blockquote>
<p>对于订阅组内消费者订阅 Topic 不一致的情况：假设有三个消费者分别为C0、C1、C2，有3个 Topic T0、T1、T2，分别拥有1、2、3个分区，并且C0订阅T0，C1订阅T0和T1，C2订阅T0、T1、T0，那么RoundRobinAssignor的分配结果如下图所示，<strong>没有订阅对应 Topic 的消费者不参与分配，但是排序轮询还是按正常一样</strong>。</p>
<p>可以看到已经尽量保证均衡了，但是 C2 承担了 4 个分区，而 C1 其实是订阅了 T1 的，如果把 T1P1 交给 C1 负责会更加均衡。</p>
</blockquote>
<img src="Kafka分区分配策略RoundRobin缺点.png" alt="img" style="zoom:50%;" />

<h5 id="StickyAssignor"><a href="#StickyAssignor" class="headerlink" title="StickyAssignor"></a>StickyAssignor</h5><blockquote>
<p>无论是RangeAssignor，还是RoundRobinAssignor，当前的分区分配算法都没有考虑上一次的分配结果。StickyAssignor解决的就是这个问题。</p>
</blockquote>
<blockquote>
<p>StickyAssignor的主要目标：</p>
<ul>
<li>分区的分配尽量均衡</li>
<li>每一次重分配的结果尽量与上一次分配结果保持一致</li>
</ul>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5StickyAssignor.png" alt="img"></p>
<blockquote>
<p>上面的例子中，C1 下线后，Sticky 模式原来分配给 C0、C2 的分区都没有发生变动，并且最终 C0、C1达到均衡的目的；而RoundRobin 模式中原本分配给 C0 的 T1P1，以及原本分配给 C2 的 T1P0 都发生了变动。</p>
</blockquote>
<blockquote>
<p>下面是另外一个例子</p>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5StickyAssignor2.png" alt="img"></p>
<h4 id="消费者组再平衡"><a href="#消费者组再平衡" class="headerlink" title="消费者组再平衡"></a>消费者组再平衡</h4><blockquote>
<p><strong>再平衡是指 Kafka 消费者组成员或者订阅 Topic 发生变化时的一种分区重分配机制，再平衡期间消费者会停下手头的事情</strong>，一般有三种情况会触发再平衡：</p>
<ul>
<li><strong>消费者组成员数量发生变化：</strong>消费者组中新增或者删除某个成员，导致需要重新调整分区分配</li>
<li><strong>订阅主题 Topic 数量发生变化：</strong>消费者订阅的 Topic 发生变化，比如订阅的 Topic 采用的是正则表达式的形式 <code>test-*</code>，如果新建了一个 Topic 名为 <code>test-hello</code>，那么该 Topic 也是需要分配给消费者的，此时就会触发再平衡</li>
<li><strong>订阅主题 Topic 的分区数发生变化：</strong>订阅主题 Topic  增加或减少了分区数量，也会触发再平衡</li>
</ul>
</blockquote>
<blockquote>
<p>再平衡主要涉及到Kafka Broker中的<strong>Group Coordinator</strong>以及内部 Topic <strong>__consumer_offsets（更正式的名字是 Offset Topic）</strong>。</p>
</blockquote>
<h5 id="Group-Coordinator"><a href="#Group-Coordinator" class="headerlink" title="Group Coordinator"></a>Group Coordinator</h5><blockquote>
<p>Group Coordinator 主要用于消费者 offset 管理、消费者组成员与 Topic Partition的分配和 Consumer Rebalance。</p>
<p>在 Broker 启动时，每个 Broker 都会启动一个 Group Coordinator ，但只有<code>__consumer_offsets</code> 的 Partition 的 Leader 才会直接与消费者进行交互，也就是该消费者组的 Group Coordinator，其他的分区副本的 Group Coordinator只是作备份，一旦 Leader 所在 Broker 挂掉之后及时进行替代。</p>
</blockquote>
<h5 id="消费者组状态机"><a href="#消费者组状态机" class="headerlink" title="消费者组状态机"></a>消费者组状态机</h5><blockquote>
<p>Kafka 设计了一套消费者组状态机，来帮 Group Coordinator 完成整个再平衡流程。状态机中为消费者组定义了 5 种状态：Empty、Dead、PreparingRebalance、CompletingRebalance 和 Stable。</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">状态</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Empty</td>
<td>消费者组内没有任何成员，但消费者组可能存在已提交的 offset 数据，而且这些 offset 数据尚未过期</td>
</tr>
<tr>
<td align="center">Dead</td>
<td>同样是消费者组内没有任何成员，但消费者组的元数据信息已经在 Group Coordinator 端被移除。Group Coordinator 组件保存着当前向它注册过的所有消费者组信息，所谓的元数据信息就类似于这个注册信息</td>
</tr>
<tr>
<td align="center">PreparingRebalance</td>
<td>消费者组准备开启再平衡，此时所有成员都要重新请求加入消费者组</td>
</tr>
<tr>
<td align="center">CompletingRebalance</td>
<td>消费者组下所有成员已经加入，各个成员正在等待分配方案。该状态在老一点的版本种被称为 AwaitingSync，它和 CompletingRebalance是等价的</td>
</tr>
<tr>
<td align="center">Stable</td>
<td>消费者组的稳定状态。该状态表明再平衡已经完成，组内各成员能够正常消费数据了</td>
</tr>
</tbody></table>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1%E7%8A%B6%E6%80%81%E6%9C%BA.png" alt="img"></p>
<p> 一个消费者组最开始是 Empty 状态，当再平衡开启后，它会被置于 PreparingRebalance 状态等待成员加入，之后变更到  CompletingRebalance 状态等待分区分配方案，最后流转到 Stable 状态完成再平衡。</p>
<p>当有新成员加入或者已有成员退出消费者组的时候，消费者组的状态从 Stable 直接跳到 PreparingRebalance 状态，此时，所有现存成员就必须重新申请加入消费者组。当所有成员都退出组后，消费者组状态变更为 Empty。<strong>Kafka定期自动删除过期位移的条件就是，消费者组要处于 Empty 状态。</strong>因此，如果你的消费者组停掉了很长的时间（超过 7 天），那么 Kafka 很可能就把该组的 offset 数据删除了。我相信，你在 Kafka 的日志种一定经常看到下面这个输出：<code>Removed ✘✘✘ expired offsets in ✘✘✘ milliseconds.</code>。这就是 Kafka 在尝试定期删除过期 offset。</p>
<h5 id="再平衡全流程"><a href="#再平衡全流程" class="headerlink" title="再平衡全流程"></a>再平衡全流程</h5><h6 id="第一步-FIND-COORDINATOR"><a href="#第一步-FIND-COORDINATOR" class="headerlink" title="第一步 FIND_COORDINATOR"></a>第一步 FIND_COORDINATOR</h6><p>消费者启动的时候会发送 FindCoordinatorRequest 请求。</p>
<p><strong>目的：</strong></p>
<ul>
<li>确定负责该消费者组的 Group Coordinator 所在的 Broker（每个 Broker 中都会有 Group Coordinator，但是一个消费者组由一个 Group Coordinator 协调工作）</li>
<li>创建与该 Broker相互通信的网络连接</li>
</ul>
<p><strong>过程：</strong></p>
<ul>
<li>如果消费者已经保存了消费者组对应的 Group Coordinator 节点的信息，并且与它之间的网络连接是正常的，那么可以进入下一阶段；否则向 Kafka 集群中**负载最小的 Broker **发送 FindCoordinatorRequest 请求寻找 Group Coordinator。</li>
<li>**Group Coordinator的选择方式是：BrokerId &#x3D;  PartitionLeader( Hash( GroupId ) % __consumer_offsets的分区数 )<strong>，即将 GroupId 取哈希之后对 <code>__consumer_offsets</code> 的分区数取余，然后</strong>这个余数就作为以后 消费者 offset 要写入的<code>__consumer_offsets</code> 的分区，这个分区 Partition Leader 所在的 Broker 中的 Group Coordinator 就负责这个消费者组的工作协调（非常绕，多看几遍）（其实就是消费者 offset 需要写入 __consumer_offsets分区的Leader所在 Broker中）。</li>
</ul>
<h6 id="第二步-JOIN-GROUP"><a href="#第二步-JOIN-GROUP" class="headerlink" title="第二步 JOIN_GROUP"></a>第二步 JOIN_GROUP</h6><p>当消费者组成员加入组时，会向 Group Coordinator 发送 JoinGroup 请求，该请求中包含成员订阅的主题。</p>
<p><strong>目的：</strong></p>
<ul>
<li>选举消费者 Leader</li>
<li>由消费者 Leader 制定具体的分区分配方案</li>
</ul>
<p><strong>过程：</strong></p>
<ul>
<li>第一个发送 JoinGroup 请求到 Group Coordinator 的成员自动成为消费者 Leader，根据 Group Coordinator 响应中的消费者组成员订阅信息制定分区分配方案。</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1JoinGroup%E8%AF%B7%E6%B1%82.png" alt="img"></p>
<h6 id="第三步-SYNC-GROUP"><a href="#第三步-SYNC-GROUP" class="headerlink" title="第三步 SYNC_GROUP"></a>第三步 SYNC_GROUP</h6><p>消费者 Leader 将制定好的分区分配方案发送在 SyncGroup 请求中发送给 Group Coordinator。其他消费者成员也会向  Group Coordinator 发送 SyncGroup 请求，只不过请求体中没有实际的内容。然后 Group Coordinator 以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区。当所有成员都成功接收到分配方案之后，消费者组就进入到了 Stable 状态，开始正常消费工作（也会经过反序列化器、拦截器）。</p>
<p><strong>目的：</strong></p>
<ul>
<li>通过  Group Coordinator 同步消费者 Leader 制定好的分区分配方案</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1SyncGroup%E8%AF%B7%E6%B1%82.png" alt="img"></p>
<h6 id="Heartbeat-线程"><a href="#Heartbeat-线程" class="headerlink" title="Heartbeat 线程"></a>Heartbeat 线程</h6><p>心跳线程是一个独立的线程，通过向 Group Coordinator 发送心跳来维持自己与消费者组的从属关系，以及对分区的所有权关系。</p>
<p>当消费者组有新成员加入时，也是<strong>通过心跳请求的响应来通知组内现有成员开启新一轮的再平衡</strong>。</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%96%B0%E6%88%90%E5%91%98%E5%85%A5%E7%BB%84.png" alt="img"></p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%88%90%E5%91%98%E7%A6%BB%E7%BB%84.png" alt="img"></p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E6%88%90%E5%91%98%E5%B4%A9%E6%BA%83%E7%A6%BB%E7%BB%84.png" alt="img"></p>
<blockquote>
<p>正常情况下，每个组内成员都会定期汇报位移给协调者。当重平衡开启时，协调者会给予成员一段缓冲时间，要求每个成员必须在这段时间内快速地上报自己的位移信息，然后再开启正常的 JoinGroup&#x2F;SyncGroup 请求发送。</p>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%86%8D%E5%B9%B3%E8%A1%A1HeartBeat%E7%BB%84%E6%88%90%E5%91%98%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB.png" alt="img"></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/jy02268879/article/details/112273332">https://blog.csdn.net/jy02268879/article/details/112273332</a></p>
<p><a target="_blank" rel="noopener" href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/25%20%20%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%87%8D%E5%B9%B3%E8%A1%A1%E5%85%A8%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90.md">https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/25%20%20%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%87%8D%E5%B9%B3%E8%A1%A1%E5%85%A8%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90.md</a></p>
<h4 id="内部Offset-Topic"><a href="#内部Offset-Topic" class="headerlink" title="内部Offset Topic"></a>内部Offset Topic</h4><blockquote>
<p>在 Kafka 0.9 版本之前，消费者的 offset 是保存在 zookeeper 中的，但是 <strong>zookeeper 不适合用于高频写操作的场景</strong>，这会影响 Kafka 的消息吞吐量，所以 Kafka 需要一个能够提供<strong>高持久性、支持高频写操作</strong>的地方保存 offset。明显 Kafka 的Topic 设计天然就满足了这两个条件，因此 Kafka 使用内部主题保存 offset 的这件事，是自然而然的。</p>
</blockquote>
<blockquote>
<p>Offset Topic 的 offset管理机制其实也很简单，就是<strong>将 Consumer 的消费的 offset 数据作为一条普通的 Kafka 消息， 提交到 __consumer_offsets 中</strong>。默认情况下，__consumer_offsets 主题的<strong>分区数是 50，副本数是 3。</strong></p>
</blockquote>
<p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题，Offset Topic 主题的 Key 和 Value 组成如下：</p>
<ul>
<li><strong>Key：</strong> 应该保存 3 部分的内容 <strong>&lt;GroupId, 主题名, 分区号&gt;</strong></li>
<li><strong>Value：</strong> 应该保存的数据有 **&lt;offset, 时间戳， 元数据&gt;**，元数据是为了帮助 Kafka 执行各种各样的后续操作，比如删除过期位移消息等。</li>
</ul>
<p>具体消费者消费的 offset 储存到 <code>__consumer_offsets</code> 的哪个分区上，是根据<code>abs(GroupId.hashCode()) % NumPartitions</code>来计算（其中，NumPartitions 是 <code>__consumer_offsets的分区数</code>）</p>
<h5 id="提交偏移量"><a href="#提交偏移量" class="headerlink" title="提交偏移量"></a>提交偏移量</h5><p>如果消费者消费到了 offset，则提交的偏移量位置是 offset + 1，指向下一跳消息的位置。</p>
<p>提交的偏移量是 poll() 最后一次拉取的偏移量。当然手动提交的时候，也能够指定偏移量位置。</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%81%8F%E7%A7%BB%E9%87%8F%E6%8F%90%E4%BA%A4%E6%96%B9%E6%B3%95.jpeg" alt="img"></p>
<h6 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h6><p>开启时，消费者使用 poll() 方法从 Kafka 中拉取消息数据，同时消费者会有一个后台线程定时向 Kafka 提交消费者的 offset，自动提交涉及两个参数：</p>
<ul>
<li><strong>enable.auto.commit：</strong>设为 true，表示开启自动提交（默认）</li>
<li><strong>auto.commit.interval.ms：</strong>自动提交时间间隔，默认是 5 秒</li>
</ul>
<p><strong>自动提交丢数据场景</strong>：消费者A，第一次 poll 了100条数据，刚好第一次提交偏移量也是 100+1（ 5 秒提交一次），但是拉取的这 100 条才处理了前 50 条，A 就挂了，相当于51 - 100 的数据已经提交了偏移量，但还没处理。因此发生了消费再平衡，由 B 来接着消费这个分区，B 从 101 开始消费，51-101 的数据就丢失了。</p>
<p><strong>自动提交重复消费场景：</strong>消费者A，第一次 poll 了 100 条数据，刚好第一次提交偏移量也是 100+1（ 5 秒提交一次），在后面的 3 秒中，消费者 A 又 poll 了 2 次数据，每次 100 条，相当于此时消费者 A 已经消费到了偏移量 300 了，此时才过 3 秒，还没有到下一次触发自动提交的时间。此时，消费者 A 挂了，发生了消费再平衡，由 B 来接着消费这个分区，那 B 就是从 101 偏移量开始消费，那么101-300都被重复消费了。</p>
<h6 id="手动提交"><a href="#手动提交" class="headerlink" title="手动提交"></a>手动提交</h6><p>使用手动提交的时候，需要将 <strong>enable.auto.commit</strong> 设置为 false。</p>
<p>**同步提交commitSync()**：调用 commitSync() 时，Consumer 程序会处于阻塞状态，直到远端的 Broker 返回提交结果。</p>
<p>**异步提交commitAsync()**：调用 commitAsync() 之后，它会立即返回，不会阻塞。commitAsync 的问题在于，出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经 “过期” 或不是最新值了（重试之前，已经有另外一次提交）。</p>
<p><a target="_blank" rel="noopener" href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/18%20%20Kafka%E4%B8%AD%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF.md">Kafka中位移提交那些事儿</a></p>
<h3 id="Broker工作原理"><a href="#Broker工作原理" class="headerlink" title="Broker工作原理"></a>Broker工作原理</h3><blockquote>
<p>Kafka在2.8版本之前的集群信息管理依赖于Zookeeper，在2.8版本之后引入了Raft协议，去除了Zookeeper的依赖，但是还是提供多Zookeeper的版本（因为Raft协议的版本暂时还不成熟），下面主要以Zookeeper的版本介绍</p>
</blockquote>
<h4 id="Zookeeper中储存的信息"><a href="#Zookeeper中储存的信息" class="headerlink" title="Zookeeper中储存的信息"></a>Zookeeper中储存的信息</h4><p>Zookeeper中主要储存以下信息</p>
<ul>
<li><strong>&#x2F;brokers&#x2F;ids</strong>： 记录有哪些在线的Broker</li>
<li><strong>&#x2F;brokers&#x2F;topics&#x2F;主题名&#x2F;partitions&#x2F;分区号&#x2F;state</strong>： 记录分区副本中谁是Leader，谁是Follower，记录有哪些分区的副本是在线的（ISR队列）</li>
<li><strong>&#x2F;controller</strong>： 负责Broker Controller组件Leader的选举，谁能先注册到这个节点，谁就是Leader</li>
</ul>
<h4 id="Broker中的Controller组件"><a href="#Broker中的Controller组件" class="headerlink" title="Broker中的Controller组件"></a>Broker中的Controller组件</h4><blockquote>
<p>Controller组件是Kafka的核心组件，主要作用是在Zookeeper的帮助下管理和协调整个Kafka集群。Kafka集群中的任意一个Broker都会有一个Controller组件，但是在运行的过程中只有一个Controller能够称为集群的Leader Controller，管理和协调集群的运行，其他的Controller作为高可用的后备，Leader Controller挂了就顶上。</p>
</blockquote>
<p>Controller组件主要负责：</p>
<ul>
<li>创建删除主题、增加分区并选择副本的Leader</li>
<li>集群Broker管理（Broker新增、退出、故障）</li>
<li>分区副本Preferred Leader选举</li>
<li>消费者组分区重分配</li>
<li>数据服务 – 向其他Broker提供集群的元数据信息</li>
</ul>
<h5 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h5><p>![image-20221027232023434](Broker Controller工作流程.png)</p>
<ol>
<li>当Broker启动的时候，会向Zookeeper中的<code>/brokers/ids/</code>写入自己的Broker ID</li>
<li>随后Controller会尝试向Zookeeper中创建<code>/controller</code>节点，第一个成功创建<code>/controller</code>节点的Controller会写入自己的Broker ID成为Leader Controller，并向<code>/controller_epoch</code>节点写入自己的任期Epoch（任期是单调递增的），然后拉取Zookeeper中相应节点中的信息进行集群的初始化。</li>
<li>其他尝试创建<code>/controller</code>节点的Controller会向<code>/controller</code>节点注册监听，当Leader挂了，就尝试顶上。</li>
<li>Leader Controller会监听<code>/brokers/ids/</code>中子节点的变化，以监控Broker的上下线。</li>
<li>Leader Controller开始负责集群信息的管理，并且维护<code>/brokers/topics/</code>节点中的信息。</li>
<li>当Leader Controller挂了之后，其他Controller会尝试创建<code>/controller</code>节点成为新的Leader Controller并将任期Epoch + 1，从Zookeeper中拉取信息初始化集群上下文，其他Broker收到小于当前Leader Controller任期Epoch的事件都会丢弃，以隔离僵尸Leader的影响。</li>
</ol>
<h5 id="Controller内部结构"><a href="#Controller内部结构" class="headerlink" title="Controller内部结构"></a>Controller内部结构</h5><blockquote>
<p>在 Kafka 0.11 版本之前，控制器的设计是相当繁琐的，代码更是有些混乱，这就导致社区中很多控制器方面的 Bug 都无法修复。<strong>控制器是多线程的设计，会在内部创建很多个线程。</strong>比如，控制器需要为每个 Broker 都创建一个对应的 Socket 连接，然后再创建一个专属的线程，用于向这些 Broker 发送特定请求。如果集群中的 Broker 数量很多，那么控制器端需要创建的线程就会很多。另外，控制器连接 ZooKeeper 的会话，也会创建单独的线程来处理 Watch 机制的通知回调。除了以上这些线程，控制器还会为主题删除创建额外的 I&#x2F;O 线程。</p>
<p>比起多线程的设计，更糟糕的是，这些线程还会访问共享的控制器缓存数据。我们都知道，多线程访问共享可变数据是维持线程安全最大的难题。为了保护数据安全性，控制器不得不在代码中大量使用ReentrantLock同步机制，这就进一步拖慢了整个控制器的处理速度。</p>
<p><strong>鉴于这些原因，社区于 0.11 版本重构了控制器的底层设计，最大的改进就是，把多线程的方案改成了单线程加事件队列的方案。</strong></p>
<p>从这张图中，我们可以看到，社区引入了一个事件处理线程，统一处理各种控制器事件，然后控制器将原来执行的操作全部建模成一个个独立的事件，发送到专属的事件队列中，供此线程消费。这就是所谓的单线程 + 队列的实现方式。 值得注意的是，这里的单线程不代表之前提到的所有线程都被“干掉”了，控制器只是把缓存状态变更方面的工作委托给了这个线程而已。</p>
<p>这个方案的最大好处在于，控制器缓存中保存的状态只被一个线程处理，因此不再需要重量级的线程同步机制来维护线程安全，Kafka 不用再担心多线程并发访问的问题，非常利于社区定位和诊断控制器的各种问题。事实上，自 0.11 版本重构控制器代码后，社区关于控制器方面的 Bug 明显少多了，这也说明了这种方案是有效的。</p>
<p>针对控制器的第二个改进就是，将之前同步操Zookeeper 全部改为异步操作。ZooKeeper 本身的 API 提供了同步写和异步写两种方式。之前控制器操作 ZooKeeper 使用的是同步的 API，性能很差，集中表现为，当有大量主题分区发生变更时，ZooKeeper 容易成为系统的瓶颈。新版本 Kafka 修改了这部分设计，完全摒弃了之前的同步 API 调用，转而采用异步 API 写入 ZooKeeper，性能有了很大的提升。根据社区的测试，改成异步之后，ZooKeeper 写入提升了 10 倍！</p>
</blockquote>
<p>![img](Broker Controller结构.jpg)</p>
<h4 id="数据的储存"><a href="#数据的储存" class="headerlink" title="数据的储存"></a>数据的储存</h4><blockquote>
<p>Kafka的存储最终实现方案是<strong>基于顺序追加写日志  + 稀疏哈希索引</strong></p>
</blockquote>
<p>一般通过以下手段来提高数据的读写性能：</p>
<ul>
<li><strong>提高读速度：</strong>利用索引，来提高查询速度，但是有了索引，大量写操作都会维护索引，那么会降低写入效率。常见的如关系型数据库MySQL</li>
<li><strong>提高写操作：</strong>这种一般是采用日志储存，通过顺序追加写的方式来提高写入速度，因为没有索引，无法快速查询，只能顺序遍历</li>
</ul>
<p>Kafka主要用来处理海量数据流，这个场景的特点主要包括：</p>
<ul>
<li><strong>写操作：</strong>写并发要求非常高，基本得达到百万级TPS。顺序追加写日志即可，<strong>无需考虑更新操作（无需考虑更新操作是跟数据库最大的区别）</strong></li>
<li><strong>读操作：</strong>相对写操作来说，比较简单，只要能按照一定规则高效查询即可（Offset或者时间戳）</li>
</ul>
<blockquote>
<p>这个时候就显示了数据结构的重要性了，因为使用的场景不一样。Kafka无需考虑数据的更新操作，只要能快速写数据，快速读数据就可以了。那么，提高写速度的就只有通过顺序追加写的方式（这是由硬件底层决定的），需要考虑的就是怎么提高读速度。这种数据有序的情况下，最好方式就是哈希索引，在内存中维护一个映射关系，每次根据消息Offset查询消息的时候，从哈希表中得到文件偏移量。再去读文件就能快速定位。但是，哈希表是要常驻在内存的，对于Kafka来说不太现实。可以在写消息的时候，将Offset设计成一个有序的字段与消息一起记录，将消息文件按照一定大小分割成块，用一个表索引每个消息文件块中第一条消息记录的Offset和磁盘位置（分片和索引），就能够通过索引快速定位消息所在文件块的位置，再顺序遍历找到消息的位置。（为什么不用B+树索引呢？因为Kafka是要删除过期数据的，用B+树索引在删除的时候就需要大量的维护，而现在这种方式只要把块文件一删，块索引一删就完事了，而且<strong>对于生产者和消费者来说，后续都是追加写或者是顺序读</strong>）</p>
</blockquote>
<img src="Kafka稀疏索引.png" style="zoom: 67%;" />

<img src="Kafka储存机制.png" style="zoom:67%;" />

<blockquote>
<p>根据 Offset 查找消息过程：</p>
<ol>
<li>根据目标 Offset 定位到 Segment 文件</li>
<li>根据<code>.index</code>文件找到小于等于目标值 Offset 的最大 Offset 对应的索引项</li>
<li>根据索引项索引 Position 定位到<code>.log</code>文件中的指定位置</li>
<li>向下遍历找到目标Record</li>
</ol>
</blockquote>
<p>Kafka 是基于「主题 + 分区 + 副本 + 分段 + 索引」的结构，每一个分区副本Replica都对应一个Log，一个Log又分为多个日志分段Segment：</p>
<ul>
<li>Kafka 中消息是以主题 Topic 为基本单位进行归类的，这里的 Topic 是逻辑上的概念，实际上在磁盘存储是根据分区 Partition 存储的, 即每个 Topic 被分成多个 Partition，分区 Partition 的数量可以在主题 Topic 创建的时候进行指定。</li>
<li>Partition 分区主要是为了解决 Kafka 存储的水平扩展问题而设计的，如果一个 Topic 的所有消息都只存储到一个 Kafka Broker 上的话， 对于 Kafka 每秒写入几百万消息的高并发系统来说，这个 Broker 肯定会出现瓶颈， 故障时候不好进行恢复，所以 Kafka 将 Topic 的消息划分成多个 Partition，然后均衡的分布到整个 Kafka Broker 集群中。</li>
<li>Partition 分区内每条消息都会被分配一个唯一的消息 id，即我们通常所说的 偏移量 Offset，因此 Kafka 只能保证每个分区内部有序性，并不能保证全局有序性。</li>
<li>然后每个 Partition 分区又被划分成了多个 LogSegment，这是为了防止 Log 日志过大，Kafka 又引入了日志分段（LogSegment）的概念，将 Log 切分为多个 LogSegement，相当于一个巨型文件被平均分割为一些相对较小的文件，这样也便于消息的查找、维护和清理。这样在做历史数据清理的时候，直接删除旧的 LogSegement 文件就可以了。</li>
<li>Log 日志在物理上只是以文件夹的形式存储，文件夹的命名规则是<code>topic名称-分区号</code>，而每个 LogSegement 对应磁盘上的4个文件：<code>.index</code>索引文件（**.index文件中保存的是相对 Offset，相对于 Segment 中的第一条消息，能够保证 Offset 的值所占用的空间不会过大<strong>）、<code>.log</code>消息数据文件、<code>.snapshot</code>快照文件、<code>.timeindex</code>时间索引文件，</strong>这些文件以当前Segment的第一条消息的Offset命名**。</li>
</ul>
<h4 id="PageCache和零拷贝"><a href="#PageCache和零拷贝" class="headerlink" title="PageCache和零拷贝"></a>PageCache和零拷贝</h4><blockquote>
<p>在 Kafka 中，大量使用了 <strong>PageCache（ Java 中使用 mmap 实现，将进程的一段虚拟地址空间映射到文件的内存地址中，避免用户态和内核态之间的数据拷贝过程</strong>），这也是 Kafka 能实现高吞吐的重要因素之一。</p>
<p>PageCache 的作用是当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据页是否在 PageCache 中，如果命中则直接返回数据，从而避免了对磁盘IO操作；如果没有命中，操作系统则会向磁盘发起读取请求并将读取的数据页存入 PageCache 中，之后再将数据返回给进程。</p>
<p>同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检查数据页是否存在缓存中，如果不存在，则 PageCache 中添加相应的数据页，最后将数据写入对应的磁盘块中。被修改过的数据页会变成脏页，操作系统会在合适的时间把脏页中断数据写入磁盘（当PageCache 被读取或者失效的时候），以保持数据的一致性。</p>
</blockquote>
<p>为什么 Kafka 不自己管理缓存，而用 PageCache 呢，主要是因为：</p>
<ul>
<li>JVM 中一切皆对象，数据的对象储存会带来所谓 Object overhead 浪费空间</li>
<li>如果由 JVM 来管理缓存，会受到 GC 的影响，并且过大的堆也会拖累 GC 的效率，降低吞吐量</li>
<li>一旦程序崩溃，自己管理的缓存数据会全部丢失（用 PageCache 的话，PageCache 中的数据会随着内核中的 Flusher 线程的调度以及对 sync()&#x2F;fsync() 的调用写回到磁盘，就算进程崩溃，也不用担心数据丢失）</li>
</ul>
<p>Kafka还使用了<strong>零拷贝（Zero-Copy）</strong>来提高系统性能，其实对于消费者来说，读取的是原原本本的数据，不需要Kafka进行加工，所以数据其实不需要经过用户态（Kafka进程），而<strong>在内核态的时候，直接就把读取到的数据发送给消费者，这样就能够避免数据从内核态传输到用户态，再传输给用户的时候又从用户态拷贝到内核态再发送到网卡中发送给消费者</strong>。</p>
<p>Linux 2.4+ 内核通过<code>sendfile</code>系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件-网络发送由一个<code>sendfile</code>调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E9%9B%B6%E6%8B%B7%E8%B4%9D.png"></p>
<h4 id="日志清理机制"><a href="#日志清理机制" class="headerlink" title="日志清理机制"></a>日志清理机制</h4><blockquote>
<p>Kafka无论消息是否被消费，Kafka都会保留所有消息，随着写入数据不断增加，磁盘占用空间越来越大，为了控制占用空间就需要对消息进行清理。日志的清理比较简单，因为Log被分为多个日志分段Segment，最先创建的Segment一定是历史日志，只要根据一定的策略删除这个Segment即可。</p>
</blockquote>
<p>Kafka中由日志管理器（LogManager）周期性检测和清理日志分段文件，提供以下两种日志清理策略，</p>
<ul>
<li><strong>日志删除（Log Retention）：</strong>按照指定策略删除日志分段LogSegment<ul>
<li><strong>基于时间策略：</strong>能够设定日志分段文件保留多久<strong>（参数优先级毫秒log.retention.ms &gt; 分钟log.retention.minutes &gt; 小时log.retention.hours ）</strong>，但是并不是日志记录超过了设定的时间就立即删除，而是根据日志分段LogSegment中消息最大的时间戳来算，LogSegment中最大时间戳超过了设定的时间，这个LogSegment才会被删除（很好理解，<strong>因为一个LogSegment中有很多消息，但不是所有消息都是超过了设定的时间，只有所有消息都超过了设定的时间，才将这个LogSegment删除</strong>）。</li>
<li><strong>基于日志大小策略：</strong>能够检查整个分区副本日志大小是否超过设定的阈值，如果超过了，从日志文件中的第一个日志段开始寻找可以删除的日志分段集合（同理，如果有一个日志分段在被删和不被删之间反复横跳，也是不会被删的）。</li>
<li><strong>基于日志起始偏移量：</strong>判断依据是某日志分段 Segment 的下一个日志分段 Segment 的起始偏移量 baseOffset 是否小于等于 logStartOffset，若是，则可以删除此日志分段。</li>
</ul>
</li>
<li><strong>日志压缩（Log Compaction）：</strong>日志压缩对于相同 Key 不同 Value 的时候，只根据 Key 保留最后一个版本（即保留最新的Value）。</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9.png"></p>
<p><a target="_blank" rel="noopener" href="http://dockone.io/article/2434664">http://dockone.io/article/2434664</a></p>
<p><a target="_blank" rel="noopener" href="https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html">https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34412985/article/details/120380212">https://blog.csdn.net/qq_34412985/article/details/120380212</a></p>
<h3 id="分区副本机制"><a href="#分区副本机制" class="headerlink" title="分区副本机制"></a>分区副本机制</h3><p>所谓的副本机制（Replication），也可以称之为备份机制，通常是指分布式系统在多台网络互联的机上保存有相同的数据拷贝。</p>
<p>Kafka 是有主题 Topic 概念的，而每个主题又进一步划分成若干个分区 Partition。副本 Replication 的概念实际上是在分区层级下定义的，每个分区配置有若干个副本。</p>
<p><strong>所谓副本（Replica），本质就是一个只能追加写消息的提交日志</strong>。根据 Kafka 副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些<strong>副本分散保存在不同的 Broker 上</strong>，从而能够对抗部分 Broker 宕机带来的数据不可用。</p>
<p><strong>Kafka 中分区的副本是基于领导者（Leader-based）的副本机制，生产者和消费者的所有请求由 Leader Replica 处理，Follower Replica 只负责异步地从 Leader Replica 中拉取数据同步，不对外提供服务。</strong></p>
<img src="Kafka Broker中的副本.png" alt="img" style="zoom: 33%;" />

<img src="Kafka副本角色.png" alt="img" style="zoom:33%;" />

<p>Leader Replica会成为 Kafka 集群的性能瓶颈，但是这种副本机制的好处是：</p>
<ul>
<li><strong>方便实现“Read-your-writes”：</strong>生产者写入后，消费者马上就能够获取到</li>
<li><strong>方便实现单调读（Monotonic Reads）</strong>：消费者多次消费消息时，不会存在从不同副本读取到不同数据的情况（因为都是从 Leader Replica中读）</li>
</ul>
<h4 id="In-sync-Replicas（ISR）"><a href="#In-sync-Replicas（ISR）" class="headerlink" title="In-sync Replicas（ISR）"></a>In-sync Replicas（ISR）</h4><p>ISR 中的副本都是与 Leader 同步的副本，相反，不在 ISR 中的追随者副本就被认为是与 Leader 不同步的。</p>
<p>ISR 是一个动态调整的集合，能否存在于 ISR 集合中的标准是<strong>Broker 端参数 replica.lag.time.max.ms 参数值，设定了 Follower 副本能够落后 Leader 副本的最长时间间隔</strong>，默认值是 10 秒，只要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 副本与 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息；否则，Follower 副本会被移动到 OSR 集合中。</p>
<h5 id="最少同步副本"><a href="#最少同步副本" class="headerlink" title="最少同步副本"></a>最少同步副本</h5><p><code>min.insync.replicas</code>参数能够再 Broker 或者主题级别进行配置，代表 ISR 列表中至少要有几个可用副本。当 ISR 列表中可用副本数量小于该值时，就认为整个分区处于不可用状态，此时客户端再向分区写入数据时就会抛出异常<code>NotEnoughReplicasExceptoin</code>。</p>
<h4 id="Out-sync-Replicas（OSR）"><a href="#Out-sync-Replicas（OSR）" class="headerlink" title="Out-sync Replicas（OSR）"></a>Out-sync Replicas（OSR）</h4><p>Kafka 把所有不在 ISR 中存活的副本都称为非同步副本（Out-sync Replicas）。</p>
<p>通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。<strong>Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举</strong>。</p>
<p>开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。</p>
<h4 id="元数据请求机制"><a href="#元数据请求机制" class="headerlink" title="元数据请求机制"></a>元数据请求机制</h4><p>在所有副本中，只有领导副本才能进行消息的读写处理。由于不同分区的领导副本可能在不同的 Broker 上，如果某个 Broker 收到了一个分区请求，但是该分区的领导副本并不在该 Broker 上，那么它就会向客户端返回一个 <code>Not a Leader for Partition</code> 的错误响应。为了解决这个问题，Kafka 提供了元数据请求机制。</p>
<p>首先<strong>集群中的每个 Broker 都会缓存所有主题的分区副本信息，客户端会定期发送发送元数据请求，然后将获取的元数据进行缓存</strong>。定时刷新元数据的时间间隔可以通过为客户端配置 <code>metadata.max.age.ms</code> 来进行指定。有了元数据信息后，客户端就知道了领导副本所在的 Broker，之后直接将读写请求发送给对应的 Broker 即可。</p>
<p>如果在定时请求的时间间隔内发生的分区副本的选举，则意味着原来缓存的信息可能已经过时了，此时还有可能会收到 <code>Not a Leader for Partition</code> 的错误响应，这种情况下客户端会再次求发出元数据请求，然后刷新本地缓存，之后再去正确的 Broker 上执行对应的操作。</p>
<p>![img](Kafka 元数据请求机制.jpg)</p>
<h4 id="Leader-Replica-选举"><a href="#Leader-Replica-选举" class="headerlink" title="Leader Replica 选举"></a>Leader Replica 选举</h4><blockquote>
<p>AR（All Replica）就是所有副本，ISR 与 OSR 的并集，存的是 Broker ID</p>
</blockquote>
<p>副本 Leader 选举是由 Controller Leader 来处理的。只有在 ISR 集合中的副本才有资格参选，随后选取 AR 中排序靠前的作为 Leader Replica。</p>
<h5 id="优先副本"><a href="#优先副本" class="headerlink" title="优先副本"></a>优先副本</h5><p>优先副本即 AR 集合列表中的第 1 个副本，比如 AR [1, 2, 0]，那么分区优先副本即为 1。引入优先副本的概念是为了 所以分区的 Leader Replica 在所有 Broker 中均匀分布，避免消费者或者生产者的请求集中在某几个 Broker 中。</p>
<p>如果优先副本被选举为 Leader Replica，则该Leader 称为 <strong>Prefect Leader</strong>。</p>
<h5 id="Leader-Replica-自动平衡"><a href="#Leader-Replica-自动平衡" class="headerlink" title="Leader Replica 自动平衡"></a>Leader Replica 自动平衡</h5><p>正常情况下，Kafka 本身会把 Leader Replica 均匀地分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些 Broker 宕机，Leader Replica重新选举之后会导致所有 Topic 中的 Leader Replica 过于集中在其他部分几台 Broker 上，造成集群负载不均衡。所以 Kafka 提供了 Leader Replica 自动平衡的机制。</p>
<p>当 Broker 中 中存在的 Leader Replica 不是优先副本的时候，不平衡数就会加 1，当不平衡比率达到设定阈值的时候就会触发自动平衡。</p>
<p>其中，Broker 中有三个参数：</p>
<ul>
<li><strong>auto.leader.rebalance.enable：</strong>默认为 True，自动 Leader Replica 平衡，生产环境中，Leader Replica 重选举的代价比较大，可能会带来性能影响，建议设置为 False 关闭。</li>
<li><strong>leader.imbalance.per.broker.percentage：</strong>默认是 10%，每个 Broker 允许的不平衡的比例。如果每个 Broker 都超过了这个值，控制器会触发 Leader Replica的平衡。</li>
<li><strong>leader.imbalance.check.interval.seconds：</strong>默认值 300 秒，检查 Leader Replica 负载是否平衡的间隔时间。</li>
</ul>
<h4 id="副本数据同步"><a href="#副本数据同步" class="headerlink" title="副本数据同步"></a>副本数据同步</h4><blockquote>
<p>为了保证数据一致性，只有被所有同步副本（ISR中所有副本）都保存了的数据才能被客户端读取到，即高水位。在这里不讨论 Kafka 事务，因为事务还依靠 LSO（Log Stable Offset）来判断事务型消费者的可见性</p>
<p><strong>高水位和日志末端位移是副本的两个重要属性，每个副本都会有。但是 Leader 副本的高水位就是分区的高水位。</strong></p>
</blockquote>
<ul>
<li><strong>高水位 HW（High Watermark）：</strong>生产者已提交消息位移 offset + 1，高水位用于定义消息的可见性，用来标识分区下的哪些消息是可以被消费者消费的，同时帮助 Kafka 完成副本的同步。</li>
<li><strong>日志末端位移 LEO（Log End Offset）：</strong>副本下一条消息写入的位移值。</li>
</ul>
<p>![img](Kafka HW 和 LEO.png)</p>
<h5 id="高水位更新机制"><a href="#高水位更新机制" class="headerlink" title="高水位更新机制"></a>高水位更新机制</h5><blockquote>
<p>每个副本对象都保存一组 HW 值和 LEO 值。而 Leader 副本所在 Broker 除了保存自己 LEO 值，还会保存所有 Follower 副本的 LEO 值（为了帮助 Leader 副本确定自己的高水位，即分区高水位）。</p>
</blockquote>
<p>注意区分保存 HW 值和 LEO 值的位置，参考下图，分别有：</p>
<ul>
<li>Broker 0 上 Leader 副本 LEO 值</li>
<li>Broker 0 上 Leader 副本储存所有 Follower 的 LEO 值</li>
<li>Broker 1 上 Follower 副本 LEO 值</li>
<li>Broker 0 上 Leader 副本 HW 值</li>
<li>Broker 1 上 Follower 副本 HW 值</li>
</ul>
<p>![img](Kafka HW 和 LEO 储存位置.png)</p>
<table>
<thead>
<tr>
<th align="center">更新对象</th>
<th>更新时机</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Broker 0 上 Leader 副本 LEO</td>
<td>Leader 副本接收到生产者发送的消息，写入到本地磁盘后，会更新其 LEO 值。</td>
</tr>
<tr>
<td align="center">Broker 0 上 远程副本 LEO</td>
<td>Follower 副本从 Leader 副本拉取消息时，会告诉 Leader 副本从哪个位移处开始拉取。Leader 副本会使用这个位移值来更新远程副本的 LEO。</td>
</tr>
<tr>
<td align="center">Broker 1 上 Follower 副本 LEO</td>
<td>Follower 副本从 Leader 副本拉取消息，写入到本地磁盘后，会更新其 LEO值。</td>
</tr>
<tr>
<td align="center">Broker 0 上 Leader 副本 HW</td>
<td>主要有两个更新时机：1. Leader 副本更新 LEO 后；2. 更新完远程副本 LEO 后。具体更新方法是：取 Leader 副本和所有 Leader 同步的远程副本 LEO 中的<strong>最小值</strong>。</td>
</tr>
<tr>
<td align="center">Broker 1 上 Follower 副本 HW</td>
<td>Follower 副本成功更新完 LEO 之后，会比较其 LEO 值与 Leader 副本发来的高水位值，并用两者的<strong>较小值</strong>去更新它自己的高水位。</td>
</tr>
</tbody></table>
<p>关于上述的与 Leader 副本保持同步，有两个判断条件：</p>
<ul>
<li>该远程 Follower 副本在 ISR 中。</li>
<li>该远程 Follower 副本 LEO 值落后于 Leader 副本 LEO 值的时间，不超过 Broker 端参数 replica.lag.time.max.ms 的值。</li>
</ul>
<p>乍一看，这两个条件好像是一回事，因为目前某个副本能否进入 ISR 就是靠第 2 个条件判断的。但有些时候，会发生这样的情况：即 Follower 副本已经“追上”了 Leader 的进度，却不在 ISR 中，比如某个刚刚重启回来的副本。如果 Kafka 只判断第 2 个条件的话，就可能出现某些副本具备了“进入 ISR”的资格，但却尚未进入到 ISR 中的情况。此时，分区高水位值就可能超过 ISR 中副本 LEO，而高水位 &gt; LEO 的情形是不被允许的。</p>
<h5 id="副本同步机制"><a href="#副本同步机制" class="headerlink" title="副本同步机制"></a>副本同步机制</h5><p>首先是初始状态。下面这张图中的 remote LEO 就是刚才的远程副本的 LEO 值。在初始状态时，所有值都是 0。</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B1.png" alt="img"></p>
<p>当生产者给主题分区发送一条消息后，状态变更为：</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B2.png" alt="img"></p>
<p>此时，Leader 副本成功将消息写入了本地磁盘，故 LEO 值被更新为 1。</p>
<p>Follower 再次尝试从 Leader 拉取消息。和之前不同的是，这次有消息可以拉取了，因此状态进一步变更为：</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B3.png" alt="img"></p>
<p>这时，Follower 副本也成功地更新 LEO 为 1。此时，Leader 和 Follower 副本的 LEO 都是 1，但各自的高水位依然是 0，还没有被更新。<strong>它们需要在下一轮的拉取中被更新</strong>，如下图所示：</p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/Kafka%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%E6%B5%81%E7%A8%8B4.png" alt="img"></p>
<p>在新一轮的拉取请求中，由于位移值是 0 的消息已经拉取成功，因此 Follower 副本这次请求拉取的是位移值 &#x3D;1 的消息。Leader 副本接收到此请求后，更新远程副本 LEO 为 1，然后更新 Leader 高水位为 1。做完这些之后，它会将当前已更新过的高水位值 1 发送给 Follower 副本。Follower 副本接收到以后，也将自己的高水位值更新成 1。至此，一次完整的消息同步周期就结束了。事实上，Kafka 就是利用这样的机制，实现了 Leader 和 Follower 副本之间的同步。</p>
<h5 id="Leader-Epoch"><a href="#Leader-Epoch" class="headerlink" title="Leader Epoch"></a>Leader Epoch</h5><blockquote>
<p>上面的例子举了两个副本的例子，如果扩展到多个副本，可能会存在问题。首先 Leader 副本高水位更新和 Follower 副本高水位更新在时间上是岔开的。Follower 副本高水位的更新是拉取数据时 Leader 返回当时的高水位，而 Leader 的高水位由所有远程副本 LEO中的最小值决定的。这种错配会导致“数据丢失”或者“数据不一致”的问题。</p>
</blockquote>
<blockquote>
<p>引入了 Leader Epoch之后，故障后恢复不再根据 HW 进行截断，而是根据 Epoch 和 Leader 的 LEO。</p>
</blockquote>
<blockquote>
<p>具体的问题示例，查看后面链接中的例子</p>
</blockquote>
<p>Leader Epoch 解决的就是上述的问题，由两部分数据组成：</p>
<ul>
<li><strong>Epoch：</strong>一个单调增加的版本号。每当副本领导权发生变更时，都会增加该版本号。小版本号的 Leader 被认为是过期 Leader，不能再行使 Leader 权力。</li>
<li><strong>起始位移（Start Offset）：</strong>Leader 副本在其 Epoch 值上写入的首条消息的位移。</li>
</ul>
<p>举例来说，某个 Partition 有两个 Leader Epoch，分别为 (0, 0) 和 (1, 100) 。这意味该 Partion 历经一次 Leader 副本变更，版本号为 0 的 Leader 从 Offset&#x3D;0 处开始写入消息，共写入了 100 条。而版本号为 1 的 Leader 则从 Offset&#x3D;100 处开始写入消息。</p>
<p>每个副本的 Leader Epoch 信息既缓存在内存中，也会定期写入消息目录下的 leaderer-epoch-checkpoint 文件中。当一个 Follower 副本从故障中恢复重新加入 ISR 中，它将：</p>
<ol>
<li>向 Leader 发送 LeaderEpochRequest，请求中包含了 Follower 的 Epoch 信息；</li>
<li><strong>Leader 将返回该 Follower 所在 Epoch 的 Last Offset；</strong></li>
<li>如果 Leader 与 Follower 处于同一 Epoch，那么 Last Offset 显然等于 Leader LEO；</li>
<li>如果 Follower 的 Epoch 落后于Leader，则Last Offset等于Follower Epoch + 1所对应的 Start Offset。这可能有点难以理解，我们还是以 (0, 0) 和 (1, 100) 为例进行说明：Offset&#x3D;100 的消息既是 Epoch&#x3D;1 的 Start Offset，也是 Epoch&#x3D;0 的 Last Offset；</li>
<li><strong>Follower 接收响应后根据返回的 Last Offset 截断数据；</strong></li>
<li>在数据同步期间，只要 Follower 发现 Leader 返回的 Epoch 信息与自身不一致，便会随之更新 Leader Epoch 并写入磁盘。</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/23%20%20Kafka%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3.md">Kafka副本机制详解</a></p>
<p><a target="_blank" rel="noopener" href="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/27%20%20%E5%85%B3%E4%BA%8E%E9%AB%98%E6%B0%B4%E4%BD%8D%E5%92%8CLeader%20Epoch%E7%9A%84%E8%AE%A8%E8%AE%BA.md">关于高水位和Leader Epoch的讨论</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/koktlzz/p/14580109.html">Kafka：副本同步机制（HW&amp;Leader Epoch）</a></p>
<h3 id="Kafka事务原理"><a href="#Kafka事务原理" class="headerlink" title="Kafka事务原理"></a>Kafka事务原理</h3><blockquote>
<p>需要注意的几个点</p>
<ul>
<li>Kafka的事务机制，<strong>涉及到 Transactional producer 和 Transactional consumer</strong>, 两者配合使用，才能实现Producer端到Consumer端有且仅有一次的语义（end-to-end EOS）（而且Consumer端的下游业务也必须支持事务）</li>
<li>当然Kafka的Producer和Consumer是解耦的，也可以使用非Transactional的Consumer来消费Transactional的Producer生产的消息，但是此时就丢失了从生产者端到消费者端事务的支持</li>
<li><strong>通过事务机制，Kafka可以实现对多个Topic的多个Partition的原子性写入</strong>，即处于同一个事务内的所有消息，不管最终需要落地到哪个Topic的哪个Partition，最终结果都是要么全部写成功，要么全部写失败</li>
<li>Kafka的事务机制，在底层依赖于幂等性生产者，需要开启幂等性功能</li>
</ul>
</blockquote>
<p>为了支持事务机制，Kafka引入了两个新的组件：<strong>事务协调器Transaction Coordinator和Transaction log</strong></p>
<ul>
<li>事务协调器Transaction Coordinator是运行在Kafka Broker上的一个<strong>功能模块</strong>，不要和主题Topic的功能混淆</li>
<li><strong>Transaction log由一个主题<code>__transaction_state</code>实现，该主题存在多个分区，每个分区都有副本，所以就有Leader分区。</strong></li>
<li>由于Transaction Coordinator是Kafka Broker内部的一个模块，而Transaction log是Kafka中的一个内部Topic，所以Kafka能够通过内部的<strong>副本复制协议和Leader选举机制（Replication Protocol and Leader Election Processes）</strong>，来确保Transaction coordinator的可用性和事务状态Transaction state的持久性。</li>
<li>Transaction log内部主题Topic中储存的只是事务的最新状态和其相关元数据的信息，Kafka Producer生产的原始消息，仍然只是储存在Kafka Producer指定的Topic中。储存的事务状态Transaction state有：<code>Ongoing</code>、<code>Prepare commit</code>、<code>Completed</code>。</li>
</ul>
<h4 id="完整事务流程"><a href="#完整事务流程" class="headerlink" title="完整事务流程"></a>完整事务流程</h4><blockquote>
<p>事务包含两种信息：事务状态和原始消息</p>
<ul>
<li><p>事务状态记录在内部主题__transaction_state中</p>
</li>
<li><p>原始消息还是储存在用户主题中</p>
</li>
</ul>
</blockquote>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/KafkaTransaction.png" alt="img"></p>
<h4 id="生产者事务"><a href="#生产者事务" class="headerlink" title="生产者事务"></a>生产者事务</h4><blockquote>
<p>步骤标号参考&lt;完整事务流程&gt;图中的顺序标号</p>
</blockquote>
<blockquote>
<p>生产者端需要设置全局唯一Transaction ID，并且开启幂等性</p>
</blockquote>
<h5 id="寻找Transaction-Coordinator"><a href="#寻找Transaction-Coordinator" class="headerlink" title="寻找Transaction Coordinator"></a>寻找Transaction Coordinator</h5><p>Producer向任意一个Broker发送<strong>FindCoordinator请求</strong>，找到<strong>Transaction Coordinator</strong>所在的位置。</p>
<p>Broker根据生产者发送过来的<strong>Transaction ID取Hash值</strong>，并根据Hash值<strong>对__transaction_state主题的分区数</strong>取余，即<code>Hash(TID) % Partition num</code>，**__transaction_state主题余数分区副本的Leader所在Broker中的Transaction Coordinator**就负责该生产者的事务记录。</p>
<h5 id="获取PID"><a href="#获取PID" class="headerlink" title="获取PID"></a>获取PID</h5><blockquote>
<p>对于生产者来说，事务中需要保存两个参数，一个是PID，一个是Producer的Epoch</p>
</blockquote>
<p>Producer向Transaction Coordinator发送<strong>InitPidRequest请求</strong>以获取PID，该行为是同步阻塞的，会等待Kafka处理完异常的事务再返回。如果Transaction Coordinator是第一次收到包含该Transaction ID的InitPidRequest请求，它会<strong>将&lt;Transaction ID, PID&gt;存入到Transaction Log中，从而保证对应的关系被持久化</strong>，即使Producer或者Broker宕机也能根据TID返回一样的PID。此外，<strong>每个PID还维护着一个Epoch，Epoch也会返回给Producer</strong>。</p>
<p>每次Producer发送InitPidRequest请求时（就是建立Session的时候，只会执行一次），<strong>Transaction Coordinator会递增该PID对应的Epoch</strong>，并完成以下操作</p>
<ul>
<li>具有相同PID，但Epoch小于最新Epoch的其他僵尸Producer新开启的事务都会被拒绝（屏蔽僵尸Producer对事务的影响）</li>
<li>Commit或者Abort之前Producer未完成的事务</li>
</ul>
<h5 id="开启事务"><a href="#开启事务" class="headerlink" title="开启事务"></a>开启事务</h5><p>Kafka从0.11.0.0版本开始，提供<code>beginTransaction()</code>方法用于开启一个事务。<strong>调用该方法后，Producer本地会记录已经开启了事务，但<code>Transaction Coordinator</code>只有在Producer发送第一条消息后才认为事务已经开启。</strong></p>
<h5 id="事务发送"><a href="#事务发送" class="headerlink" title="事务发送"></a>事务发送</h5><p>在这一个阶段包含整个事务数据处理过程，并且包含多种请求（以下按请求顺序）：</p>
<ol>
<li><strong>AddPartitionsToTxnRequest</strong>：一个Producer可能会给多个**&lt;Topic, Partition&gt;<strong>发送数据，在此之前，它需要先向Transaction Coordinator发送<code>AddPartitionsToTxnRequest</code>请求。Transaction Coordinator会将该</strong>&lt;Transaction, Topic, Partition&gt;<strong>存于Transaction Log内，并将其状态置为BEGIN（还会有事务超时时间的设置），如流程图4.1所示。有了该信息后，我们才可以在后续步骤中为每个</strong>&lt;Topic, Partition&gt;**设置COMMIT或者ABORT标记（如流程图5.2所示）。</li>
<li><strong>ProduceRequest</strong>：就是生产者实际需要发送的消息，除了Topic、Partition、Key、Value的数据，该请求还包含了<strong>PID、Epoch、SeqNumber</strong>。（流程图4.2所示）</li>
<li><strong>AddOffsetsToTxnRequest</strong>：<code>sendOffsetsToTransaction</code>方法能够将<strong>多组消息的发送和消费放入同一批处理内</strong>，该方法会先判断当前事务中是否传入了相同的Group ID，如果是，则到下一个请求，不会发出<strong>AddOffsetsToTxnRequest</strong>请求；否则，生产者会向Transaction Coordinator发送<strong>AddOffsetsToTxnRequest</strong>请求，事务协调器会将**事务中所有的&lt;Topic, Partition&gt;**存于Transaction Log中，并将其状态记为BEGIN，流程图4.3所示。</li>
<li><strong>TxnOffsetCommitRequest</strong>：Producer发送<strong>TxnOffsetCommitRequest</strong>请求给<strong>Consumer Coordinator</strong>，从而将本事务中包含的<strong>读操作相关</strong>的各个&lt;Topic， Partition&gt;的Offset持久化到内部的**__consumer_offsets主题<strong>中，如流程图4.4所示。</strong>Consumer Coordinator**会通过PID和对应的epoch来验证是否允许该Producer的请求。<ul>
<li>写入**__consumer_offsets**的Offset信息在当前事务Commit前对外是不可见的。也即在当前事务被Commit前，可认为该Offset尚未Commit，也即对应的消息尚未被完成处理。</li>
<li><strong>Consumer Coordinator</strong>并不会立即更新缓存中相应**&lt;Topic, Partition&gt;**的Offset，因为此时这些更新操作尚未被COMMIT或ABORT。</li>
</ul>
</li>
</ol>
<h5 id="Commit或Abort事务"><a href="#Commit或Abort事务" class="headerlink" title="Commit或Abort事务"></a>Commit或Abort事务</h5><blockquote>
<p> 数据写入完成之后，需要对事务进行Commit或者是Abort</p>
</blockquote>
<blockquote>
<p>Commit事务能够使得Producer写入的数据对下游Consumer可见；Abort事务能够使得Producer产生的数据对READ_COMMITTED等级的下游Consumer不可见</p>
</blockquote>
<p>Producer会发送<strong>EndTxnRequest</strong>请求，随后Transaction Coordinator会执行以下操作：</p>
<ul>
<li>向Transaction Log中写入<strong>PREPARE_COMMIT或者PREPARE_ABORT</strong>，流程图中5.1所示</li>
<li>事务协调器发出<strong>WriteTxnMarkerRequest</strong>请求至事务涉及到的各个分区的Leader，<strong>将COMMIT或ABORT信息以Transaction Marker的形式写入至用户数据日志以及Offset Log（__consumer_offsets）中</strong>，流程图5.2所示</li>
<li>待所有<strong>WriteTxnMarkerRequest</strong>请求响应后，事务协调器将<strong>COMPLETE_COMMIT或COMPLETE_ABORT信息</strong>写入Transaction Log中，表明该事务结束，流程图5.3所示（这个时候Transaction Log中关于该事务的消息都可以被移除，因为事务日志是以主题的方式储存的，所以也是会被定期删除）（<strong>COMPLETE_COMMIT或COMPLETE_ABORT信息的写入不需要等到所有副本的ACK，因为如果消息丢失，可以根据事务协议重发</strong>）</li>
</ul>
<h4 id="消费者事务"><a href="#消费者事务" class="headerlink" title="消费者事务"></a>消费者事务</h4><p>Kafka 消费者消费消息时可以指定具体的读隔离级别，当指定使用 read_committed 隔离级别时，在内部会使用存储在目标 topic-partition 中的 事务控制消息，来过滤掉没有提交的消息，包括回滚的消息和尚未提交的消息。</p>
<p>需要注意的是，过滤消息时，Kafka consumer 不需要跟 transactional coordinator 进行 rpc 交互，因为 topic 中存储的消息，包括正常的数据消息和控制消息，包含了足够的元数据信息来支持消息过滤。Kafka 消费者消费消息时也可以指定使用 read_uncommitted 隔离级别，此时目标 topic-partition 中的所有消息都会被返回，不会进行过滤。</p>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="Zookeeper简介"><a href="#Zookeeper简介" class="headerlink" title="Zookeeper简介"></a>Zookeeper简介</h3><h4 id="Zookeeper的作用"><a href="#Zookeeper的作用" class="headerlink" title="Zookeeper的作用"></a>Zookeeper的作用</h4><blockquote>
<p>目的是解决协作任务，如果是在单台机器上的多线程任务，能够使用操作系统提供的原语对资源进行访问，但是如果是跨多台机器分布式协作任务，就不能使用操作系统提供的原语了，因此需要一个中间件来解决分布式任务之间对资源的访问协调</p>
</blockquote>
<blockquote>
<p>本质是一个分布式文件系统，以及有事件通知机制，不适合用作海量数据的储存，一个znode解决能够储存的数据大小默认是1M</p>
</blockquote>
<p>Zookeeper基于分布式计算的核心概念而设计，主要目的是给开发人员提供一套容易理解和开发的接口，从而简化分布式系统构建的任务。Zookeeper是从文件系统API得到启发，提供一组简单的API，是的开发人员可以实现通用的协作任务，包括选举主节点、管理组内成员关系、管理元数据等。</p>
<ul>
<li>顺序一致性：从同一客户端发起的事务请求，最终会严格地按照顺序被应用到Zookeeper中</li>
<li>原子性：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，集群中的所有机器都成功应用了某一个事务，要么都没有应用</li>
<li>单一视图：无论客户端连到哪一个Zookeeper服务器上，其看到的服务端数据模型都是一致的</li>
<li>可靠性：一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来</li>
<li>最终一致性：Zookeeper仅仅能保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态</li>
</ul>
<h4 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h4><blockquote>
<p>CAP理论：没有系统能够同时满足一致性、可用性、分区容错性这三种属性，只能尽量保证两种</p>
</blockquote>
<ul>
<li>一致性（Consistency）：等同于所有节点访问同一份最新的数据副本</li>
<li>可用性（Available）：每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据</li>
<li>分区容错性（Partition tolerance）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择</li>
</ul>
<h4 id="常用场景"><a href="#常用场景" class="headerlink" title="常用场景"></a>常用场景</h4><ul>
<li>主从模式</li>
<li>分布式锁</li>
<li>统一命名服务</li>
<li>统一配置管理</li>
<li>服务器节点动态上下线</li>
<li>软负载均衡</li>
</ul>
<h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><p>ls、get、set、stat、create、delete、deleteall、help</p>
<p>ls、get都可以通过加<code>-w</code>参数监听节点的状态</p>
<h4 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h4><table>
<thead>
<tr>
<th></th>
<th>持久节点</th>
<th>临时节点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>无序节点</strong></td>
<td>持久无序节点</td>
<td>临时无序节点</td>
</tr>
<tr>
<td><strong>有序节点</strong></td>
<td>持久有序节点</td>
<td>临时有序节点</td>
</tr>
</tbody></table>
<ul>
<li>持久节点：创建了之后就一直存在，除非使用delete删除</li>
<li>临时节点：当创建该节点的客户端连接断开&#x2F;会话超时时，这个节点就会被删除（临时节点不允许有子节点）</li>
<li>有序节点：有序znode节点会被分配唯一个单调递增的整数序号，并附加到路径名上面，如创建的路径名<code>/tasks/task-</code>，分配序号是2，则最后创建出来的节点为<code>/tasks/task-2</code></li>
</ul>
<blockquote>
<p>znode中储存的数据主要包括存储数据、访问权限、子节点引用、节点状态信息</p>
<ul>
<li>data：znode存储的业务数据信息</li>
<li>ACL：记录客户端对znode节点的访问权限，如IP、Digest等</li>
<li>child：当前节点的子节点引用</li>
<li>stat：包含znode节点的状态信息，比如事务Id、版本号、时间戳等等</li>
</ul>
</blockquote>
<h4 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h4><blockquote>
<p>写数据会先写入Leader节点，然后通知Follower节点进行变更</p>
</blockquote>
<blockquote>
<p>读数据既能够从Leader节点中读，也能从Follower节点中读</p>
</blockquote>
<p><strong>角色</strong>：</p>
<ul>
<li>Leader节点：集群内唯一，事务请求的唯一调度和处理者，保证集群事务处理的顺序性</li>
<li>Follower节点：主要处理客户端的非事务请求，转发事务请求给Leader节点，参与事务请求Proposal的投票，参与Leader选举投票</li>
<li>Observer节点：3.3.0版本开始引入的服务器角色，会处理客户端的非事务请求，并转发事务请求给Leader节点，但是不参与任何形式的投票</li>
</ul>
<p><strong>节点工作状态</strong>：</p>
<ul>
<li>LOOKING：正在寻找Leader，处于该状态时，会认为当前集群中没有Leader，因此需要进入Leader的选举状态</li>
<li>FOLLOWING：跟随者状态，表明当前节点角色是Follower</li>
<li>LEADING：领导者状态，表明当前节点角色是Leader</li>
<li>OBSERVING：观察者状态，表明当前服务器角色是Oberver</li>
</ul>
<h3 id="Watcher监听机制"><a href="#Watcher监听机制" class="headerlink" title="Watcher监听机制"></a>Watcher监听机制</h3><blockquote>
<p>Zookeeper允许客户端对某个znode注册一个Watcher监听，当服务端的一些指定事件触发了Watcher，服务端就会发送一个事件通知该客户端znode节点的变化，客户端根据znode节点的变化类型作出处理</p>
</blockquote>
<h4 id="Watcher类型（待施工）"><a href="#Watcher类型（待施工）" class="headerlink" title="Watcher类型（待施工）"></a>Watcher类型（待施工）</h4><p>- </p>
<h3 id="Zookeeper原子广播协议ZAB"><a href="#Zookeeper原子广播协议ZAB" class="headerlink" title="Zookeeper原子广播协议ZAB"></a>Zookeeper原子广播协议ZAB</h3><blockquote>
<p>包括两种模式，消息广播和崩溃恢复</p>
</blockquote>
<img src="ZXID.png" alt="image-20220907164835614" style="zoom:50%;" />

<p>需要了解的两个ID</p>
<ul>
<li><strong>Server Id</strong> –  服务器Id，即配置文件中的myid，每个节点上的值都要设为不同</li>
<li><strong>ZXID</strong> – 事务ID，由一个64位的数字组成<ul>
<li>高32位是Leader的任期epoch，每次选举Leader，epoch都会自增加一</li>
<li>低32位是事务计数器，单调递增，每产生一个事务，计数器加一</li>
</ul>
</li>
</ul>
<h4 id="消息广播：Zookeeper如何保证事务的顺序一致性？"><a href="#消息广播：Zookeeper如何保证事务的顺序一致性？" class="headerlink" title="消息广播：Zookeeper如何保证事务的顺序一致性？"></a>消息广播：Zookeeper如何保证事务的顺序一致性？</h4><p><strong>Zookeeper的保证的最终一致性也叫顺序一致性</strong>，即每个节点的数据都是严格按照事务的发起顺序生效的。</p>
<blockquote>
<p>由ZXID的产生规则可以看出，在同一个Leader的任期内，ZXID是连续的，<strong>每个服务器节点都会保存着自己最新生效的ZXID</strong>，节点可以通过最新提案的ZXID与自身最新的ZXID是否相差<code>1</code>，来保证事务是严格按照顺序生效的</p>
</blockquote>
<p>Zookeeper集群的写入是由Leader节点协调的，<strong>类似于InnoDB引擎的二阶段提交</strong>，Leader会将提案广播给所有Follower，<strong>当收到半数以上的ACK时</strong>，就能够将提案生效(commit)并广播给所有Follower节点。</p>
<h5 id="详细过程-1"><a href="#详细过程-1" class="headerlink" title="详细过程"></a>详细过程</h5><ul>
<li>客户端发起一个事务，如果连接的是Follower，就会将事务转交给Leader处理</li>
<li>Leader收到请求后会生成一个ZXID，并将事务存到磁盘日志文件，此外，<strong>Leader会使用一个ConcurrentHashMap记录所有未提交的提案，key为ZXID，value是提案的信息</strong>，并将提案的ZXID与内容放到Map中，作为待提交的提案，并广播给Follower进行处理（Leader会为每个Follower都分配一个单独的FIFO队列，提案会被放到这个FIFO队列中）</li>
<li>Follower收到提案之后会把它写到磁盘日志文件中，完全写入后，发送ACK响应给Leader</li>
<li>Leader收到Follower的ACK信息后，根据ACK中的ZXID从Map中获取到对应的提案，并对ACK计数，提案提交判断流程是</li>
</ul>
<ol>
<li>首先判断该事务ZXID之前还有没有未提交的事务（map中是否有存在<code>ZXID - 1</code>的key），有，则暂时不能提交</li>
<li>随后判断提案是否收到半数以上ACK，如果达到半数，则可以提交，将磁盘中日志文件的提案加载到znode内存数据结构中，将该提案转移到一个<code>ConcurrentLinkedQueue toBeApplied</code>中，里面记录着能提交的提案，并将该ZXID从当前map中清除，根据queue逐个向Followers广播提交当前提案</li>
</ol>
<ul>
<li>Follower收到commit消息后，将磁盘中日志文件数据加载到znode内存数据结构中，数据即能生效</li>
</ul>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E6%81%AF%E5%B9%BF%E6%92%AD1.png" alt="image-20220907203724192"></p>
<p><img src="/2022/09/05/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE/%E6%B6%88%E6%81%AF%E5%B9%BF%E6%92%AD2.png" alt="image-20220907203759457"></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/cfeb2f97af8a">https://www.jianshu.com/p/cfeb2f97af8a</a></p>
<p><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/239261">https://time.geekbang.org/column/article/239261</a></p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903464414232584#heading-12">https://juejin.cn/post/6844903464414232584#heading-12</a></p>
<h4 id="崩溃恢复"><a href="#崩溃恢复" class="headerlink" title="崩溃恢复"></a>崩溃恢复</h4><blockquote>
<p>因为消息广播中的两阶段提交并不能解决Leader故障，因此需要崩溃恢复</p>
</blockquote>
<blockquote>
<p>Zookeeper正常工作时，Zab协议会一直处于广播模式，直到<strong>Leader故障</strong>或<strong>失去了指定数量的Follower</strong>，就会进入崩溃恢复模式</p>
</blockquote>
<p>崩溃恢复必须要保证两点：</p>
<ul>
<li>已经被Leader发送出去的提案，最终会被所有服务器都提交</li>
<li>只在Leader中出现的提案，都要丢弃</li>
</ul>
<h5 id="详细过程-2"><a href="#详细过程-2" class="headerlink" title="详细过程"></a>详细过程</h5><ul>
<li>每台Follow节点都会发起投票，每个节点都会先投自己一票，并同步给其他Follower节点。</li>
<li>节点收到其他节点的投票信息后，进行选票筛选，不是同一个投票轮次的投票信息会被丢弃，随后根据（ZXID，Server Id）投票，<strong>这里的ZXID是本地磁盘日志文件中的</strong>，ZXID最大值获选，如果ZXID相同，则Server Id更大者胜出，更新自己的投票信息，并开始新一轮的投票，直到相同票数信息超过半数</li>
<li>新Leader被选出，将epoch + 1，事务计数器置0，开始一个新的纪元<ul>
<li>Follower连接到新的Leader上，会对比自己的ZXID与Leader的ZXID，所有没见过的提案都会被排队并提交</li>
<li>当<code>旧的Leader</code>重新连接到<code>新的Leader</code>的时候，它已经变成了Follower，然后会对比ZXID，多出来的提案会被丢弃清除</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/sunddenly/p/4138580.html">https://www.cnblogs.com/sunddenly/p/4138580.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.51cto.com/article/704705.html">https://www.51cto.com/article/704705.html</a></p>
<h3 id="分布式锁的实现"><a href="#分布式锁的实现" class="headerlink" title="分布式锁的实现"></a>分布式锁的实现</h3><blockquote>
<p>羊群效应是指，一个节点挂掉，所有节点都去监听，然后做出反应，这样会给服务器带来巨大的压力</p>
</blockquote>
<blockquote>
<p>如果一个客户端的ZooKeeper会话过期，那么它所创建的短暂znode将会被删除，已持有的锁会被释放，或是放弃了申请锁的位置。使用锁的应用程序应当意识到它已经不再持有锁，应当清理它的状态，然后通过创建并尝试申请一个新的锁对象来重新启动。注意，这个过程是由应用程序控制的，而不是锁，因为锁是不能预知应用程序需要如何清理自己的状态。</p>
</blockquote>
<h4 id="非公平锁"><a href="#非公平锁" class="headerlink" title="非公平锁"></a>非公平锁</h4><blockquote>
<p>依赖临时节点客户端连接断开会自动删除的特性</p>
</blockquote>
<blockquote>
<p>存在的问题：羊群效应</p>
</blockquote>
<ol>
<li>客户端以同一个资源名称路径创建一个临时节点，如<code>/path/resourceA</code></li>
<li>客户端观察节点是否创建成功<ol>
<li>如果创建成功，则表明自己已经取得了资源的使用权</li>
<li>如果节点已经存在，则表明资源已经被其他客户端占用，则在该节点上设置监听器</li>
<li>如果其他异常失败，则进行节点创建重试，或者其他处理</li>
</ol>
</li>
<li>客户端使用完资源以后，主动删除节点，或者由于网络异常，连接断开，临时节点被删除</li>
<li>其他客户端监听到临时节点被删除的事件，开始重复步骤1</li>
</ol>
<h4 id="公平锁"><a href="#公平锁" class="headerlink" title="公平锁"></a>公平锁</h4><blockquote>
<p>依赖临时节点客户端连接断开会自动删除的特性</p>
</blockquote>
<blockquote>
<p>依赖顺序节点会自动产生单调递增的整数序号的特性</p>
</blockquote>
<blockquote>
<p>如果想要实现可公平重入锁，可以在获取到资源使用权的时候，在节点数据中写一个状态值，每次获取锁状态值就加一，释放锁就减一，为0的时候删除节点</p>
</blockquote>
<ol>
<li>客户端在同一个目录下创建一个临时顺序节点，如<code>/resourceA/A-000001</code></li>
<li>客户端获取资源目录下的所有节点，观察序号最小的节点是不是自己创建的序号<ol>
<li>如果是，则表示自己已经取得了资源的使用权</li>
<li>如果不是，则表示资源已经被其他客户端占用，在自己的前一个节点（序号比自己小的节点中，序号最大的节点）设置监听器</li>
<li>如果其他异常失败，则重试，或者其他处理</li>
</ol>
</li>
<li>客户端使用完资源以后，主动删除节点，或者由于网络异常，连接断开，临时节点被删除</li>
<li>在被删除节点上设置了监听器的客户端监听到删除事件，开始重复步骤2</li>
</ol>
<h3 id="Leader选举机制"><a href="#Leader选举机制" class="headerlink" title="Leader选举机制"></a>Leader选举机制</h3><p>跟崩溃恢复差不多</p>
<h3 id="Chroot特性"><a href="#Chroot特性" class="headerlink" title="Chroot特性"></a>Chroot特性</h3><blockquote>
<p>3.2.0版本后添加的特性，Chroot特性允许每个客户端为自己设置一个命名空间。如果一个客户端设置了Chroot，那么对Zookeeper集群的任何操作，都会被限制在自己的命名空间下。Chroot能够将客户端对应上Zookeeper的一颗子树，因此在多个应用公用一个Zookeeper集群的时候，有利于应用间的相互隔离。</p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/08/30/MySQL%E5%82%A8%E5%AD%98%E8%BF%87%E7%A8%8B%E6%B8%B8%E6%A0%87%E4%BD%BF%E7%94%A8%E8%B8%A9%E5%9D%91%EF%BC%88NOT-FOUND%EF%BC%89/" rel="prev" title="MySQL储存过程游标使用踩坑（NOT FOUND）">
                  <i class="fa fa-chevron-left"></i> MySQL储存过程游标使用踩坑（NOT FOUND）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/09/14/Spring-validation%E4%BD%BF%E7%94%A8%E5%8F%8A%E6%A0%A1%E9%AA%8C%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/" rel="next" title="Spring validation使用及校验异常处理">
                  Spring validation使用及校验异常处理 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2021 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Junhao Lin</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">46k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:48</span>
  </span>
</div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="/js/canvas-nest.js"></script>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/pace.js"></script>

  




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.7.2/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"IceVitaLemon","repo":"IceVitaLemon.github.io","client_id":"2bac2f2e44e15b59b869","client_secret":"cde7426c367b8a22029dd71acac79712c5f67459","admin_user":"IceVitaLemon","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.7.2/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"255b29d5f31d145400ece6193ab5318d"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
